<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>Microsoft Research</title>
	<atom:link href="https://www.microsoft.com/en-us/research/feed/" rel="self" type="application/rss+xml" />
	<link>https://www.microsoft.com/en-us/research/</link>
	<description></description>
	<lastBuildDate>Mon, 30 Jun 2025 16:00:19 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.7.2</generator>
	<item>
		<title>AI Testing and Evaluation: Learnings from genome editing</title>
		<link>https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-genome-editing/</link>
		
		<dc:creator><![CDATA[Kathleen Sullivan, Alta Charo, Daniel Kluttz]]></dc:creator>
		<pubDate>Mon, 30 Jun 2025 16:00:17 +0000</pubDate>
				<category><![CDATA[Microsoft Research Podcast]]></category>
		<guid isPermaLink="false">https://www.microsoft.com/en-us/research/?p=1142130</guid>

					<description><![CDATA[<p>Bioethics and law expert R. Alta Charo explores the value of regulating technologies at the application level and the role of coordinated oversight in genome editing, while Microsoft GM Daniel Kluttz reflects on Charo’s points, drawing parallels to AI governance.</p>
<p>The post <a href="https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-genome-editing/">AI Testing and Evaluation: Learnings from genome editing</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img fetchpriority="high" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP1-AI-TE_Hero_Feature_1400x788.jpg" alt="illustration of R. Alta Charo, Kathleen Sullivan, and Daniel Kluttz for the Microsoft Research Podcast" class="wp-image-1142157" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP1-AI-TE_Hero_Feature_1400x788.jpg 1400w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP1-AI-TE_Hero_Feature_1400x788-300x169.jpg 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP1-AI-TE_Hero_Feature_1400x788-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP1-AI-TE_Hero_Feature_1400x788-768x432.jpg 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP1-AI-TE_Hero_Feature_1400x788-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP1-AI-TE_Hero_Feature_1400x788-655x368.jpg 655w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP1-AI-TE_Hero_Feature_1400x788-240x135.jpg 240w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP1-AI-TE_Hero_Feature_1400x788-640x360.jpg 640w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP1-AI-TE_Hero_Feature_1400x788-960x540.jpg 960w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP1-AI-TE_Hero_Feature_1400x788-1280x720.jpg 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure>


<div class="wp-block-msr-podcast-container my-4">
	<iframe src="https://player.blubrry.com/?podcast_id=146599312&modern=1" class="podcast-player" frameborder="0" height="164px" width="100%" scrolling="no" title="Podcast Player"></iframe>
</div>



<p>Generative AI presents a unique challenge and opportunity to reexamine governance practices for the responsible development, deployment, and use of AI. To advance thinking in this space, Microsoft has tapped into the experience and knowledge of experts across domains—from genome editing to cybersecurity—to investigate the role of testing and evaluation as a governance tool. <em><a href="https://www.microsoft.com/en-us/research/story/ai-testing-and-evaluation-learnings-from-science-and-industry/">AI Testing and Evaluation: Learnings from Science and Industry</a>, </em>hosted by Microsoft Research’s <a href="https://www.microsoft.com/en-us/research/people/kasull/">Kathleen Sullivan</a>, explores what the technology industry and policymakers can learn from these fields and how that might help shape the course of AI development.</p>



<p>In this episode, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" target="_blank" href="https://law.wisc.edu/profiles/racharo@wisc.edu">Alta Charo<span class="sr-only"> (opens in new tab)</span></a>, emerita professor of law and bioethics at the University of Wisconsin–Madison, joins Sullivan for a conversation on the evolving landscape of genome editing and its regulatory implications. Drawing on decades of experience in biotechnology policy, Charo emphasizes the importance of distinguishing between hazards and risks and describes the field&#8217;s approach to regulating <em>applications </em>of technology rather than the technology itself. The discussion also explores opportunities and challenges in biotech’s multi-agency oversight model and the role of international coordination. Later, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" target="_blank" href="https://www.linkedin.com/in/daniel-kluttz/">Daniel Kluttz<span class="sr-only"> (opens in new tab)</span></a>, a partner general manager in Microsoft&#8217;s Office of Responsible AI, joins Sullivan to discuss how insights from genome editing could inform more nuanced and robust governance frameworks for emerging technologies like AI.</p>



<div class="wp-block-group msr-pattern-link-list is-layout-flow wp-block-group-is-layout-flow">
<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading h5" id="learn-more">Learn more:</h2>



<p><a href="https://www.microsoft.com/en-us/research/publication/learning-from-other-domains-to-advance-ai-evaluation-and-testing-governance-of-genome-edition-in-human-therapeutics-and-agricultural-applications/" target="_blank" rel="noreferrer noopener">Learning from other Domains to Advance AI Evaluation and Testing: Governance of Genome Edition in Human Therapeutics and Agricultural Applications</a><br>Case study | January 2025&nbsp;</p>



<p><a href="https://www.microsoft.com/en-us/research/blog/learning-from-other-domains-to-advance-ai-evaluation-and-testing/" target="_blank" rel="noreferrer noopener">Learning from other domains to advance AI evaluation and testing</a>&nbsp;<br>Microsoft Research Blog | June 2025&nbsp;</p>



<p><a href="https://www.microsoft.com/en-us/ai/responsible-ai?ef_id=_k_cb05d5950e4f117c457ebda628845b7f_k_&OCID=AIDcmm1o1fzy5i_SEM__k_cb05d5950e4f117c457ebda628845b7f_k_&msclkid=cb05d5950e4f117c457ebda628845b7f" target="_blank" rel="noreferrer noopener">Responsible AI: Ethical policies and practices | Microsoft AI</a>&nbsp;</p>



<p><a href="https://www.microsoft.com/en-us/research/focus-area/ai-and-microsoft-research/" target="_blank" rel="noreferrer noopener">AI and Microsoft Research</a>&nbsp;</p>
</div>



<div style="height:25px" aria-hidden="true" class="wp-block-spacer"></div>



<section class="wp-block-msr-subscribe-to-podcast subscribe-to-podcast">
	<div class="subscribe-to-podcast__inner border-top border-bottom border-width-2">
		<h2 class="h5 subscribe-to-podcast__heading">
			Subscribe to the <a href="https://www.microsoft.com/en-us/research/podcast">Microsoft Research Podcast</a>:		</h2>
		<ul class="subscribe-to-podcast__list list-unstyled">
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://itunes.apple.com/us/podcast/microsoft-research-a-podcast/id1318021537?mt=2" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="black" viewBox="0 0 32 32">  <path d="M7.12 0c-3.937-0.011-7.131 3.183-7.12 7.12v17.76c-0.011 3.937 3.183 7.131 7.12 7.12h17.76c3.937 0.011 7.131-3.183 7.12-7.12v-17.76c0.011-3.937-3.183-7.131-7.12-7.12zM15.817 3.421c3.115 0 5.932 1.204 8.079 3.453 1.631 1.693 2.547 3.489 3.016 5.855 0.161 0.787 0.161 2.932 0.009 3.817-0.5 2.817-2.041 5.339-4.317 7.063-0.812 0.615-2.797 1.683-3.115 1.683-0.12 0-0.129-0.12-0.077-0.615 0.099-0.792 0.192-0.953 0.64-1.141 0.713-0.296 1.932-1.167 2.677-1.911 1.301-1.303 2.229-2.932 2.677-4.719 0.281-1.1 0.244-3.543-0.063-4.672-0.969-3.595-3.907-6.385-7.5-7.136-1.041-0.213-2.943-0.213-4 0-3.636 0.751-6.647 3.683-7.563 7.371-0.245 1.004-0.245 3.448 0 4.448 0.609 2.443 2.188 4.681 4.255 6.015 0.407 0.271 0.896 0.547 1.1 0.631 0.447 0.192 0.547 0.355 0.629 1.14 0.052 0.485 0.041 0.62-0.072 0.62-0.073 0-0.62-0.235-1.199-0.511l-0.052-0.041c-3.297-1.62-5.407-4.364-6.177-8.016-0.187-0.943-0.224-3.187-0.036-4.052 0.479-2.323 1.396-4.135 2.921-5.739 2.199-2.319 5.027-3.543 8.172-3.543zM16 7.172c0.541 0.005 1.068 0.052 1.473 0.14 3.715 0.828 6.344 4.543 5.833 8.229-0.203 1.489-0.713 2.709-1.619 3.844-0.448 0.573-1.537 1.532-1.729 1.532-0.032 0-0.063-0.365-0.063-0.803v-0.808l0.552-0.661c2.093-2.505 1.943-6.005-0.339-8.296-0.885-0.896-1.912-1.423-3.235-1.661-0.853-0.161-1.031-0.161-1.927-0.011-1.364 0.219-2.417 0.744-3.355 1.672-2.291 2.271-2.443 5.791-0.348 8.296l0.552 0.661v0.813c0 0.448-0.037 0.807-0.084 0.807-0.036 0-0.349-0.213-0.683-0.479l-0.047-0.016c-1.109-0.885-2.088-2.453-2.495-3.995-0.244-0.932-0.244-2.697 0.011-3.625 0.672-2.505 2.521-4.448 5.079-5.359 0.547-0.193 1.509-0.297 2.416-0.281zM15.823 11.156c0.417 0 0.828 0.084 1.131 0.24 0.645 0.339 1.183 0.989 1.385 1.677 0.62 2.104-1.609 3.948-3.631 3.005h-0.015c-0.953-0.443-1.464-1.276-1.475-2.36 0-0.979 0.541-1.828 1.484-2.328 0.297-0.156 0.709-0.235 1.125-0.235zM15.812 17.464c1.319-0.005 2.271 0.463 2.625 1.291 0.265 0.62 0.167 2.573-0.292 5.735-0.307 2.208-0.479 2.765-0.905 3.141-0.589 0.52-1.417 0.667-2.209 0.385h-0.004c-0.953-0.344-1.157-0.808-1.553-3.527-0.452-3.161-0.552-5.115-0.285-5.735 0.348-0.823 1.296-1.285 2.624-1.291z"/></svg>
						<span class="subscribe-to-podcast__link-text">Apple Podcasts</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://subscribebyemail.com/www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M6.4 6a2.392 2.392 0 00-2.372 2.119L16 15.6l11.972-7.481A2.392 2.392 0 0025.6 6H6.4zM4 10.502V22.8a2.4 2.4 0 002.4 2.4h19.2a2.4 2.4 0 002.4-2.4V10.502l-11.365 7.102a1.2 1.2 0 01-1.27 0L4 10.502z"/></svg>
						<span class="subscribe-to-podcast__link-text">Email</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://subscribeonandroid.com/www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M12.414 4.02c-.062.012-.126.023-.18.06a.489.489 0 00-.12.675L13.149 6.3c-1.6.847-2.792 2.255-3.18 3.944h13.257c-.388-1.69-1.58-3.097-3.179-3.944l1.035-1.545a.489.489 0 00-.12-.675.492.492 0 00-.675.135l-1.14 1.68a7.423 7.423 0 00-2.55-.45c-.899 0-1.758.161-2.549.45l-1.14-1.68a.482.482 0 00-.494-.195zm1.545 3.824a.72.72 0 110 1.44.72.72 0 010-1.44zm5.278 0a.719.719 0 110 1.44.719.719 0 110-1.44zM8.44 11.204A1.44 1.44 0 007 12.644v6.718c0 .795.645 1.44 1.44 1.44.168 0 .33-.036.48-.09v-9.418a1.406 1.406 0 00-.48-.09zm1.44 0V21.76c0 .793.646 1.44 1.44 1.44h10.557c.793 0 1.44-.647 1.44-1.44V11.204H9.878zm14.876 0c-.169 0-.33.035-.48.09v9.418c.15.052.311.09.48.09a1.44 1.44 0 001.44-1.44v-6.719a1.44 1.44 0 00-1.44-1.44zM11.8 24.16v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84zm5.759 0v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84z"/></svg>
						<span class="subscribe-to-podcast__link-text">Android</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://open.spotify.com/show/4ndjUXyL0hH1FXHgwIiTWU" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M16 4C9.383 4 4 9.383 4 16s5.383 12 12 12 12-5.383 12-12S22.617 4 16 4zm5.08 17.394a.781.781 0 01-1.086.217c-1.29-.86-3.477-1.434-5.303-1.434-1.937.002-3.389.477-3.403.482a.782.782 0 11-.494-1.484c.068-.023 1.71-.56 3.897-.562 1.826 0 4.365.492 6.171 1.696.36.24.457.725.217 1.085zm1.56-3.202a.895.895 0 01-1.234.286c-2.338-1.457-4.742-1.766-6.812-1.747-2.338.02-4.207.466-4.239.476a.895.895 0 11-.488-1.723c.145-.041 2.01-.5 4.564-.521 2.329-.02 5.23.318 7.923 1.995.419.26.547.814.286 1.234zm1.556-3.745a1.043 1.043 0 01-1.428.371c-2.725-1.6-6.039-1.94-8.339-1.942h-.033c-2.781 0-4.923.489-4.944.494a1.044 1.044 0 01-.474-2.031c.096-.023 2.385-.55 5.418-.55h.036c2.558.004 6.264.393 9.393 2.23.497.292.663.931.371 1.428z"/></svg>
						<span class="subscribe-to-podcast__link-text">Spotify</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M6.667 4a2.676 2.676 0 00-2.612 2.13v.003c-.036.172-.055.35-.055.534v18.666c0 .183.019.362.055.534v.003a2.676 2.676 0 002.076 2.075h.002c.172.036.35.055.534.055h18.666A2.676 2.676 0 0028 25.333V6.667a2.676 2.676 0 00-2.13-2.612h-.003A2.623 2.623 0 0025.333 4H6.667zM8 8h1.333C17.42 8 24 14.58 24 22.667V24h-2.667v-1.333c0-6.618-5.382-12-12-12H8V8zm0 5.333h1.333c5.146 0 9.334 4.188 9.334 9.334V24H16v-1.333A6.674 6.674 0 009.333 16H8v-2.667zM10 20a2 2 0 11-.001 4.001A2 2 0 0110 20z"/></svg>
						<span class="subscribe-to-podcast__link-text">RSS Feed</span>
					</a>
				</li>
					</ul>
	</div>
</section>


<div class="wp-block-msr-show-more">
	<div class="bg-neutral-100 p-5">
		<div class="show-more-show-less" data-mount="show-more-show-less">
			<div>
				<span>
					

<h2 class="wp-block-heading" id="transcript-1">Transcript</h2>



<p>[MUSIC]</p>



<p><strong>KATHLEEN SULLIVAN:</strong> Welcome to <em>AI Testing and Evaluation: Learnings from Science and Industry</em>. I&#8217;m your host, Kathleen Sullivan.</p>



<p>As generative AI continues to advance, Microsoft has gathered a range of experts—from genome editing to cybersecurity—to share how their fields approach evaluation and risk assessment. Our goal is to learn from their successes and their stumbles to move the science and practice of AI testing forward. In this series, we&#8217;ll explore how these insights might help guide the future of AI development, deployment, and responsible use.</p>



<p>[MUSIC ENDS]</p>



<p>Today I&#8217;m excited to welcome R. Alta Charo, the Warren P. Knowles Professor Emerita of Law and Bioethics at the University of Wisconsin–Madison, to explore testing and risk assessment in genome editing.</p>



<p>Professor Charo has been at the forefront of biotechnology policy and governance for decades, advising former President Obama&#8217;s transition team on issues of medical research and public health, as well as serving as a senior policy advisor at the Food and Drug Administration. She consults on gene therapy and genome editing for various companies and organizations and has held positions on a number of advisory committees, including for the National Academy of Sciences. Her committee work has spanned women&#8217;s health, stem cell research, genome editing, biosecurity, and more.</p>



<p>After our conversation with Professor Charo, we&#8217;ll hear from Daniel Kluttz, a partner general manager in Microsoft&#8217;s Office of Responsible AI, about what these insights from biotech regulation could mean for AI governance and risk assessment and his team&#8217;s work governing sensitive AI uses and emerging technologies.</p>



<p>Alta, thank you so much for being here today. I&#8217;m a follower of your work and have really been looking forward to our conversation.</p>



				</span>
				<span id="show-more-show-less-toggle-1" class="show-more-show-less-toggleable-content">
					



<p><strong>ALTA CHARO:</strong> It&#8217;s my pleasure. Thanks for having me.</p>



<p><strong>SULLIVAN:</strong> Alta, I&#8217;d love to begin by stepping back in time a bit before you became a leading figure in bioethics and legal policy. You&#8217;ve shared that your interest in science was really inspired by your brothers’ interest in the topic and that your upbringing really helped shape your perseverance and resilience. Can you talk to us about what put you on the path to law and policy?</p>



<p><strong>CHARO:</strong> Well, I think it&#8217;s true that many of us are strongly influenced by our families and certainly my family had, kind of, a science-y, techy orientation. My father was a refugee, you know, escaping the Nazis, and when he finally was able to start working in the United States, he took advantage of the G.I. Bill to learn how to repair televisions and radios, which were really just coming in in the 1950s. So he was, kind of, technically oriented.</p>



<p>My mother retrained from being a talented amateur artist to becoming a math teacher, and not surprisingly, both my brothers began to aim toward things like engineering and chemistry and physics. And our form of entertainment was to watch PBS or <em>Star Trek</em>. [LAUGHTER]</p>



<p>And so the interest comes from that background coupled with, in the 1960s, this enormous surge of interest in the so-called nature-versus-nurture debate about the degree to which we are destined by our biology or shaped by our environments. It was a heady debate, and one that perfectly combined the two interests in politics and science.</p>



<p><strong>SULLIVAN:</strong> For listeners who are brand new to your field in genomic editing, can you give us what I&#8217;ll call a “90-second survey” of the space in perhaps plain language and why it&#8217;s important to have a framework for ensuring its responsible use.</p>



<p><strong>CHARO:</strong> Well, you know, genome editing is both very old and very new. At base, what we&#8217;re talking about is a way to either delete sections of the <em>genome</em>, our collection of genes, or to add things or to alter what&#8217;s there. The goal is simply to be able to take what might not be healthy and make it healthy, whether it&#8217;s a plant, an animal, or a human.</p>



<p>Many people have compared it to a word processor, where you can edit text by swapping things in and out. You could change the letter <em>g</em> to the letter <em>h</em> in every word, and in our genomes, you can do similar kinds of things.</p>



<p>But because of this, we have a responsibility to make sure that whatever we change doesn&#8217;t become dangerous and that it doesn&#8217;t become socially disruptive. Now the earliest forms of genome editing were very inefficient, and so we didn&#8217;t worry that much. But with the advances that were spearheaded by people like Jennifer Doudna and Emmanuelle Charpentier, who won the Nobel Prize for their work in this area, genome editing has become much easier to do.</p>



<p>It&#8217;s become more efficient. It doesn&#8217;t require as much sophisticated laboratory equipment. It&#8217;s moved from being something that only a few people can do to something that we&#8217;re going to be seeing in our junior high school biology labs. And that means you have to pay attention to who&#8217;s doing it, why are they doing it, what are they releasing, if anything, into the environment, what are they trying to sell, and is it honest and is it safe?</p>



<p><strong>SULLIVAN:</strong> How would you describe the risks, and are there, you know, sort of, specifically inherent risks in the technology itself, or do those risks really emerge only when it&#8217;s applied in certain contexts, like CRISPR in agriculture or CRISPR for human therapies?</p>



<p><strong>CHARO:</strong> Well, to answer that, I&#8217;m going to do something that may seem a little picky, even pedantic. [LAUGHTER] But I&#8217;m going to distinguish between hazards and risks. So there are certain intrinsic hazards. That is, there are things that can go wrong.</p>



<p>You want to change one particular gene or one particular portion of a gene, and you might accidentally change something else, a so-called <em>off-target effect</em>. Or you might change something in a gene expecting a certain effect but not necessarily anticipating that there&#8217;s going to be an interaction between what you changed and what was there, a <em>gene-gene interaction</em>, that might have an unanticipated kind of result, a side effect essentially.</p>



<p>So there are some intrinsic hazards, but risk is a hazard coupled with the probability that it&#8217;s going to actually create something harmful. And that really depends upon the application.</p>



<p>If you are doing something that is making a change in a human being that is going to be a lifelong change, that enhances the significance of that hazard. It amplifies what I call the risk because if something goes wrong, then its consequences are greater.</p>



<p>It may also be that in other settings, what you&#8217;re doing is going to have a much lower risk because you&#8217;re working with a more familiar substance, your predictive power is much greater, and it&#8217;s not going into a human or an animal or into the environment. So I think that you have to say that the risk <em>and</em> the benefits, by the way, all are going to depend upon the particular application.</p>



<p><strong>SULLIVAN:</strong> Yeah, I think on this point of application, there&#8217;s many players involved in that, right. Like, we often hear about this puzzle of who&#8217;s actually responsible for ensuring safety and a reasonable balance between risks and benefits or hazards and benefits, to quote you. Is it the scientists, the biotech companies, government agencies? And then if you could touch upon, as well, maybe how does the nature of genome editing risks … how do those responsibilities get divvied up?</p>



<p><strong>CHARO:</strong> Well, in the 1980s, we had a very significant policy discussion about whether we should regulate the technology—no matter how it&#8217;s used or for whatever purpose—or if we should simply fold the technology in with all the other technologies that we currently have and regulate its applications the way we regulate applications generally. And we went for the second, the so-called <em>coordinated framework</em>.</p>



<p>So what we have in the United States is a system in which if you use genome editing in purely laboratory-based work, then you will be regulated the way we regulate laboratories.</p>



<p>There&#8217;s also, at most universities because of the way the government works with this, something called Institutional Biosafety Committees, <em>IBCs</em>. You want to do research that involves recombinant DNA and modern biotechnology, <em>including</em> genome editing but not limited to it, you have to go first to your IBC, and they look and see what you&#8217;re doing to decide if there&#8217;s a danger there that you have not anticipated that requires special attention.</p>



<p>If what you&#8217;re doing is going to get released into the environment or it&#8217;s going to be used to change an animal that&#8217;s going to be in the environment, then there are agencies that oversee the safety of our environment, predominantly the Environmental Protection Agency and the U.S. Department of Agriculture.</p>



<p>If you&#8217;re working with humans and you&#8217;re doing medical therapies, like you&#8217;re doing the gene therapies that just have been developed for things like sickle cell anemia, then you have to go through a very elaborate regulatory process that&#8217;s overseen by the Food and Drug Administration and also seen locally at the research stages overseen by institutional review boards that make sure the people who are being recruited into research understand what they&#8217;re getting into, that they&#8217;re the right people to be recruited, etc.</p>



<p>So we do have this kind of Jenga game …</p>



<p><strong>SULLIVAN:</strong> [LAUGHS] Yeah, sounds like it.</p>



<p><strong>CHARO:</strong> … of regulatory agencies. And on top of all that, most of this involves professionals who&#8217;ve had to be licensed in some way. There may be state laws specifically on licensing. If you are dealing with things that might cross national borders, there may be international treaties and agreements that cover this.</p>



<p>And, of course, the insurance industry plays a big part because they decide whether or not what you&#8217;re doing is safe enough to be insured. So all of these things come together in a way that is not at all easy to understand if you&#8217;re not, kind of, working in the field. But the bottom-line thing to remember, the way to really think about it is, we don&#8217;t regulate genome editing; we regulate the things that use genome editing.</p>



<p><strong>SULLIVAN:</strong> Yeah, that makes a lot of sense. Actually, maybe just following up a little bit on this notion of a variety of different, particularly like government agencies being involved. You know, in this multi-stakeholder model, where do you see gaps today that need to be filled, some of the pros and cons to keep in mind, and, you know, just as we think about distributing these systems at a global level, like, what are some of the considerations you are keeping in mind on that front?</p>



<p><strong>CHARO:</strong> Well, certainly there are times where the way the statutes were written that govern the regulation of drugs or the regulation of foods did not anticipate this tremendous capacity we now have in the area of biotechnology generally or genome editing in particular. And so you can find that there are times where it feels a little bit ambiguous, and the agencies have to figure out how to apply their existing rules.</p>



<p>So an example. If you&#8217;re going to make alterations in an animal, right, we have a system for regulating drugs, including veterinary drugs. But we didn&#8217;t have something that regulated genome editing of animals. But in a sense, genome editing of an animal is the same thing as using a veterinary drug. You&#8217;re trying to affect the animal&#8217;s physical constitution in some fashion.</p>



<p>And it took a long time within the FDA to, sort of, work out how the regulation of veterinary drugs would apply if you think about the genetic construct that&#8217;s being used to alter the animal as the same thing as injecting a chemically based drug. And on that basis, they now know here&#8217;s the regulatory path—here are the tests you have to do; here are the permissions you have to do; here&#8217;s the surveillance you have to do after it goes on the market.</p>



<p>Even there, sometimes, it was confusing. What happens when it&#8217;s not the kind of animal you&#8217;re thinking about when you think about animal drugs? Like, we think about pigs and dogs, but what about mosquitoes?</p>



<p>Because there, you&#8217;re really thinking more about pests, and if you&#8217;re editing the mosquito so that it can&#8217;t, for example, transmit dengue fever, right, it feels more like a public health thing than it is a drug for the mosquito itself, and it, kind of, fell in between the agencies that possibly had jurisdiction. And it took a while for the USDA, the Department of Agriculture, and the Food and Drug Administration to work out an agreement about how they would share this responsibility. So you do get those kinds of areas in which you have at least ambiguity.</p>



<p>We also have situations where frankly the fact that some things can move across national borders means you have to have a system for harmonizing or coordinating national rules. If you want to, for example, genetically engineer mosquitoes that can&#8217;t transmit dengue, mosquitoes have a tendency to fly. [LAUGHTER] And so &#8230; they can&#8217;t fly very far. That&#8217;s good. That actually makes it easier to control.</p>



<p>But if you&#8217;re doing work that&#8217;s right near a border, then you have to be sure that the country next to you has the same rules for whether it&#8217;s permitted to do this and how to surveil what you&#8217;ve done in order to be sure that you got the results you wanted to get and no other results. And that also is an area where we have a lot of work to be done in terms of coordinating across government borders and harmonizing our rules.</p>



<p><strong>SULLIVAN:</strong> Yeah, I mean, you&#8217;ve touched on this a little bit, but there is such this striking balance between advancing technology, ensuring public safety, and sometimes, I think it feels just like you&#8217;re walking a tightrope where, you know, if we clamp down too hard, we&#8217;ll stifle innovation, and if we&#8217;re too lax, we risk some of these unintended consequences. And on a global scale like you just mentioned, as well. How has the field of genome editing found its balance?</p>



<p><strong>CHARO:</strong> It&#8217;s still being worked out, frankly, but it&#8217;s finding its balance application by application. So in the United States, we have two very different approaches on regulation of things that are going to go into the market.</p>



<p>Some things can&#8217;t be marketed until they&#8217;ve gotten an approval from the government. So you come up with a new drug, you can&#8217;t sell that until it&#8217;s gone through FDA approval.</p>



<p>On the other hand, for most foods that are made up of familiar kinds of things, you can go on the market, and it&#8217;s only after they&#8217;re on the market that the FDA can act to withdraw it if a problem arises. So basically, we have either <em>pre</em>-market controls: you can&#8217;t go on without permission. Or <em>post</em>-market controls: we can take you off the market <em>if</em> a problem occurs.</p>



<p>How do we decide which one is appropriate for a particular application? It&#8217;s based on our experience. New drugs typically are both less familiar than existing things on the market and also have a higher potential for injury if they, in fact, are not effective or they are, in fact, dangerous and toxic.</p>



<p>If you have foods, even bioengineered foods, that are basically the same as foods that are already here, it can go on the market with notice but without a prior approval. But if you create something truly novel, then it has to go through a whole long process.</p>



<p>And so that is the way that we make this balance. We look at the application area. And we&#8217;re just now seeing in the Department of Agriculture a new approach on some of the animal editing, again, to try and distinguish between things that are simply a more efficient way to make a familiar kind of animal variant and those things that are genuinely novel and to have a regulatory process that is more rigid the more unfamiliar it is and the more that we see a risk associated with it.</p>



<p><strong>SULLIVAN:</strong> I know we&#8217;re at the end of our time here and maybe just a quick kind of lightning-round of a question. For students, young scientists, lawyers, or maybe even entrepreneurs listening who are inspired by your work, what&#8217;s the single piece of advice you give them if they&#8217;re interested in policy, regulation, the ethical side of things in genomics or other fields?</p>



<p><strong>CHARO:</strong> I&#8217;d say be a bio-optimist and read a lot of science fiction. Because it expands your imagination about what the world could be like. Is it going to be a world in which we&#8217;re now going to be growing our buildings instead of building them out of concrete?</p>



<p>Is it going to be a world in which our plants will glow in the evening so we don&#8217;t need to be using batteries or electrical power from other sources but instead our environment is adapting to our needs?</p>



<p>You know, expand your imagination with a sense of optimism about what could be and see ethics and regulation not as an obstacle but as a partner to bringing these things to fruition in a way that&#8217;s responsible and helpful to everyone.</p>



<p>[TRANSITION MUSIC]</p>



<p><strong>SULLIVAN:</strong> Wonderful. Well, Alta, this has been just an absolute pleasure. So thank you.</p>



<p><strong>CHARO:</strong> It was my pleasure. Thank you for having me.</p>



<p><strong>SULLIVAN:</strong> Now, I&#8217;m happy to bring in Daniel Kluttz. As a partner general manager in Microsoft&#8217;s Office of Responsible AI, Daniel leads the group’s Sensitive Uses and Emerging Technologies program.</p>



<p>Daniel, it&#8217;s great to have you here. Thanks for coming in.</p>



<p><strong>DANIEL KLUTTZ:</strong> It&#8217;s great to be here, Kathleen.</p>



<p><strong>SULLIVAN:</strong> Yeah. So maybe before we unpack Alta Charo’s insights, I&#8217;d love to just understand the elevator pitch here. What exactly is [the] Sensitive Uses and Emerging Tech program, and what was the impetus for establishing it?</p>



<p><strong>KLUTTZ:</strong> Yeah. So the Sensitive Uses and Emerging Technologies program sits within our Office of Responsible AI at Microsoft. And inherent in the name, there are two real core functions. There&#8217;s the sensitive uses and emerging technologies. What does that mean?</p>



<p>Sensitive uses, think of that as Microsoft&#8217;s internal consulting and oversight function for our higher-risk, most impactful AI system deployments. And so my team is a team of multidisciplinary experts who engages in sort of a white-glove-treatment sort of way with product teams at Microsoft that are designing, building, and deploying these higher-risk AI systems, and where that sort of consulting journey culminates is in a set of bespoke requirements tailored to the use case of that given system that really implement and apply our more standardized, generalized requirements that apply across the board.</p>



<p>Then the emerging technologies function of my team faces a little bit further out, trying to look around corners to see what new and novel and emerging risks are coming out of new AI technologies with the idea that we work with our researchers, our engineering partners, and, of course, product leaders across the company to understand where Microsoft is going with those emerging technologies, and we&#8217;re developing sort of rapid, quick-fire early-steer guidance that implements our policies ahead of that formal internal policymaking process, which can take a bit of time. So it&#8217;s designed to, sort of, both afford that innovation speed that we like to optimize for at Microsoft but also integrate our responsible AI commitments and our AI principles into emerging product development.</p>



<p><strong>SULLIVAN:</strong> That segues really nicely, actually, as we met with Professor Charo and she was, you know, talking about the field of genome editing and the governing at the application level. I&#8217;d love to just understand how similar or not is that to managing the risks of AI in our world?</p>



<p><strong>KLUTTZ:</strong> Yeah. I mean, Professor Charo’s comments were music to my ears because, you know, where we make our bread and butter, so to speak, in our team is in applying to use cases. AI systems, especially in this era of generative AI, are almost inherently multi-use, dual use. And so what really matters is how you&#8217;re going to apply that more general-purpose technology. Who&#8217;s going to use it? In what domain is it going to be deployed? And then tailor that oversight to those use cases. Try to be risk proportionate.</p>



<p>Professor Charo talked a little bit about this, but if it&#8217;s something that&#8217;s been done before and it&#8217;s just a new spin on an old thing, maybe we&#8217;re not so concerned about how closely we need to oversee and gate that application of that technology, whereas if it&#8217;s something new and novel or some new risk that might be posed by that technology, we take a little bit closer look and we are overseeing that in a more sort of high-touch way.</p>



<p><strong>SULLIVAN:</strong> Maybe following up on that, I mean, how do you define sensitive use or maybe like high-impact application, and once that&#8217;s labeled, what happens? Like, what kind of steps kick in from there?</p>



<p><strong>KLUTTZ:</strong> Yeah. So we have this Sensitive Uses program that&#8217;s been at Microsoft since 2019. I came to Microsoft in 2019 when we were starting this program in the Office of Responsible AI, and it had actually been incubated in Microsoft Research with our Aether community of colleagues who are experts in sociotechnical approaches to responsible AI, as well. Once we put it in the Office of Responsible AI, I came over. I came from academia. I was a researcher myself …</p>



<p><strong>SULLIVAN:</strong> At Berkeley, right?</p>



<p><strong>KLUTTZ:</strong> At Berkeley. That&#8217;s right. Yep. Sociologist by training and a lawyer in a past life. [LAUGHTER] But that has helped sort of bridge those fields for me.</p>



<p>But Sensitive Uses, we force all of our teams when they&#8217;re envisioning their system design to think about, could the reasonably foreseeable use or <em>misuse</em> of the system that they&#8217;re developing in practice result in three really major, sort of, risk types. One is, could that deployment result in a consequential impact on someone&#8217;s legal position or life opportunity? Another category we have is, could that foreseeable use or misuse result in significant psychological or physical injury or harm? And then the third really ties in with a longstanding commitment we&#8217;ve had to human rights at Microsoft. And so could that system in it&#8217;s reasonably foreseeable use or misuse result in human rights impacts and injurious consequences to folks along different dimensions of human rights? </p>



<p>Once you decide, we have a process to reporting that project into my office, and we will triage that project, working with the product team, for example, and our Responsible AI Champs community, which are folks who are dispersed throughout the ecosystem at Microsoft and educated in our responsible AI program, and then determine, OK, is it in scope for our program? If it is, say, OK, we&#8217;re going to go along for that ride with you, and then we get into that whole sort of consulting arrangement that then culminates in this set of bespoke use-case-based requirements applying our AI principles.</p>



<p><strong>SULLIVAN:</strong> That&#8217;s super fascinating. What are some of the approaches in the governance of genome editing are you maybe seeing happening in AI governance or maybe just, like, bubbling up in conversations around it?</p>



<p><strong>KLUTTZ:</strong> Yeah, I mean, I think we&#8217;ve learned a lot from fields like genome editing that Professor Charo talked about and others. And again, it gets back to this, sort of, risk-proportionate-based approach. It&#8217;s a balancing test. It&#8217;s a tradeoff of trying to, sort of, foster innovation and really look for the beneficial uses of these technologies. I appreciated her speaking about that. What are the intended uses of the system, right? And then getting to, OK, how do we balance trying to, again, foster that innovation in a very fast-moving space, a pretty complex space, and a very unsettled space contrasting to other, sort of, professional fields or technological fields that have a long history and are relatively settled from an oversight and regulatory standpoint? This one is <em>not</em>, and for good reason. It is still developing.</p>



<p>And I think, you know, there are certain oversight and policy regimes that exist today that can be applied. Professor Charo talked about this, as well, where, you know, maybe you have certain policy and oversight regimes that, depending on how the application of that technology is applied, applies there versus some horizontal, overarching regulatory sort of framework. And I think that applies from an internal governance standpoint, as well.</p>



<p><strong>SULLIVAN:</strong> Yeah. It&#8217;s a great point. So what isn&#8217;t being explored from genome editing that, you know, maybe we think could be useful to AI governance, or as we think about the evolving frameworks …</p>



<p><strong>KLUTTZ:</strong> Yeah.</p>



<p><strong>SULLIVAN:</strong> … what maybe we should be taking into account from what Professor Charo shared with us?</p>



<p><strong>KLUTTZ:</strong> So one of the things I&#8217;ve thought about and took from Professor Charo’s discussion was she had just this amazing way of framing up how genome editing regulation is done. And she said, you know, we don&#8217;t regulate genome editing; we regulate the things that <em>use</em> genome editing. And while it&#8217;s not a one-to-one analogy with the AI space because we do have this sort of very general model level distinction versus application layer and even platform layer distinctions, I think it&#8217;s fair to say, you know, we don&#8217;t regulate AI applications writ large. We regulate the things that use AI in a very similar way. And that&#8217;s how we think of our internal policy and oversight process at Microsoft, as well.</p>



<p>And maybe there are things that we regulated and oversaw internally at the first instance and the first time we saw it come through, and it graduates into more of a programmatic framework for how we manage that. So one good example of that is some of our higher-risk AI systems that we offer out of Azure at the platform level. When I say that, I mean APIs that you call that developers can then build their own applications on top of. We were really deep in evaluating and assessing mitigations on those platform systems in the first instance, but we also graduated them into what we call our Limited Access AI services program.</p>



<p>And some of the things that Professor Charo discussed really resonated with me. You know, she had this moment where she was mentioning how, you know, you want to know who&#8217;s using your tools and how they&#8217;re being used. And it&#8217;s the same concepts. We want to have trust in our customers, we want to understand their use cases, and we want to apply technical controls that, sort of, force those use cases or give us signal post-deployment that use cases are being done in a way that may give us some level of concern, to reach out and understand what those use cases are.</p>



<p><strong>SULLIVAN:</strong> Yeah, you&#8217;re hitting on a great point. And I love this kind of layered approach that we&#8217;re taking and that Alta highlighted, as well. Maybe to double-click a little bit just on that post-market control and what we&#8217;re tracking, kind of, once things are out and being used by our customers. How do we take some of that deployment data and bring it back in to maybe even better inform upfront governance or just how we think about some of the frameworks that we&#8217;re operating in?</p>



<p><strong>KLUTTZ:</strong> It&#8217;s a great question. The number one thing is for us at Microsoft, we want to know the voice of our customer. We want our customers to talk to us. We don&#8217;t want to just understand telemetry and data. But it&#8217;s really getting out there and understanding from our customers and not <em>just</em> our customers. I would say our <em>stakeholders</em> is maybe a better term because that includes civil society organizations. It includes governments. It includes all of these non, sort of, customer actors that we care about and that we&#8217;re trying to sort of optimize for, as well. It includes end users of our enterprise customers. If we can gather data about how our products are being used and trying to understand maybe areas that we didn&#8217;t foresee how customers or users might be using those things, and then we can tune those systems to better align with what both customers and users want but also our own AI principles and policies and programs.</p>



<p><strong>SULLIVAN:</strong> Daniel, before coming to Microsoft, you led social science research and sociotechnical applications of AI-driven tech at Berkeley. What do you think some of the biggest challenges are in defining and maybe even just, kind of, measuring at, like, a societal level some of the impacts of AI more broadly?</p>



<p><strong>KLUTTZ:</strong> Measuring social phenomenon is a difficult thing. And one of the things that, as social scientists, you&#8217;re very interested in is scientifically observing and measuring social phenomena. Well, that sounds great. It sounds also very high level and jargony. What do we mean by that? You know, it&#8217;s very easy to say that you&#8217;re collecting data and you&#8217;re measuring, I don&#8217;t know, trust in AI, right? That&#8217;s a very fuzzy concept.</p>



<p><strong>SULLIVAN:</strong> Right. Definitely.</p>



<p><strong>KLUTTZ:</strong> It is a concept that we want to get to, but we have to unpack that, and we have to develop what we call <em>measurable constructs</em>. What are the things that we might observe that could give us an indication toward what is a very fuzzy and general concept. And there&#8217;s challenges with that everywhere. And I&#8217;m extremely fortunate to work at Microsoft with some of the world&#8217;s leading sociotechnical researchers and some of these folks who are thinking about—you know, very steeped in measurement theory, literally PhDs in these fields—how to both measure <em>and</em> allow for a scalable way to do that at a place the size of Microsoft. And that is trying to develop frameworks that are scalable and repeatable and put into our platform that then serves our product teams. Are we providing, as a platform, a service to those product teams that they can plug in and do their automated evaluations at scale as much as possible and then go back in over the top and do some of your more qualitative targeted testing and evaluations.</p>



<p><strong>SULLIVAN:</strong> Yeah, makes a lot of sense. Before we close out, if you&#8217;re game for it, maybe we do a quick lightning round. Just 30-second answers here. Favorite real-world sensitive use case you&#8217;ve ever reviewed.</p>



<p><strong>KLUTTZ:</strong> Oh gosh. Wow, this is where I get to be the social scientist.</p>



<p><strong>SULLIVAN:</strong> [LAUGHS] Yes.</p>



<p><strong>KLUTTZ: </strong>It’s like, define <em>favorite</em>, Kathleen. [LAUGHS] Most <em>memorable</em>, most <em>painful</em>.</p>



<p><strong>SULLIVAN:</strong> Let&#8217;s do most memorable.</p>



<p><strong>KLUTTZ:</strong> We’ll do most memorable.</p>



<p><strong>SULLIVAN:</strong> Yeah.</p>



<p><strong>KLUTTZ:</strong> You know, I would say the most memorable project I worked on was when we rolled out the new Bing Chat, which is no longer called Bing Chat, because that was the first really big cross-company effort to deploy GPT-4, which was, you know, the next step up in AI innovation from our partners at OpenAI. And I really value working hand in hand with engineering teams and with researchers and that was us at our best and really sort of turbocharged the model that we have.<s></s></p>



<p><strong>SULLIVAN:</strong> Wonderful. What&#8217;s one of the most overused phrases that you have in your AI governance meetings?</p>



<p><strong>KLUTTZ:</strong> Gosh. [LAUGHS] If I hear “We need to get aligned; we need to align on this more” …</p>



<p><strong>SULLIVAN:</strong> [LAUGHS] Right.</p>



<p><strong>KLUTTZ:</strong> But, you know, it&#8217;s said for a reason. And I think it sort of speaks to that clever nature. That&#8217;s one that comes to mind.</p>



<p><strong>SULLIVAN:</strong> That&#8217;s great. And then maybe, maybe last one. What are you most excited about in the next, I don&#8217;t know, let&#8217;s say three months? This world is moving so fast!</p>



<p><strong>KLUTTZ:</strong> You know, the pace of innovation, as you just said, is just staggering. It is unbelievable. And sometimes it can feel overwhelming in my space. But what I am most excited about is how we are building up this Emerging … I mentioned this Emerging Technologies program in my team as a, sort of, formal program is relatively new. And I really enjoy being able to take a step back and think a little bit more about the future and a little bit more holistically. And I love working with engineering teams and sort of strategic visionaries who are thinking about what we&#8217;re doing a year from now or five years from now, or even 10 years from now, and I get to be a part of those conversations. And that really gives me energy and helps me … helps keep me grounded and not just dealing with the day to day, and, you know, various fire drills that you may run. It&#8217;s thinking strategically and having that foresight about what&#8217;s to come. And it&#8217;s exciting.</p>



<p><strong>SULLIVAN:</strong> Great. Well, Daniel, just thanks so much for being here. I had such a wonderful discussion with you, and I think the thoughtfulness in our discussion today I hope resonates with our listeners. And again, thanks to Alta for setting the stage and sharing her really amazing, insightful thoughts here, as well. So thank you.</p>



<p>[MUSIC]</p>



<p><strong>KLUTTZ:</strong> Thank you, Kathleen. I appreciate it. It&#8217;s been fun.</p>



<p><strong>SULLIVAN: </strong>And to our listeners, thanks for tuning in. You can find resources related to this podcast in the show notes. And if you want to learn more about how Microsoft approaches AI governance, you can visit microsoft.com/RAI.</p>



<p>See you next time!&nbsp;</p>



<p>[MUSIC FADES]</p>

				</span>
			</div>
			<button
				class="action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle"
				aria-expanded="false"
				data-show-less-text="Show less"
				type="button"
				aria-controls="show-more-show-less-toggle-1"
				aria-label="Show more content"
				data-alternate-aria-label="Show less content">
				Show more			</button>
		</div>
	</div>
</div>
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-genome-editing/">AI Testing and Evaluation: Learnings from genome editing</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>PadChest-GR: A bilingual grounded radiology reporting benchmark for chest X-rays</title>
		<link>https://www.microsoft.com/en-us/research/blog/padchest-gr-a-bilingual-grounded-radiology-reporting-benchmark-for-chest-x-rays/</link>
		
		<dc:creator><![CDATA[Daniel Coelho de Castro, Javier Alvarez-Valle]]></dc:creator>
		<pubDate>Thu, 26 Jun 2025 16:08:25 +0000</pubDate>
				<category><![CDATA[Research Blog]]></category>
		<guid isPermaLink="false">https://www.microsoft.com/en-us/research/?p=1142540</guid>

					<description><![CDATA[<p>The world’s first multimodal, bilingual radiology dataset could reshape the way radiologists and AI systems make sense of X-rays. PadChest-GR, developed by the University of Alicante with Microsoft Research, has the potential to advance research across the field for years to come.</p>
<p>The post <a href="https://www.microsoft.com/en-us/research/blog/padchest-gr-a-bilingual-grounded-radiology-reporting-benchmark-for-chest-x-rays/">PadChest-GR: A bilingual grounded radiology reporting benchmark for chest X-rays</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/PadChest-BlogHeroFeature-1400x788-1.jpg" alt="Alt text: The image features three white icons on a gradient background transitioning from blue on the left to green on the right. The first icon, located on the left, resembles an X-ray of a ribcage enclosed in a square with rounded corners. The middle icon depicts a hierarchical structure with one circle at the top connected by lines to two smaller circles below it. The third icon, positioned on the right, shows the letters "N" and "A" separated by a diagonal line, with a tilde (~) above the "N"." class="wp-image-1142658" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/PadChest-BlogHeroFeature-1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/PadChest-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/PadChest-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/PadChest-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/PadChest-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/PadChest-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/PadChest-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/PadChest-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/PadChest-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/PadChest-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure>



<p>In our ever-evolving journey to enhance healthcare through technology, we’re announcing a unique new benchmark for grounded radiology report generation—<strong><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://ai.nejm.org/doi/full/10.1056/AIdbp2401120" target="_blank" rel="noreferrer noopener">PadChest-GR<span class="sr-only"> (opens in new tab)</span></a></strong>. The world’s first multimodal, bilingual sentence-level radiology report dataset, developed&nbsp;by the University of Alicante with Microsoft Research, University Hospital Sant Joan d’Alacant and MedBravo, is set to redefine how AI and radiologists interpret radiological images. Our work demonstrates how collaboration between humans and AI can create powerful feedback loops—where new datasets drive better AI models, and those models, in turn, inspire richer datasets. We&#8217;re excited to share this progress in NEJM AI, highlighting both the clinical relevance and research excellence of this initiative.&nbsp;</p>



<h2 class="wp-block-heading" id="a-new-frontier-in-radiology-report-generation">A new frontier in radiology report generation&nbsp;</h2>



<p>It is estimated that over half of people visiting hospitals have radiology scans that must be interpreted by a clinical professional. Traditional radiology reports often condense multiple findings into unstructured narratives. In contrast, grounded radiology reporting demands that each finding be described and localized individually.</p>



<p>This can mitigate the risk of AI fabrications and enable new interactive capabilities that enhance clinical and patient interpretability. PadChest-GR is the first bilingual dataset to address this need with 4,555 chest X-ray studies complete with Spanish and English sentence-level descriptions and precise spatial (bounding box) annotations for both positive and negative findings. It is the first public benchmark that enables us to evaluate generation of fully grounded radiology reports in chest X-rays.&nbsp;</p>



<figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1516" height="781" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/grounded_report_example.png" alt="Figure 1: A chest X-ray overlaid with numbered bounding boxes, next to a matching list of structured radiological findings in Spanish and English. " class="wp-image-1142582" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/grounded_report_example.png 1516w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/grounded_report_example-300x155.png 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/grounded_report_example-1024x528.png 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/grounded_report_example-768x396.png 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/grounded_report_example-240x124.png 240w" sizes="auto, (max-width: 1516px) 100vw, 1516px" /><figcaption class="wp-element-caption">Figure 1. Example of a grounded report from PadChest-GR. The original free-text report in Spanish was <em>”Motivo de consulta: Preoperatorio. Rx PA tórax: Impresión diagnóstica: Ateromatosis aórtica calcificada. Engrosamiento pleural biapical. Atelectasia laminar basal izquierda. Elongación aórtica. Sin otros hallazgos radiológicos significativos.”</em></figcaption></figure>



<p>This benchmark isn’t standing alone—it plays a critical role in powering our state-of-the-art multimodal report generation model, <strong>MAIRA-2</strong>. Leveraging the detailed annotations of PadChest-GR, MAIRA-2 represents our commitment to building more interpretable and clinically useful AI systems. You can explore our work on MAIRA-2 on our <a href="https://www.microsoft.com/en-us/research/project/project-maira/">project web page</a>, including recent user research conducted with <a href="https://www.microsoft.com/en-us/research/publication/multimodal-healthcare-ai-identifying-and-designing-clinically-relevant-vision-language-applications-for-radiology/" target="_blank" rel="noreferrer noopener">clinicians in healthcare settings</a>.</p>



<p>PadChest-GR is a testament to the power of collaboration. Aurelia Bustos at MedBravo and Antonio Pertusa at the University of Alicante published the original&nbsp;<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://bimcv.cipf.es/bimcv-projects/padchest/" target="_blank" rel="noreferrer noopener">PadChest dataset<span class="sr-only"> (opens in new tab)</span></a> in 2020,&nbsp;with the help of Jose María Salinas from Hospital San Juan de Alicante and María de la Iglesia Vayá from the Center of Excellence in Biomedical Imaging at the Ministry of Health in Valencia, Spain. We started to look at PadChest and were deeply impressed by the scale, depth, and diversity of the data.</p>



<p>As we worked more closely with the dataset, we realized the opportunity to develop this for grounded radiology reporting research and worked with the team at the University of Alicante to determine how to approach this together. Our complementary expertise was a nice fit. At Microsoft Research, our mission is to push the boundaries of medical AI through innovative, data-driven solutions. The University of Alicante, with its deep clinical expertise, provided critical insights that greatly enriched the dataset’s relevance and utility. The result of this collaboration is the PadChest-GR dataset.</p>



<p>A significant enabler of our annotation process was <strong>Centaur Labs</strong>. The team of senior and junior radiologists from the University Hospital Sant Joan d’Alacant, coordinated by Joaquin Galant,&nbsp;used this HIPAA-compliant labeling platform to&nbsp;perform rigorous study-level quality control and bounding box annotations. The annotation protocol implemented ensured that each annotation was accurate and consistent, forming the backbone of a dataset designed for the next generation of grounded radiology report generation models.&nbsp;</p>



<h2 class="wp-block-heading" id="accelerating-padchest-gr-dataset-annotation-with-ai">Accelerating PadChest-GR dataset annotation with AI&nbsp;</h2>



<p>Our approach integrates advanced large language models with comprehensive manual annotation:&nbsp;</p>



<p><strong>Data Selection & Processing:</strong> Leveraging <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://azure.microsoft.com/en-us/products/ai-services/openai-service" target="_blank" rel="noreferrer noopener">Microsoft Azure OpenAI Service<span class="sr-only"> (opens in new tab)</span></a> with GPT-4, we extracted sentences describing individual positive and negative findings from raw radiology reports, translated them from Spanish to English, and linked each sentence to the existing expert labels from PadChest. This was done for a selected subset of the full PadChest dataset, carefully curated to reflect a realistic distribution of clinically relevant findings.&nbsp;</p>



<p><strong>Manual Quality Control & Annotation:</strong> The processed studies underwent meticulous quality checks on the Centaur Labs platform by radiologist from Hospital San Juan de Alicante. Each positive finding was then annotated with bounding boxes to capture critical spatial information.&nbsp;</p>



<p><strong>Standardization & Integration:</strong> All annotations were harmonized into coherent grounded reports, preserving the structure and context of the original findings while enhancing interpretability.&nbsp;</p>



<figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1752" height="790" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/dataflow.png" alt="Figure 2: A detailed block diagram illustrating the flow of data between various stages of AI processing and manual annotation. " class="wp-image-1142586" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/dataflow.png 1752w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/dataflow-300x135.png 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/dataflow-1024x462.png 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/dataflow-768x346.png 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/dataflow-1536x693.png 1536w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/dataflow-240x108.png 240w" sizes="auto, (max-width: 1752px) 100vw, 1752px" /><figcaption class="wp-element-caption">Figure 2. Overview of the data curation pipeline.</figcaption></figure>



<h2 class="wp-block-heading" id="impact-and-future-directions">Impact and future directions&nbsp;</h2>



<p>PadChest-GR not only sets a new benchmark for grounded radiology reporting, but also serves as the foundation for our MAIRA-2 model, which already showcases the potential of highly interpretable <a href="https://www.microsoft.com/en-us/industry/blog/healthcare/2025/05/19/developing-next-generation-cancer-care-management-with-multi-agent-orchestration/" target="_blank" rel="noreferrer noopener">AI in clinical settings</a>. While we developed PadChest-GR to help train and validate our own models, we believe the research community will greatly benefit from this dataset for many years to come. We look forward to seeing the broader research community build on this—improving grounded reporting AI models and using PadChest-GR as a standard for evaluation. We believe that by fostering open collaboration and sharing our resources, we can accelerate progress in medical imaging AI and ultimately improve patient care together with the community.</p>



<p>The collaboration between Microsoft Research and the University of Alicante highlights the transformative power of working together across disciplines. With our publication in NEJM-AI and the integral role of PadChest-GR in the development of <a href="https://www.microsoft.com/en-us/research/publication/maira-2-grounded-radiology-report-generation/" target="_blank" rel="noreferrer noopener">MAIRA-2<span class="sr-only"> (opens in new tab)</span></a> and <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/radfact" target="_blank" rel="noreferrer noopener">RadFact<span class="sr-only"> (opens in new tab)</span></a>, we are excited about the future of AI-empowered radiology. We invite researchers and industry experts to explore PadChest-GR and MAIRA-2, contribute innovative ideas, and join us in advancing the field of grounded radiology reporting.&nbsp;</p>



<p>Papers already using PadChest-GR:</p>



<ul class="wp-block-list">
<li><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" target="_blank" href="https://nam06.safelinks.protection.outlook.com/?url=https%3A%2F%2Farxiv.org%2Fabs%2F2406.04449&data=05%7C02%7Cv-ammelfi%40microsoft.com%7C3a510e2a628c41f431e608ddb23acd37%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C638862687830178131%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&sdata=BI0coh1EYtLPEme8ygYDgaY8OLiLxA7kJj0dj3KXvNM%3D&reserved=0">[2406.04449] MAIRA-2: Grounded Radiology Report Generation<span class="sr-only"> (opens in new tab)</span></a></li>



<li><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" target="_blank" href="https://nam06.safelinks.protection.outlook.com/?url=https%3A%2F%2Farxiv.org%2Fabs%2F2502.03333&data=05%7C02%7Cv-ammelfi%40microsoft.com%7C3a510e2a628c41f431e608ddb23acd37%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C638862687830198918%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&sdata=udnptjC4kQA22qIDmTCwoSJI4ol%2Fp95%2FOsidJdZ4CWc%3D&reserved=0">RadVLM: A Multitask Conversational Vision-Language Model for Radiology<span class="sr-only"> (opens in new tab)</span></a></li>



<li><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" target="_blank" href="https://nam06.safelinks.protection.outlook.com/?url=https%3A%2F%2Farxiv.org%2Fabs%2F2503.03278&data=05%7C02%7Cv-ammelfi%40microsoft.com%7C3a510e2a628c41f431e608ddb23acd37%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C638862687830212221%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&sdata=taRcdqfs7Dis0FxmUDJDAr7DGmggLDyf9et2pYu0mm8%3D&reserved=0">Enhancing Abnormality Grounding for Vision Language Models with Knowledge Descriptions<span class="sr-only"> (opens in new tab)</span></a></li>



<li><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" target="_blank" href="https://nam06.safelinks.protection.outlook.com/?url=https%3A%2F%2Fopenreview.net%2Fforum%3Fid%3D0Jn1d4gYRS&data=05%7C02%7Cv-ammelfi%40microsoft.com%7C3a510e2a628c41f431e608ddb23acd37%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C638862687830225142%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&sdata=QcvL%2FgUDBqxkr5Zxtx9PwSLZsYwEKWdoGaC9LHKxr7Q%3D&reserved=0">Visual Prompt Engineering for Vision Language Models in Radiology<span class="sr-only"> (opens in new tab)</span></a></li>
</ul>



<p>For further details or to download PadChest-GR, please visit the <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://bimcv.cipf.es/bimcv-projects/padchest-gr/" target="_blank" rel="noreferrer noopener">BIMCV PadChest-GR Project<span class="sr-only"> (opens in new tab)</span></a>.&nbsp;</p>



<p>Models in the Azure Foundry that can do Grounded Reporting:&nbsp;</p>



<ul class="wp-block-list">
<li><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" target="_blank" href="https://nam06.safelinks.protection.outlook.com/?url=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fazure%2Fai-foundry%2Fhow-to%2Fhealthcare-ai%2Fdeploy-cxrreportgen&data=05%7C02%7Cv-ammelfi%40microsoft.com%7C3a510e2a628c41f431e608ddb23acd37%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C638862687830239988%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&sdata=dvRiCJL5l9vOk89pdPgmjPBVOtiHIzK5DZ7uhGbRk0Q%3D&reserved=0">How to deploy and use CXRReportGen healthcare AI model with Azure AI Foundry &#8211; Azure AI Foundry | Microsoft Learn<span class="sr-only"> (opens in new tab)</span></a></li>



<li><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" target="_blank" href="https://nam06.safelinks.protection.outlook.com/?url=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fazure%2Fhealth-bot%2Fcopilot%2Forchestrator&data=05%7C02%7Cv-ammelfi%40microsoft.com%7C3a510e2a628c41f431e608ddb23acd37%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C638862687830255286%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&sdata=t3r8%2BHHR1KvoLZi4YnI44DYT855MbYZisNc4f5f1OTg%3D&reserved=0">Healthcare Orchestrator &#8211; Healthcare agent service | Microsoft Learn<span class="sr-only"> (opens in new tab)</span></a></li>
</ul>



<h2 class="wp-block-heading" id="acknowledgement">Acknowledgement</h2>



<ul class="wp-block-list">
<li>Authors: <a href="https://www.microsoft.com/en-us/research/people/dacoelh/">Daniel C. Castro<span class="sr-only"> (opens in new tab)</span></a>, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://arxiv.org/search/cs?searchtype=author&query=Bustos,+A" target="_blank" rel="noreferrer noopener">Aurelia Bustos<span class="sr-only"> (opens in new tab)</span></a>, <a href="https://www.microsoft.com/en-us/research/people/shbannur/">Shruthi Bannur<span class="sr-only"> (opens in new tab)</span></a>, <a href="https://www.microsoft.com/en-us/research/people/sthyland/">Stephanie L. Hyland<span class="sr-only"> (opens in new tab)</span></a>, <a href="https://www.microsoft.com/en-us/research/people/kenzabouzid/">Kenza Bouzid<span class="sr-only"> (opens in new tab)</span></a>, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://arxiv.org/search/cs?searchtype=author&query=Wetscherek,+M+T" target="_blank" rel="noreferrer noopener">Maria Teodora Wetscherek<span class="sr-only"> (opens in new tab)</span></a>, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://arxiv.org/search/cs?searchtype=author&query=S%C3%A1nchez-Valverde,+M+D" target="_blank" rel="noreferrer noopener">Maria Dolores Sánchez-Valverde<span class="sr-only"> (opens in new tab)</span></a>, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://arxiv.org/search/cs?searchtype=author&query=Jaques-P%C3%A9rez,+L" target="_blank" rel="noreferrer noopener">Lara Jaques-Pérez<span class="sr-only"> (opens in new tab)</span></a>, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://arxiv.org/search/cs?searchtype=author&query=P%C3%A9rez-Rodr%C3%ADguez,+L" target="_blank" rel="noreferrer noopener">Lourdes Pérez-Rodríguez<span class="sr-only"> (opens in new tab)</span></a>, <a href="https://www.microsoft.com/en-us/research/people/kenjitak/" target="_blank" rel="noreferrer noopener">Kenji Takeda<span class="sr-only"> (opens in new tab)</span></a>, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://arxiv.org/search/cs?searchtype=author&query=Salinas,+J+M" target="_blank" rel="noreferrer noopener">José María Salinas<span class="sr-only"> (opens in new tab)</span></a>, <a href="https://www.microsoft.com/en-us/research/people/jaalvare/">Javier Alvarez-Valle<span class="sr-only"> (opens in new tab)</span></a>, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://arxiv.org/search/cs?searchtype=author&query=Herrero,+J+G" target="_blank" rel="noreferrer noopener">Joaquín Galant Herrero<span class="sr-only"> (opens in new tab)</span></a>, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://arxiv.org/search/cs?searchtype=author&query=Pertusa,+A" target="_blank" rel="noreferrer noopener">Antonio Pertusa<span class="sr-only"> (opens in new tab)</span></a>&nbsp;</li>
</ul>



<ul class="wp-block-list">
<li>MSR Health Futures UK: <a href="https://www.microsoft.com/en-us/research/people/hamurfet/">Hannah Richardson</a>, <a href="https://www.microsoft.com/en-us/research/people/vsalvatelli/">Valentina Salvatelli</a>, <a href="https://www.microsoft.com/en-us/research/people/harssharma/">Harshita Sharma</a>, <a href="https://www.microsoft.com/en-us/research/people/sbondtaylor/">Sam Bond-Taylor</a>, <a href="https://www.microsoft.com/en-us/research/people/maxilse/">Max Ilse</a>, <a href="https://www.microsoft.com/en-us/research/people/fperezgarcia/">Fernando Perez-Garcia</a>, <a href="https://www.microsoft.com/en-us/research/people/antonsc/">Anton Schwaighofer</a>, <a href="https://www.microsoft.com/en-us/research/people/carlson/">Jonathan Carlson</a> </li>
</ul>



<ul class="wp-block-list">
<li>MSR Flow: <a href="https://www.microsoft.com/en-us/research/people/kenjitak/">Kenji Takeda</a>, <a href="https://www.microsoft.com/en-us/research/people/evelynev/">Evelyn Viegas</a>, <a href="https://www.microsoft.com/en-us/research/people/allorens/">Ashley Llorens</a></li>
</ul>



<ul class="wp-block-list">
<li>HLS: <a href="https://www.microsoft.com/en-us/research/people/mlungren/">Matthew Lungren</a>, <a href="https://www.microsoft.com/en-us/research/people/naiteeks/">Naiteek Sangani</a>, <a href="https://www.microsoft.com/en-us/research/people/shreyjain/">Shrey Jain</a>, <a href="https://www.microsoft.com/en-us/research/people/itarapov/">Ivan Tarapov</a>, <a href="https://www.microsoft.com/en-us/research/people/wguyman/">Will Guyman</a>, Mert Oez, Chris Burt, David Ardman</li>
</ul>
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/blog/padchest-gr-a-bilingual-grounded-radiology-reporting-benchmark-for-chest-x-rays/">PadChest-GR: A bilingual grounded radiology reporting benchmark for chest X-rays</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>AI Testing and Evaluation: Learnings from Science and Industry</title>
		<link>https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-science-and-industry/</link>
		
		<dc:creator><![CDATA[Kathleen Sullivan, Amanda Craig Deckard]]></dc:creator>
		<pubDate>Mon, 23 Jun 2025 16:38:09 +0000</pubDate>
				<category><![CDATA[Microsoft Research Podcast]]></category>
		<guid isPermaLink="false"></guid>

					<description><![CDATA[<p>In the introductory episode of this new series, host Kathleen Sullivan and Senior Director Amanda Craig Deckard explore Microsoft’s efforts to draw on the experience of other domains to help advance the role of AI testing and evaluation as a governance tool.</p>
<p>The post <a href="https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-science-and-industry/">AI Testing and Evaluation: Learnings from Science and Industry</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP0-AI-TE_Hero_Feature_1400x788.jpg" alt="Illustrated headshots of Amanda Craig Deckard & Kathleen Sullivan." class="wp-image-1141309" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP0-AI-TE_Hero_Feature_1400x788.jpg 1400w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP0-AI-TE_Hero_Feature_1400x788-300x169.jpg 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP0-AI-TE_Hero_Feature_1400x788-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP0-AI-TE_Hero_Feature_1400x788-768x432.jpg 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP0-AI-TE_Hero_Feature_1400x788-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP0-AI-TE_Hero_Feature_1400x788-655x368.jpg 655w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP0-AI-TE_Hero_Feature_1400x788-240x135.jpg 240w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP0-AI-TE_Hero_Feature_1400x788-640x360.jpg 640w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP0-AI-TE_Hero_Feature_1400x788-960x540.jpg 960w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP0-AI-TE_Hero_Feature_1400x788-1280x720.jpg 1280w" sizes="auto, (max-width: 1400px) 100vw, 1400px" /></figure>


<div class="wp-block-msr-podcast-container my-4">
	<iframe loading="lazy" src="https://player.blubrry.com/?podcast_id=146460793&modern=1" class="podcast-player" frameborder="0" height="164px" width="100%" scrolling="no" title="Podcast Player"></iframe>
</div>



<p>Generative AI presents a unique challenge and opportunity to reexamine governance practices for the responsible development, deployment, and use of AI. To advance thinking in this space, Microsoft has tapped into the experience and knowledge of experts across domains—from genome editing to cybersecurity—to investigate the role of testing and evaluation as a governance tool. <em><a href="https://www.microsoft.com/en-us/research/story/ai-testing-and-evaluation-learnings-from-science-and-industry/">AI Testing and Evaluation: Learnings from Science and Industry</a>, </em>hosted by Microsoft Research’s <a href="https://www.microsoft.com/en-us/research/people/kasull/">Kathleen Sullivan</a>, explores what the technology industry and policymakers can learn from these fields and how that might help shape the course of AI development.</p>



<p>In this episode, <a href="https://www.microsoft.com/en-us/research/people/amcraig/">Amanda Craig Deckard</a>, senior director of public policy in Microsoft&#8217;s Office of Responsible AI, joins Sullivan to detail the company’s efforts to help inform AI governance discussions and decisions, including, more recently, around the role of AI testing and evaluation. Craig Deckard and Sullivan delve into the tension that exists between the risk and opportunity of technology, the similarities and differences between AI development and the fields Microsoft is studying, and the role of different stakeholders in advancing AI governance and public policy.</p>



<div class="wp-block-group msr-pattern-link-list is-layout-flow wp-block-group-is-layout-flow">
<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading h5" id="learn-more-1">Learn more:</h2>



<ul class="wp-block-list list-unstyled">
<li><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" target="_blank" href="https://cdn-dynmedia-1.microsoft.com/is/content/microsoftcorp/microsoft/msc/documents/presentations/CSR/Global-Governance-Book-DIGITAL.pdf">Global Governance: Goals and Lessons for AI<span class="sr-only"> (opens in new tab)</span></a><br>E-book | May 2024</li>



<li><a href="https://www.microsoft.com/en-us/research/blog/learning-from-other-domains-to-advance-ai-evaluation-and-testing/">Learning from other domains to advance AI evaluation and testing</a><br>Microsoft Research Blog | June 2025</li>



<li><a href="https://www.microsoft.com/en-us/ai/responsible-ai?ef_id=_k_cb05d5950e4f117c457ebda628845b7f_k_&OCID=AIDcmm1o1fzy5i_SEM__k_cb05d5950e4f117c457ebda628845b7f_k_&msclkid=cb05d5950e4f117c457ebda628845b7f" target="_blank" rel="noreferrer noopener">Responsible AI: Ethical policies and practices | Microsoft AI</a></li>
</ul>
</div>



<p><a href="https://www.microsoft.com/en-us/research/focus-area/ai-and-microsoft-research/" target="_blank" rel="noreferrer noopener">AI and Microsoft Research</a></p>



<div style="height:25px" aria-hidden="true" class="wp-block-spacer"></div>



<section class="wp-block-msr-subscribe-to-podcast subscribe-to-podcast">
	<div class="subscribe-to-podcast__inner border-top border-bottom border-width-2">
		<h2 class="h5 subscribe-to-podcast__heading">
			Subscribe to the <a href="https://www.microsoft.com/en-us/research/podcast">Microsoft Research Podcast</a>:		</h2>
		<ul class="subscribe-to-podcast__list list-unstyled">
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://itunes.apple.com/us/podcast/microsoft-research-a-podcast/id1318021537?mt=2" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="black" viewBox="0 0 32 32">  <path d="M7.12 0c-3.937-0.011-7.131 3.183-7.12 7.12v17.76c-0.011 3.937 3.183 7.131 7.12 7.12h17.76c3.937 0.011 7.131-3.183 7.12-7.12v-17.76c0.011-3.937-3.183-7.131-7.12-7.12zM15.817 3.421c3.115 0 5.932 1.204 8.079 3.453 1.631 1.693 2.547 3.489 3.016 5.855 0.161 0.787 0.161 2.932 0.009 3.817-0.5 2.817-2.041 5.339-4.317 7.063-0.812 0.615-2.797 1.683-3.115 1.683-0.12 0-0.129-0.12-0.077-0.615 0.099-0.792 0.192-0.953 0.64-1.141 0.713-0.296 1.932-1.167 2.677-1.911 1.301-1.303 2.229-2.932 2.677-4.719 0.281-1.1 0.244-3.543-0.063-4.672-0.969-3.595-3.907-6.385-7.5-7.136-1.041-0.213-2.943-0.213-4 0-3.636 0.751-6.647 3.683-7.563 7.371-0.245 1.004-0.245 3.448 0 4.448 0.609 2.443 2.188 4.681 4.255 6.015 0.407 0.271 0.896 0.547 1.1 0.631 0.447 0.192 0.547 0.355 0.629 1.14 0.052 0.485 0.041 0.62-0.072 0.62-0.073 0-0.62-0.235-1.199-0.511l-0.052-0.041c-3.297-1.62-5.407-4.364-6.177-8.016-0.187-0.943-0.224-3.187-0.036-4.052 0.479-2.323 1.396-4.135 2.921-5.739 2.199-2.319 5.027-3.543 8.172-3.543zM16 7.172c0.541 0.005 1.068 0.052 1.473 0.14 3.715 0.828 6.344 4.543 5.833 8.229-0.203 1.489-0.713 2.709-1.619 3.844-0.448 0.573-1.537 1.532-1.729 1.532-0.032 0-0.063-0.365-0.063-0.803v-0.808l0.552-0.661c2.093-2.505 1.943-6.005-0.339-8.296-0.885-0.896-1.912-1.423-3.235-1.661-0.853-0.161-1.031-0.161-1.927-0.011-1.364 0.219-2.417 0.744-3.355 1.672-2.291 2.271-2.443 5.791-0.348 8.296l0.552 0.661v0.813c0 0.448-0.037 0.807-0.084 0.807-0.036 0-0.349-0.213-0.683-0.479l-0.047-0.016c-1.109-0.885-2.088-2.453-2.495-3.995-0.244-0.932-0.244-2.697 0.011-3.625 0.672-2.505 2.521-4.448 5.079-5.359 0.547-0.193 1.509-0.297 2.416-0.281zM15.823 11.156c0.417 0 0.828 0.084 1.131 0.24 0.645 0.339 1.183 0.989 1.385 1.677 0.62 2.104-1.609 3.948-3.631 3.005h-0.015c-0.953-0.443-1.464-1.276-1.475-2.36 0-0.979 0.541-1.828 1.484-2.328 0.297-0.156 0.709-0.235 1.125-0.235zM15.812 17.464c1.319-0.005 2.271 0.463 2.625 1.291 0.265 0.62 0.167 2.573-0.292 5.735-0.307 2.208-0.479 2.765-0.905 3.141-0.589 0.52-1.417 0.667-2.209 0.385h-0.004c-0.953-0.344-1.157-0.808-1.553-3.527-0.452-3.161-0.552-5.115-0.285-5.735 0.348-0.823 1.296-1.285 2.624-1.291z"/></svg>
						<span class="subscribe-to-podcast__link-text">Apple Podcasts</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://subscribebyemail.com/www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M6.4 6a2.392 2.392 0 00-2.372 2.119L16 15.6l11.972-7.481A2.392 2.392 0 0025.6 6H6.4zM4 10.502V22.8a2.4 2.4 0 002.4 2.4h19.2a2.4 2.4 0 002.4-2.4V10.502l-11.365 7.102a1.2 1.2 0 01-1.27 0L4 10.502z"/></svg>
						<span class="subscribe-to-podcast__link-text">Email</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://subscribeonandroid.com/www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M12.414 4.02c-.062.012-.126.023-.18.06a.489.489 0 00-.12.675L13.149 6.3c-1.6.847-2.792 2.255-3.18 3.944h13.257c-.388-1.69-1.58-3.097-3.179-3.944l1.035-1.545a.489.489 0 00-.12-.675.492.492 0 00-.675.135l-1.14 1.68a7.423 7.423 0 00-2.55-.45c-.899 0-1.758.161-2.549.45l-1.14-1.68a.482.482 0 00-.494-.195zm1.545 3.824a.72.72 0 110 1.44.72.72 0 010-1.44zm5.278 0a.719.719 0 110 1.44.719.719 0 110-1.44zM8.44 11.204A1.44 1.44 0 007 12.644v6.718c0 .795.645 1.44 1.44 1.44.168 0 .33-.036.48-.09v-9.418a1.406 1.406 0 00-.48-.09zm1.44 0V21.76c0 .793.646 1.44 1.44 1.44h10.557c.793 0 1.44-.647 1.44-1.44V11.204H9.878zm14.876 0c-.169 0-.33.035-.48.09v9.418c.15.052.311.09.48.09a1.44 1.44 0 001.44-1.44v-6.719a1.44 1.44 0 00-1.44-1.44zM11.8 24.16v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84zm5.759 0v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84z"/></svg>
						<span class="subscribe-to-podcast__link-text">Android</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://open.spotify.com/show/4ndjUXyL0hH1FXHgwIiTWU" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M16 4C9.383 4 4 9.383 4 16s5.383 12 12 12 12-5.383 12-12S22.617 4 16 4zm5.08 17.394a.781.781 0 01-1.086.217c-1.29-.86-3.477-1.434-5.303-1.434-1.937.002-3.389.477-3.403.482a.782.782 0 11-.494-1.484c.068-.023 1.71-.56 3.897-.562 1.826 0 4.365.492 6.171 1.696.36.24.457.725.217 1.085zm1.56-3.202a.895.895 0 01-1.234.286c-2.338-1.457-4.742-1.766-6.812-1.747-2.338.02-4.207.466-4.239.476a.895.895 0 11-.488-1.723c.145-.041 2.01-.5 4.564-.521 2.329-.02 5.23.318 7.923 1.995.419.26.547.814.286 1.234zm1.556-3.745a1.043 1.043 0 01-1.428.371c-2.725-1.6-6.039-1.94-8.339-1.942h-.033c-2.781 0-4.923.489-4.944.494a1.044 1.044 0 01-.474-2.031c.096-.023 2.385-.55 5.418-.55h.036c2.558.004 6.264.393 9.393 2.23.497.292.663.931.371 1.428z"/></svg>
						<span class="subscribe-to-podcast__link-text">Spotify</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M6.667 4a2.676 2.676 0 00-2.612 2.13v.003c-.036.172-.055.35-.055.534v18.666c0 .183.019.362.055.534v.003a2.676 2.676 0 002.076 2.075h.002c.172.036.35.055.534.055h18.666A2.676 2.676 0 0028 25.333V6.667a2.676 2.676 0 00-2.13-2.612h-.003A2.623 2.623 0 0025.333 4H6.667zM8 8h1.333C17.42 8 24 14.58 24 22.667V24h-2.667v-1.333c0-6.618-5.382-12-12-12H8V8zm0 5.333h1.333c5.146 0 9.334 4.188 9.334 9.334V24H16v-1.333A6.674 6.674 0 009.333 16H8v-2.667zM10 20a2 2 0 11-.001 4.001A2 2 0 0110 20z"/></svg>
						<span class="subscribe-to-podcast__link-text">RSS Feed</span>
					</a>
				</li>
					</ul>
	</div>
</section>


<div class="wp-block-msr-show-more">
	<div class="bg-neutral-100 p-5">
		<div class="show-more-show-less" data-mount="show-more-show-less">
			<div>
				<span>
					

<h2 class="wp-block-heading" id="transcript">Transcript&nbsp;</h2>



<p>[MUSIC]&nbsp;</p>



<p><strong>KATHLEEN SULLIVAN:</strong> Welcome to <em>AI Testing and Evaluation: Learnings from Science and Industry</em>. I&#8217;m your host, Kathleen Sullivan.</p>



<p>As generative AI continues to advance, Microsoft has gathered a range of experts—from genome editing to cybersecurity—to share how their fields approach evaluation and risk assessment. Our goal is to learn from their successes and their stumbles to move the science and practice of AI testing forward. In this series, we&#8217;ll explore how these insights might help guide the future of AI development, deployment, and responsible use.</p>



				</span>
				<span id="show-more-show-less-toggle-2" class="show-more-show-less-toggleable-content">
					



<p>[MUSIC ENDS]&nbsp;&nbsp;</p>



<p>For our introductory episode, I&#8217;m pleased to welcome Amanda Craig Deckard from Microsoft to discuss the company&#8217;s efforts to learn about testing in other sectors.&nbsp;&nbsp;</p>



<p>Amanda is senior director of public policy in the Office of Responsible AI, where she leads a team that works closely with engineers, researchers, and policy experts to help ensure AI is being developed and used responsibly. Their insights shape Microsoft&#8217;s contribution to public policy discussions on laws, norms, and standards for AI.&nbsp;&nbsp;</p>



<p>Amanda, welcome to the podcast.&nbsp;&nbsp;</p>



<p><strong>AMANDA CRAIG DECKARD:</strong> Thank you.&nbsp;&nbsp;</p>



<p><strong>SULLIVAN:</strong> Amanda, let&#8217;s give the listeners a little bit of your background. What&#8217;s your origin story? Can you talk to us a little bit about maybe how you started in tech? And I would love to also learn a little bit more about what your team does in the Office of Responsible AI.&nbsp;&nbsp;</p>



<p><strong>CRAIG DECKARD:</strong> Sure. Thank you. I&#8217;d say my [LAUGHS] path to tech, to Microsoft, as well, was a bit, like, circuitous, maybe. You know, I thought for the longest time I was going to be a journalist. I studied forced migration. I worked in a sort of state level sort of trial court in Indiana, a legal service provider in India, just to give you a bit of a flavor.</p>



<p>I made my way to Microsoft in 2014 and have been here since, working in cybersecurity public policy first and now in responsible AI. And the way that our Office of Responsible AI has really, sort of, structured itself is bringing together the kind of expertise to really work on defining policy and how to operationalize it at the same time.</p>



<p>And, you know, that means that we have been working through this, you know, real challenge of defining internal policy and practice, making sure that&#8217;s deeply grounded in the work of our colleagues at Microsoft Research, and then really closely working with engineering to make sure that we have the processes, that we have the tools, to implement that policy at scale.&nbsp;&nbsp;</p>



<p>And I&#8217;m really drawn to these kind of hard problems where they have the character of two things being true or there&#8217;s like, you know, real tension on both sides and in particular, in the context of those kinds of problems, roles in which, like, the whole job is actually just sitting with that tension, not necessarily, like, resolving it and expecting that you&#8217;re done.</p>



<p>And I think, really, there are two reasons why tech is so, kind of, representative of that kind of challenge that I&#8217;ve always found fascinating. You know, one is that, of course, tech is, sort of, ubiquitous. It&#8217;s really impacting so many people&#8217;s lives. But also, you know, because, as I think has become part of our vernacular now, but, you know, is not necessarily immediately intuitive, is like the fact that technology is both a tool and a weapon. And so that&#8217;s just, like, another reason why, you know, we have to continuously work through that tension and, sort of, like, sit with it, right, and even as tech evolves over time.</p>



<p><strong>SULLIVAN:</strong> You bring up such great points, and this field is not black and white. I think that even underscores, you know, this notion that you highlighted that it&#8217;s impacting everyone. And, you know, to set the stage for our listeners, last year, we pulled in a bunch of experts from cybersecurity, biotech, finance, and we ran this large workshop to study how they&#8217;re thinking about governance in those playbooks. And so I&#8217;d love to understand a little bit more about what sparked that effort—and, you know, there&#8217;s a piece of this which is really centered around testing—and to hear from you why the focus on testing is so important.&nbsp;</p>



<p><strong>CRAIG DECKARD:</strong> If I could rewind a little bit and give you a bit of history of how we even arrived at bringing these experts together, you know, we actually started on this journey in 2023. At that time, there were, like, a lot of these big questions swirling around about, you know, what did we need in terms of governance for AI? Of course, this was in the immediate aftermath of the ChatGPT sort of wave and everyone recognizing that, like, the technology was going to have a different level of impact in the near term. And so, you know, what do we need from governance? What do we need at the global level, in particular, of governance?&nbsp;&nbsp;</p>



<p>And so at the time, in early 2023 especially, there were a lot of attempts to sort of draw analogies to other global governance institutions in other domains. So we actually in 2023 brought together a different workshop than the one that you&#8217;re referring to specifically focused on testing last year. And we, kind of, had two big takeaways from that conversation.&nbsp;&nbsp;</p>



<p>One was, what are the actual functions of these institutions and how do they apply to AI? And, actually, one of the takeaways was they all sort of apply. [LAUGHS] There&#8217;s, like, a role for, you know, any of the functions, whether it be sort of driving consensus on research or building industry standards or managing, kind of, frontier risks, for thinking about how those might be needed in the AI context.&nbsp;&nbsp;</p>



<p>And one of the other big takeaways was that, you know, there are also limitations in these analogies. You know, each of the institutions grew up in its own, sort of, unique historical moment, like the one that we sit in with AI right now. And in each of those circumstances, they don&#8217;t exactly translate to this moment. And so, yeah, there was like this kind of, OK, we want to draw what we can from this conversation and then we also want to understand, what is also very important that&#8217;s just different for AI right now?&nbsp;&nbsp;</p>



<p>We published a <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://cdn-dynmedia-1.microsoft.com/is/content/microsoftcorp/microsoft/msc/documents/presentations/CSR/Global-Governance-Book-DIGITAL.pdf" target="_blank" rel="noreferrer noopener">book with the lessons from that conversation in 2023<span class="sr-only"> (opens in new tab)</span></a>. And then we actually went on a bit of a tour [LAUGHS] with that content where we had a number of roundtables actually all over the world where we gathered feedback on how those analogies were landing, how our takeaways were landing. And one of the things that we took from them was a gap that some of the participants saw in the analogies that we chose to focus on. So across multiple conversations, other domains kept being raised, like, why did you not also study pharmaceuticals? Why did you also not study cybersecurity, for example? And so that, you know, naturally got us thinking about what further lessons we could draw from <em>those</em> domains.&nbsp;</p>



<p>At the same time, though, we also saw a need to, again, go deeper than what we went and really, like, focus on a narrower problem. So that&#8217;s really what led us to trying to think about a more specific problem where we could think across levels of governance and bring in some of these other domains. And, you know, testing was top of mind. Continues to be a really important topic in the AI policy conversation right now, I think, for really good reason. A lot of policymakers are focused on, you know, what we need to do to,&nbsp;kind of, have there be sufficient trust, and testing is going to be a part of that—really better understand risk, enable everyone to be able to make more, kind of, risk-informed decisions, right. Testing is an important component for governance and AI and, of course, in all of these other domains, as well.&nbsp;&nbsp;</p>



<p>So I&#8217;ll just add the other, kind of, input into the process for this second round was exploring other analogies beyond those that we, kind of, got feedback on. And one of the early, kind of, examples of another domain that would be really worthwhile to study that came to mind from, sort of, just studying the literature was genome editing. &nbsp;</p>



<p>You know, genome editing was really interesting through the process of thinking about other kind of general-purpose technologies. We also arrived at nanoscience and brought those into the conversation.&nbsp;</p>



<p><strong>SULLIVAN:</strong> That&#8217;s great. I mean, actually, if you could double-click,&nbsp;I mean, you just named a number of industries. I&#8217;d love to just understand which of those worlds maybe feels the closest to what we&#8217;re wrestling with, with AI and maybe which is kind of the farthest off, and what makes them stand out to you?</p>



<p><strong>CRAIG DECKARD:</strong> Oh, such a good question. For this second round, we actually brought together eight different domains, right. And I think we actually thought we would come out of this conversation with some bit of clarity around, <em>Oh, if we just, sort of, take this approach for this domain or that domain, we&#8217;ll sort of have—at least for now—really solved part of the puzzle.</em> [LAUGHS] And, you know, our public policy team the day after the workshop, we had a, sort of, follow-on discussion, and the very first thing that we started with in that conversation was like, <em>OK, so which of these domains?</em> And fascinatingly, like, everyone was sort of like, <em>Ahh! </em>[LAUGHS] <em>None of them are applying perfectly</em>. I mean, this is also speaking to the limitations of analogies that we already acknowledged.&nbsp;&nbsp;</p>



<p>And also, you know, all of the experts from across these domains gave us really interesting insights into, sort of, the tradeoffs and the limitations and how they were working. None are really applying perfectly for us. But all of them do offer a thread of insight that is really useful for thinking about testing in AI, and there are some different dimensions that I think are really useful as framing for that.&nbsp;&nbsp;</p>



<p>I mean, one is just this horizontal-versus-vertical,<strong>&nbsp;</strong>kind of, difference in domains and, you know, the horizontal technology like genome editing or nanoscience&nbsp;just being inherently different and seemingly very similar to AI in that you want to be able to understand risks in the technology itself <em>and</em> there is just so much contextual, sort of, factor that matters in the application of those technologies for how the risk manifests that you really need to, kind of, do those two things at once—of understanding the technology but then really thinking about risk and governance in the context of application versus, you know, a context like or a domain like civil aviation or nuclear technology, for example.</p>



<p>You know, even in the workshop itself that we hosted late last year, where we brought together this second round of experts, it was really interesting. We actually started the conversation by trying to understand how those different domains defined risks, where they were able to set risk thresholds. That&#8217;s been such a part of the AI policy conversation in the last year. And, you know, it was really instructive that the more vertical domains were able to, sort of, snap to clearer answers much more quickly. [LAUGHS] But, like, the horizontal nanoscience and genome editing were not because it just depends, right. So anyway, the horizontal-vertical dimension seems like a really important one to draw from and apply to AI. </p>



<p>The couple of others that I would offer is just, you know, thinking about the different kinds of technologies. You know, obviously, there&#8217;s some of the domains that we studied that they&#8217;re just inherently, sort of, like, physical technologies … a mix of physical and digital or virtual in a lot of cases because all of these are, of course, applying digital technology. But like, you know, there is just a difference between something like an <em>airplane</em> or a <em>medical device</em> or, you know, the more kind of virtual or intangible sort of technologies even, you know, of course, AI and some of the other like cyber and genome editing but also like, you know, financial services having some of that quality. And again, I think the thing that&#8217;s interesting to us about AI is to think about AI and risk evaluation of AI as being, you know, having a large component of that being about the kind of virtual or intangible technology. <em>And also</em>, you know, there is a future of robotics where we might need to think about the, kind of, physical risk evaluation kind of work, as well.</p>



<p>And then the final thing I&#8217;d maybe say in terms of thinking about which domains have the lessons for AI that are most applicable is just how they&#8217;ve grappled with these different kind of governance questions. Things like how to turn the dial in terms of being more or less prescriptive on risk evaluation approaches, how they think about the balance of, kind of, pre-market versus post-market risk evaluation in testing, and what the tradeoffs have been there across domains has been really interesting to kind of tease out. And then also thinking about, sort of, who does what?</p>



<p>So, you know, in each of these different domains, it was interesting to hear about, like, you know, the role of industry, the role of governments, the role of third-party experts in designing evaluations and developing standards and actually doing the work, and, kind of, having the pull through of what it means for risk and governance decisions. There were, again, there was a variety of, sort of, approaches across these domains that I think were interesting for AI.</p>



<p><strong>SULLIVAN:</strong> You mentioned that there&#8217;s a number of different stakeholders to be considering across the board as we&#8217;re thinking about policy, as we&#8217;re thinking about regulation. Where can we collaborate more across industry? Is it academia? Regulators? Just, how can we move the needle faster?&nbsp;&nbsp;</p>



<p><strong>CRAIG DECKARD:</strong> I think all of the above [LAUGHTER] is needed. But it&#8217;s also really important to have all of that, kind of, expertise brought together, you know, and I think, you know, one of the things that we certainly heard from multiple of the domains, if not all of them, was that same actual interest and need and the same sort of ongoing work to try to figure that out.</p>



<p>You know, even where there had been progress in some of the other domains with bringing together, you know, some industry stakeholders or, you know, industry and government, there was still a desire to actually do more there. Like, if there was some progress in industry and government, the need was, <em>And more kind of cross-jurisdiction government conversation</em>, for example. Or some progress on, you know, within the industry but needing to, like, strengthen the partnership with academia, for example. So, you know, I think it speaks to, like, the quality of your question, to be honest, that, you know, all of these domains are actually still grappling with this and still seeing the need to grow in that direction more.&nbsp;&nbsp;</p>



<p>What I&#8217;d say about AI today is that we have made good progress with, you know, starting to build some industry partnerships. You know, we were a founding member of the <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.frontiermodelforum.org/" target="_blank" rel="noreferrer noopener">Frontier Model Forum, or FMF<span class="sr-only"> (opens in new tab)</span></a>, which has been a very useful place for us to work with some peers on really trying to bring forward some best practices that apply across our organizations. You know, there are other forums as well, like <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://mlcommons.org/" target="_blank" rel="noreferrer noopener">MLCommons<span class="sr-only"> (opens in new tab)</span></a>, where we&#8217;re working with others in industry and broader, sort of, academic and civil society communities. <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://partnershiponai.org/" target="_blank" rel="noreferrer noopener">Partnership on AI<span class="sr-only"> (opens in new tab)</span></a> is another one I think about that, kind of, fits that mold, as well, in a really positive way. And, like, there are a lot of different, sort of, governance needs to think through and where, you know, we can really think about bringing that expertise together is going to be so important.</p>



<p>I think about almost, like, in the near to mid-term, like three issues that we need to address in the AI, kind of, policy and testing context. One is just building kind of, like, a flexible framework that allows us to really build trust while we continue to advance the science and the standards. You know, we are going to need to do both at once. And so we need a flexible framework that enables that kind of agility, and advancing the science and the standards, that <em>is </em>going to be something that really demands that kind of cross-discipline or cross kind of expertise group coming together to work on that—researchers, academics, civil society, governments and, of course, industry.</p>



<p>And so I think that is, actually, the second problem is, like, how do we actually build the kind of forums and ways of working together, the public-private partnership kind of efforts that allow all of that expertise to come together and fit together over time, right. Because when these are really big, broad challenges, you kind of have to break them down incrementally, make progress on them, and then bring them back together. </p>



<p>And so I think about, like, one example that I, you know, really have been reflecting on lately is, you know, in the context of building standards, like, how do you do that, right? Again, standards are going to benefit from that whole community of expertise. And, you know, there are lots of different kinds of quote-unquote standards, though, right. You kind of have the “small <em>s</em>” industry standards. You have the kind of “big <em>S</em>” international standards, for example. And how do you, kind of, leverage one to accelerate the other, I think, is part of, like, how we need to work together within this ecosystem. And, like, I think what we and others have done in an organization like <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://c2pa.org/" target="_blank" rel="noreferrer noopener">C2PA [Coalition for Content Provenance and Authenticity]<span class="sr-only"> (opens in new tab)</span></a>, for example, where we&#8217;ve really built an industry specification but then built on that towards an international standard effort is one example that is interesting, right, to point to.</p>



<p>And then, you know, I actually think that bridges to the third thing that we need to do together within this whole community, which is, you know, really think again about how we manage the breadth of this challenge and opportunity of AI by thinking about this horizontal-vertical problem. And, you know, I think that&#8217;s where it&#8217;s not just the sort of tech industry, for example. It&#8217;s broader industry that&#8217;s going to be really applying this technology that needs to get involved in the conversation about not just, sort of, testing AI models, for example, but also testing how AI systems or applications are working in context. And so, yes, so much fun opportunity!&nbsp;</p>



<p>[MUSIC]&nbsp;</p>



<p><strong>SULLIVAN:</strong> Amanda, this was just fantastic. You&#8217;ve really set the stage for this podcast. And thank you so much for sharing your time and wisdom with us.&nbsp;&nbsp;</p>



<p><strong>CRAIG DECKARD:</strong> Thank you.&nbsp;</p>



<p><strong>SULLIVAN:</strong> And to our listeners, we&#8217;re so glad you joined us for this conversation. An exciting lineup of episodes are on the way, and we can&#8217;t wait to have you back for the next one.&nbsp;&nbsp;</p>



<p>[MUSIC FADES]&nbsp;</p>

				</span>
			</div>
			<button
				class="action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle"
				aria-expanded="false"
				data-show-less-text="Show less"
				type="button"
				aria-controls="show-more-show-less-toggle-2"
				aria-label="Show more content"
				data-alternate-aria-label="Show less content">
				Show more			</button>
		</div>
	</div>
</div>
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-science-and-industry/">AI Testing and Evaluation: Learnings from Science and Industry</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Learning from other domains to advance AI evaluation and testing</title>
		<link>https://www.microsoft.com/en-us/research/blog/learning-from-other-domains-to-advance-ai-evaluation-and-testing/</link>
		
		<dc:creator><![CDATA[Amanda Craig Deckard, Chad Atalla]]></dc:creator>
		<pubDate>Mon, 23 Jun 2025 16:35:06 +0000</pubDate>
				<category><![CDATA[Research Blog]]></category>
		<guid isPermaLink="false">https://www.microsoft.com/en-us/research/?p=1142208</guid>

					<description><![CDATA[<p>As generative AI becomes more capable and widely deployed, familiar questions from the governance of other transformative technologies have resurfaced. Which opportunities, capabilities, risks, and impacts should be evaluated? Who should conduct evaluations, and at what stages of the technology lifecycle? What tests or measurements should be used? And how can we know if the [&#8230;]</p>
<p>The post <a href="https://www.microsoft.com/en-us/research/blog/learning-from-other-domains-to-advance-ai-evaluation-and-testing/">Learning from other domains to advance AI evaluation and testing</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/RAI-BlogHeroFeature-1400x788-2.jpg" alt="Illustrated headshots of the Guests from the limited podcast series, AI Testing and Evaluation: Learnings from Science and Industry" class="wp-image-1143007" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/RAI-BlogHeroFeature-1400x788-2.jpg 1400w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/RAI-BlogHeroFeature-1400x788-2-300x169.jpg 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/RAI-BlogHeroFeature-1400x788-2-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/RAI-BlogHeroFeature-1400x788-2-768x432.jpg 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/RAI-BlogHeroFeature-1400x788-2-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/RAI-BlogHeroFeature-1400x788-2-655x368.jpg 655w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/RAI-BlogHeroFeature-1400x788-2-240x135.jpg 240w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/RAI-BlogHeroFeature-1400x788-2-640x360.jpg 640w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/RAI-BlogHeroFeature-1400x788-2-960x540.jpg 960w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/RAI-BlogHeroFeature-1400x788-2-1280x720.jpg 1280w" sizes="auto, (max-width: 1400px) 100vw, 1400px" /></figure>



<p>As generative AI becomes more capable and widely deployed, familiar questions from the governance of other transformative technologies have resurfaced. Which opportunities, capabilities, risks, and impacts should be evaluated? Who should conduct evaluations, and at what stages of the technology lifecycle? What tests or measurements should be used? And how can we know if the results are reliable?&nbsp;&nbsp;</p>



<p>Recent research and reports from <a href="https://www.microsoft.com/en-us/research/publication/evaluating-generative-ai-systems-is-a-social-science-measurement-challenge/" target="_blank" rel="noreferrer noopener">Microsoft<span class="sr-only"> (opens in new tab)</span></a>, the <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.aisi.gov.uk/research-agenda" target="_blank" rel="noreferrer noopener">UK AI Security Institute<span class="sr-only"> (opens in new tab)</span></a>, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.nytimes.com/2024/04/15/technology/ai-models-measurement.html" target="_blank" rel="noreferrer noopener"><em>The New York Times</em><span class="sr-only"> (opens in new tab)</span></a>, and <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.technologyreview.com/2025/05/08/1116192/how-to-build-a-better-ai-benchmark/" target="_blank" rel="noreferrer noopener"><em>MIT Technology Review</em><span class="sr-only"> (opens in new tab)</span></a><em> </em>have highlighted gaps in how we evaluate AI models and systems. These gaps also form foundational context for recent international expert consensus reports: the inaugural&nbsp;<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.gov.uk/government/publications/international-ai-safety-report-2025/international-ai-safety-report-2025" target="_blank" rel="noreferrer noopener"><em>International AI Safety Report</em><span class="sr-only"> (opens in new tab)</span></a> (2025) and the <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.scai.gov.sg/2025/scai2025-report" target="_blank" rel="noreferrer noopener"><em>Singapore Consensus</em><span class="sr-only"> (opens in new tab)</span></a> (2025). Closing these gaps at a pace that matches AI innovation will lead to more reliable evaluations that can help guide deployment decisions, inform policy, and deepen trust.&nbsp;</p>



<p>Today, we’re launching a limited-series podcast, <em><a href="https://www.microsoft.com/en-us/research/story/ai-testing-and-evaluation-learnings-from-science-and-industry/">AI Testing and Evaluation: Learnings from Science and Industry</a></em>, to share insights from domains that have grappled with testing and measurement questions. Across four episodes, host <a href="https://www.microsoft.com/en-us/research/people/kasull/?msockid=2c47c4e187ba63ee2e2ed011867d620c" target="_blank" rel="noreferrer noopener">Kathleen Sullivan</a> speaks with academic experts in <a href="https://www.microsoft.com/en-us/research/publication/learning-from-other-domains-to-advance-ai-evaluation-and-testing-governance-of-genome-edition-in-human-therapeutics-and-agricultural-applications/">genome editing</a>, <a href="https://www.microsoft.com/en-us/research/publication/learning-from-other-domains-to-advance-ai-evaluation-and-testing-cybersecurity-standards-and-testing-lessons-for-ai-safety-and-security/">cybersecurity</a>, <a href="https://www.microsoft.com/en-us/research/publication/learning-from-other-domains-to-advance-ai-evaluation-and-testing-the-history-and-evolution-of-testing-in-pharmaceutical-regulation/">pharmaceuticals</a>, and <a href="https://www.microsoft.com/en-us/research/publication/learning-from-other-domains-to-advance-ai-evaluation-and-testing-medical-device-testing-regulatory-requirements-evolution-and-lessons-for-ai-governance/">medical devices</a> to find out which technical and regulatory steps have helped to close evaluation gaps and earn public trust.</p>



<p>We’re also sharing written case studies from experts, along with top-level lessons we’re applying to AI. At the close of the podcast series, we’ll offer Microsoft’s deeper reflections on next steps toward more reliable and trustworthy approaches to AI evaluation.&nbsp;</p>



<h2 class="wp-block-heading" id="lessons-from-eight-case-studies">Lessons from eight case studies&nbsp;</h2>



<p>Our research on risk evaluation, testing, and assurance models in other domains began in December 2024, when <a href="https://www.microsoft.com/en-us/ai/responsible-ai">Microsoft’s Office of Responsible AI<span class="sr-only"> (opens in new tab)</span></a> gathered independent experts from the fields of civil aviation, cybersecurity, financial services, genome editing, medical devices, nanoscience, nuclear energy, and pharmaceuticals. In bringing this group together, we drew on our own learnings and feedback received on our e-book, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://blogs.microsoft.com/on-the-issues/2024/09/23/global-governance-goals-and-lessons-for-ai/" target="_blank" rel="noreferrer noopener"><em>Global Governance: Goals and Lessons for AI</em><span class="sr-only"> (opens in new tab)</span></a><em>, </em>in which we studied the higher-level goals and institutional approaches that had been leveraged for cross-border governance in the past.&nbsp;</p>



<p>While approaches to risk evaluation and testing vary significantly across the case studies, there was one consistent, top-level takeaway: evaluation frameworks always reflect trade-offs among different policy objectives, such as safety, efficiency, and innovation.&nbsp;&nbsp;</p>



<p>Experts across all eight fields noted that policymakers have had to weigh trade-offs in designing evaluation frameworks. These frameworks must account for both the limits of current science and the need for agility in the face of uncertainty. They likewise agreed that early design choices, often reflecting the “DNA” of the historical moment in which they’re made, as cybersecurity expert Stewart Baker described it, are important as they are difficult to scale down or undo later.&nbsp;</p>



<p>Strict, pre-deployment testing regimes—such as those used in civil aviation, medical devices, nuclear energy, and pharmaceuticals—offer strong safety assurances but can be resource-intensive and slow to adapt. These regimes often emerged in response to well-documented failures and are backed by decades of regulatory infrastructure and detailed technical standards.&nbsp;&nbsp;</p>



<p>In contrast, fields marked by dynamic and complex interdependencies between the tested system and its external environment—such as cybersecurity and bank stress testing—rely on more adaptive governance frameworks, where testing may be used to generate actionable insights about risk rather than primarily serve as a trigger for regulatory enforcement.&nbsp;&nbsp;</p>



<p>Moreover, in pharmaceuticals, where interdependencies are at play and there is emphasis on pre-deployment testing, experts highlighted a potential trade-off with post-market monitoring of downstream risks and efficacy evaluation.&nbsp;</p>



<p>These variations in approaches across domains—stemming from differences in risk profiles, types of technologies, maturity of the evaluation science, placement of expertise in the assessor ecosystem, and context in which technologies are deployed, among other factors—also inform takeaways for AI.</p>



<h2 class="wp-block-heading" id="applying-risk-evaluation-and-governance-lessons-to-ai">Applying risk evaluation and governance lessons to AI&nbsp;</h2>



<p>While no analogy perfectly fits the AI context, the genome editing and nanoscience cases offer interesting insights for general-purpose technologies like AI, where risks vary widely depending on how the technology is applied.&nbsp;&nbsp;</p>



<p>Experts highlighted the benefits of governance frameworks that are more flexible and tailored to specific use cases and application contexts. In these fields, it is challenging to define risk thresholds and design evaluation frameworks in the abstract. Risks become more visible and assessable once the technology is applied to a particular use case and context-specific variables are known.&nbsp;&nbsp;</p>



<p>These and other insights also helped us distill qualities essential to ensuring that testing is a reliable governance tool across domains, including:&nbsp;</p>



<ol start="1" class="wp-block-list">
<li><strong>Rigor </strong>in defining what is being examined and why it matters. This requires detailed <a href="https://www.microsoft.com/en-us/research/publication/evaluating-generative-ai-systems-is-a-social-science-measurement-challenge/">specification of what is being measured</a> and understanding how the deployment context may affect outcomes.</li>



<li><strong>Standardization </strong>of how tests should be conducted to achieve valid, reliable results. This requires establishing technical standards that provide methodological guidance and ensure quality and consistency.&nbsp;</li>



<li><strong>Interpretability </strong>of test results and how they inform risk decisions. This requires establishing expectations for evidence and improving literacy in how to understand, contextualize, and use test results—while remaining aware of their limitations.&nbsp;</li>
</ol>



<h2 class="wp-block-heading" id="toward-stronger-foundations-for-ai-testing">Toward stronger foundations for AI testing&nbsp;</h2>



<p>Establishing robust foundations for AI evaluation and testing requires effort to improve rigor, standardization, and interpretability—and to ensure that methods keep pace with rapid technological progress and evolving scientific understanding.&nbsp;&nbsp;</p>



<p>Taking lessons from other general-purpose technologies, this foundational work must also be pursued for both AI models and systems. While testing models will continue to be important, reliable evaluation tools that provide assurance for system performance will enable broad adoption of AI, including in high-risk scenarios. A strong feedback loop on evaluations of AI models and systems could not only accelerate progress on methodological challenges but also bring focus to which opportunities, capabilities, risks, and impacts are most appropriate and efficient to evaluate at what points along the AI development and deployment lifecycle.</p>



<h2 class="wp-block-heading" id="acknowledgements">Acknowledgements&nbsp;</h2>



<p>We would like to thank the following external experts who have contributed to our research program on lessons for AI testing and evaluation: Mateo Aboy, Paul Alp, Gerónimo Poletto Antonacci, Stewart Baker, Daniel Benamouzig, Pablo Cantero, Daniel Carpenter, Alta Charo, Jennifer Dionne, Andy Greenfield, Kathryn Judge, Ciaran Martin, and Timo Minssen.&nbsp;&nbsp;</p>



<h2 class="wp-block-heading" id="case-studies">Case studies&nbsp;</h2>



<p><strong>Civil aviation:</strong> <em><a href="https://www.microsoft.com/en-us/research/publication/learning-from-other-domains-to-advance-ai-evaluation-and-testing-testing-in-aircraft-design-and-manufacturing/">Testing in Aircraft Design and Manufacturing</a></em>, by Paul Alp&nbsp;</p>



<p><strong>Cybersecurity:</strong> <em><a href="https://www.microsoft.com/en-us/research/publication/learning-from-other-domains-to-advance-ai-evaluation-and-testing-cybersecurity-standards-and-testing-lessons-for-ai-safety-and-security/">Cybersecurity Standards and Testing—Lessons for AI Safety and Security</a></em>, by Stewart Baker&nbsp;</p>



<p><strong>Financial services (bank stress testing):</strong> <em><a href="https://www.microsoft.com/en-us/research/publication/learning-from-other-domains-to-advance-ai-evaluation-and-testing-the-evolving-use-of-bank-stress-test/">The Evolving Use of Bank Stress Tests</a></em>, by Kathryn Judge&nbsp;</p>



<p><strong>Genome editing:</strong> <em><a href="https://www.microsoft.com/en-us/research/publication/learning-from-other-domains-to-advance-ai-evaluation-and-testing-governance-of-genome-edition-in-human-therapeutics-and-agricultural-applications/">Governance of Genome Editing in Human Therapeutics and Agricultural Applications</a></em>, by Alta Charo and Andy Greenfield&nbsp;</p>



<p><strong>Medical devices:</strong> <em><a href="https://www.microsoft.com/en-us/research/publication/learning-from-other-domains-to-advance-ai-evaluation-and-testing-medical-device-testing-regulatory-requirements-evolution-and-lessons-for-ai-governance/">Medical Device Testing: Regulatory Requirements, Evolution and Lessons for AI Governance</a></em>,<em> </em>by Mateo Aboy and Timo Minssen&nbsp;</p>



<p><strong>Nanoscience:</strong> <em><a href="https://www.microsoft.com/en-us/research/publication/learning-from-other-domains-to-advance-ai-evaluation-and-testing-the-regulatory-landscape-of-nanoscience-and-nanotechnology-and-applications-to-future-ai-regulation/">The regulatory landscape of nanoscience and nanotechnology, and applications to future AI regulation</a></em>, by Jennifer Dionne&nbsp;</p>



<p><strong>Nuclear energy:</strong> <em><a href="https://www.microsoft.com/en-us/research/publication/learning-from-other-domains-to-advance-ai-evaluation-and-testing-testing-in-the-nuclear-industry/">Testing in the Nuclear Industry</a></em>, by Pablo Cantero and Gerónimo Poletto Antonacci&nbsp;</p>



<p><strong>Pharmaceuticals:</strong> <em><a href="https://www.microsoft.com/en-us/research/publication/learning-from-other-domains-to-advance-ai-evaluation-and-testing-the-history-and-evolution-of-testing-in-pharmaceutical-regulation/">The History and Evolution of Testing in Pharmaceutical Regulation</a></em>, by Daniel Benamouzig and Daniel Carpenter</p>
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/blog/learning-from-other-domains-to-advance-ai-evaluation-and-testing/">Learning from other domains to advance AI evaluation and testing</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Breaking bonds, breaking ground: Advancing the accuracy of computational chemistry with deep learning</title>
		<link>https://www.microsoft.com/en-us/research/blog/breaking-bonds-breaking-ground-advancing-the-accuracy-of-computational-chemistry-with-deep-learning/</link>
		
		<dc:creator><![CDATA[Rianne van den Berg, Jan Hermann, Christopher Bishop, Paola Gori Giorgi]]></dc:creator>
		<pubDate>Wed, 18 Jun 2025 10:01:47 +0000</pubDate>
				<category><![CDATA[Research Blog]]></category>
		<guid isPermaLink="false">https://www.microsoft.com/en-us/research/?p=1141626</guid>

					<description><![CDATA[<p>Microsoft researchers achieved a breakthrough in the accuracy of DFT, a method for predicting the properties of molecules and materials, by using deep learning. This work can lead to better batteries, green fertilizers, precision drug discovery, and more.</p>
<p>The post <a href="https://www.microsoft.com/en-us/research/blog/breaking-bonds-breaking-ground-advancing-the-accuracy-of-computational-chemistry-with-deep-learning/">Breaking bonds, breaking ground: Advancing the accuracy of computational chemistry with deep learning</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/DFT-Blog-BlogHeroFeature-1400x788-1.jpg" alt="Alt text: A dark blue, wavy surface with multiple colorful spheres placed on it. The spheres are in various colors including red, green, blue, yellow, purple, and orange. Each sphere is surrounded by small white particles that appear to be floating around them. The background is a gradient of dark teal to black." class="wp-image-1142136" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/DFT-Blog-BlogHeroFeature-1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/DFT-Blog-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/DFT-Blog-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/DFT-Blog-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/DFT-Blog-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/DFT-Blog-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/DFT-Blog-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/DFT-Blog-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/DFT-Blog-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/DFT-Blog-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w" sizes="auto, (max-width: 1400px) 100vw, 1400px" /></figure>



<p>We are excited to share our first big milestone in solving a grand challenge that has hampered the predictive power of computational chemistry, biochemistry, and materials science for decades. By using a scalable deep-learning approach and generating an unprecedented quantity of diverse, highly accurate data, we have achieved a breakthrough in the accuracy of density functional theory (DFT), the workhorse method that thousands of scientists use every year to simulate matter at the atomistic level. Within the region of chemical space represented in our large training dataset, our model reaches the accuracy required to reliably predict experimental outcomes, as assessed on the well-known benchmark dataset <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://pubmed.ncbi.nlm.nih.gov/28675494/" target="_blank" rel="noreferrer noopener">W4-17<span class="sr-only"> (opens in new tab)</span></a>. This removes a fundamental barrier to shifting the balance of molecule and material design from being driven by laboratory experiments to being driven by computational simulations. The implications for accelerating scientific discovery are far reaching, spanning applications from drugs to batteries and green fertilizers.</p>



<h2 class="wp-block-heading" id="what-is-dft">What is DFT?</h2>



<p>Molecules and materials are made of atoms, which are held together by their electrons. These electrons act as a glue, determining the stability and properties of the chemical structure. Accurately computing the strength and properties of the electron glue is essential for predicting whether a chemical reaction will proceed, whether a candidate drug molecule will bind to its target protein, whether a material is suitable for carbon capture, or if a flow battery can be optimized for renewable energy storage. Unfortunately, a brute-force approach amounts to solving the many-electron Schrödinger equation, which requires computation that scales exponentially with the number of electrons. Considering that an atom has dozens of electrons, and that molecules and materials have large numbers of atoms, we could easily end up waiting the age of the universe to complete our computation unless we restrict our attention to small systems with only a few atoms.</p>



<figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<iframe loading="lazy" title="What is Density Functional Theory (DFT)" width="500" height="281" src="https://www.youtube-nocookie.com/embed/wtB50-si1hI?feature=oembed&rel=0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div></figure>



<p>DFT, introduced by Walter Kohn and collaborators in 1964-1965, was a true scientific breakthrough, earning Kohn the Nobel Prize in Chemistry in 1998. DFT provides an extraordinary reduction in the computational cost of calculating the electron glue in an exact manner, from exponential to cubic, making it possible to perform calculations of practical value within seconds to hours.</p>



<div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-1 wp-block-buttons-is-layout-flex">
<div class="wp-block-button is-style-outline is-style-outline--3"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/articles/timeline-the-continuing-evolution-of-density-functional-theory/">DFT Timeline</a></div>
</div>



<h2 class="wp-block-heading" id="what-is-the-grand-challenge-in-dft">What is the grand challenge in DFT?&nbsp;</h2>



<p>But there is a catch: the exact reformulation has a small but crucial term—the exchange-correlation (XC) functional—which Kohn proved is universal (i.e., the same for all molecules and materials), but for which no explicit expression is known. For 60 years, people have designed practical approximations for the XC functional. The magazine <em>Science</em> dubbed the gold rush to design better XC models the “<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.science.org/doi/10.1126/science.1077710" target="_blank" rel="noreferrer noopener">pursuit of the Divine Functional<span class="sr-only"> (opens in new tab)</span></a>”. With time, these approximations have grown into a zoo of hundreds of different XC functionals from which users must choose, often using experimental data as a guide. Owing to the uniquely favorable computational cost of DFT, existing functionals have enabled scientists to gain extremely useful insight into a huge variety of chemical problems. However, the limited accuracy and scope of current XC functionals mean that DFT is still mostly used to interpret experimental results rather than predict them.</p>



<h2 class="wp-block-heading" id="why-is-it-important-to-increase-the-accuracy-of-dft">Why is it important to increase the accuracy of DFT?&nbsp;</h2>



<p>We can contrast the present state of computational chemistry with the state of aircraft engineering and design. Thanks to predictive simulations, aeronautical engineers no longer need to build and test thousands of prototypes to identify one viable design. However, this is exactly what we currently must do in molecular and materials sciences. We send thousands of potential candidates to the lab, because the accuracy of the computational methods is not sufficient to <em>predict</em> the experiments. To make a significant shift in the balance from laboratory to <em>in silico</em> experiments, we need to remove the fundamental bottleneck of the insufficient accuracy of present XC functionals. This amounts to bringing the error of DFT calculations with respect to experiments within <em>chemical accuracy</em>, which is around 1 kcal/mol for most chemical processes. Present approximations typically have errors that are 3 to 30 times larger.</p>



<figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<iframe loading="lazy" title="DFT for drug and material discovery" width="500" height="281" src="https://www.youtube-nocookie.com/embed/ckXVse-XZMQ?feature=oembed&rel=0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div></figure>



<h2 class="wp-block-heading" id="how-can-ai-make-a-difference">How can AI make a difference?&nbsp;</h2>



<p>AI can transform how we model molecules and materials with DFT by learning the XC functional directly from highly accurate data. The goal is to learn how the XC functional captures the complex relationship between its input, the electron density, and its output, the XC energy. You can think of the density like a glue, with regions of space where there is a lot of it and other regions with less of it. Traditionally, researchers have built XC functional approximations using the concept of the so-called <em>Jacob’s ladder</em>: a hierarchy of increasingly complex, hand-designed descriptors of the electron density. Including density descriptors from higher rungs of this ladder aims to improve accuracy, but it comes at the price of increased computational cost. Even the few attempts that use machine learning have stayed within this traditional paradigm, thereby taking an approach that is akin to what people were doing in computer vision and speech recognition before the deep-learning era. Progress toward better accuracy has stagnated for at least two decades with this approach.&nbsp;</p>



<p>Our project is driven by the intuition that a true deep learning approach—where relevant representations of the electron density are learned directly from data in a computationally scalable way—has the potential to revolutionize the accuracy of DFT, much like deep learning has transformed other fields.<strong> </strong>A significant challenge with going down this path, however, is that feature or representation learning is very data-hungry, and there is very little data around—too little to test this hypothesis reliably.</p>



<h2 class="wp-block-heading" id="what-have-we-done-in-this-milestone">What have we done in this milestone?</h2>



<p>The first step was generating data—a lot of it. This posed a major challenge, since the data must come from accurate solutions of the many-electron Schrödinger equation, which is precisely the prohibitively expensive problem that DFT is designed to replace. Fortunately, decades of progress in the scientific community have led to smarter, more efficient variants of brute-force methods, making it possible to compute reference data for <em>small</em> molecules at experimental accuracy. While these high-accuracy methods, also referred to as wavefunction methods, are far too costly for routine use in applications, we made a deliberate investment in them for this project. The reason? The upfront cost of generating high-quality training data is offset by the long-term benefit of enabling vast numbers of industrially relevant applications with cost effective DFT using the trained XC functional. Crucially, we rely on the ability of DFT—and our learned XC functional—to generalize from high-accuracy data for small systems to larger, more complex molecules.&nbsp;</p>



<p>There are many different high-accuracy wavefunction methods, each tailored to different regions of chemical space. However, their use at scale is not well established, as they require extensive expertise—small methodological choices can significantly affect accuracy at the level that we target. We therefore joined forces with <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.une.edu.au/staff-profiles/science-and-technology/amir-karton" target="_blank" rel="noreferrer noopener">Prof. Amir Karton<span class="sr-only"> (opens in new tab)</span></a> from the University of New England, Australia, a world-leading expert who developed widely recognized benchmark datasets for a fundamental thermochemical property: atomization energy—the energy required to break all bonds in a molecule and separate it into individual atoms. To create a training dataset of atomization energies at unprecedented scale, our team at Microsoft built a scalable pipeline to produce highly diverse molecular structures. Using these structures and substantial Azure compute resources via Microsoft’s <a href="https://www.microsoft.com/en-us/research/collaboration/accelerating-foundation-models-research/">Accelerating Foundation Models Research program<span class="sr-only"> (opens in new tab)</span></a>, Prof. Karton applied a high-accuracy wavefunction method to compute the corresponding energy labels. The result is a <a href="https://www.microsoft.com/en-us/research/publication/accurate-chemistry-collection-coupled-cluster-atomization-energies-for-broad-chemical-space/">dataset<span class="sr-only"> (opens in new tab)</span></a> two orders of magnitude larger than previous efforts. We are <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="http://aka.ms/MSR-ACC" target="_blank" rel="noreferrer noopener">releasing a large part of this dataset<span class="sr-only"> (opens in new tab)</span></a> to the scientific community.</p>



<p>Data generation was only half of the challenge. We also needed to design a dedicated deep-learning architecture for the XC functional—one that is both computationally scalable and capable of learning meaningful representations from electron densities to accurately predict the XC energy. Our team of machine learning specialists, assisted by DFT experts, introduced a series of innovations that solve these and other challenges inherent to this complex learning problem. The result is <a href="https://www.microsoft.com/en-us/research/publication/accurate-and-scalable-exchange-correlation-with-deep-learning/"><strong>Skala</strong>, an XC functional that generalizes to unseen molecules, reaching the accuracy needed to predict experiments</a>. This demonstrates for the first time that deep learning can truly disrupt DFT: reaching experimental accuracy does not require the computationally expensive hand-designed features of Jacob’s ladder. Instead, we can retain the original computational complexity of DFT while allowing the XC functional to learn how to extract meaningful features and predict accurate energies.</p>



<figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1400" height="391" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/DFT_combined-figure.png" alt="We compare the accuracy of Skala against the best existing functionals of varying computational cost. The prediction errors are evaluated on two well-known public benchmark datasets: the W4-17 dataset for atomization energies (y axis, mean absolute error) and the GMTKN55 dataset for general main-group chemistry (x axis, weighted total mean absolute deviation, or WTMAD-2 for short). Skala achieves near "chemical accuracy" (1 kcal/mol) on atomization energies. This is the accuracy required for predictive modeling of laboratory experiments, which, to date, no existing functional has reached. Skala works especially well on the “single reference” subset of this dataset, reaching a groundbreaking 0.85 kcal/mol. On the GMTKN55 dataset, Skala shows competitive accuracy to the best-performing hybrid functionals, at a lower cost." class="wp-image-1142366" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/DFT_combined-figure.png 1400w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/DFT_combined-figure-300x84.png 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/DFT_combined-figure-1024x286.png 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/DFT_combined-figure-768x214.png 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/DFT_combined-figure-240x67.png 240w" sizes="auto, (max-width: 1400px) 100vw, 1400px" /><figcaption class="wp-element-caption">We compare the accuracy of Skala against the best existing functionals of varying computational cost. The prediction errors are evaluated on two well-known public benchmark datasets: the W4-17 dataset for atomization energies (y axis, mean absolute error) and the GMTKN55 dataset for general main-group chemistry (x axis, weighted total mean absolute deviation, or WTMAD-2 for short). Skala achieves near &#8220;chemical accuracy&#8221; (1 kcal/mol) on atomization energies. This is the accuracy required for predictive modeling of laboratory experiments, which, to date, no existing functional has reached. Skala works especially well on the “single reference” subset of this dataset, reaching a groundbreaking 0.85 kcal/mol. On the GMTKN55 dataset, Skala shows competitive accuracy to the best-performing hybrid functionals, at a lower cost.</figcaption></figure>



<blockquote class="wp-block-quote is-style-spectrum is-layout-flow wp-block-quote-is-layout-flow">
<p>&#8220;<em>Skala is a new density functional for the exchange-correlation energy that employs meta-GGA ingredients plus D3 dispersion and machine-learned nonlocal features of the electron density. Some exact constraints were imposed, and some others “emerge” from the fitting to about 150,000 accurate energy differences for sp molecules and atoms. Skala achieves high, hybrid-like accuracy on a large and diverse data set of properties of main group molecules, which has no overlap with its training set. The computational cost of Skala is higher than that of the r2SCAN meta-GGA for small molecules, but about the same for systems with 1,000 or more occupied orbitals. Its cost seems to be only 10% of the cost of standard hybrids and 1% of the cost of local hybrids. Developed by a Microsoft team of density functional theorists and deep-learning experts, Skala could be the first machine-learned density functional to compete with existing functionals for wide use in computational chemistry, and a sign of things to come in that and related fields. Skala learned from big data and was taught by insightful human scientists.”</em></p>
<cite><em>— John P. Perdew, Professor of Physics, School of Science and Engineering, Tulane University</em></cite></blockquote>



<p>This first milestone was achieved for a challenging property in a specific region of chemical space—atomization energies of main group molecules—for which we generated our initial large batch of high-accuracy training data. Building on this foundation, we have started to expand our training dataset to cover a broader range of general chemistry, using our scalable in-house data generation pipeline. With the first small batch of training data beyond atomization energies, we have already extended the accuracy of our model, making it competitive with the best existing XC functionals across a wider spectrum of main group chemistry. This motivates us to continue growing our high-accuracy data generation campaign, engaging with external experts such as Prof. Amir Karton, who noted, “After years of benchmarking DFT methods against experimental accuracy, this is the first time I’ve witnessed such an unprecedented leap in the accuracy–cost trade-off. It is genuinely exciting to see how the creation of our new dataset has enabled these groundbreaking results — opening up a path for transformative advances across chemical, biochemical, and materials research.”</p>



<figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<iframe loading="lazy" title="Deep learning for DFT" width="500" height="281" src="https://www.youtube-nocookie.com/embed/Zzt3h10KLp4?feature=oembed&rel=0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div></figure>



<h2 class="wp-block-heading" id="advancing-computational-chemistry-together">Advancing computational chemistry together</h2>



<p>We are excited to work closely with the global computational chemistry community to accelerate progress for all and look forward to openly releasing our first XC functional in the near future.&nbsp;</p>



<blockquote class="wp-block-quote is-style-spectrum is-layout-flow wp-block-quote-is-layout-flow">
<p>&#8220;<em>Density Functional Theory&nbsp;(DFT) and related technologies are a core Digital Chemistry technology supporting advancements in&nbsp;Merck’s&nbsp;diverse Life Science, Healthcare and Electronics businesses.&nbsp;However, the limitations of traditional DFT methods, which have persisted for the last 50 years, have hindered its full potential. Microsoft Research&#8217;s innovative approach to integrating deep learning represents a&nbsp;substantial leap, enhancing its accuracy, robustness, and scalability. We are&nbsp;looking forward&nbsp;to exploring&nbsp;how this can advance&nbsp;Digital Chemistry workflows&nbsp;and unlock new possibilities for the future, aligning with our commitment to developing advanced algorithms and technologies that propel scientific innovation at Merck.&#8221;</em></p>
<cite><em>— Jan Gerit Brandenburg – Director for Digital Chemistry at Merck&nbsp;</em></cite></blockquote>



<blockquote class="wp-block-quote is-style-spectrum is-layout-flow wp-block-quote-is-layout-flow">
<p>&#8220;<em>We are entering a golden age for predictive and realistic simulations: very accurate electronic-structure calculations provide vast amounts of consistent data that can be used to train novel machine-learning architectures, delivering the holy grail of precision and computational efficiency.&#8221;</em></p>
<cite><em>— Professor Nicola Marzari, Chair of Theory and Simulation of Materials, EPFL and PSI</em></cite></blockquote>



<div style="height:10px" aria-hidden="true" class="wp-block-spacer"></div>



<p>We believe that our new functional can help unlock new opportunities for businesses and are eager to work together on real-world applications. <strong>Today, we are delighted to launch the DFT Research Early Access Program (DFT REAP) and welcome Flagship Pioneering as the first participant.</strong> This program is for companies and research labs to collaborate with us to accelerate innovation across many industries. To find out more about how to join this program please visit:&nbsp;<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://aka.ms/DFT-REAP" target="_blank" rel="noreferrer noopener">https://aka.ms/DFT-REAP<span class="sr-only"> (opens in new tab)</span></a>&nbsp;</p>



<blockquote class="wp-block-quote is-style-spectrum is-layout-flow wp-block-quote-is-layout-flow">
<p><em>“Microsoft’s effort to enhance the predictive power of computational chemistry reflects a bold but thoughtful step toward a simulation-first future. At Flagship, we believe that openly shared, foundational advances in science &#8211; like this leap forward in DFT accuracy &#8211; can serve as powerful enablers of innovation. These next-generation tools promise to accelerate discovery across a wide range of sectors, from therapeutics to materials science, by helping researchers navigate chemical and biological space with far greater precision and speed.”</em></p>
<cite><em>— </em>Junaid Bajwa, M.D., Senior Partner at Flagship Pioneering and Science Partner at Pioneering Intelligence</cite></blockquote>



<p>By making our work available to the scientific community, we hope to enable widespread testing and gather valuable feedback that will guide future improvements. For the first time, deep learning offers a clear and computationally scalable path to building an accurate, efficient, and broadly applicable model of the universal XC functional—one that could transform the computational design of molecules and materials.</p>



<div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-2 wp-block-buttons-is-layout-flex">
<div class="wp-block-button is-style-outline is-style-outline--4"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://aka.ms/SkalaDFT">Skala Paper</a></div>



<div class="wp-block-button is-style-outline is-style-outline--5"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://aka.ms/MSR-ACC-paper">Dataset Paper</a></div>



<div class="wp-block-button is-style-outline is-style-outline--6"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="http://aka.ms/MSR-ACC" target="_blank" rel="noreferrer noopener">Dataset</a></div>
</div>



<h2 class="wp-block-heading" id="acknowledgement">Acknowledgement</h2>



<p>This work is the product of a highly collaborative and interdisciplinary effort led by <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-ai-for-science/" target="_blank" rel="noreferrer noopener">Microsoft Research AI for Science</a>, in partnership with colleagues from Microsoft Research Accelerator, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://quantum.microsoft.com/" target="_blank" rel="noreferrer noopener">Microsoft Quantum</a> and the <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.une.edu.au/" target="_blank" rel="noreferrer noopener">University of New England</a>. The full author list includes <a href="https://www.microsoft.com/en-us/research/people/giulialuise/" target="_blank" rel="noreferrer noopener">Giulia Luise</a>, <a href="https://www.microsoft.com/en-us/research/people/chinweihuang/" target="_blank" rel="noreferrer noopener">Chin-Wei Huang</a>, <a href="https://www.microsoft.com/en-us/research/people/thijsvogels/" target="_blank" rel="noreferrer noopener">Thijs Vogels</a><a href="https://www.microsoft.com/en-us/research/people/derkkooi/" target="_blank" rel="noreferrer noopener">, Derk P. Kooi</a>, <a href="https://www.microsoft.com/en-us/research/people/sehlert/" target="_blank" rel="noreferrer noopener">Sebastian Ehlert</a>, <a href="https://www.microsoft.com/en-us/research/people/slanius/" target="_blank" rel="noreferrer noopener">Stephanie Lanius</a>, Klaas J. H. Giesbertz, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.une.edu.au/staff-profiles/science-and-technology/amir-karton" target="_blank" rel="noreferrer noopener">Amir Karton</a>, <a href="https://www.microsoft.com/en-us/research/people/dgunceler/" target="_blank" rel="noreferrer noopener">Deniz Gunceler</a>, <a href="https://www.microsoft.com/en-us/research/people/meganstanley/" target="_blank" rel="noreferrer noopener">Megan Stanley</a>, <a href="https://www.microsoft.com/en-us/research/people/wbruinsma/" target="_blank" rel="noreferrer noopener">Wessel P. Bruinsma</a>, <a href="https://www.microsoft.com/en-us/research/people/victorgar/" target="_blank" rel="noreferrer noopener">Victor Garcia Satorras</a>, <a href="https://www.microsoft.com/en-us/research/people/marwinsegler/" target="_blank" rel="noreferrer noopener">Marwin Segler</a>, <a href="https://www.microsoft.com/en-us/research/people/kenjitak/" target="_blank" rel="noreferrer noopener">Kenji Takeda</a>, <a href="https://www.microsoft.com/en-us/research/people/hul/" target="_blank" rel="noreferrer noopener">Lin Huang</a>, <a href="https://www.microsoft.com/en-us/research/people/weixinran/" target="_blank" rel="noreferrer noopener">Xinran Wei</a>, <a href="https://www.microsoft.com/en-us/research/people/josegarri/" target="_blank" rel="noreferrer noopener">José Garrido Torres</a>, Albert Katbashev, Rodrigo Chavez Zavaleta, Bálint Máté, Sékou-Oumar Kaba, Roberto Sordillo, Yingrong Chen, David B. Williams-Young, <a href="https://www.microsoft.com/en-us/research/people/cmbishop/" target="_blank" rel="noreferrer noopener">Christopher M. Bishop</a>, <a href="https://www.microsoft.com/en-us/research/people/janhermann/" target="_blank" rel="noreferrer noopener">Jan Hermann</a>, <a href="https://www.microsoft.com/en-us/research/people/rvandenberg/" target="_blank" rel="noreferrer noopener">Rianne van den Berg</a> and <a href="https://www.microsoft.com/en-us/research/people/pgorigiorgi/" target="_blank" rel="noreferrer noopener">Paola Gori Giorgi</a>. </p>
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/blog/breaking-bonds-breaking-ground-advancing-the-accuracy-of-computational-chemistry-with-deep-learning/">Breaking bonds, breaking ground: Advancing the accuracy of computational chemistry with deep learning</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>New methods boost reasoning in small and large language models</title>
		<link>https://www.microsoft.com/en-us/research/blog/new-methods-boost-reasoning-in-small-and-large-language-models/</link>
		
		<dc:creator><![CDATA[Li Lyna Zhang, Xian Zhang, Xueting Han, Dongdong Zhang]]></dc:creator>
		<pubDate>Tue, 17 Jun 2025 16:00:00 +0000</pubDate>
				<category><![CDATA[Research Blog]]></category>
		<guid isPermaLink="false">https://www.microsoft.com/en-us/research/?p=1141870</guid>

					<description><![CDATA[<p>New techniques are reimagining how LLMs reason. By combining symbolic logic, mathematical rigor, and adaptive planning, these methods enable models to tackle complex, real-world problems across a variety of fields.</p>
<p>The post <a href="https://www.microsoft.com/en-us/research/blog/new-methods-boost-reasoning-in-small-and-large-language-models/">New methods boost reasoning in small and large language models</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/NewMethods-BlogHeroFeature-1400x788-1.jpg" alt="The image shows a diagram illustrating the relationship between mathematical statements in natural language and formal language. On the left, there is a blue box labeled "Mathematical statement in natural language." An arrow points from this box to a central section containing four smaller boxes arranged in two rows. The top row contains "Formalization" and "Informalization," while the bottom row contains "Symbolic Equivalence" and "Semantic Consistency." An arrow points from this central section to a purple box on the right labeled "Mathematical statement in formal language." The background of the image transitions from blue on the left to purple on the right." class="wp-image-1142121" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/NewMethods-BlogHeroFeature-1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/NewMethods-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/NewMethods-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/NewMethods-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/NewMethods-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/NewMethods-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/NewMethods-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/NewMethods-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/NewMethods-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/NewMethods-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w" sizes="auto, (max-width: 1400px) 100vw, 1400px" /></figure>



<p>Artificial intelligence is advancing across a wide range of fields, with one of the most important developments being its growing capacity for reasoning. This capability could help AI becomes a reliable partner in critical domains like scientific research and healthcare.</p>



<p>To support this progress, we’ve identified three primary strategies to strengthen reasoning capabilities in both small and large language models: improve architectural design to boost performance in smaller models; incorporate mathematical reasoning techniques to increase reliability; and build stronger generalization capabilities to enable reasoning across a variety of fields.</p>



<h2 class="wp-block-heading" id="smarter-reasoning-in-smaller-models">Smarter reasoning in smaller models</h2>



<p>While language models trained on broad world knowledge hold great potential, they lack the ability to learn continuously and refine their understanding. This limitation becomes especially pronounced in smaller models, where limited capacity makes strong reasoning even harder.</p>



<p>The problem stems from how current language models operate. They rely on fast, pattern recognition-based responses that break down in complex scenarios. In contrast, people use deliberate, step-by-step reasoning, test different approaches, and evaluate outcomes. To address this gap, we’re building methods to enable stronger reasoning in smaller systems.</p>



<p><a href="https://www.microsoft.com/en-us/research/articles/li-zhang-rstar-math/" target="_blank" rel="noreferrer noopener">rStar-Math</a> is a method that uses Monte Carlo Tree Search (MCTS) to simulate deeper, more methodical reasoning in smaller models. It uses a three-step, self-improving cycle:&nbsp;</p>



<ul class="wp-block-list">
<li><strong>Problem decomposition</strong> breaks down complex mathematical problems into manageable steps, creating a thorough and accurate course of reasoning.</li>



<li><strong>Process preference model (PPM)</strong> trains small models to predict reward labels for each step, improving process-level supervision.</li>



<li><strong>Iterative refinement</strong> applies a four-round, self-improvement cycle in which updated strategy models and PPMs guide MCTS to improve performance.&nbsp;</li>
</ul>



<p>When tested on four small language models ranging from 1.5 billion to 7 billion parameters, rStar-Math achieved an average accuracy of 53% on the American Invitational Mathematics Examination (AIME)—performance that places it among the top 20% of high school competitors in the US.</p>



<figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1049" height="322" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-1.png" alt="Figure 1: A three-part diagram illustrating the rStar-Math framework. (a) Shows an MCTS-driven reasoning tree with Q-values and answer verification using PPM or Python; correct and incorrect steps are marked. (b) Depicts how Q-value filtering constructs per-step preference pairs from partial to full solutions. (c) Outlines four rounds of self-evolution, alternating between SLM and PPM improvements using terminal-guided and PPM-augmented MCTS." class="wp-image-1141894" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-1.png 1049w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-1-300x92.png 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-1-1024x314.png 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-1-768x236.png 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-1-240x74.png 240w" sizes="auto, (max-width: 1049px) 100vw, 1049px" /><figcaption class="wp-element-caption">Figure 1. The rStar-Math framework </figcaption></figure>



<p>Logic-RL is a reinforcement learning framework that strengthens logical reasoning through a practical system prompt and a structured reward function. By training models on logic puzzles, Logic-RL grants rewards only when both the reasoning process and the final answer meet strict formatting requirements. This prevents shortcuts and promotes analytical rigor.</p>



<p>Language models trained with Logic-RL demonstrate strong performance beyond logic puzzles, generalizing effectively to mathematical competition problems. On the AIME and AMC (American Mathematics Competitions) datasets, 7-billion-parameter models improved accuracy by 125% and 38%, respectively, compared with baseline models.</p>



<h2 class="wp-block-heading" id="building-reliable-mathematical-reasoning">Building reliable mathematical reasoning&nbsp;</h2>



<p>Mathematics poses a unique challenge for language models, which often struggle to meet its precision and rigor using natural language. To address this, we’re creating formal and symbolic methods to enable language models to adopt structured mathematical tools. The goal is to convert language model outputs into code based on the fundamental rules of arithmetic, like 1 + 1 = 2, allowing us to systematically verify accuracy.&nbsp;</p>



<p><a href="https://www.microsoft.com/en-us/research/publication/proving-olympiad-inequalities-by-synergizing-llms-and-symbolic-reasoning/" target="_blank" rel="noreferrer noopener">LIPS</a> (LLM-based Inequality Prover with Symbolic Reasoning) is a system that combines LLMs’ pattern recognition capabilities with symbolic reasoning. LIPS draws on the strategies participants in math competitions use in order to distinguish between tasks best suited to symbolic solvers (e.g., scaling) and those better handled by language models (e.g., rewriting). On 161 Olympiad-level problems, LIPS achieved state-of-the-art results without additional training data.</p>



<figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1295" height="426" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-2.png" alt="Figure 2: A three-part diagram showing the LIPS framework for inequality proof generation. On the left, a current inequality problem is transformed into new inequality subproblems via tactic generation using symbolic-based and LLM-generated rewriting methods. In the center, these new goals are filtered and ranked using LLM and symbolic methods. On the right, a ranked sequence of inequalities forms a complete proof, applying named tactics like Cauchy-Schwarz, AM-GM, and LLM simplification, ending with the original inequality verified." class="wp-image-1141898" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-2.png 1295w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-2-300x99.png 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-2-1024x337.png 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-2-768x253.png 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-2-240x79.png 240w" sizes="auto, (max-width: 1295px) 100vw, 1295px" /><figcaption class="wp-element-caption">Figure 2. An overview of LIPS</figcaption></figure>



<p>However, translating natural-language math problems into precise, machine-readable formats is a challenge. Our goal is to bridge the gap between the one-pass success rate, where the top-ranked generated result is correct, and the k-pass success rate, where at least one of the top <em>k</em> generated results is correct.</p>



<p>We developed a <a href="https://www.microsoft.com/en-us/research/publication/autoformalizing-mathematical-statements-by-symbolic-equivalence-and-semantic-consistency/">new framework</a> using two evaluation methods. <strong>Symbolic equivalence</strong> checks whether outputs are logically identical, while <strong>semantic consistency</strong> uses embedding similarity to detect subtle differences missed by symbolic checks.</p>



<p>When we evaluated this approach on the MATH and miniF2F datasets, which include problems from various math competitions, it improved accuracy by up to 1.35 times over baseline methods.</p>



<figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1271" height="377" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-3.png" alt="Figure 3: A flowchart illustrating the autoformalization framework. On the left, a natural language math statement is converted into a formal language theorem via an "Autoformalize" step. In the center, formal statements undergo symbolic equivalence checks, while informalized versions are evaluated for semantic consistency. Arrows represent symbolic and semantic equivalence, informalization, and scoring. On the right, validated formal statements are output, demonstrating multiple logically equivalent formulations. A legend explains arrow types for formalization, equivalence, and output scoring." class="wp-image-1141897" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-3.png 1271w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-3-300x89.png 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-3-1024x304.png 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-3-768x228.png 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-3-240x71.png 240w" sizes="auto, (max-width: 1271px) 100vw, 1271px" /><figcaption class="wp-element-caption">Figure 3. An overview of the auto-formalization framework</figcaption></figure>



<p>To address the shortage of high-quality training data, we developed a <a href="https://www.microsoft.com/en-us/research/publication/neuro-symbolic-data-generation-for-math-reasoning/" target="_blank" rel="noreferrer noopener">neuro-symbolic framework</a> that automatically generates diverse, well-structured math problems. Symbolic solvers create the problems, while language models translate them into natural language. This approach not only broadens training resources but also supports more effective instruction and evaluation of mathematical reasoning in language models.</p>



<figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1255" height="404" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-4.png" alt="Figure 4: A flowchart illustrating the neuro-symbolic data generation framework. It begins with a natural language math problem about a sandbox's perimeter. This is formalized into symbolic assertions, then mutated while preserving structure. The formal problem is solved and informalized into a new natural language Q&A about a garden's dimensions. The process continues with further mutation to generate problems of varying difficulty—examples include an easy question about a rectangle’s width and a medium one involving expressions for area." class="wp-image-1142036" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-4.png 1255w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-4-300x97.png 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-4-1024x330.png 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-4-768x247.png 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-4-240x77.png 240w" sizes="auto, (max-width: 1255px) 100vw, 1255px" /><figcaption class="wp-element-caption">Figure 4. An overview of the neuro-symbolic data generation framework </figcaption></figure>



<h2 class="wp-block-heading" id="boosting-generalization-across-domains">Boosting generalization across domains&nbsp;</h2>



<p>A key indicator of advanced AI is its ability to generalize—the ability to transfer reasoning skills across different domains. We found that training language models on math data significantly improved performance in coding, science, and other areas, revealing unexpected cross-domain benefits.&nbsp;</p>



<p>This discovery motivated us to develop <a href="https://www.microsoft.com/en-us/research/publication/chain-of-reasoning-towards-unified-mathematical-reasoning-in-large-language-models-via-a-multi-paradigm-perspective/">Chain-of-Reasoning</a> (CoR), an approach that unifies reasoning across natural language, code, and symbolic forms. CoR lets models blend these formats using natural language to frame context, code for precise calculations, and symbolic representations for abstraction. By adjusting prompts, CoR adapts both reasoning depth and paradigm diversity to match specific problem requirements.&nbsp;</p>



<p>Tests of CoR across five math datasets showed its ability to tackle both computational and proof-based problems, demonstrating strong general mathematical problem-solving skills.</p>



<figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1183" height="493" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-5.png" alt="Figure 5: Diagram illustrating three reasoning paradigms: (a) Single-paradigm reasoning, where all reasoning steps use the same medium (e.g., natural language, algorithms, or symbols); (b) Tool-integrated single-paradigm reasoning, where natural language drives reasoning, but code is used to solve specific sub-problems, with results reintegrated into the language-based reasoning; (c) CoR (multi-paradigm) reasoning framework, which enables reasoning across different paradigms with varying depths to handle diverse problem types, supported by examples." class="wp-image-1141896" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-5.png 1183w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-5-300x125.png 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-5-1024x427.png 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-5-768x320.png 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-5-240x100.png 240w" sizes="auto, (max-width: 1183px) 100vw, 1183px" /><figcaption class="wp-element-caption">Figure 5. CoR’s reasoning process under different types of methods</figcaption></figure>



<p>Current language models often rely on domain-specific solutions, limiting their flexibility across different types of problems. To move beyond this constraint, we developed <a href="https://www.microsoft.com/en-us/research/articles/cpl/" target="_blank" rel="noreferrer noopener">Critical Plan Step Learning</a> (CPL), an approach focused on high-level abstract planning that teaches models to identify key knowledge, break down problems, and make strategic decisions.&nbsp;</p>



<p>The technique draws on how people solve problems, by breaking them down, identifying key information, and recalling relevant knowledge—strategies we want language models to learn.&nbsp;</p>



<p>CPL combines two key components: <strong>plan-based MCTS</strong>, which searches multi-step solution paths and constructs planning trees, and <strong>step-APO</strong>, which learns preferences for strong intermediate steps while filtering out weak ones. This combination enhances reasoning and improves generalization across tasks, moving AI systems closer to the flexible thinking that characterizes human intelligence.</p>



<figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1238" height="585" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-6.png" alt="Figure 6: Illustration of CPL. Left: Plans represent abstract thinking for problem-solving, which allows for better generalization, whereas task-specific solutions often limit it. Right: CPL searches within the action space on high-level abstract plans using MCTS and obtains advantage estimates for step-level preferences. CPL can then identify and learn critical steps that provide a distinct advantage over others." class="wp-image-1141895" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-6.png 1238w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-6-300x142.png 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-6-1024x484.png 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-6-768x363.png 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-6-240x113.png 240w" sizes="auto, (max-width: 1238px) 100vw, 1238px" /><figcaption class="wp-element-caption">Figure 6. Overview of the CPL framework</figcaption></figure>



<h2 class="wp-block-heading" id="looking-ahead-next-steps-in-ai-reasoning">Looking ahead: Next steps in AI reasoning</h2>



<p>From building reliable math solvers to unifying reasoning approaches, researchers are redefining how language models approach complex tasks. Their work sets the stage for more capable and versatile AI systems—applicable to education, science, healthcare, and beyond. Despite these advances, hallucinations and imprecise logic continue to pose risks in critical fields like medicine and scientific research, where accuracy is essential.</p>



<p>These challenges are driving the team’s exploration of additional tools and frameworks to improve language model reasoning. This includes <a href="https://www.microsoft.com/en-us/research/publication/autoverus-automated-proof-generation-for-rust-code/">AutoVerus</a> for automated proof generation in Rust code, <a href="https://www.microsoft.com/en-us/research/publication/automated-proof-generation-for-rust-code-via-self-evolution/">SAFE</a> for addressing data scarcity in Rust formal verification, and <a href="https://www.microsoft.com/en-us/research/publication/alchemy-amplifying-theorem-proving-capability-through-symbolic-mutation/">Alchemy</a>, which uses symbolic mutation to improve neural theorem proving.</p>



<p>Together, these technologies represent important progress toward building trustworthy, high-performing reasoning models and signal a broader shift toward addressing some of AI&#8217;s current limitations.</p>
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/blog/new-methods-boost-reasoning-in-small-and-large-language-models/">New methods boost reasoning in small and large language models</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>How AI is reshaping the future of healthcare and medical research</title>
		<link>https://www.microsoft.com/en-us/research/podcast/how-ai-is-reshaping-the-future-of-healthcare-and-medical-research/</link>
		
		<dc:creator><![CDATA[Peter Lee, Bill Gates, S&eacute;bastien Bubeck]]></dc:creator>
		<pubDate>Thu, 12 Jun 2025 16:17:04 +0000</pubDate>
				<category><![CDATA[Microsoft Research Podcast]]></category>
		<guid isPermaLink="false">https://www.microsoft.com/en-us/research/?p=1141685</guid>

					<description><![CDATA[<p>Technologists Bill Gates and Sébastien Bubeck discuss the state of generative AI in medicine, how access to “medical intelligence” might help empower people across healthcare, and how AI’s accelerating improvements are likely to affect both delivery and discovery.</p>
<p>The post <a href="https://www.microsoft.com/en-us/research/podcast/how-ai-is-reshaping-the-future-of-healthcare-and-medical-research/">How AI is reshaping the future of healthcare and medical research</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<iframe loading="lazy" title="How AI is reshaping the future of healthcare and medical research" width="500" height="281" src="https://www.youtube-nocookie.com/embed/N0w9uO7kH80?feature=oembed&rel=0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div></figure>


<div class="wp-block-msr-podcast-container my-4">
	<iframe loading="lazy" src="https://player.blubrry.com/?podcast_id=146193015&modern=1" class="podcast-player" frameborder="0" height="164px" width="100%" scrolling="no" title="Podcast Player"></iframe>
</div>



<p>In November 2022, OpenAI’s ChatGPT kick-started a new era in AI. This was followed less than a half year later by the release of GPT-4. In the months leading up to GPT-4&#8217;s public release, Peter Lee, president of Microsoft Research, cowrote a book full of optimism for the potential of advanced AI models to transform the world of healthcare. What has happened since? In this special podcast series, <em>The AI Revolution in Medicine, Revisited</em>, Lee revisits the book, exploring how patients, providers, and other medical professionals are experiencing and using generative AI today while examining what he and his coauthors got right—and what they didn’t foresee.&nbsp;</p>



<p>In this episode, Microsoft co-founder and Gates Foundation Chair<em> </em><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.gatesnotes.com/meet-bill" target="_blank" rel="noreferrer noopener">Bill Gates<span class="sr-only"> (opens in new tab)</span></a> and OpenAI research lead <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="http://sbubeck.com/" target="_blank" rel="noreferrer noopener">Sébastien Bubeck<span class="sr-only"> (opens in new tab)</span></a>, formerly Microsoft’s VP of AI, join Lee to discuss how they’re seeing generative AI’s adoption in healthcare unfolding globally and the opportunities for further adoption, such as the development of proper benchmarks. Together, the three use insights drawn from unparalleled access to the continuing evolution of AI to explore the yet untapped potential of the technology to empower clinicians and patients alike and talk about the urgency to create AI-driven healthcare systems in underserved countries. They also reflect on the distinction between healthcare <em>delivery</em> and healthcare <em>discovery</em> and how the type and pace of change brought on by AI may differ for each.&nbsp;</p>



<div class="wp-block-group msr-pattern-link-list is-layout-flow wp-block-group-is-layout-flow">
<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading h5" id="learn-more-1">Learn more:</h2>



<ul class="wp-block-list list-unstyled">
<li><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.gatesfoundation.org/" target="_blank" rel="noreferrer noopener">Gates Foundation<span class="sr-only"> (opens in new tab)</span></a></li>



<li><a href="https://www.microsoft.com/en-us/research/publication/sparks-of-artificial-general-intelligence-early-experiments-with-gpt-4/?msockid=35739e94ab6c69d41b738b93aa076831">Sparks of Artificial General Intelligence: Early experiments with GPT-4</a> (Bubeck, Lee)&nbsp;<br>Publication | March 2023</li>



<li><a href="https://www.microsoft.com/en-us/research/blog/predicting-and-explaining-ai-model-performance-a-new-approach-to-evaluation/?msockid=35739e94ab6c69d41b738b93aa076831" target="_blank" rel="noreferrer noopener">Predicting and explaining AI model performance: A new approach to evaluation</a><br>Microsoft Research Blog | May 2025</li>



<li><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://openai.com/index/healthbench/" target="_blank" rel="noreferrer noopener">Introducing HealthBench: An evaluation for AI systems and human health<span class="sr-only"> (opens in new tab)</span></a><br>OpenAI publication | May 2025</li>



<li><a href="https://www.microsoft.com/en-us/research/publication/the-ai-revolution-in-medicine-gpt-4-and-beyond/" target="_blank" rel="noreferrer noopener">The AI Revolution in Medicine: GPT-4 and Beyond</a><br>Book | Peter Lee, Carey Goldberg, Isaac Kohane | April 2023</li>
</ul>
</div>



<div style="height:25px" aria-hidden="true" class="wp-block-spacer"></div>



<section class="wp-block-msr-subscribe-to-podcast subscribe-to-podcast">
	<div class="subscribe-to-podcast__inner border-top border-bottom border-width-2">
		<h2 class="h5 subscribe-to-podcast__heading">
			Subscribe to the <a href="https://www.microsoft.com/en-us/research/podcast">Microsoft Research Podcast</a>:		</h2>
		<ul class="subscribe-to-podcast__list list-unstyled">
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://itunes.apple.com/us/podcast/microsoft-research-a-podcast/id1318021537?mt=2" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="black" viewBox="0 0 32 32">  <path d="M7.12 0c-3.937-0.011-7.131 3.183-7.12 7.12v17.76c-0.011 3.937 3.183 7.131 7.12 7.12h17.76c3.937 0.011 7.131-3.183 7.12-7.12v-17.76c0.011-3.937-3.183-7.131-7.12-7.12zM15.817 3.421c3.115 0 5.932 1.204 8.079 3.453 1.631 1.693 2.547 3.489 3.016 5.855 0.161 0.787 0.161 2.932 0.009 3.817-0.5 2.817-2.041 5.339-4.317 7.063-0.812 0.615-2.797 1.683-3.115 1.683-0.12 0-0.129-0.12-0.077-0.615 0.099-0.792 0.192-0.953 0.64-1.141 0.713-0.296 1.932-1.167 2.677-1.911 1.301-1.303 2.229-2.932 2.677-4.719 0.281-1.1 0.244-3.543-0.063-4.672-0.969-3.595-3.907-6.385-7.5-7.136-1.041-0.213-2.943-0.213-4 0-3.636 0.751-6.647 3.683-7.563 7.371-0.245 1.004-0.245 3.448 0 4.448 0.609 2.443 2.188 4.681 4.255 6.015 0.407 0.271 0.896 0.547 1.1 0.631 0.447 0.192 0.547 0.355 0.629 1.14 0.052 0.485 0.041 0.62-0.072 0.62-0.073 0-0.62-0.235-1.199-0.511l-0.052-0.041c-3.297-1.62-5.407-4.364-6.177-8.016-0.187-0.943-0.224-3.187-0.036-4.052 0.479-2.323 1.396-4.135 2.921-5.739 2.199-2.319 5.027-3.543 8.172-3.543zM16 7.172c0.541 0.005 1.068 0.052 1.473 0.14 3.715 0.828 6.344 4.543 5.833 8.229-0.203 1.489-0.713 2.709-1.619 3.844-0.448 0.573-1.537 1.532-1.729 1.532-0.032 0-0.063-0.365-0.063-0.803v-0.808l0.552-0.661c2.093-2.505 1.943-6.005-0.339-8.296-0.885-0.896-1.912-1.423-3.235-1.661-0.853-0.161-1.031-0.161-1.927-0.011-1.364 0.219-2.417 0.744-3.355 1.672-2.291 2.271-2.443 5.791-0.348 8.296l0.552 0.661v0.813c0 0.448-0.037 0.807-0.084 0.807-0.036 0-0.349-0.213-0.683-0.479l-0.047-0.016c-1.109-0.885-2.088-2.453-2.495-3.995-0.244-0.932-0.244-2.697 0.011-3.625 0.672-2.505 2.521-4.448 5.079-5.359 0.547-0.193 1.509-0.297 2.416-0.281zM15.823 11.156c0.417 0 0.828 0.084 1.131 0.24 0.645 0.339 1.183 0.989 1.385 1.677 0.62 2.104-1.609 3.948-3.631 3.005h-0.015c-0.953-0.443-1.464-1.276-1.475-2.36 0-0.979 0.541-1.828 1.484-2.328 0.297-0.156 0.709-0.235 1.125-0.235zM15.812 17.464c1.319-0.005 2.271 0.463 2.625 1.291 0.265 0.62 0.167 2.573-0.292 5.735-0.307 2.208-0.479 2.765-0.905 3.141-0.589 0.52-1.417 0.667-2.209 0.385h-0.004c-0.953-0.344-1.157-0.808-1.553-3.527-0.452-3.161-0.552-5.115-0.285-5.735 0.348-0.823 1.296-1.285 2.624-1.291z"/></svg>
						<span class="subscribe-to-podcast__link-text">Apple Podcasts</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://subscribebyemail.com/www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M6.4 6a2.392 2.392 0 00-2.372 2.119L16 15.6l11.972-7.481A2.392 2.392 0 0025.6 6H6.4zM4 10.502V22.8a2.4 2.4 0 002.4 2.4h19.2a2.4 2.4 0 002.4-2.4V10.502l-11.365 7.102a1.2 1.2 0 01-1.27 0L4 10.502z"/></svg>
						<span class="subscribe-to-podcast__link-text">Email</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://subscribeonandroid.com/www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M12.414 4.02c-.062.012-.126.023-.18.06a.489.489 0 00-.12.675L13.149 6.3c-1.6.847-2.792 2.255-3.18 3.944h13.257c-.388-1.69-1.58-3.097-3.179-3.944l1.035-1.545a.489.489 0 00-.12-.675.492.492 0 00-.675.135l-1.14 1.68a7.423 7.423 0 00-2.55-.45c-.899 0-1.758.161-2.549.45l-1.14-1.68a.482.482 0 00-.494-.195zm1.545 3.824a.72.72 0 110 1.44.72.72 0 010-1.44zm5.278 0a.719.719 0 110 1.44.719.719 0 110-1.44zM8.44 11.204A1.44 1.44 0 007 12.644v6.718c0 .795.645 1.44 1.44 1.44.168 0 .33-.036.48-.09v-9.418a1.406 1.406 0 00-.48-.09zm1.44 0V21.76c0 .793.646 1.44 1.44 1.44h10.557c.793 0 1.44-.647 1.44-1.44V11.204H9.878zm14.876 0c-.169 0-.33.035-.48.09v9.418c.15.052.311.09.48.09a1.44 1.44 0 001.44-1.44v-6.719a1.44 1.44 0 00-1.44-1.44zM11.8 24.16v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84zm5.759 0v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84z"/></svg>
						<span class="subscribe-to-podcast__link-text">Android</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://open.spotify.com/show/4ndjUXyL0hH1FXHgwIiTWU" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M16 4C9.383 4 4 9.383 4 16s5.383 12 12 12 12-5.383 12-12S22.617 4 16 4zm5.08 17.394a.781.781 0 01-1.086.217c-1.29-.86-3.477-1.434-5.303-1.434-1.937.002-3.389.477-3.403.482a.782.782 0 11-.494-1.484c.068-.023 1.71-.56 3.897-.562 1.826 0 4.365.492 6.171 1.696.36.24.457.725.217 1.085zm1.56-3.202a.895.895 0 01-1.234.286c-2.338-1.457-4.742-1.766-6.812-1.747-2.338.02-4.207.466-4.239.476a.895.895 0 11-.488-1.723c.145-.041 2.01-.5 4.564-.521 2.329-.02 5.23.318 7.923 1.995.419.26.547.814.286 1.234zm1.556-3.745a1.043 1.043 0 01-1.428.371c-2.725-1.6-6.039-1.94-8.339-1.942h-.033c-2.781 0-4.923.489-4.944.494a1.044 1.044 0 01-.474-2.031c.096-.023 2.385-.55 5.418-.55h.036c2.558.004 6.264.393 9.393 2.23.497.292.663.931.371 1.428z"/></svg>
						<span class="subscribe-to-podcast__link-text">Spotify</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M6.667 4a2.676 2.676 0 00-2.612 2.13v.003c-.036.172-.055.35-.055.534v18.666c0 .183.019.362.055.534v.003a2.676 2.676 0 002.076 2.075h.002c.172.036.35.055.534.055h18.666A2.676 2.676 0 0028 25.333V6.667a2.676 2.676 0 00-2.13-2.612h-.003A2.623 2.623 0 0025.333 4H6.667zM8 8h1.333C17.42 8 24 14.58 24 22.667V24h-2.667v-1.333c0-6.618-5.382-12-12-12H8V8zm0 5.333h1.333c5.146 0 9.334 4.188 9.334 9.334V24H16v-1.333A6.674 6.674 0 009.333 16H8v-2.667zM10 20a2 2 0 11-.001 4.001A2 2 0 0110 20z"/></svg>
						<span class="subscribe-to-podcast__link-text">RSS Feed</span>
					</a>
				</li>
					</ul>
	</div>
</section>


<div class="wp-block-msr-show-more">
	<div class="bg-neutral-100 p-5">
		<div class="show-more-show-less" data-mount="show-more-show-less">
			<div>
				<span>
					

<h2 class="wp-block-heading" id="transcript">Transcript</h2>



<p>[MUSIC]  &nbsp;&nbsp;&nbsp;</p>



<p>[BOOK PASSAGE] &nbsp;</p>



<p><strong>PETER LEE: </strong>“In ‘The Little Black Bag,’ a classic science fiction story, a high-tech doctor&#8217;s kit of the future is accidentally transported back to the 1950s, into the shaky hands of a washed-up, alcoholic doctor. The ultimate medical tool, it redeems the doctor wielding it, allowing him to practice gratifyingly heroic medicine. … The tale ends badly for the doctor and his treacherous assistant, but it offered a picture of how advanced technology could transform medicine—powerful when it was written nearly 75 years ago and still so today.&nbsp;What would be the Al equivalent of that little black bag? At this moment when new capabilities are emerging, how do we imagine them into medicine?”&nbsp;&nbsp;</p>



<p>[END OF BOOK PASSAGE]   &nbsp;</p>



<p>[THEME MUSIC]   &nbsp;</p>



<p>This is <em>The AI Revolution in Medicine, Revisited</em>. I’m your host, Peter Lee.  &nbsp;</p>



<p>Shortly after OpenAI’s GPT-4 was publicly released, Carey Goldberg, Dr. Zak Kohane, and I published <em>The AI Revolution in Medicine </em>to help educate the world of healthcare and medical research about the transformative impact this new generative AI technology could have. But because we wrote the book when GPT-4 was still a secret, we had to speculate. Now, two years later, what did we get right, and what did we get wrong?   &nbsp;</p>



<p>In this series, we’ll talk to clinicians, patients, hospital administrators, and others to understand the reality of AI in the field and where we go from here. &nbsp;</p>



<p>[THEME MUSIC FADES]</p>



				</span>
				<span id="show-more-show-less-toggle-7" class="show-more-show-less-toggleable-content">
					



<p>The book passage I read at the top is from “Chapter 10: The Big Black Bag.”&nbsp;</p>



<p>In imagining AI in medicine, Carey, Zak, and I included in our book two fictional accounts. In the first, a medical resident consults GPT-4 on her personal phone as the patient in front of her crashes. Within seconds, it offers an alternate response based on recent literature. In the second account, a 90-year-old woman with several chronic conditions is living independently and receiving near-constant medical support from an AI aide.&nbsp;&nbsp;&nbsp;</p>



<p>In our conversations with the guests we’ve spoken to so far, we’ve caught a glimpse of these predicted futures, seeing how clinicians and patients are <em>actually</em> using AI today and how developers are leveraging the technology in the healthcare products and services they’re creating. In fact, that first fictional account isn’t so fictional after all, as most of the doctors in the real world actually appear to be using AI at least occasionally—and sometimes much more than occasionally—to help in their daily clinical work. And as for the second fictional account, which is more of a <em>science fiction</em> account, it seems we are indeed on the verge of a new way of delivering and receiving healthcare, though the future is still very much open.&nbsp;</p>



<p>As we continue to examine the current state of AI in healthcare and its potential to transform the field, I’m pleased to welcome Bill Gates and Sébastien Bubeck.&nbsp;&nbsp;</p>



<p>Bill may be best known as the co-founder of Microsoft, having created the company with his childhood friend Paul Allen in 1975. He’s now the founder of Breakthrough Energy, which aims to advance clean energy innovation, and TerraPower, a company developing groundbreaking nuclear energy and science technologies. He also chairs the world’s largest philanthropic organization, the Gates Foundation, and focuses on solving a variety of health challenges around the globe and here at home.&nbsp;</p>



<p>Sébastien is a research lead at OpenAI. He was previously a distinguished scientist, vice president of AI, and a colleague of mine here at Microsoft, where his work included spearheading the development of the family of small language models known as Phi. While at Microsoft, he also coauthored the discussion-provoking 2023 paper “<a href="https://www.microsoft.com/en-us/research/publication/sparks-of-artificial-general-intelligence-early-experiments-with-gpt-4/?msockid=35739e94ab6c69d41b738b93aa076831">Sparks of Artificial General Intelligence</a>,” which presented the results of early experiments with GPT-4 conducted by a small team from Microsoft Research.&nbsp;&nbsp;&nbsp;</p>



<p>[TRANSITION MUSIC]&nbsp;&nbsp;</p>



<p>Here’s my conversation with Bill Gates and Sébastien Bubeck.&nbsp;</p>



<p><strong>LEE:</strong> Bill, welcome.&nbsp;</p>



<p><strong>BILL GATES:</strong> Thank you.&nbsp;</p>



<p><strong>LEE:</strong> Seb &#8230;&nbsp;</p>



<p><strong>SÉBASTIEN BUBECK:</strong> Yeah. Hi, hi, Peter. Nice to be here.&nbsp;</p>



<p><strong>LEE:</strong> You know, one of the things that I&#8217;ve been doing just to get the conversation warmed up is to talk about origin stories, and what I mean about origin stories is, you know, what was the first contact that you had with large language models or the concept of generative AI that convinced you or made you think that something really important was happening?&nbsp;</p>



<p>And so, Bill, I think I&#8217;ve heard the story about, you know, the time when the OpenAI folks—Sam Altman, Greg Brockman, and others—showed you something, but could we hear from you what those early encounters were like and what was going through your mind?&nbsp;&nbsp;</p>



<p><strong>GATES:</strong> Well, I’d been visiting OpenAI soon after it was created to see things like GPT-2 and to see the little arm they had that was trying to match human manipulation and, you know, looking at their games like Dota that they were trying to get as good as human play. And honestly, I didn&#8217;t think the language model stuff they were doing, even when they got to GPT-3, would show the ability to learn, you know, in the same sense that a human reads a biology book and is able to take that knowledge and access it not only to pass a test but also to create new medicines.&nbsp;</p>



<p>And so my challenge to them was that if their LLM could get a five on the advanced placement biology test, then I would say, OK, it took biologic knowledge and encoded it in an accessible way and that I didn&#8217;t expect them to do that very quickly but it would be profound.&nbsp;&nbsp;</p>



<p>And it was only about six months after I challenged them to do that, that an early version of GPT-4 they brought up to a dinner at my house, and in fact, it answered most of the questions that night very well. The one it got totally wrong, we were … because it was so good, we kept thinking, <em>Oh, we must be wrong</em>. It turned out it was a math weakness [LAUGHTER] that, you know, we later understood that that was an area of, weirdly, of incredible weakness of those early models. But, you know, that was when I realized, OK, the age of cheap intelligence was at its beginning.&nbsp;</p>



<p><strong>LEE:</strong> Yeah. So I guess it seems like you had something similar to me in that my first encounters, I actually harbored some skepticism. Is it fair to say you were skeptical before that?&nbsp;</p>



<p><strong>GATES:</strong> Well, the idea that we’ve figured out how to encode and access knowledge in this very deep sense without even understanding the nature of the encoding, …&nbsp;</p>



<p><strong>LEE:</strong> Right.&nbsp;&nbsp;</p>



<p><strong>GATES:</strong> … that is a bit weird.&nbsp;&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>GATES:</strong> We have an algorithm that creates the computation, but even say, OK, where is the president&#8217;s birthday stored in there? Where is this fact stored in there? The fact that even <em>now</em> when we&#8217;re playing around, getting a little bit more sense of it, it&#8217;s opaque to us what the semantic encoding is, it&#8217;s, kind of, amazing to me. I thought the invention of knowledge storage would be an explicit way of encoding knowledge, not an implicit statistical training.&nbsp;</p>



<p><strong>LEE:</strong> Yeah, yeah. All right. So, Seb, you know, on this same topic, you know, I got—as we say at Microsoft—I got pulled into the tent. [LAUGHS]&nbsp;</p>



<p><strong>BUBECK:</strong> Yes.&nbsp;&nbsp;</p>



<p><strong>LEE:</strong> Because this was a very secret project. And then, um, I had the opportunity to select a small number of researchers in MSR [Microsoft Research] to join and start investigating this thing seriously. And the first person I pulled in was <em>you</em>.&nbsp;</p>



<p><strong>BUBECK:</strong> Yeah.&nbsp;</p>



<p><strong>LEE:</strong> And so what were your first encounters? Because I actually don&#8217;t remember what happened then.&nbsp;</p>



<p><strong>BUBECK:</strong> Oh, I remember it very well. [LAUGHS] My first encounter with GPT-4 was in a meeting with the two of you, actually. But my kind of first contact, the first moment where I realized that something was happening with generative AI, was before that. And I agree with Bill that I also wasn&#8217;t too impressed by GPT-3.&nbsp;</p>



<p>I though that it was kind of, you know, very naturally mimicking the web, sort of parroting what was written there in a nice way. Still in a way which seemed very impressive. But it wasn&#8217;t really intelligent in any way. But shortly after GPT-3, there was a model before GPT-4 that really shocked me, and this was the first image generation model, DALL-E 1.&nbsp;</p>



<p>So that was in 2021. And I will forever remember the press release of OpenAI where they had this prompt of an avocado chair and then you had this image of the avocado chair. [LAUGHTER] And what really shocked me is that clearly the model kind of “understood” what is a chair, what is an avocado, and was able to merge those concepts.&nbsp;</p>



<p>So this was really, to me, the first moment where I saw some understanding in those models.&nbsp;&nbsp;</p>



<p><strong>LEE: </strong>So this was, just to get the timing right, that was before I pulled you into the tent.&nbsp;</p>



<p><strong>BUBECK: </strong>That was before. That was like a year before.&nbsp;</p>



<p><strong>LEE: </strong>Right.&nbsp;&nbsp;</p>



<p><strong>BUBECK: </strong>And now I will tell you how, you know, we went from that moment to the meeting with the two of you and GPT-4.&nbsp;</p>



<p>So once I saw this kind of understanding, I thought, OK, fine. It understands concept, but it’s still not able to reason. It cannot—as, you know, Bill was saying—it cannot learn from your document. It cannot reason.&nbsp;&nbsp;</p>



<p>So I set out to try to <em>prove</em> that. You know, this is what I was in the business of at the time, trying to prove things in mathematics. So I was trying to prove that basically autoregressive transformers could <em>never</em> reason. So I was trying to prove this. And after a year of work, I had something reasonable to show. And so I had the meeting with the two of you, and I had this example where I wanted to say, there is no way that an LLM is going to be able to do <em>x</em>.&nbsp;</p>



<p>And then as soon as I … I don&#8217;t know if you remember, Bill. But as soon as I said that, you said, oh, but wait a second. I had, you know, the OpenAI crew at my house recently, and they showed me a new model. Why don&#8217;t we ask this new model this question?&nbsp;&nbsp;</p>



<p><strong>LEE: </strong>Yeah.<strong>&nbsp;</strong>&nbsp;</p>



<p><strong>BUBECK: </strong>And we did, and it solved it on the spot. And that really, honestly, just changed my life. Like, you know, I had been working for a year trying to say that this was impossible. And just right there, it was shown to be possible.&nbsp;&nbsp;</p>



<p><strong>LEE:</strong> [LAUGHS] One of the very first things I got interested in—because I was really thinking a lot about healthcare—<em>was</em> healthcare and medicine.&nbsp;</p>



<p>And I don&#8217;t know if the two of you remember, but I ended up doing a lot of tests. I ran through, you know, step one and step two of the US Medical Licensing Exam. Did a whole bunch of other things. I wrote this big report. It was, you know, I can&#8217;t remember … a couple hundred pages.&nbsp;&nbsp;</p>



<p>And I needed to share this with someone. I didn&#8217;t … there weren&#8217;t too many people I could share it with. So I sent, I think, a copy to you, Bill. Sent a copy to you, Seb.&nbsp;&nbsp;</p>



<p>I hardly slept for about a week putting that report together. And, yeah, and I kept working on it. But I was far from alone. I think everyone who was in the tent, so to speak, in those early days was going through something pretty similar. All right. So I think … of course, a lot of what I put in the report also ended up being examples that made it into the book.&nbsp;</p>



<p>But the main purpose of this conversation isn&#8217;t to reminisce about [LAUGHS] or indulge in those reminiscences but to talk about what&#8217;s happening in healthcare and medicine. And, you know, as I said, we wrote this book. We did it very, very quickly. Seb, you helped. Bill, you know, you provided a review and some endorsements.&nbsp;</p>



<p>But, you know, honestly, we didn&#8217;t know what we were talking about because no one had access to this thing. And so we just made a bunch of guesses. So really, the whole thing I wanted to probe with the two of you is, now with two years of experience out in the world, what, you know, what do we think is happening today?&nbsp;</p>



<p>You know, is AI actually having an impact, positive or negative, on healthcare and medicine? And what do we now think is going to happen in the next two years, five years, or 10 years? And so I realize it&#8217;s a little bit too abstract to just ask it that way. So let me just try to narrow the discussion and guide us a little bit.&nbsp;&nbsp;</p>



<p>Um, the kind of administrative and clerical work, paperwork, around healthcare—and we made a lot of guesses about that—that appears to be going well, but, you know, Bill, I know we&#8217;ve discussed that sometimes that you think there ought to be a lot more going on.&nbsp;Do you have a viewpoint on how AI is actually finding its way into reducing paperwork?&nbsp;</p>



<p><strong>GATES:</strong> Well, I’m stunned … I don&#8217;t think there should be a patient-doctor meeting where the AI is not sitting in and both transcribing, offering to help with the paperwork, and even making suggestions, although the doctor will be the one, you know, who makes the final decision about the diagnosis and whatever prescription gets done.&nbsp;&nbsp;</p>



<p>It&#8217;s so helpful. You know, when that patient goes home and their, you know, son who wants to understand what happened has some questions, that AI should be available to continue that conversation. And the way you can improve that experience and streamline things and, you know, involve the people who advise you. I don&#8217;t understand why that&#8217;s not more adopted, because there you still have the human in the loop making that final decision.&nbsp;</p>



<p>But even for, like, follow-up calls to make sure the patient did things, to understand if they have concerns and knowing when to escalate back to the doctor, the benefit is incredible. And, you know, that thing is ready for prime time. That paradigm is ready for prime time, in my view.&nbsp;</p>



<p><strong>LEE:</strong> Yeah, there are some good products, but it seems like the number one use right now—and we kind of got this from some of the previous guests in previous episodes—is the use of AI just to respond to emails from patients. [LAUGHTER] Does that make sense to you?&nbsp;</p>



<p><strong>BUBECK:</strong> Yeah. So maybe I want to second what Bill was saying but maybe take a step back first. You know, two years ago, like, the concept of clinical scribes, which is one of the things that we&#8217;re talking about right now, it would have sounded, in fact, it sounded two years ago, borderline dangerous. Because everybody was worried about hallucinations. What happened if you have this AI listening in and then it transcribes, you know, something wrong?&nbsp;</p>



<p>Now, two years later, I think it&#8217;s mostly working. And in fact, it is not yet, you know, fully adopted. You&#8217;re right. But it is in production. It is used, you know, in many, many places. So this rate of progress <em>is</em> astounding because it wasn&#8217;t obvious that we would be able to overcome those obstacles of hallucination. It&#8217;s not to say that hallucinations are fully solved. In the case of the closed system, they are.&nbsp;&nbsp;</p>



<p>Now, I think more generally what&#8217;s going on in the background is that there is something that we, that certainly I, underestimated, which is this management overhead. So I think the reason why this is not adopted everywhere is really a training and teaching aspect. People need to be taught, like, those systems, how to interact with them.&nbsp;</p>



<p>And one example that I really like, a study that recently appeared where they tried to use ChatGPT for diagnosis and they were <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2825395" target="_blank" rel="noreferrer noopener">comparing doctors without and with ChatGPT<span class="sr-only"> (opens in new tab)</span></a>. And the amazing thing … so this was a set of cases where the accuracy of the doctors alone was around 75%. ChatGPT alone was 90%. So that&#8217;s already kind of mind blowing. But then the kicker is that doctors with ChatGPT was 80%.&nbsp;&nbsp;</p>



<p>Intelligence alone is not enough. It&#8217;s also how it&#8217;s presented, how you interact with it. And ChatGPT, it&#8217;s an amazing tool. Obviously, I absolutely love it. But it&#8217;s not … you don&#8217;t want a doctor to have to type in, you know, prompts and use it that way.&nbsp;</p>



<p>It should be, as Bill was saying, kind of running continuously in the background, sending you notifications. And you have to be really careful of the rate at which those notifications are being sent. Because if they are too frequent, then the doctor will learn to ignore them. So you have to … all of those things matter, in fact, at least as much as the level of intelligence of the machine.&nbsp;</p>



<p><strong>LEE:</strong> One of the things I think about, Bill, in that scenario that you described, doctors do some thinking about the patient when they write the note. So, you know, I&#8217;m always a little uncertain whether it&#8217;s actually … you know, you wouldn&#8217;t necessarily want to fully automate this, I don&#8217;t think. Or at least there needs to be some prompt to the doctor to make sure that the doctor puts some thought into what happened in the encounter with the patient. Does that make sense to you at all?&nbsp;</p>



<p><strong>GATES:</strong> At this stage, you know, I’d still put the onus on the doctor to write the conclusions and the summary and not delegate that.&nbsp;</p>



<p>The tradeoffs you make a little bit are somewhat dependent on the situation you&#8217;re in. If you&#8217;re in Africa,<strong> </strong>where most people never meet a real doctor their entire life, the idea of being able to have some of this advice and diagnosis is extremely advantageous because you&#8217;re comparing it to nothing.&nbsp;</p>



<p>So, yes, the doctor’s still going to have to do a lot of work, but just the quality of letting the patient and the people around them interact and ask questions and have things explained, that alone is such a quality improvement. It&#8217;s mind blowing.&nbsp;&nbsp;</p>



<p><strong>LEE:</strong> So since you mentioned, you know, Africa—and, of course, this touches on the mission and some of the priorities of the Gates Foundation and this idea of democratization of access to expert medical care—what&#8217;s the most interesting stuff going on right now? Are there people and organizations or technologies that are impressing you or that you&#8217;re tracking?&nbsp;</p>



<p><strong>GATES:</strong> Yeah. So the Gates Foundation has given out a lot of grants to people in Africa doing education, agriculture but more healthcare examples than anything. And the way these things start off, they often start out either being patient-centric in a narrow situation, like, <em>OK, I&#8217;m a pregnant woman; talk to me</em>. Or, <em>I have infectious disease symptoms; talk to me</em>. Or they&#8217;re connected to a health worker where they&#8217;re helping that worker get their job done. And we have lots of pilots out, you know, in both of those cases.&nbsp;&nbsp;</p>



<p>The dream would be eventually to have the thing the patient consults be so broad that it&#8217;s like having a doctor available who understands the local things.&nbsp;&nbsp;</p>



<p><strong>LEE: </strong>Right.&nbsp;&nbsp;</p>



<p><strong>GATES: </strong>We&#8217;re not there yet. But over the next two or three years, you know, particularly given the worsening financial constraints against African health systems, where the withdrawal of money has been dramatic, you know, figuring out how to take this—what I sometimes call “free intelligence”—and build a quality health system around that, we will have to be more radical in low-income countries than any rich country is ever going to be.&nbsp;&nbsp;</p>



<p><strong>LEE:</strong> Also, there&#8217;s maybe a different regulatory environment, so some of those things maybe are easier? Because right now, I think the world hasn&#8217;t figured out how to and whether to regulate, let&#8217;s say, an AI that might give a medical diagnosis or write a prescription for a medication.&nbsp;</p>



<p><strong>BUBECK:</strong> Yeah. I think one issue with this, and it&#8217;s also slowing down the deployment of AI in healthcare more generally, is a lack of proper benchmark. Because, you know, you were mentioning the USMLE [United States Medical Licensing Examination], for example. That&#8217;s a great test to test <em>human beings</em> and <em>their</em> knowledge of healthcare and medicine. But it&#8217;s not a great test to give to an AI.&nbsp;</p>



<p>It&#8217;s not asking the right questions. So finding what are the right questions to test whether an AI system is ready to give diagnosis in a constrained setting, that&#8217;s a very, very important direction, which to my surprise, is not yet accelerating at the rate that I was hoping for.&nbsp;</p>



<p><strong>LEE:</strong> OK, so that gives me an excuse to get more now into the core AI tech because something I&#8217;ve discussed with both of you is this issue of what are the right tests. And you both know the very first test I give to any new spin of an LLM is I present a patient, the results—a <em>mythical</em> patient—the results of my physical exam, my <em>mythical</em> physical exam. Maybe some results of some initial labs. And then I present or propose a differential diagnosis. And if you&#8217;re not in medicine, a differential diagnosis you can just think of as a prioritized list of the possible diagnoses that fit with all that data. And in that proposed differential, I always intentionally make two mistakes.&nbsp;</p>



<p>I make a textbook technical error in one of the possible elements of the differential diagnosis, and I have an error of omission. And, you know, I just want to know, does the LLM understand what I&#8217;m talking about? And all the good ones out there do now. But then I want to know, can it spot the errors? And then most importantly, is it willing to tell me I&#8217;m wrong, that I&#8217;ve made a mistake?&nbsp;&nbsp;</p>



<p>That last piece seems really hard for AI today. And so let me ask you first, Seb, because at the time of this taping, of course, there was a new spin of GPT-4o last week that became <em>overly</em> sycophantic. In other words, it was actually prone in that test of mine not only to <em>not</em> tell me I&#8217;m wrong, but it actually praised me for the creativity of my differential. [LAUGHTER] What&#8217;s up with that?&nbsp;</p>



<p><strong>BUBECK:</strong> Yeah, I guess it&#8217;s a testament to the fact that training those models is still more of an art than a science. So it&#8217;s a difficult job. Just to be clear with the audience, we have rolled back that [LAUGHS] version of GPT-4o, so now we don&#8217;t have the sycophant version out there.&nbsp;</p>



<p>Yeah, no, it&#8217;s a really difficult question. It has to do … as you said, it&#8217;s very technical. It has to do with the post-training and how, like, where do you nudge the model? So, you know, there is this very classical by now technique called RLHF [reinforcement learning from human feedback], where you push the model in the direction of a certain reward model. So the reward model is just telling the model, you know, what behavior is good, what behavior is bad.&nbsp;</p>



<p>But this reward model is itself an LLM, and, you know, Bill was saying at the very beginning of the conversation that we don&#8217;t really understand how those LLMs deal with concepts like, you know, where is the capital of France located? Things like that. It is the same thing for this reward model. We don&#8217;t know why it says that it prefers one output to another, and whether this is correlated with some sycophancy is, you know, something that we discovered basically just now. That if you push too hard in optimization on this reward model, you will get a sycophant model.&nbsp;</p>



<p>So it&#8217;s kind of … what I&#8217;m trying to say is we became too good at what we were doing, and we ended up, in fact, in a trap of the reward model.&nbsp;</p>



<p><strong>LEE:</strong> I mean, you do want … it&#8217;s a difficult balance because you do want models to follow your desires and …&nbsp;</p>



<p><strong>BUBECK:</strong> It&#8217;s a very difficult, very difficult balance.&nbsp;</p>



<p><strong>LEE:</strong> So this brings up then the following question for me, which is the extent to which we think we&#8217;ll need to have specially trained models for things. So let me start with you, Bill. Do you have a point of view on whether we will need to, you know, quote-unquote take AI models to med school? Have them specially trained? Like, if you were going to deploy something to give medical care in underserved parts of the world, do we need to do something special to create those models?&nbsp;</p>



<p><strong>GATES:</strong> We certainly need to teach them the African languages and the unique dialects so that the multimedia interactions are very high quality. We certainly need to teach them the disease prevalence and unique disease patterns like, you know, neglected tropical diseases and malaria. So we need to gather a set of facts that somebody trying to go for a US customer base, you know, wouldn&#8217;t necessarily have that in there.&nbsp;</p>



<p>Those two things are actually very straightforward because the additional training time is small. I&#8217;d say for the next few years, we’ll also need to do reinforcement learning about the context of being a doctor and how important certain behaviors are. Humans learn over the course of their life to some degree that, I’m in a different context and the way I behave in terms of being willing to criticize or be nice, you know, how important is it? Who&#8217;s here? What&#8217;s my relationship to them?&nbsp;&nbsp;</p>



<p>Right now, these machines don&#8217;t have that broad social experience. And so if you know it&#8217;s going to be used for health things, a lot of reinforcement learning of the very best humans in that context would still be valuable. Eventually, the models will, having read all the literature of the world about good doctors, bad doctors, it&#8217;ll understand as soon as you say, “I want you to be a doctor diagnosing somebody.” All of the implicit reinforcement that fits that situation, you know, will be there.</p>



<p><strong>LEE:</strong> Yeah.</p>



<p><strong>GATES:</strong> And so I hope three years from now, we don&#8217;t have to do that reinforcement learning. But today, for any medical context, you would want a lot of data to reinforce tone, willingness to say things when, you know, there might be something significant at stake.&nbsp;</p>



<p><strong>LEE:</strong> Yeah. So, you know, something Bill said, kind of, reminds me of another thing that I think we missed, which is, the context also … and the specialization also pertains to different, I guess, what we still call “modes,” although I don&#8217;t know if the idea of multimodal is the same as it was two years ago. But, you know, what do you make of all of the hubbub around—in fact, within Microsoft Research, this is a big deal, but I think we&#8217;re far from alone—you know, medical images and vision, video, proteins and molecules, cell, you know, cellular data and so on.&nbsp;</p>



<p><strong>BUBECK:</strong> Yeah. OK. So there is a lot to say to everything … to the last, you know, couple of minutes. Maybe on the specialization aspect, you know, I think there is, hiding behind this, a really fundamental scientific question of whether eventually we have a singular AGI [artificial general intelligence] that kind of knows everything and you can just put, you know, explain your own context and it will just get it and understand everything.&nbsp;</p>



<p>That&#8217;s one vision. I have to say, I don&#8217;t particularly believe in this vision. In fact, we humans are not like that at all. I think, hopefully, we are general intelligences, yet we have to specialize a lot. And, you know, I did myself a lot of RL, reinforcement learning, on mathematics. Like, that&#8217;s what I did, you know, spent a lot of time doing that. And I didn&#8217;t improve on other aspects. You know, in fact, I probably degraded in other aspects. [LAUGHTER] So it&#8217;s … I think it&#8217;s an important example to have in mind.&nbsp;</p>



<p><strong>LEE:</strong> I think I might disagree with you on that, though, because, like, doesn&#8217;t a model have to see both good science and bad science in order to be able to gain the ability to discern between the two?&nbsp;</p>



<p><strong>BUBECK:</strong> Yeah, no, that absolutely. I think there is value in seeing the generality, in having a very broad base. But then you, kind of, specialize on verticals. And this is where also, you know, open-weights model, which we haven&#8217;t talked about yet, are really important because they allow you to provide this broad base to everyone. And then you can specialize on top of it.&nbsp;</p>



<p><strong>LEE:</strong> So we have about three hours of stuff to talk about, but our time is actually running low.</p>



<p><strong>BUBECK: </strong>Yes, yes, yes.&nbsp;&nbsp;</p>



<p><strong>LEE:</strong> So I think I want … there&#8217;s a more provocative question. It&#8217;s almost a silly question, but I need to ask it of the two of you, which is, is there a future, you know, where AI replaces doctors or replaces, you know, medical specialties that we have today? So what does the world look like, say, five years from now?&nbsp;</p>



<p><strong>GATES:</strong> Well, it’s important to distinguish healthcare discovery activity from healthcare delivery activity. We focused mostly on delivery. I think it&#8217;s very much within the realm of possibility that the AI is not only accelerating healthcare discovery but substituting for a lot of the roles of, you know, <em>I’m an organic chemist</em>, or <em>I run various types of assays</em>. I can see those, which are, you know, testable-output-type jobs but with still very high value, I can see, you know, some replacement in those areas before the doctor.&nbsp;&nbsp;</p>



<p>The doctor, still understanding the human condition and long-term dialogues, you know, they&#8217;ve had a lifetime of reinforcement of that, particularly when you get into areas like mental health. So I wouldn’t say in five years, either people will choose to adopt it, but it will be profound that there&#8217;ll be this nearly free intelligence that can do follow-up, that can help you, you know, make sure you went through different possibilities.&nbsp;</p>



<p>And so I’d say, yes, we&#8217;ll have doctors, but I&#8217;d say healthcare will be massively transformed in its quality and in efficiency by AI in that time period.&nbsp;</p>



<p><strong>LEE:</strong> Is there a comparison, useful comparison, say, between doctors and, say, programmers, computer programmers, or doctors and, I don&#8217;t know, lawyers?&nbsp;</p>



<p><strong>GATES:</strong> Programming is another one that has, kind of, a mathematical correctness to it, you know, and so the objective function that you&#8217;re trying to reinforce to, as soon as you can understand the state machines, you can have something that&#8217;s “checkable”; that&#8217;s correct. So I think programming, you know, which is weird to say, that the machine will beat us at most programming tasks before we let it take over roles that have deep empathy, you know, physical presence and social understanding in them.&nbsp;</p>



<p><strong>LEE:</strong> Yeah. By the way, you know, I fully expect in five years that AI will produce mathematical proofs that are checkable for validity, <em>easily checkable</em>, because they&#8217;ll be written in a proof-checking language like Lean or something but will be so complex that no human mathematician can understand them. I expect that to happen.&nbsp;&nbsp;</p>



<p>I can imagine in some fields, like cellular biology, we could have the same situation in the future because the molecular pathways, the chemistry, biochemistry of human cells or living cells is as complex as any mathematics, and so it seems possible that we may be in a state where in wet lab, we see, <em>Oh yeah, this actually works</em>, but no one can understand why.&nbsp;</p>



<p><strong>BUBECK:</strong> Yeah, absolutely. I mean, I think I really agree with Bill’s distinction of the discovery and the delivery, and indeed, the discovery’s when you can check things, and at the end, there is an artifact that you can verify. You know, you can run the protocol in the wet lab and see [if you have] produced what you wanted. So I absolutely agree with that.&nbsp;&nbsp;</p>



<p>And in fact, you know, we don&#8217;t have to talk five years from now. I don&#8217;t know if you know, but just recently, there was a <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://arxiv.org/abs/2503.23758" target="_blank" rel="noreferrer noopener">paper that was published on a scientific discovery using o3- mini<span class="sr-only"> (opens in new tab)</span></a>. So this is really amazing. And, you know, just very quickly, just so people know, it was about this statistical physics model, the frustrated Potts model, which has to do with coloring, and basically, the case of three colors, like, more than two colors was open for a long time, and o3 was able to reduce the case of three colors to two colors.&nbsp;&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>BUBECK:</strong> Which is just, like, astounding. And this is not … this is <em>now</em>. This is happening right now. So this is something that I personally didn&#8217;t expect it would happen so quickly, and it&#8217;s due to those reasoning models.&nbsp;&nbsp;</p>



<p>Now, on the delivery side, I would add something more to it for the reason why doctors and, in fact, lawyers and coders will remain for a long time, and it&#8217;s because we still don&#8217;t understand how those models generalize. Like, at the end of the day, we are not able to tell you when they are confronted with a really new, novel situation, whether they will work or not.&nbsp;</p>



<p><em>Nobody</em> is able to give you that guarantee. And I think until we understand this generalization better, we&#8217;re not going to be willing to just let the system in the wild without human supervision.&nbsp;</p>



<p><strong>LEE:</strong> But don&#8217;t human doctors, human specialists … so, for example, a cardiologist sees a patient in a certain way that a nephrologist &#8230;&nbsp;</p>



<p><strong>BUBECK:</strong> Yeah.</p>



<p><strong>LEE:</strong> &#8230; or an endocrinologist might not.</p>



<p><strong>BUBECK:</strong> That&#8217;s right. But <em>another</em> cardiologist will understand and, kind of, expect a certain level of generalization from their peer. And this, we just don&#8217;t have it with AI models. Now, of course, you&#8217;re exactly right. That generalization is also hard for humans. Like, if you have a human trained for one task and you put them into another task, then you don&#8217;t … you often don&#8217;t know.<strong> </strong>But you have other examples. So if you have two humans that were trained on a task and you put them on another one, then you kind of expect that they will do the same on the other task.&nbsp;</p>



<p><strong>LEE:</strong> OK. You know, the podcast is focused on what&#8217;s happened over the last two years. But now, I&#8217;d like one provocative prediction about what you think the world of AI and medicine is going to be at some point in the future. You pick your timeframe. I don&#8217;t care if it&#8217;s two years or 20 years from now, but, you know, what do you think will be different about AI in medicine in <em>that</em> future than today?&nbsp;</p>



<p><strong>BUBECK:</strong> Yeah, I think the deployment is going to accelerate soon. Like, we’re really not missing very much. There is this enormous capability overhang. Like, even if progress completely stopped, with current systems, we can do a lot more than what we&#8217;re doing right now. So I think this will … this <em>has to be</em> realized, you know, sooner rather than later.&nbsp;</p>



<p>And I think it&#8217;s probably dependent on these benchmarks and proper evaluation and tying this with regulation. So these are things that take time in human society and for good reason. But now we already are at two years; you know, give it another two years and it should be really …&nbsp;&nbsp;</p>



<p><strong>LEE:</strong> Will AI prescribe your medicines? Write your prescriptions?&nbsp;</p>



<p><strong>BUBECK:</strong> I think yes. I think yes.&nbsp;</p>



<p><strong>LEE:</strong> OK. Bill?&nbsp;</p>



<p><strong>GATES:</strong> Well, I think the next two years, we’ll have massive pilots, and so the amount of use of the AI, still in a copilot-type mode, you know, we should get millions of patient visits, you know, both in general medicine and in the mental health side, as well. And I think that&#8217;s going to build up both the data <em>and</em> the confidence to give the AI some additional autonomy. You know, are you going to let it talk to you at night when you&#8217;re panicked about your mental health with some ability to escalate?<strong>&nbsp;</strong>&nbsp;</p>



<p>And, you know, I&#8217;ve gone so far as to tell politicians with national health systems that if they deploy AI appropriately, that the quality of care, the overload of the doctors, the improvement in the economics will be enough that their voters will be <em>stunned</em> because they just don&#8217;t expect this, and, you know, they could be reelected [LAUGHTER] just on this one thing of fixing what is a very overloaded and economically challenged health system in these rich countries.&nbsp;</p>



<p>You know, my personal role is going to be to make sure that in the poorer countries, there isn&#8217;t some lag; in fact, in many cases, that we’ll be more aggressive because, you know, we&#8217;re comparing to having no access to doctors at all. And, you know, so I think whether it&#8217;s India or Africa, there’ll be lessons that are globally valuable because we need medical intelligence. And, you know, thank god AI is going to provide a lot of that.&nbsp;</p>



<p><strong>LEE:</strong> Well, on that optimistic note, I think that&#8217;s a good way to end. Bill, Seb, really appreciate all of this.&nbsp;&nbsp;</p>



<p>I think the most fundamental prediction we made in the book is that AI would actually find its way into the practice of medicine, and I think that that at least has come true, maybe in different ways than we expected, but it&#8217;s come true, and I think it&#8217;ll only accelerate from here. So thanks again, both of you.&nbsp;</p>



<p>[TRANSITION MUSIC]&nbsp;</p>



<p><strong>GATES:</strong> Yeah. Thanks, you guys.&nbsp;</p>



<p><strong>BUBECK:</strong> Thank you, Peter. Thanks, Bill.&nbsp;</p>



<p><strong>LEE: </strong>I just always feel such a sense of privilege to have a chance to interact and actually work with people like Bill and Sébastien.&nbsp;&nbsp;&nbsp;</p>



<p>With Bill, I&#8217;m always amazed at how practically minded he is. He&#8217;s really thinking about the nuts and bolts of what AI might be able to do for people, and his thoughts about underserved parts of the world, the idea that we might actually be able to empower people with access to expert medical knowledge, I think is both inspiring and amazing.&nbsp;&nbsp;</p>



<p>And then, Seb, Sébastien Bubeck, he’s just absolutely a brilliant mind. He has a really firm grip on the deep mathematics of artificial intelligence and brings that to bear in his research and development work. And where that mathematics takes him isn&#8217;t just into the nuts and bolts of algorithms but into philosophical questions about the nature of intelligence.&nbsp;&nbsp;</p>



<p>One of the things that Sébastien brought up was the state of evaluation of AI systems. And indeed, he was fairly critical in our conversation. But of course, the world of AI research and development is just moving so fast, and indeed, since we recorded our conversation, OpenAI, in fact, released a new evaluation metric that is directly relevant to medical applications, and that is something called <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://openai.com/index/healthbench/" target="_blank" rel="noreferrer noopener">HealthBench</a>. And Microsoft Research also released a new evaluation approach or process called <a href="https://www.microsoft.com/en-us/research/publication/general-scales-unlock-ai-evaluation-with-explanatory-and-predictive-power/">ADeLe</a>.&nbsp;&nbsp;</p>



<p>HealthBench and ADeLe are examples of new approaches to evaluating AI models that are less about testing their knowledge and ability to pass multiple-choice exams and instead are evaluation approaches designed to assess how well AI models are able to complete tasks that actually arise every day in typical healthcare or biomedical research settings. These are examples of really important good work that speak to how well AI models work in the real world of healthcare and biomedical research and how well they can collaborate with human beings in those settings.&nbsp;</p>



<p>You know, I asked Bill and Seb to make some predictions about the future. You know, my own answer, I expect that we&#8217;re going to be able to use AI to change how we diagnose patients, change how we decide treatment options.&nbsp;&nbsp;</p>



<p>If you&#8217;re a doctor or a nurse and you encounter a patient, you’ll ask questions, do a physical exam, you know, call out for labs just like you do today, but then you’ll be able to engage with AI based on all of that data and just ask, you know, based on all the other people who have gone through the same experience, who have similar data, how were they diagnosed? How were they treated? What were their outcomes? And what does that mean for the patient I have right now? Some people call it the “patients like me” paradigm. And I think that&#8217;s going to become real because of AI within our lifetimes. That idea of really grounding the delivery in healthcare and medical practice through data and intelligence, I actually now don&#8217;t see any barriers to that future becoming real.&nbsp;</p>



<p>[THEME MUSIC]&nbsp;</p>



<p>I’d like to extend another big thank you to Bill and Sébastien for their time. And to our listeners, as always, it’s a pleasure to have you along for the ride. I hope you’ll join us for our remaining conversations, as well as a second coauthor roundtable with Carey and Zak.&nbsp;&nbsp;</p>



<p>Until next time.&nbsp;&nbsp;</p>



<p>[MUSIC FADES]</p>

				</span>
			</div>
			<button
				class="action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle"
				aria-expanded="false"
				data-show-less-text="Show less"
				type="button"
				aria-controls="show-more-show-less-toggle-7"
				aria-label="Show more content"
				data-alternate-aria-label="Show less content">
				Show more			</button>
		</div>
	</div>
</div>



<div class="wp-block-buttons is-layout-flex wp-block-buttons-is-layout-flex">
<div class="wp-block-button is-style-outline is-style-outline--8"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/story/the-ai-revolution-in-medicine-revisited/">AI Revolution in Medicine podcast series</a></div>
</div>
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/podcast/how-ai-is-reshaping-the-future-of-healthcare-and-medical-research/">How AI is reshaping the future of healthcare and medical research</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Rewriting SymCrypt in Rust to modernize Microsoft’s cryptographic library </title>
		<link>https://www.microsoft.com/en-us/research/blog/rewriting-symcrypt-in-rust-to-modernize-microsofts-cryptographic-library/</link>
		
		<dc:creator><![CDATA[Jonathan Protzenko, Samuel Lee, Samreen Khadeer, Son Ho, Oleksii Oleksenko, Michael Naehrig, Cédric Fournet]]></dc:creator>
		<pubDate>Tue, 10 Jun 2025 16:00:00 +0000</pubDate>
				<category><![CDATA[Research Blog]]></category>
		<guid isPermaLink="false">https://www.microsoft.com/en-us/research/blog/rewriting-symcrypt-in-rust-to-modernize-microsofts-cryptographic-library/</guid>

					<description><![CDATA[<p>We're rewriting parts of Microsoft's SymCrypt cryptographic library in Rust to improve memory safety and defend against side-channel attacks, enabling formal verification while maintaining backward compatibility via a Rust-to-C compiler.</p>
<p>The post <a href="https://www.microsoft.com/en-us/research/blog/rewriting-symcrypt-in-rust-to-modernize-microsofts-cryptographic-library/">Rewriting SymCrypt in Rust to modernize Microsoft’s cryptographic library </a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/RewritingSymCrypt-BlogHeroFeature-1400x788-1.jpg" alt="Three white icons on a gradient background that transitions from blue on the left to pink on the right. The first icon, on the left, is a microchip with a padlock in the center. The middle icon is a flowchart diagram with connected shapes. The third icon, on the right, consists of two angle brackets facing each other." class="wp-image-1141377" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/RewritingSymCrypt-BlogHeroFeature-1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/RewritingSymCrypt-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/RewritingSymCrypt-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/RewritingSymCrypt-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/RewritingSymCrypt-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/RewritingSymCrypt-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/RewritingSymCrypt-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/RewritingSymCrypt-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/RewritingSymCrypt-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/RewritingSymCrypt-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w" sizes="auto, (max-width: 1400px) 100vw, 1400px" /></figure>



<p>Outdated coding practices and memory-unsafe languages like C are putting software, including cryptographic libraries, at risk. Fortunately, memory-safe languages like Rust, along with formal verification tools, are now mature enough to be used at scale, helping prevent issues like crashes, data corruption, flawed implementation, and side-channel attacks.</p>



<p>To address these vulnerabilities and improve memory safety, we’re rewriting <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/SymCrypt" target="_blank" rel="noreferrer noopener">SymCrypt<span class="sr-only"> (opens in new tab)</span></a>—Microsoft’s open-source cryptographic library—in Rust. We’re also incorporating formal verification methods. SymCrypt is used in Windows, Azure Linux, Xbox, and other platforms.</p>



<p>Currently, SymCrypt is primarily written in cross-platform C, with limited use of hardware-specific optimizations through intrinsics (compiler-provided low-level functions) and assembly language (direct processor instructions). It provides a wide range of algorithms, including AES-GCM, SHA, ECDSA, and the more recent post-quantum algorithms ML-KEM and ML-DSA.&nbsp;</p>



<p>Formal verification will confirm that implementations behave as intended and don’t deviate from algorithm specifications, critical for preventing attacks. We’ll also analyze compiled code to detect side-channel leaks caused by timing or hardware-level behavior.</p>



<h2 class="wp-block-heading" id="proving-rust-program-properties-with-aeneas">Proving Rust program properties with Aeneas</h2>



<p>Program verification is the process of proving that a piece of code will always satisfy a given property, no matter the input. Rust’s type system profoundly improves the prospects for program verification by providing strong ownership guarantees, by construction, using a discipline known as “aliasing xor mutability”.</p>



<p>For example, reasoning about C code often requires proving that two non-const pointers are live and non-overlapping, a property that can depend on external client code. In contrast, Rust’s type system guarantees this property for any two mutably borrowed references.</p>



<p>As a result, new tools have emerged specifically for verifying Rust code. We chose <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://aeneasverif.github.io/" target="_blank" rel="noreferrer noopener">Aeneas<span class="sr-only"> (opens in new tab)</span></a> because it helps provide a clean separation between code and proofs.</p>



<p>Developed by Microsoft Azure Research in partnership with Inria, the French National Institute for Research in Digital Science and Technology, Aeneas connects to proof assistants like <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://lean-lang.org/" target="_blank" rel="noreferrer noopener">Lean<span class="sr-only"> (opens in new tab)</span></a>, allowing us to draw on a large body of mathematical proofs—especially valuable given the mathematical nature of cryptographic algorithms—and benefit from Lean’s active user community.</p>



<h2 class="wp-block-heading" id="compiling-rust-to-c-supports-backward-compatibility">Compiling Rust to C supports backward compatibility &nbsp;</h2>



<p>We recognize that switching to Rust isn’t feasible for all use cases, so we’ll continue to support, extend, and certify C-based APIs as long as users need them. Users won’t see any changes, as Rust runs underneath the existing C APIs.</p>



<p>Some users compile our C code directly and may rely on specific toolchains or compiler features that complicate the adoption of Rust code. To address this, we will use <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/AeneasVerif/eurydice/" target="_blank" rel="noreferrer noopener">Eurydice<span class="sr-only"> (opens in new tab)</span></a>, a Rust-to-C compiler developed by Microsoft Azure Research, to replace handwritten C code with C generated from formally verified Rust. <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/AeneasVerif/eurydice/" target="_blank" rel="noreferrer noopener">Eurydice<span class="sr-only"> (opens in new tab)</span></a> compiles directly from Rust’s MIR intermediate language, and the resulting C code will be checked into the SymCrypt repository alongside the original Rust source code.</p>



<p>As more users adopt Rust, we&#8217;ll continue supporting this compilation path for those who build SymCrypt from source code but aren’t ready to use the Rust compiler. In the long term, we hope to transition users to either use precompiled SymCrypt binaries (via C or Rust APIs), or compile from source code in Rust, at which point the Rust-to-C compilation path will no longer be needed.</p>



	<div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="1115760">
		

		<p class="msr-promo__label text-gray-800 text-center text-uppercase">
		<span class="px-4 bg-white display-inline-block font-weight-semibold small">Microsoft research podcast</span>
	</p>
	
	<div class="row pt-3 pb-4 align-items-center">
						<div class="msr-promo__media col-12 col-md-5">
				<a class="bg-gray-300 display-block" href="https://www.microsoft.com/en-us/research/podcast/neurips-2024-the-co-evolution-of-ai-and-systems-with-lidong-zhou/" aria-label="NeurIPS 2024: The co-evolution of AI and systems with Lidong Zhou" data-bi-cN="NeurIPS 2024: The co-evolution of AI and systems with Lidong Zhou" target="_blank">
					<img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2024/12/Lidong-and-Eliza_Abstracts_Hero_Feature_No_Text_1400x788.jpg" alt="Illustrated headshots of Lidong Zhou and Eliza Strickland" />
				</a>
			</div>
			
			<div class="msr-promo__content p-3 px-5 col-12 col-md">

									<h2 class="h4">NeurIPS 2024: The co-evolution of AI and systems with Lidong Zhou</h2>
				
								<p id="neurips-2024-the-co-evolution-of-ai-and-systems-with-lidong-zhou" class="large">Just after his NeurIPS 2024 keynote on the co-evolution of systems and AI, Microsoft CVP Lidong Zhou joins the podcast to discuss how rapidly advancing AI impacts the systems supporting it and the opportunities to use AI to enhance systems engineering itself.</p>
				
								<div class="wp-block-buttons justify-content-center justify-content-md-start">
					<div class="wp-block-button">
						<a href="https://www.microsoft.com/en-us/research/podcast/neurips-2024-the-co-evolution-of-ai-and-systems-with-lidong-zhou/" aria-describedby="neurips-2024-the-co-evolution-of-ai-and-systems-with-lidong-zhou" class="btn btn-brand glyph-append glyph-append-chevron-right" data-bi-cN="NeurIPS 2024: The co-evolution of AI and systems with Lidong Zhou" target="_blank">
							Listen now						</a>
					</div>
				</div>
							</div><!--/.msr-promo__content-->
	</div><!--/.msr-promo__inner-wrap-->
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span>	</div><!--/.msr-promo-->
	


<h2 class="wp-block-heading" id="timing-analysis-with-revizor">Timing analysis with Revizor&nbsp;</h2>



<p>Even software that has been verified for functional correctness can remain vulnerable to low-level security threats, such as side channels caused by timing leaks or speculative execution. These threats operate at the hardware level and can leak private information, such as memory load addresses, branch targets, or division operands, even when the source code is provably correct.&nbsp;</p>



<p>To address this, we’re extending <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/sca-fuzzer" target="_blank" rel="noreferrer noopener">Revizor<span class="sr-only"> (opens in new tab)</span></a>, a tool developed by Microsoft Azure Research, to more effectively analyze SymCrypt binaries. Revizor models microarchitectural leakage and uses fuzzing techniques to systematically uncover instructions that may expose private information through known hardware-level effects. &nbsp;</p>



<p>Earlier cryptographic libraries relied on constant-time programming to avoid operations on secret data. However, recent research has shown that this alone is insufficient with today’s CPUs, where every new optimization may open a new side channel. </p>



<p>By analyzing binary code for specific compilers and platforms, our extended Revizor tool enables deeper scrutiny of vulnerabilities that aren’t visible in the source code.</p>



<h2 class="wp-block-heading" id="verified-rust-implementations-begin-with-ml-kem">Verified Rust implementations begin with ML-KEM</h2>



<p>This long-term effort is in alignment with the Microsoft <a href="https://www.microsoft.com/en-us/trust-center/security/secure-future-initiative" target="_blank" rel="noreferrer noopener">Secure Future Initiative</a> and brings together experts across Microsoft, building on decades of Microsoft Research investment in program verification and security tooling.</p>



<p>A preliminary version of ML-KEM in Rust is now available on the preview <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/SymCrypt/tree/feature/verifiedcrypto/lib/rust" target="_blank" rel="noreferrer noopener">feature/verifiedcrypto<span class="sr-only"> (opens in new tab)</span></a> branch of the SymCrypt repository. We encourage users to try the Rust build and <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/SymCrypt/issues" target="_blank" rel="noreferrer noopener">share feedback<span class="sr-only"> (opens in new tab)</span></a>. Looking ahead, we plan to support direct use of the same cryptographic library in Rust without requiring C bindings.&nbsp;</p>



<p>Over the coming months, we plan to rewrite, verify, and ship several algorithms in Rust as part of SymCrypt. As our investment in Rust deepens, we expect to gain new insights into how to best leverage the language for high-assurance cryptographic implementations with low-level optimizations.&nbsp;</p>



<p>As performance is key to scalability and sustainability, we’re holding new implementations to a high bar using our benchmarking tools to match or exceed existing systems.</p>



<h2 class="wp-block-heading" id="looking-forward">Looking forward&nbsp;</h2>



<p>This is a pivotal moment for high-assurance software. Microsoft’s investment in Rust and formal verification presents a rare opportunity to advance one of our key libraries. We’re excited to scale this work and ultimately deliver an industrial-grade, Rust-based, FIPS-certified cryptographic library.</p>
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/blog/rewriting-symcrypt-in-rust-to-modernize-microsofts-cryptographic-library/">Rewriting SymCrypt in Rust to modernize Microsoft’s cryptographic library </a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>BenchmarkQED: Automated benchmarking of RAG systems</title>
		<link>https://www.microsoft.com/en-us/research/blog/benchmarkqed-automated-benchmarking-of-rag-systems/</link>
		
		<dc:creator><![CDATA[Darren Edge, Ha Trinh, Andres Morales Esquivel, Jonathan Larson]]></dc:creator>
		<pubDate>Thu, 05 Jun 2025 16:00:00 +0000</pubDate>
				<category><![CDATA[Research Blog]]></category>
		<guid isPermaLink="false">https://www.microsoft.com/en-us/research/?p=1140429</guid>

					<description><![CDATA[<p>BenchmarkQED is an open-source toolkit for benchmarking RAG systems using automated query generation, evaluation, and dataset prep. It shows that LazyGraphRAG outperforms standard methods, especially on complex, global queries.</p>
<p>The post <a href="https://www.microsoft.com/en-us/research/blog/benchmarkqed-automated-benchmarking-of-rag-systems/">BenchmarkQED: Automated benchmarking of RAG systems</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/BenchmarkQED-BlogHeroFeature-1400x788-1.jpg" alt="Diagram showing how the dimensions of query source (data-driven vs activity-driven) and query scope (local vs global) create four query classes that span the local-to-global query spectrum: data-local, activity-local, data-global, and activity-global. " class="wp-image-1140721" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/BenchmarkQED-BlogHeroFeature-1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/BenchmarkQED-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/BenchmarkQED-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/BenchmarkQED-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/BenchmarkQED-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/BenchmarkQED-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/BenchmarkQED-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/BenchmarkQED-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/BenchmarkQED-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/BenchmarkQED-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w" sizes="auto, (max-width: 1400px) 100vw, 1400px" /></figure>



<p>One of the key&nbsp;use cases&nbsp;for generative AI&nbsp;involves answering questions over&nbsp;private datasets,&nbsp;with retrieval-augmented generation (RAG)&nbsp;as the&nbsp;go-to framework.&nbsp;As&nbsp;new RAG&nbsp;techniques&nbsp;emerge,&nbsp;there’s&nbsp;a growing&nbsp;need to benchmark&nbsp;their performance&nbsp;across&nbsp;diverse&nbsp;datasets&nbsp;and&nbsp;metrics.&nbsp;</p>



<p>To meet this need,&nbsp;we’re&nbsp;introducing&nbsp;BenchmarkQED,&nbsp;a new suite of tools&nbsp;that&nbsp;automates&nbsp;RAG benchmarking at&nbsp;scale, available on&nbsp;<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/benchmark-qed" target="_blank" rel="noreferrer noopener">GitHub<span class="sr-only"> (opens in new tab)</span></a>. It includes components for&nbsp;query generation, evaluation, and dataset preparation, each&nbsp;designed to support rigorous, reproducible&nbsp;testing.&nbsp;&nbsp;</p>



<p>BenchmarkQED&nbsp;complements the RAG methods in our open-source&nbsp;GraphRAG&nbsp;library, enabling users to run a&nbsp;<a href="https://www.microsoft.com/en-us/research/publication/from-local-to-global-a-graph-rag-approach-to-query-focused-summarization/" target="_blank" rel="noreferrer noopener">GraphRAG</a>-style evaluation across models, metrics, and datasets.&nbsp;GraphRAG&nbsp;uses a&nbsp;large&nbsp;language model (LLM)&nbsp;to generate and summarize entity-based knowledge graphs, producing more comprehensive and diverse answers than standard RAG for large-scale&nbsp;tasks.&nbsp;</p>



<p>In this post, we walk through&nbsp;the core components of&nbsp;BenchmarkQED&nbsp;that&nbsp;contribute to the overall benchmarking process.&nbsp;We also share some of the latest benchmark results comparing our <a href="https://www.microsoft.com/en-us/research/blog/lazygraphrag-setting-a-new-standard-for-quality-and-cost/" target="_blank" rel="noreferrer noopener">LazyGraphRAG</a> system&nbsp;to&nbsp;competing methods,&nbsp;including&nbsp;a vector-based&nbsp;RAG with a 1M-token context window, where the leading&nbsp;LazyGraphRAG&nbsp;configuration&nbsp;showed&nbsp;significant win rates&nbsp;across all combinations of quality metrics&nbsp;and query classes.</p>



<p>In the <a href="https://www.microsoft.com/en-us/research/publication/from-local-to-global-a-graph-rag-approach-to-query-focused-summarization/" target="_blank" rel="noreferrer noopener">paper</a>, we distinguish between <em>local queries</em>, where answers are found in a small number of text regions, and sometimes even a single region, and <em>global queries</em>, which require reasoning over large portions of or even the entire dataset. </p>



<p>Conventional&nbsp;vector-based RAG&nbsp;excels at&nbsp;local queries because the&nbsp;regions&nbsp;containing&nbsp;the&nbsp;answer&nbsp;to the query&nbsp;resemble the&nbsp;query&nbsp;itself&nbsp;and can be retrieved&nbsp;as&nbsp;the&nbsp;nearest neighbor in the&nbsp;vector&nbsp;space&nbsp;of text embeddings.&nbsp;However, it struggles&nbsp;with&nbsp;global questions,&nbsp;such as, “What are the main themes of the dataset?” which&nbsp;require&nbsp;understanding&nbsp;dataset qualities not&nbsp;explicitly&nbsp;stated&nbsp;in&nbsp;the text.&nbsp;&nbsp;</p>



<h2 class="wp-block-heading" id="autoq-automated-query-synthesis">AutoQ: Automated query synthesis</h2>



<p>This limitation&nbsp;motivated&nbsp;the development of&nbsp;GraphRAG&nbsp;a system designed to&nbsp;answer&nbsp;global queries. GraphRAG&#8217;s evaluation&nbsp;requirements&nbsp;subsequently&nbsp;led to the creation of&nbsp;AutoQ, a method for synthesizing these global queries for any dataset.</p>



<p>AutoQ extends this approach by generating synthetic queries across the spectrum of queries, from local to global. It defines four distinct classes based on the source and scope of the query (Figure 1, top) forming a logical progression along the spectrum (Figure 1, bottom).</p>



<figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="4026" height="2117" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/Figure1-4.png" alt="Diagram showing how the dimensions of query source (data-driven vs activity-driven) and query scope (local vs global) create four query classes that span the local-to-global query spectrum: data-local, activity-local, data-global, and activity-global. " class="wp-image-1140725" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/Figure1-4.png 4026w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/Figure1-4-300x158.png 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/Figure1-4-1024x538.png 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/Figure1-4-768x404.png 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/Figure1-4-1536x808.png 1536w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/Figure1-4-2048x1077.png 2048w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/Figure1-4-240x126.png 240w" sizes="auto, (max-width: 4026px) 100vw, 4026px" /><figcaption class="wp-element-caption">Figure 1. Construction of a 2&#215;2 design space for synthetic query generation with&nbsp;AutoQ, showing how the four resulting query classes map onto the local-global query spectrum.&nbsp;</figcaption></figure>



<p>AutoQ&nbsp;can be configured to generate&nbsp;any number and distribution of synthetic queries&nbsp;along these&nbsp;classes, enabling consistent benchmarking&nbsp;across datasets without&nbsp;requiring user&nbsp;customization.&nbsp;Figure 2 shows the synthesis process and sample&nbsp;queries&nbsp;from each class, using&nbsp;an AP News dataset.</p>



<figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="4162" height="2117" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/Figure2-3.png" alt="Diagram showing the processes for synthesizing queries in each of the four classes. Each process involves steps like generating dataset summaries, personas, tasks, and candidate queries, followed by clustering candidate queries and selecting the final query set. The data-local example query is “Why are junior doctors in South Korea striking in February 2024?”. The activity-local example query is “What are the public health implications of the newly discovered Alaskapox virus in Alaska?”. The data-global example query is “Across the dataset, what are the key public health challenges and the measures being taken to address them?”. The activity-global example query is “Across the dataset, what are the main public health initiatives mentioned that target underserved communities?”." class="wp-image-1140728" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/Figure2-3.png 4162w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/Figure2-3-300x153.png 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/Figure2-3-1024x521.png 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/Figure2-3-768x391.png 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/Figure2-3-1536x781.png 1536w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/Figure2-3-2048x1042.png 2048w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/Figure2-3-240x122.png 240w" sizes="auto, (max-width: 4162px) 100vw, 4162px" /><figcaption class="wp-element-caption">Figure 2. Synthesis process and example query for each of the&nbsp;four&nbsp;AutoQ&nbsp;query classes.&nbsp;</figcaption></figure>



	<div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="1116360">
		

		<p class="msr-promo__label text-gray-800 text-center text-uppercase">
		<span class="px-4 bg-white display-inline-block font-weight-semibold small">Microsoft Research Blog</span>
	</p>
	
	<div class="row pt-3 pb-4 align-items-center">
						<div class="msr-promo__media col-12 col-md-5">
				<a class="bg-gray-300 display-block" href="https://www.microsoft.com/en-us/research/story/microsoft-research-2024-a-year-in-review/" aria-label="Research at Microsoft 2024: Meeting the challenge of a changing world" data-bi-cN="Research at Microsoft 2024: Meeting the challenge of a changing world" target="_blank">
					<img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2024/12/Year-in-review-2024_Stories_Hero_Feature-1400x788-1.jpg" alt="Research at Microsoft 2024 - Year in Review" />
				</a>
			</div>
			
			<div class="msr-promo__content p-3 px-5 col-12 col-md">

									<h2 class="h4">Research at Microsoft 2024: Meeting the challenge of a changing world</h2>
				
								<p id="research-at-microsoft-2024-meeting-the-challenge-of-a-changing-world" class="large">In this new AI era, technology is changing even faster than before, and the transition from research to reality, from concept to solution, now takes days or weeks rather than months or years.</p>
				
								<div class="wp-block-buttons justify-content-center justify-content-md-start">
					<div class="wp-block-button">
						<a href="https://www.microsoft.com/en-us/research/story/microsoft-research-2024-a-year-in-review/" aria-describedby="research-at-microsoft-2024-meeting-the-challenge-of-a-changing-world" class="btn btn-brand glyph-append glyph-append-chevron-right" data-bi-cN="Research at Microsoft 2024: Meeting the challenge of a changing world" target="_blank">
							Read more						</a>
					</div>
				</div>
							</div><!--/.msr-promo__content-->
	</div><!--/.msr-promo__inner-wrap-->
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span>	</div><!--/.msr-promo-->
	


<h2 class="wp-block-heading" id="autoe-automated-evaluation-framework">AutoE: Automated evaluation&nbsp;framework&nbsp;</h2>



<p>Our evaluation of GraphRAG focused on analyzing key qualities of answers to global questions. The following qualities were used for the current evaluation:</p>



<ul class="wp-block-list">
<li><strong>Comprehensiveness</strong>:&nbsp;Does the&nbsp;answer&nbsp;address&nbsp;all&nbsp;relevant&nbsp;aspects&nbsp;of the question?&nbsp;</li>



<li><strong>Diversity</strong>:&nbsp;Does it present&nbsp;varied perspectives&nbsp;or&nbsp;insights?&nbsp;</li>



<li><strong>Empowerment</strong>:&nbsp;Does it&nbsp;help the reader understand and make informed judgments?&nbsp;</li>



<li><strong>Relevance</strong>:&nbsp;Does&nbsp;it&nbsp;address what the question is specifically asking?&nbsp;&nbsp;</li>
</ul>



<p>The&nbsp;AutoE&nbsp;component&nbsp;scales&nbsp;evaluation of&nbsp;these qualities&nbsp;using the LLM-as-a-Judge method.&nbsp;It&nbsp;presents&nbsp;pairs of answers to an LLM, along with the query and target metric,&nbsp;in counterbalanced order.&nbsp;The&nbsp;model determines whether the first answer wins, loses, or ties with the second.&nbsp;Over&nbsp;a set of queries, whether&nbsp;from&nbsp;AutoQ&nbsp;or elsewhere, this&nbsp;produces&nbsp;win rates between&nbsp;competing&nbsp;methods. When&nbsp;ground truth&nbsp;is available, AutoE&nbsp;can also score answers on&nbsp;correctness, completeness, and&nbsp;related metrics.</p>



<p>An illustrative&nbsp;evaluation&nbsp;is&nbsp;shown in Figure&nbsp;3.&nbsp;Using a dataset of&nbsp;1,397&nbsp;AP News&nbsp;articles&nbsp;on&nbsp;health and healthcare, AutoQ&nbsp;generated&nbsp;50 queries&nbsp;per&nbsp;class&nbsp;(200&nbsp;total).&nbsp;AutoE&nbsp;then&nbsp;compared&nbsp;LazyGraphRAG&nbsp;to&nbsp;a competing&nbsp;RAG method, running six&nbsp;trials&nbsp;per&nbsp;query&nbsp;across four&nbsp;metrics,&nbsp;using&nbsp;GPT-4.1 as a judge.</p>



<p>These&nbsp;trial-level results were aggregated&nbsp;using metric-based win rates,&nbsp;where each trial is scored 1 for a win, 0.5 for a tie, and 0 for a loss,&nbsp;and then averaged to calculate the overall win rate for each RAG method.</p>



<figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1200" height="1000" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/Figure3-4.png" alt="Bar charts with the y-axes representing win rates for LazyGraphRAG conditions. The x-axes contain a range of comparison conditions. Bars are clustered by LazyGraphRAG (LGR) condition and charts are faceted by query class. " class="wp-image-1140915" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/Figure3-4.png 1200w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/Figure3-4-300x250.png 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/Figure3-4-1024x853.png 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/Figure3-4-768x640.png 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/Figure3-4-216x180.png 216w" sizes="auto, (max-width: 1200px) 100vw, 1200px" /><figcaption class="wp-element-caption">Figure 3. Win rates of four&nbsp;LazyGraphRAG&nbsp;(LGR) configurations across methods, broken down by the&nbsp;AutoQ&nbsp;query class and averaged across&nbsp;AutoE’s&nbsp;four metrics: comprehensiveness, diversity, empowerment, and relevance.&nbsp;LazyGraphRAG&nbsp;outperforms&nbsp;comparison conditions&nbsp;where the bar&nbsp;is above&nbsp;50%.</figcaption></figure>



<p>The four LazyGraphRAG conditions (LGR_b200_c200, LGR_b50_c200, LGR_b50_c600, LGR_b200_c200_mini) differ by query budget (b50, b200) and chunk size (c200, c600). All used GPT-4o mini for relevance tests and GPT-4o for query expansion (to five subqueries) and answer generation, except for LGR_b200_c200_mini, which used GPT-4o mini throughout.</p>



<p>Comparison&nbsp;systems&nbsp;were&nbsp;GraphRAG&nbsp;(Local, Global, and Drift Search),&nbsp;Vector&nbsp;RAG&nbsp;with 8k-&nbsp;and 120k-token windows, and&nbsp;three&nbsp;published&nbsp;methods:&nbsp;<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/HKUDS/LightRAG" target="_blank" rel="noreferrer noopener">LightRAG<span class="sr-only"> (opens in new tab)</span></a>,&nbsp;<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/profintegra/raptor-rag" target="_blank" rel="noreferrer noopener">RAPTOR<span class="sr-only"> (opens in new tab)</span></a>, and&nbsp;<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://arxiv.org/abs/2503.02922" target="_blank" rel="noreferrer noopener">TREX<span class="sr-only"> (opens in new tab)</span></a>.&nbsp;All&nbsp;methods&nbsp;were limited to the same 8k&nbsp;tokens&nbsp;for answer generation.&nbsp;GraphRAG&nbsp;Global Search&nbsp;used&nbsp;level 2&nbsp;of the community hierarchy.</p>



<p>LazyGraphRAG outperformed every comparison condition using the same generative model (GPT-4o), winning all 96 comparisons, with all but one reaching statistical significance. The best overall performance came from the larger budget, smaller chunk size configuration (LGR_b200_c200). For DataLocal queries, the smaller budget (LGR_b50_c200) performed slightly better, likely because fewer chunks were relevant. For ActivityLocal queries, the larger chunk size (LGR_b50_c600) had a slight edge, likely because longer chunks provide a more coherent context.</p>



<p>Competing methods performed relatively better on the query classes for which they were designed: GraphRAG Global for global queries, Vector RAG for local queries, and GraphRAG Drift Search, which combines both strategies, posed the strongest challenge overall.</p>



<p>Increasing Vector RAG’s context window from 8k to 120k tokens did not improve its performance compared to LazyGraphRAG. This raised the question of how LazyGraphRAG would perform against Vector RAG with 1-million token context window containing most of the dataset.</p>



<p>Figure 4 shows the follow-up experiment comparing LazyGraphRAG to Vector RAG using GPT-4.1 that enabled this comparison. Even against the 1M-token window, LazyGraphRAG achieved higher win rates across all comparisons, failing to reach significance only for the relevance of answers to DataLocal queries. These queries tend to benefit most from Vector RAG’s ranking of directly relevant chunks, making it hard for LazyGraphRAG to generate answers that have greater <em>relevance</em> to the query, even though these answers may be dramatically more comprehensive, diverse, and empowering overall.</p>



<figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1200" height="1000" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/Figure4-1.png" alt="Bar charts with the y-axes representing win rates for LazyGraphRAG. The x-axes contain comparison conditions for vector-based RAG with 8 thousand, 120 thousand, and 1 million token context windows. Charts are faceted by query class and quality metric." class="wp-image-1140735" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/Figure4-1.png 1200w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/Figure4-1-300x250.png 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/Figure4-1-1024x853.png 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/Figure4-1-768x640.png 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/Figure4-1-216x180.png 216w" sizes="auto, (max-width: 1200px) 100vw, 1200px" /><figcaption class="wp-element-caption">Figure 4.&nbsp;Win rates of&nbsp;LazyGraphRAG&nbsp;(LGR)&nbsp;over Vector RAG&nbsp;across different&nbsp;context window sizes, broken down by the&nbsp;four&nbsp;AutoQ&nbsp;query classes&nbsp;and&nbsp;four&nbsp;AutoE&nbsp;metrics:&nbsp;comprehensiveness, diversity, empowerment, and relevance.&nbsp;Bars above 50%&nbsp;indicate&nbsp;that&nbsp;LazyGraphRAG&nbsp;outperformed&nbsp;the&nbsp;comparison&nbsp;condition.&nbsp;</figcaption></figure>



<h2 class="wp-block-heading" id="autod-automated-data-sampling-and-summarization">AutoD: Automated data sampling and summarization</h2>



<p>Text datasets have an underlying topical structure, but the depth, breadth, and connectivity of that structure can vary widely. This variability makes it difficult to evaluate RAG systems consistently, as results may reflect the idiosyncrasies of the dataset rather than the system’s general capabilities.</p>



<p>The AutoD component addresses this by sampling datasets to meet a target specification, defined by the number of topic clusters (breadth) and the number of samples per cluster (depth). This creates consistency across datasets, enabling more meaningful comparisons, as structurally aligned datasets lead to comparable AutoQ queries, which in turn support consistent AutoE evaluations.</p>



<p>AutoD also includes tools for summarizing input or output datasets in a way that reflects their topical coverage. These summaries play an important role in the AutoQ query synthesis process, but they can also be used more broadly, such as in prompts where context space is limited.</p>



<h2 class="wp-block-heading" id="supporting-the-community-with-open-data-and-tools">Supporting the&nbsp;community with open data and tools&nbsp;</h2>



<p>Since the release of the&nbsp;GraphRAG&nbsp;paper,&nbsp;we’ve&nbsp;received&nbsp;many requests&nbsp;to share the&nbsp;dataset of the&nbsp;<a href="https://www.microsoft.com/en-us/behind-the-tech" target="_blank" rel="noreferrer noopener"><em>Behind the Tech</em><span class="sr-only"> (opens in new tab)</span></a>&nbsp;podcast&nbsp;transcripts&nbsp;we used in our evaluation.&nbsp;An updated version of this dataset&nbsp;is now available in the <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/benchmark-qed" target="_blank" rel="noreferrer noopener">BenchmarkQED&nbsp;repository<span class="sr-only"> (opens in new tab)</span></a>, alongside&nbsp;the&nbsp;AP News dataset&nbsp;containing&nbsp;1,397&nbsp;health-related&nbsp;articles,&nbsp;licensed for open&nbsp;release.&nbsp;&nbsp;</p>



<p>We hope these datasets, together with&nbsp;the&nbsp;<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/benchmark-qed" target="_blank" rel="noreferrer noopener">BenchmarkQED&nbsp;tools<span class="sr-only"> (opens in new tab)</span></a>,&nbsp;help&nbsp;accelerate&nbsp;benchmark-driven&nbsp;development of&nbsp;RAG systems and&nbsp;AI question-answering.&nbsp;We invite the community to try them&nbsp;on&nbsp;<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/benchmark-qed" target="_blank" rel="noreferrer noopener">GitHub<span class="sr-only"> (opens in new tab)</span></a>.&nbsp;</p>
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/blog/benchmarkqed-automated-benchmarking-of-rag-systems/">BenchmarkQED: Automated benchmarking of RAG systems</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>What AI&#8217;s impact on individuals means for the health workforce and industry</title>
		<link>https://www.microsoft.com/en-us/research/podcast/what-ais-impact-on-individuals-means-for-the-health-workforce-and-industry/</link>
		
		<dc:creator><![CDATA[Peter Lee, Ethan Mollick, Azeem Azhar]]></dc:creator>
		<pubDate>Thu, 29 May 2025 15:13:48 +0000</pubDate>
				<category><![CDATA[Microsoft Research Podcast]]></category>
		<guid isPermaLink="false">https://www.microsoft.com/en-us/research/?p=1140315</guid>

					<description><![CDATA[<p>Ethan Mollick and Azeem Azhar, thought leaders at the forefront of AI’s influence on work, education, and society, discuss the impact of AI at the individual level and what that means for the healthcare workforce and the organizations and systems in medicine.</p>
<p>The post <a href="https://www.microsoft.com/en-us/research/podcast/what-ais-impact-on-individuals-means-for-the-health-workforce-and-industry/">What AI&#8217;s impact on individuals means for the health workforce and industry</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="1401" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/Episode6-PeterEthanAzeem-AIRevolution_Hero_Feature_No_Text_1400x788.jpg" alt="Illustrated headshots of Azeem Azhar, Peter Lee, and Ethan Mollick." class="wp-image-1140433" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/Episode6-PeterEthanAzeem-AIRevolution_Hero_Feature_No_Text_1400x788.jpg 1401w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/Episode6-PeterEthanAzeem-AIRevolution_Hero_Feature_No_Text_1400x788-300x169.jpg 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/Episode6-PeterEthanAzeem-AIRevolution_Hero_Feature_No_Text_1400x788-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/Episode6-PeterEthanAzeem-AIRevolution_Hero_Feature_No_Text_1400x788-768x432.jpg 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/Episode6-PeterEthanAzeem-AIRevolution_Hero_Feature_No_Text_1400x788-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/Episode6-PeterEthanAzeem-AIRevolution_Hero_Feature_No_Text_1400x788-655x368.jpg 655w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/Episode6-PeterEthanAzeem-AIRevolution_Hero_Feature_No_Text_1400x788-240x135.jpg 240w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/Episode6-PeterEthanAzeem-AIRevolution_Hero_Feature_No_Text_1400x788-640x360.jpg 640w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/Episode6-PeterEthanAzeem-AIRevolution_Hero_Feature_No_Text_1400x788-960x540.jpg 960w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/Episode6-PeterEthanAzeem-AIRevolution_Hero_Feature_No_Text_1400x788-1280x720.jpg 1280w" sizes="auto, (max-width: 1401px) 100vw, 1401px" /></figure>


<div class="wp-block-msr-podcast-container my-4">
	<iframe loading="lazy" src="https://player.blubrry.com/?podcast_id=145869951&modern=1" class="podcast-player" frameborder="0" height="164px" width="100%" scrolling="no" title="Podcast Player"></iframe>
</div>



<p>In November 2022, OpenAI’s ChatGPT kick-started a new era in AI. This was followed less than a half year later by the release of GPT-4. In the months leading up to GPT-4’s public release, Peter Lee, president of Microsoft Research, cowrote a book full of optimism for the potential of advanced AI models to transform the world of healthcare. What has happened since? In this special podcast series, Lee revisits the book, exploring how patients, providers, and other medical professionals are experiencing and using generative AI today while examining what he and his coauthors got right—and what they didn’t foresee.</p>



<p>In this episode, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://mgmt.wharton.upenn.edu/profile/emollick/" target="_blank" rel="noreferrer noopener">Ethan Mollick<span class="sr-only"> (opens in new tab)</span></a> and <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.azeemazhar.com/" target="_blank" rel="noreferrer noopener">Azeem Azhar<span class="sr-only"> (opens in new tab)</span></a>, thought leaders at the forefront of AI’s impact on work, education, and society, join Lee to discuss how generative AI is reshaping healthcare and organizational systems. Mollick, professor at the Wharton School, discusses the conflicting emotions that come with navigating AI’s effect on the tasks we enjoy and those we don’t; the systemic challenges in AI adoption; and the need for organizations to actively experiment with AI rather than wait for top-down solutions. Azhar, a technology analyst and writer who explores the intersection of AI, economics, and society, explores how generative AI is transforming healthcare through applications like medical scribing, clinician support, and consumer health monitoring.</p>



<div class="wp-block-group msr-pattern-link-list is-layout-flow wp-block-group-is-layout-flow">
<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading h5" id="learn-more-1">Learn more:</h2>



<ul class="wp-block-list list-unstyled">
<li><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/" target="_blank" rel="noreferrer noopener">Co-Intelligence: Living and Working with AI<span class="sr-only"> (opens in new tab)</span></a>&nbsp;(Mollick)<br>Book | April 2024</li>



<li><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.oneusefulthing.org/" target="_blank" rel="noreferrer noopener">One Useful Thing<span class="sr-only"> (opens in new tab)</span></a> (Mollick)<br>Substack blog/newsletter</li>



<li><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://diversionbooks.com/books/the-exponential-age/" target="_blank" rel="noreferrer noopener">The Exponential Age: How Accelerating Technology is Transforming Business, Politics and Society<span class="sr-only"> (opens in new tab)</span></a> (Azhar)<br>Book | September 2021</li>



<li><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.exponentialview.co/" target="_blank" rel="noreferrer noopener">Exponential View<span class="sr-only"> (opens in new tab)</span></a> (Azhar)<br>Substack blog/newsletter</li>



<li><a href="https://www.microsoft.com/en-us/research/publication/the-ai-revolution-in-medicine-gpt-4-and-beyond/" target="_blank" rel="noreferrer noopener">The AI Revolution in Medicine: GPT-4 and Beyond</a>  &nbsp;<br>Book | Peter Lee, Carey Goldberg, Isaac Kohane | April 2023</li>
</ul>
</div>



<div style="height:25px" aria-hidden="true" class="wp-block-spacer"></div>



<section class="wp-block-msr-subscribe-to-podcast subscribe-to-podcast">
	<div class="subscribe-to-podcast__inner border-top border-bottom border-width-2">
		<h2 class="h5 subscribe-to-podcast__heading">
			Subscribe to the <a href="https://www.microsoft.com/en-us/research/podcast">Microsoft Research Podcast</a>:		</h2>
		<ul class="subscribe-to-podcast__list list-unstyled">
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://itunes.apple.com/us/podcast/microsoft-research-a-podcast/id1318021537?mt=2" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="black" viewBox="0 0 32 32">  <path d="M7.12 0c-3.937-0.011-7.131 3.183-7.12 7.12v17.76c-0.011 3.937 3.183 7.131 7.12 7.12h17.76c3.937 0.011 7.131-3.183 7.12-7.12v-17.76c0.011-3.937-3.183-7.131-7.12-7.12zM15.817 3.421c3.115 0 5.932 1.204 8.079 3.453 1.631 1.693 2.547 3.489 3.016 5.855 0.161 0.787 0.161 2.932 0.009 3.817-0.5 2.817-2.041 5.339-4.317 7.063-0.812 0.615-2.797 1.683-3.115 1.683-0.12 0-0.129-0.12-0.077-0.615 0.099-0.792 0.192-0.953 0.64-1.141 0.713-0.296 1.932-1.167 2.677-1.911 1.301-1.303 2.229-2.932 2.677-4.719 0.281-1.1 0.244-3.543-0.063-4.672-0.969-3.595-3.907-6.385-7.5-7.136-1.041-0.213-2.943-0.213-4 0-3.636 0.751-6.647 3.683-7.563 7.371-0.245 1.004-0.245 3.448 0 4.448 0.609 2.443 2.188 4.681 4.255 6.015 0.407 0.271 0.896 0.547 1.1 0.631 0.447 0.192 0.547 0.355 0.629 1.14 0.052 0.485 0.041 0.62-0.072 0.62-0.073 0-0.62-0.235-1.199-0.511l-0.052-0.041c-3.297-1.62-5.407-4.364-6.177-8.016-0.187-0.943-0.224-3.187-0.036-4.052 0.479-2.323 1.396-4.135 2.921-5.739 2.199-2.319 5.027-3.543 8.172-3.543zM16 7.172c0.541 0.005 1.068 0.052 1.473 0.14 3.715 0.828 6.344 4.543 5.833 8.229-0.203 1.489-0.713 2.709-1.619 3.844-0.448 0.573-1.537 1.532-1.729 1.532-0.032 0-0.063-0.365-0.063-0.803v-0.808l0.552-0.661c2.093-2.505 1.943-6.005-0.339-8.296-0.885-0.896-1.912-1.423-3.235-1.661-0.853-0.161-1.031-0.161-1.927-0.011-1.364 0.219-2.417 0.744-3.355 1.672-2.291 2.271-2.443 5.791-0.348 8.296l0.552 0.661v0.813c0 0.448-0.037 0.807-0.084 0.807-0.036 0-0.349-0.213-0.683-0.479l-0.047-0.016c-1.109-0.885-2.088-2.453-2.495-3.995-0.244-0.932-0.244-2.697 0.011-3.625 0.672-2.505 2.521-4.448 5.079-5.359 0.547-0.193 1.509-0.297 2.416-0.281zM15.823 11.156c0.417 0 0.828 0.084 1.131 0.24 0.645 0.339 1.183 0.989 1.385 1.677 0.62 2.104-1.609 3.948-3.631 3.005h-0.015c-0.953-0.443-1.464-1.276-1.475-2.36 0-0.979 0.541-1.828 1.484-2.328 0.297-0.156 0.709-0.235 1.125-0.235zM15.812 17.464c1.319-0.005 2.271 0.463 2.625 1.291 0.265 0.62 0.167 2.573-0.292 5.735-0.307 2.208-0.479 2.765-0.905 3.141-0.589 0.52-1.417 0.667-2.209 0.385h-0.004c-0.953-0.344-1.157-0.808-1.553-3.527-0.452-3.161-0.552-5.115-0.285-5.735 0.348-0.823 1.296-1.285 2.624-1.291z"/></svg>
						<span class="subscribe-to-podcast__link-text">Apple Podcasts</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://subscribebyemail.com/www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M6.4 6a2.392 2.392 0 00-2.372 2.119L16 15.6l11.972-7.481A2.392 2.392 0 0025.6 6H6.4zM4 10.502V22.8a2.4 2.4 0 002.4 2.4h19.2a2.4 2.4 0 002.4-2.4V10.502l-11.365 7.102a1.2 1.2 0 01-1.27 0L4 10.502z"/></svg>
						<span class="subscribe-to-podcast__link-text">Email</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://subscribeonandroid.com/www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M12.414 4.02c-.062.012-.126.023-.18.06a.489.489 0 00-.12.675L13.149 6.3c-1.6.847-2.792 2.255-3.18 3.944h13.257c-.388-1.69-1.58-3.097-3.179-3.944l1.035-1.545a.489.489 0 00-.12-.675.492.492 0 00-.675.135l-1.14 1.68a7.423 7.423 0 00-2.55-.45c-.899 0-1.758.161-2.549.45l-1.14-1.68a.482.482 0 00-.494-.195zm1.545 3.824a.72.72 0 110 1.44.72.72 0 010-1.44zm5.278 0a.719.719 0 110 1.44.719.719 0 110-1.44zM8.44 11.204A1.44 1.44 0 007 12.644v6.718c0 .795.645 1.44 1.44 1.44.168 0 .33-.036.48-.09v-9.418a1.406 1.406 0 00-.48-.09zm1.44 0V21.76c0 .793.646 1.44 1.44 1.44h10.557c.793 0 1.44-.647 1.44-1.44V11.204H9.878zm14.876 0c-.169 0-.33.035-.48.09v9.418c.15.052.311.09.48.09a1.44 1.44 0 001.44-1.44v-6.719a1.44 1.44 0 00-1.44-1.44zM11.8 24.16v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84zm5.759 0v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84z"/></svg>
						<span class="subscribe-to-podcast__link-text">Android</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://open.spotify.com/show/4ndjUXyL0hH1FXHgwIiTWU" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M16 4C9.383 4 4 9.383 4 16s5.383 12 12 12 12-5.383 12-12S22.617 4 16 4zm5.08 17.394a.781.781 0 01-1.086.217c-1.29-.86-3.477-1.434-5.303-1.434-1.937.002-3.389.477-3.403.482a.782.782 0 11-.494-1.484c.068-.023 1.71-.56 3.897-.562 1.826 0 4.365.492 6.171 1.696.36.24.457.725.217 1.085zm1.56-3.202a.895.895 0 01-1.234.286c-2.338-1.457-4.742-1.766-6.812-1.747-2.338.02-4.207.466-4.239.476a.895.895 0 11-.488-1.723c.145-.041 2.01-.5 4.564-.521 2.329-.02 5.23.318 7.923 1.995.419.26.547.814.286 1.234zm1.556-3.745a1.043 1.043 0 01-1.428.371c-2.725-1.6-6.039-1.94-8.339-1.942h-.033c-2.781 0-4.923.489-4.944.494a1.044 1.044 0 01-.474-2.031c.096-.023 2.385-.55 5.418-.55h.036c2.558.004 6.264.393 9.393 2.23.497.292.663.931.371 1.428z"/></svg>
						<span class="subscribe-to-podcast__link-text">Spotify</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M6.667 4a2.676 2.676 0 00-2.612 2.13v.003c-.036.172-.055.35-.055.534v18.666c0 .183.019.362.055.534v.003a2.676 2.676 0 002.076 2.075h.002c.172.036.35.055.534.055h18.666A2.676 2.676 0 0028 25.333V6.667a2.676 2.676 0 00-2.13-2.612h-.003A2.623 2.623 0 0025.333 4H6.667zM8 8h1.333C17.42 8 24 14.58 24 22.667V24h-2.667v-1.333c0-6.618-5.382-12-12-12H8V8zm0 5.333h1.333c5.146 0 9.334 4.188 9.334 9.334V24H16v-1.333A6.674 6.674 0 009.333 16H8v-2.667zM10 20a2 2 0 11-.001 4.001A2 2 0 0110 20z"/></svg>
						<span class="subscribe-to-podcast__link-text">RSS Feed</span>
					</a>
				</li>
					</ul>
	</div>
</section>


<div class="wp-block-msr-show-more">
	<div class="bg-neutral-100 p-5">
		<div class="show-more-show-less" data-mount="show-more-show-less">
			<div>
				<span>
					

<h2 class="wp-block-heading" id="transcript">Transcript</h2>



<p>[MUSIC]  &nbsp;</p>



<p>[BOOK PASSAGE] </p>



<p><strong>PETER LEE:</strong> “In American primary care, the missing workforce is stunning in magnitude, the shortfall estimated to reach up to 48,000 doctors within the next dozen years. China and other countries with aging populations can expect drastic shortfalls, as well. Just last month, I asked a respected colleague retiring from primary care who he would recommend as a replacement; he told me bluntly that, other than expensive concierge care practices, he could not think of anyone, even for himself. This mismatch between need and supply will only grow, and the US is far from alone among developed countries in facing it.”</p>



<p>[END OF BOOK PASSAGE]  &nbsp;</p>



<p>[THEME MUSIC]  &nbsp;</p>



<p>This is <em>The AI Revolution in Medicine, Revisited</em>. I’m your host, Peter Lee.  &nbsp;</p>



<p>Shortly after OpenAI&#8217;s GPT-4 was publicly released, Carey Goldberg, Dr. Zak Kohane, and I published <em>The AI Revolution in Medicine </em>to help educate the world of healthcare and medical research about the transformative impact this new generative AI technology could have. But because we wrote the book when GPT-4 was still a secret, we had to speculate. Now, two years later, what did we get right, and what did we get wrong?   &nbsp;</p>



<p>In this series, we’ll talk to clinicians, patients, hospital administrators, and others to understand the reality of AI in the field and where we go from here.    &nbsp;</p>



<p>[THEME MUSIC FADES]</p>



				</span>
				<span id="show-more-show-less-toggle-9" class="show-more-show-less-toggleable-content">
					



<p>The book passage I read at the top is from “Chapter 4: Trust but Verify,” which was written by Zak. </p>



<p>You know, it’s no secret that in the US and elsewhere shortages in medical staff and the rise of clinician burnout are affecting the quality of patient care for the worse. In our book, we predicted that generative AI would be something that might help address these issues.</p>



<p>So in this episode, we’ll delve into how individual performance gains that our previous guests have described might affect the healthcare workforce as a whole, and on the patient side, we’ll look into the influence of generative AI on the consumerization of healthcare. Now, since all of this consumes such a huge fraction of the overall economy, we’ll also get into what a general-purpose technology as disruptive as generative AI might mean in the context of labor markets and beyond.&nbsp;&nbsp;</p>



<p>To help us do that, I’m pleased to welcome Ethan Mollick and Azeem Azhar.</p>



<p>Ethan Mollick is the Ralph J. Roberts Distinguished Faculty Scholar, a Rowan Fellow, and an associate professor at the Wharton School of the University of Pennsylvania. His research into the effects of AI on work, entrepreneurship, and education is applied by organizations around the world, leading him to be named one of <em>Time</em> magazine&#8217;s most influential people in AI for 2024. He&#8217;s also the author of the <em>New York Times</em> best-selling book <em>Co-Intelligence</em>.</p>



<p>Azeem Azhar is an author, founder, investor, and one of the most thoughtful and influential voices on the interplay between disruptive emerging technologies and business and society. In his best-selling book, <em>The Exponential Age</em>, and in his highly regarded newsletter and podcast, <em>Exponential View</em>, he explores how technologies like AI are reshaping everything from healthcare to geopolitics.</p>



<p>Ethan and Azeem are two leading thinkers on the ways that disruptive technologies—and especially AI—affect our work, our jobs, our business enterprises, and whole industries. As economists, they are trying to work out whether we are in the midst of an economic revolution as profound as the shift from an agrarian to an industrial society.</p>



<p>[TRANSITION MUSIC]</p>



<p>Here is my interview with Ethan Mollick:</p>



<p><strong>LEE: </strong>Ethan, welcome.</p>



<p><strong>ETHAN MOLLICK: </strong>So happy to be here, thank you.</p>



<p><strong>LEE:</strong> I described you as a professor at Wharton, which I think most of the people who listen to this podcast series know of as an elite business school. So it might surprise some people that you study AI. And beyond that, you know, that I would seek you out to talk about AI in medicine. [LAUGHTER] So to get started, how and why did it happen that you&#8217;ve become one of <em>the</em> leading experts on AI?</p>



<p><strong>MOLLICK:</strong> It&#8217;s actually an interesting story. I&#8217;ve been AI-adjacent my whole career. When I was [getting] my PhD at MIT, I worked with <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.britannica.com/biography/Marvin-Minsky" target="_blank" rel="noreferrer noopener">Marvin Minsky<span class="sr-only"> (opens in new tab)</span></a> and the MIT [Massachusetts Institute of Technology] Media Labs AI group. But I was never the technical AI guy. I was the person who was trying to explain AI to everybody else who didn&#8217;t understand it.</p>



<p>And then I became very interested in, how do you train and teach? And AI was always a part of that. I was building games for teaching, teaching tools that were used in hospitals and elsewhere, simulations. So when LLMs burst into the scene, I had already been using them and had a good sense of what they could do. And between that and, kind of, being practically oriented and getting some of the first research projects underway, especially under education and AI and performance, I became sort of a go-to person in the field.</p>



<p>And once you&#8217;re in a field where nobody knows what&#8217;s going on and we&#8217;re all making it up as we go along—I thought it&#8217;s funny that you led with the idea that you have a couple of months head start for GPT-4, right. Like that&#8217;s all we have at this point, is a few months&#8217; head start. [LAUGHTER] So being a few months ahead is good enough to be an expert at this point. Whether it should be or not is a different question.</p>



<p><strong>LEE:</strong> Well, if I understand correctly, leading AI companies like OpenAI, Anthropic, and others have now sought you out as someone who should get early access to really start to do early assessments and gauge early reactions. How has that been?</p>



<p><strong>MOLLICK:</strong> So, I mean, I think the bigger picture is less about me than about two things that tells us about the state of AI right now.</p>



<p>One, nobody really knows what&#8217;s going on, right. So in a lot of ways, if it wasn&#8217;t for your work, Peter, like, I don&#8217;t think people would be thinking about medicine as much because these systems weren&#8217;t built for medicine. They weren&#8217;t built to change education. They weren&#8217;t built to write memos. They, like, they weren&#8217;t built to do any of these things. They weren&#8217;t really built to do anything in particular. It turns out they&#8217;re just good at many things.</p>



<p>And to the extent that the labs work on them, they care about their coding ability above everything else and maybe math and science secondarily. They don&#8217;t think about the fact that it expresses high empathy. They don&#8217;t think about its accuracy and diagnosis or where it&#8217;s inaccurate. They don&#8217;t think about how it&#8217;s changing education forever.</p>



<p>So one part of this is the fact that they go to my Twitter feed or ask me for advice is an indicator of where they are, too, which is they&#8217;re not thinking about this. And the fact that a few months&#8217; head start continues to give you a lead tells you that we are at the very cutting edge. These labs aren&#8217;t sitting on projects for two years and then releasing them. Months after a project is complete or sooner, it&#8217;s out the door. Like, there&#8217;s very little delay. So we&#8217;re kind of all in the same boat here, which is a very unusual space for a new technology.</p>



<p><strong>LEE: </strong>And I, you know, explained that you&#8217;re at Wharton. Are you an odd fit as a faculty member at Wharton, or is this a trend now even in business schools that AI experts are becoming key members of the faculty?</p>



<p><strong>MOLLICK: </strong>I mean, it&#8217;s a little of both, right. It&#8217;s faculty, so everybody does everything. I&#8217;m a professor of innovation-entrepreneurship. I&#8217;ve launched startups before and working on that and education means I think about, how do organizations redesign themselves? How do they take advantage of these kinds of problems? So medicine&#8217;s always been very central to that, right. A lot of people in my MBA class have been MDs either switching, you know, careers or else looking to advance from being sort of individual contributors to running teams. So I don&#8217;t think that&#8217;s that bad a fit. But I also think this is general-purpose technology; it&#8217;s going to touch everything. The focus on this is medicine, but Microsoft does far more than medicine, right. It&#8217;s … there&#8217;s transformation happening in literally every field, in every country. This is a widespread effect.</p>



<p>So I don&#8217;t think we should be surprised that business schools matter on this because we care about management. There&#8217;s a long tradition of management and medicine going together. There&#8217;s actually a great academic paper that shows that <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.nber.org/papers/w23880" target="_blank" rel="noreferrer noopener">teaching hospitals that also have MBA programs associated with them have higher management scores and perform better<span class="sr-only"> (opens in new tab)</span></a>. So I think that these are not as foreign concepts, especially as medicine continues to get more complicated.</p>



<p><strong>LEE: </strong>Yeah. Well, in fact, I want to dive a little deeper on these issues of management, of entrepreneurship, um, education. But before doing that, if I could just stay focused on you. There is always something interesting to hear from people about their first encounters with AI. And throughout this entire series, I&#8217;ve been doing that both <em>pre</em>-generative AI and post-generative AI. So you, sort of, hinted at the pre-generative AI. You were in Minsky&#8217;s lab. Can you say a little bit more about that early encounter? And then tell us about your first encounters with generative AI.</p>



<p><strong>MOLLICK:</strong> Yeah. Those are great questions. So first of all, when I was at the media lab, that was pre-the current boom in sort of, you know, even in the old-school machine learning kind of space. So there was a lot of potential directions to head in. While I was there, there were projects underway, for example, to record every interaction small children had. One of the professors was recording everything their baby interacted with in the hope that maybe that would give them a hint about how to build an AI system.</p>



<p>There was a bunch of projects underway that were about labeling every concept and how they relate to other concepts. So, like, it was very much Wild West of, like, how do we make an AI work—which has been this repeated problem in AI, which is, what is this thing?</p>



<p>The fact that it was just like brute force over the corpus of all human knowledge turns out to be a little bit of like a, you know, it&#8217;s a miracle and a little bit of a disappointment in some ways [LAUGHTER] compared to how elaborate some of this was. So, you know, I think that, that was sort of my first encounters in sort of the intellectual way.</p>



<p>The generative AI encounters actually started with the original, sort of, GPT-3, or, you know, earlier versions. And it was actually game-based. So I played games like AI Dungeon. And as an educator, I realized, oh my gosh, this stuff could write essays at a fourth-grade level. That&#8217;s really going to change the way, like, middle school works, was my thinking at the time. And I was posting about that back in, you know, 2021 that this is a big deal. But I think everybody was taken surprise, including the AI companies themselves, by, you know, ChatGPT, by GPT-3.5. The difference in degree turned out to be a difference in kind.</p>



<p><strong>LEE:</strong> Yeah, you know, if I think back, even with GPT-3, and certainly this was the case with GPT-2, it was, at least, you know, from where I was sitting, it was hard to get people to really take this seriously and pay attention.</p>



<p><strong>MOLLICK: </strong>Yes.</p>



<p><strong>LEE:</strong> You know, it&#8217;s remarkable. Within Microsoft, I think a turning point was the use of GPT-3 to do code completions. And that was actually productized as <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/features/copilot" target="_blank" rel="noreferrer noopener">GitHub Copilot<span class="sr-only"> (opens in new tab)</span></a>, the very first version. That, I think, is where there was widespread belief. But, you know, in a way, I think there is, even for me early on, a sense of denial and skepticism. Did you have those initially at any point?</p>



<p><strong>MOLLICK: </strong>Yeah, I mean, it still happens today, right. Like, this is a weird technology. You know, the original denial and skepticism was, I couldn&#8217;t see where this was going. It didn&#8217;t seem like a miracle because, you know, of course computers can complete code for you. Like, what else are they supposed to do? Of course, computers can give you answers to questions and write fun things. So there&#8217;s difference of moving into a world of generative AI. I think a lot of people just thought that&#8217;s what computers could do. So it made the conversations a little weird. But even today, faced with these, you know, with very strong reasoner models that operate at the level of PhD students, I think a lot of people have issues with it, right.</p>



<p>I mean, first of all, they seem intuitive to use, but they&#8217;re not always intuitive to use because the first use case that everyone puts AI to, it fails at because they use it like Google or some other use case. And then it&#8217;s genuinely upsetting in a lot of ways. I think, you know, I write in my book about the idea of three sleepless nights. That hasn&#8217;t changed. Like, you have to have an intellectual crisis to some extent, you know, and I think people do a lot to avoid having that existential angst of like, “Oh my god, what does it mean that a machine could think—<em>apparently think</em>—like a person?”</p>



<p>So, I mean, I see resistance now. I saw resistance then. And then on top of all of that, there&#8217;s the fact that the curve of the technology is quite great. I mean, the price of GPT-4 level intelligence from, you know, when it was released has dropped 99.97% at this point, right.</p>



<p><strong>LEE:</strong> Yes. Mm-hmm.</p>



<p><strong>MOLLICK:</strong> I mean, I could run a GPT-4 class system basically on my phone. Microsoft&#8217;s releasing things that can almost run on like, you know, like it fits in almost no space, that are almost as good as the original GPT-4 models. I mean, I don&#8217;t think people have a sense of how fast the trajectory is moving either.</p>



<p><strong>LEE:</strong> Yeah, you know, there&#8217;s something that I think about often. There is this existential dread, or will this technology replace me? But I think the first people to feel that are researchers—people encountering this for the first time. You know, if you were working, let&#8217;s say, in Bayesian reasoning or in traditional, let&#8217;s say, Gaussian mixture model based, you know, speech recognition, you do get this feeling, <em>Oh, my god, this technology has just solved the problem that I&#8217;ve dedicated my life to</em>. And there is this really difficult period where you have to cope with that. And I think this is going to be spreading, you know, in more and more walks of life. And so this … at what point does that sort of sense of dread hit you, if ever?</p>



<p><strong>MOLLICK: </strong>I mean, you know, it&#8217;s not even dread as much as like, you know, Tyler Cowen wrote that it&#8217;s impossible to not feel a little bit of sadness as you use these AI systems, too. Because, like, I was talking to a friend, just as the most minor example, and his talent that he was very proud of was he was very good at writing limericks for birthday cards. He&#8217;d write these limericks. Everyone was always amused by them. [LAUGHTER]</p>



<p>And now, you know, GPT-4 and GPT-4.5, they made limericks obsolete. Like, anyone can write a good limerick, right. So this was a talent, and it was a little sad. Like, this thing that you cared about mattered.</p>



<p>You know, as academics, we&#8217;re a little used to dead ends, right, and like, you know, some getting the lap. But the idea that entire fields are hitting that way. Like in medicine, there&#8217;s a lot of support systems that are now obsolete. And the question is how quickly you change that. In education, a lot of our techniques are obsolete.</p>



<p>What do you do to change that? You know, it&#8217;s like the fact that this brute force technology is good enough to solve so many problems is weird, right. And it&#8217;s not just the end of, you know, of our research angles that matter, too. Like, for example, I ran this, you know, 14-person-plus, multimillion-dollar effort at Wharton to build these teaching simulations, and we&#8217;re very proud of them. It took years of work to build one.</p>



<p>Now we&#8217;ve built a system that can build teaching simulations on demand by you talking to it with one team member. And, you know, you literally can create any simulation by having a discussion with the AI. I mean, you know, there&#8217;s a switch to a new form of excitement, but there is a little bit of like, this mattered to me, and, you know, now I have to change how I do things. I mean, adjustment happens. But if you haven&#8217;t had that displacement, I think that&#8217;s a good indicator that you haven&#8217;t really faced AI yet.</p>



<p><strong>LEE: </strong>Yeah, what&#8217;s so interesting just listening to you is you use words like sadness, and yet I can see the—and hear the—excitement in your voice and your body language. So, you know, that&#8217;s also kind of an interesting aspect of all of this.&nbsp;</p>



<p><strong>MOLLICK:</strong> Yeah, I mean, I think there&#8217;s something on the other side, right. But, like, I can&#8217;t say that I haven&#8217;t had moments where like, <em>ughhhh</em>, but then there&#8217;s joy and basically like also, you know, freeing stuff up. I mean, I think about doctors or professors, right. These are jobs that bundle together lots of different tasks that you would never have put together, right. If you&#8217;re a doctor, you would never have expected the same person to be good at keeping up with the research and being a good diagnostician and being a good manager and being good with people and being good with hand skills.</p>



<p>Like, who would ever want that kind of bundle? That&#8217;s not something you&#8217;re all good at, right. And a lot of our stress of our job comes from the fact that we suck at some of it. And so to the extent that AI steps in for that, you kind of feel bad about some of the stuff that it&#8217;s doing that you wanted to do. But it&#8217;s much more uplifting to be like, I don&#8217;t have to do this stuff I&#8217;m bad anymore, or I get the support to make myself good at it. And the stuff that I really care about, I can focus on more. Well, because we are at kind of a unique moment where whatever you&#8217;re best at, you&#8217;re still better than AI. And I think it&#8217;s an ongoing question about how long that lasts. But for right now, like you&#8217;re not going to say, OK, AI replaces me entirely in my job in medicine. It&#8217;s very unlikely.</p>



<p>But you will say it replaces these 17 things I&#8217;m bad at, but I never liked that anyway. So it&#8217;s a period of both excitement and a little anxiety.</p>



<p><strong>LEE:</strong> Yeah, I&#8217;m going to want to get back to this question about in what ways AI may or may not replace doctors or some of what doctors and nurses and other clinicians do. But before that, let&#8217;s get into, I think, the real meat of this conversation. In previous episodes of this podcast, we talked to clinicians and healthcare administrators and technology developers that are very rapidly injecting AI today to do various forms of workforce automation, you know, automatically writing a clinical encounter note, automatically filling out a referral letter or request for prior authorization for some reimbursement to an insurance company.</p>



<p>And so these sorts of things are intended not only to make things more efficient and lower costs but also to reduce various forms of drudgery, <em>cognitive burden</em> on frontline health workers. So how do you think about the impact of AI on that aspect of workforce, and, you know, what would you expect will happen over the next few years in terms of impact on efficiency and costs?</p>



<p><strong>MOLLICK: </strong>So I mean, this is a case where I think we&#8217;re facing the big bright problem in AI in a lot of ways, which is that this is … at the individual level, there&#8217;s lots of performance gains to be gained, right. The problem, though, is that we as individuals fit into systems, in medicine as much as anywhere else or more so, right. Which is that you could individually boost your performance, but it&#8217;s also about systems that fit along with this, right.</p>



<p>So, you know, if you could automatically, you know, record an encounter, if you could automatically make notes, does that change what you should be expecting for notes or the value of those notes or what they&#8217;re for? How do we take what one person does and validate it across the organization and roll it out for everybody without making it a 10-year process that it feels like IT in medicine often is? Like, so we&#8217;re in this really interesting period where there&#8217;s incredible amounts of individual innovation in productivity and performance improvements in this field, like very high levels of it, but not necessarily seeing that same thing translate to organizational efficiency or gains.</p>



<p>And one of my big concerns is seeing that happen. We&#8217;re seeing that in nonmedical problems, the same kind of thing, which is, you know, we&#8217;ve got research showing 20 and 40% performance improvements, like not uncommon to see those things. But then the organization doesn&#8217;t capture it; the system doesn&#8217;t capture it. Because the individuals are doing their own work and the systems don&#8217;t have the ability to, kind of, learn or adapt as a result.</p>



<p><strong>LEE:</strong> You know, where are those productivity gains going, then, when you get to the organizational level?</p>



<p><strong>MOLLICK: </strong>Well, they&#8217;re dying for a few reasons. One is, there&#8217;s a tendency for individual contributors to underestimate the power of management, right.</p>



<p>Practices associated with good management increase happiness, decrease, you know, issues, increase success rates. In the same way, about 40%, as far as we can tell, of the US advantage over other companies, of US firms, has to do with management ability. Like, management is a big deal. Organizing is a big deal. Thinking about how you coordinate is a big deal.</p>



<p>At the individual level, when things get stuck there, right, you can&#8217;t start bringing them up to how systems work together. It becomes, <em>How do I deal with a doctor that has a 60% performance improvement? </em>We really only have one thing in our playbook for doing that right now, which is, <em>OK, we could fire 40% of the other doctors and still have a performance gain</em>, which is not the answer you want to see happen.</p>



<p>So because of that, people are hiding their use. They&#8217;re actually hiding their use for lots of reasons.</p>



<p>And it&#8217;s a weird case because the people who are able to figure out best how to use these systems, for a lot of use cases, they&#8217;re actually clinicians themselves because they&#8217;re experimenting all the time. Like, they have to take those encounter notes. And if they figure out a better way to do it, they figure that out. You don&#8217;t want to wait for, you know, a med tech company to figure that out and then sell that back to you when it can be done by the physicians themselves.</p>



<p>So we&#8217;re just not used to a period where everybody&#8217;s innovating and where the management structure isn&#8217;t in place to take advantage of that. And so we&#8217;re seeing things stalled at the individual level, and people are often, especially in risk-averse organizations or organizations where there&#8217;s lots of regulatory hurdles, people are so afraid of the regulatory piece that they don&#8217;t even bother trying to make change.</p>



<p><strong>LEE:</strong> If you are, you know, the leader of a hospital or a clinic or a whole health system, how should you approach this? You know, how should you be trying to extract positive success out of AI?</p>



<p><strong>MOLLICK: </strong>So I think that you need to embrace the right kind of risk, right. We don&#8217;t want to put risk on our patients … like, we don&#8217;t want to put uninformed risk. But innovation involves risk to how organizations operate. They involve change. So I think part of this is embracing the idea that R&D has to happen in organizations again.</p>



<p>What&#8217;s happened over the last 20 years or so has been organizations giving that up. Partially, that&#8217;s a trend to focus on what you&#8217;re good at and not try and do this other stuff. Partially, it&#8217;s because it&#8217;s outsourced now to software companies that, like, Salesforce tells you how to organize your sales team. Workforce tells you how to organize your organization. Consultants come in and will tell you how to make change based on the average of what other people are doing in your field.</p>



<p>So companies and organizations and hospital systems have all started to give up their ability to create their own organizational change. And when I talk to organizations, I often say they have to have two approaches. They have to think about the crowd and the lab.</p>



<p>So the crowd is the idea of how to empower clinicians and administrators and supporter networks to start using AI and experimenting in ethical, legal ways and then sharing that information with each other. And the lab is, how are we doing R&D about the approach of how to [get] AI to work, not just in direct patient care, right. But also fundamentally, like, what paperwork can you cut out? How can we better explain procedures? Like, what management role can this fill?</p>



<p>And we need to be doing active experimentation on that. We can&#8217;t just wait for, you know, Microsoft to solve the problems. It has to be at the level of the organizations themselves.</p>



<p><strong>LEE:</strong> So let&#8217;s shift a little bit to the patient. You know, one of the things that we see, and I think everyone is seeing, is that people are turning to chatbots, like ChatGPT, actually to seek healthcare information for, you know, their own health or the health of their loved ones.</p>



<p>And there was already, prior to all of this, a trend towards, let&#8217;s call it, consumerization of healthcare. So just in the business of healthcare delivery, do you think AI is going to hasten these kinds of trends, or from the consumer&#8217;s perspective, what … ?</p>



<p><strong>MOLLICK: </strong>I mean, absolutely, right. Like, all the early data that we have suggests that for most common medical problems, you should just consult AI, too, right. In fact, there is a real question to ask: at what point does it become unethical for doctors themselves to not ask for a second opinion from the AI because it&#8217;s cheap, right? You could overrule it or whatever you want, but like not asking seems foolish.</p>



<p>I think the two places where there&#8217;s a burning almost, you know, moral imperative is … let&#8217;s say, you know, I&#8217;m in Philadelphia, I&#8217;m a professor, I have access to really good healthcare through the Hospital University of Pennsylvania system. I know doctors. You know, I&#8217;m lucky. I&#8217;m well connected. If, you know, something goes wrong, I have friends who I can talk to. I have specialists. I&#8217;m, you know, pretty well educated in this space.</p>



<p>But for most people on the planet, they don&#8217;t have access to good medical care, they don&#8217;t have good health. It feels like it&#8217;s absolutely imperative to say when should you use AI and when not. Are there blind spots? What are those things?</p>



<p>And I worry that, like, to me, that would be the crash project I&#8217;d be invoking because I&#8217;m doing the same thing in education, which is this system is not as good as being in a room with a great teacher who also uses AI to help you, but it&#8217;s better than not getting an, you know, to the level of education people get in many cases. Where should we be using it? How do we guide usage in the right way? Because the AI labs aren&#8217;t thinking about this. We have to.</p>



<p>So, to me, there is a burning need here to understand this. And I worry that people will say, you know, everything that&#8217;s true—AI can hallucinate, AI can be biased. All of these things are absolutely true, but people are going to use it. The early indications are that it is quite useful. And unless we take the active role of saying, here&#8217;s when to use it, here&#8217;s when not to use it, we don&#8217;t have a right to say, don&#8217;t use this system. And I think, you know, we have to be exploring that.</p>



<p><strong>LEE:</strong> What do people need to understand about AI? And what should schools, universities, and so on be teaching?</p>



<p><strong>MOLLICK:</strong> Those are, kind of, two separate questions in lot of ways. I think a lot of people want to teach AI <em>skills</em>, and I will tell you, as somebody who works in this space a lot, there isn&#8217;t like an easy, sort of, AI skill, right. I could teach you prompt engineering in two to three classes, but every indication we have is that for most people under most circumstances, the value of prompting, you know, any one case is probably not that useful.</p>



<p>A lot of the tricks are disappearing because the AI systems are just starting to use them themselves. So asking good questions, being a good manager, being a good thinker tend to be important, but like magic tricks around making, you know, the AI do something because you use the right phrase used to be something that was real but is rapidly disappearing.</p>



<p>So I worry when people say teach AI skills. No one&#8217;s been able to articulate to me as somebody who knows AI very well and teaches classes on AI, what those AI skills that everyone should learn are, right.</p>



<p>I mean, there’s value in learning a little bit how the models work. There&#8217;s a value in working with these systems. A lot of it&#8217;s just hands on keyboard kind of work. But, like, we don&#8217;t have an easy slam dunk “this is what you learn in the world of AI” because the systems are getting better, and as they get better, they get less sensitive to these prompting techniques. They get better prompting themselves. They solve problems spontaneously and start being agentic. So it&#8217;s a hard problem to ask about, like, what do you train someone on? I think getting people experience in hands-on-keyboards, getting them to … there&#8217;s like four things I could teach you about AI, and two of them are already starting to disappear.</p>



<p>But, like, one is be direct. Like, tell the AI exactly what you want. That&#8217;s very helpful. Second, provide as much context as possible. That can include things like acting as a doctor, but also all the information you have. The third is give it step-by-step directions—that&#8217;s becoming less important. And the fourth is good and bad examples of the kind of output you want. Those four, that&#8217;s like, that&#8217;s it as far as the research telling you what to do, and the rest is building intuition.</p>



<p><strong>LEE:</strong> I&#8217;m really impressed that you didn&#8217;t give the answer, “Well, everyone should be teaching my book, <em>Co-Intelligence</em>.” [LAUGHS]</p>



<p><strong>MOLLICK:</strong> Oh, no, sorry! Everybody should be teaching my book <em>Co-Intelligence</em>. I apologize. [LAUGHTER]</p>



<p><strong>LEE:</strong> It&#8217;s good to chuckle about that, but actually, I can&#8217;t think of a better book, like, if you were to assign a textbook in any professional education space, I think <em>Co-Intelligence</em> would be number one on my list. Are there other things that you think are essential reading?</p>



<p><strong>MOLLICK:</strong> That&#8217;s a really good question. I think that a lot of things are evolving very quickly. I happen to, kind of, hit a sweet spot with <em>Co-Intelligence</em> to some degree because I talk about how I used it, and I was, sort of, an advanced user of these systems.</p>



<p>So, like, it&#8217;s, sort of, like my Twitter feed, my online newsletter. I&#8217;m just trying to, kind of, in some ways, it&#8217;s about trying to make people aware of what these systems can do by just showing a lot, right. Rather than picking one thing, and, like, this is a general-purpose technology. Let&#8217;s use it for this. And, like, everybody gets a light bulb for a different reason. So more than reading, it is using, you know, and that can be Copilot or whatever your favorite tool is.</p>



<p>But using it. Voice modes help a lot. In terms of readings, I mean, I think that there is a couple of good guides to understanding AI that were originally blog posts. I think Tim Lee has one called <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.understandingai.org/" target="_blank" rel="noreferrer noopener">Understanding AI<span class="sr-only"> (opens in new tab)</span></a>, and it had a good overview …</p>



<p><strong>LEE:</strong> Yeah, that&#8217;s a great one.</p>



<p><strong>MOLLICK: </strong>… of that topic that I think explains how transformers work, which can give you some mental sense. I think <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://karpathy.ai/" target="_blank" rel="noreferrer noopener">[Andrej] Karpathy<span class="sr-only"> (opens in new tab)</span></a> has some really nice videos of use that I would recommend.</p>



<p>Like on the medical side, I think the book that you did, if you&#8217;re in medicine, you should read that. I think that that&#8217;s very valuable. But like all we can offer are hints in some ways. Like there isn&#8217;t … if you&#8217;re looking for the instruction manual, I think it can be very frustrating because it&#8217;s like you want the best practices and procedures laid out, and we cannot do that, right. That&#8217;s not how a system like this works.</p>



<p><strong>LEE:</strong> Yeah.</p>



<p><strong>MOLLICK:</strong> It&#8217;s not a person, but thinking about it like a person can be helpful, right.</p>



<p><strong>LEE:</strong> One of the things that has been sort of a fun project for me for the last few years is I have been a founding board member of a new medical school at Kaiser Permanente. And, you know, that medical school curriculum is being formed in this era. But it&#8217;s been perplexing to understand, you know, what this means for a medical school curriculum. And maybe even more perplexing for me, at least, is the accrediting bodies, which are extremely important in US medical schools; how accreditors should think about what&#8217;s necessary here.</p>



<p>Besides the things that you&#8217;ve … the, kind of, four key ideas you mentioned, if you were talking to the board of directors of the LCME [Liaison Committee on Medical Education] accrediting body, what&#8217;s the one thing you would want them to really internalize?</p>



<p><strong>MOLLICK: </strong>This is both a fast-moving and vital area. This can&#8217;t be viewed like a usual change, which [is], “Let&#8217;s see how this works.” Because it&#8217;s, like, the things that make medical technologies hard to do, which is like unclear results, limited, you know, expensive use cases where it rolls out slowly. So one or two, you know, advanced medical facilities get access to, you know, proton beams or something else at multi-billion dollars of cost, and that takes a while to diffuse out. That&#8217;s not happening here. This is all happening at the same time, all at once. This is now … AI <em>is</em> part of medicine.</p>



<p>I mean, there&#8217;s a minor point that I&#8217;d make that actually is a really important one, which is large language models, generative AI overall, work incredibly differently than other forms of AI. So the other worry I have with some of these accreditors is they blend together <em>algorithmic</em> forms of AI, which medicine has been trying for long time—decision support, algorithmic methods, like, medicine more so than other places has been thinking about those issues. Generative AI, even though it uses the same underlying techniques, is a completely different beast.</p>



<p>So, like, even just take the most simple thing of algorithmic aversion, which is a well-understood problem in medicine, right. Which is, so you have a tool that could tell you as a radiologist, you know, the chance of this being cancer; you don&#8217;t like it, you overrule it, right.</p>



<p>We don&#8217;t find algorithmic aversion happening with LLMs in the same way. People actually enjoy using them because it&#8217;s more like working with a person. The flaws are different. The approach is different. So you need to both view this as universal applicable <em>today</em>, which makes it urgent, but also as something that is not the same as your other form of AI, and your AI working group that is thinking about how to solve this problem is not the right people here.</p>



<p><strong>LEE:</strong> You know, I think the world has been trained because of the magic of web search to view computers as question-answering machines. Ask a question, get an answer.</p>



<p><strong>MOLLICK: </strong>Yes. Yes.</p>



<p><strong>LEE:</strong> Write a query, get results. And as I have interacted with medical professionals, you can see that medical professionals have that model of a machine in mind. And I think that&#8217;s partly, I think psychologically, why hallucination is so alarming. Because you have a mental model of a computer as a machine that has absolutely rock-solid perfect memory recall.</p>



<p>But the thing that was so powerful in <em>Co-Intelligence</em>, and we tried to get at this in our book also, is that&#8217;s not the sweet spot. It&#8217;s this sort of deeper interaction, more of a collaboration. And I thought your use of the term <em>Co-Intelligence</em> really just even in the title of the book tried to capture this. When I think about education, it seems like that&#8217;s the first step, to get past this concept of a machine being just a question-answering machine. Do you have a reaction to that idea?</p>



<p><strong>MOLLICK:</strong> I think that&#8217;s very powerful. You know, we&#8217;ve been trained over so many years at both using computers but also in science fiction, right. Computers are about cold logic, right. They will give you the right answer, but if you ask it what love is, they explode, right. Like that&#8217;s the classic way you defeat the evil robot in <em>Star Trek</em>, right. “Love does not compute.” [LAUGHTER]</p>



<p>Instead, we have a system that makes mistakes, is warm, beats doctors in empathy in almost every controlled study on the subject, right. Like, absolutely can outwrite you in a sonnet but will absolutely struggle with giving you the right answer every time. And I think our mental models are just broken for this. And I think you&#8217;re absolutely right. And that&#8217;s part of what I thought your book does get at really well is, like, this is a different thing. It&#8217;s also generally applicable. Again, the model in your head should be kind of like a person even though it isn&#8217;t, right.</p>



<p>There&#8217;s a lot of warnings and caveats to it, but if you start from <em>person</em>, <em>smart person</em> you&#8217;re talking to, your mental model will be more accurate than smart machine, even though both are flawed examples, right. So it will make mistakes; it will make errors. The question is, what do you trust it on? What do you not trust it? As you get to know a model, you&#8217;ll get to understand, like, I totally don&#8217;t trust it for this, but I absolutely trust it for that, right.</p>



<p><strong>LEE:</strong> All right. So we&#8217;re getting to the end of the time we have together. And so I’d just like to get now into something a little bit more provocative. And I get the question all the time. You know, will AI replace doctors? In medicine and other advanced knowledge work, project out five to 10 years. What do think happens?</p>



<p><strong>MOLLICK: </strong>OK, so first of all, let&#8217;s acknowledge systems change much more slowly than individual use. You know, doctors are not individual actors; they&#8217;re part of systems, right. So not just the system of a patient who like may or may not want to talk to a machine instead of a person but also legal systems and administrative systems and systems that allocate labor and systems that train people.</p>



<p>So, like, it&#8217;s hard to imagine that in five to 10 years medicine being so upended that even if AI was better than doctors at every single thing doctors do, that we&#8217;d actually see as radical a change in medicine as you might in other fields. I think you will see faster changes happen in consulting and law and, you know, coding, other spaces than medicine.</p>



<p>But I do think that there is good reason to suspect that AI will outperform people while still having flaws, right. That&#8217;s the difference. We&#8217;re already seeing that for common medical questions in enough randomized controlled trials that, you know, best doctors beat AI, but the AI beats the mean doctor, right. Like, that&#8217;s just something we should acknowledge is happening at this point.</p>



<p>Now, will that work in your specialty? No. Will that work with all the contingent social knowledge that you have in your space? Probably not.</p>



<p>Like, these are vignettes, right. But, like, that&#8217;s kind of where things are. So let&#8217;s assume, right … you&#8217;re asking two questions. One is, how good will AI get?</p>



<p><strong>LEE:</strong> Yeah.</p>



<p><strong>MOLLICK:</strong> And we don&#8217;t know the answer to that question. I will tell you that your colleagues at Microsoft and increasingly the labs, the AI labs themselves, are all saying they think they&#8217;ll have a machine smarter than a human at every intellectual task in the next two to three years. If that doesn&#8217;t happen, that makes it easier to assume the future, but let&#8217;s just assume that that&#8217;s the case. I think medicine starts to change with the idea that people feel obligated to use this to help for everything.</p>



<p>Your patients will be using it, and it will be your advisor and helper at the beginning phases, right. And I think that I expect people to be better at empathy. I expect better bedside manner. I expect management tasks to become easier. I think administrative burden might lighten if we handle this right way or much worse if we handle it badly. Diagnostic accuracy will increase, right.</p>



<p>And then there&#8217;s a set of discovery pieces happening, too, right. One of the core goals of all the AI companies is to accelerate medical research. How does that happen and how does that affect us is a, kind of, unknown question. So I think clinicians are in both the eye of the storm and surrounded by it, right. Like, they can resist AI use for longer than most other fields, but everything around them is going to be affected by it.</p>



<p><strong>LEE: </strong>Well, Ethan, this has been really a fantastic conversation. And, you know, I think in contrast to all the other conversations we&#8217;ve had, this one gives especially the leaders in healthcare, you know, people actually trying to lead their organizations into the future, whether it&#8217;s in education or in delivery, a lot to think about. So I really appreciate you joining.</p>



<p><strong>MOLLICK:</strong> Thank you.</p>



<p>[TRANSITION MUSIC] &nbsp;</p>



<p>I&#8217;m a computing researcher who works with people who are right in the middle of today&#8217;s bleeding-edge developments in AI. And because of that, I often lose sight of how to talk to a broader audience about what it&#8217;s all about. And so I think one of Ethan&#8217;s superpowers is that he has this knack for explaining complex topics in AI in a really accessible way, getting right to the most important points without making it so simple as to be useless. That&#8217;s why I rarely miss an opportunity to read up on his latest work.</p>



<p>One of the first things I learned from Ethan is the intuition that you can, sort of, think of AI as a very knowledgeable intern. In other words, think of it as a persona that you can interact with, but you also need to be a manager for it and to always assess the work that it does.</p>



<p>In our discussion, Ethan went further to stress that there is, because of that, a serious education gap. You know, over the last decade or two, we&#8217;ve all been trained, mainly by search engines, to think of computers as question-answering machines. In medicine, in fact, there&#8217;s a question-answering application that is really popular called <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" target="_blank" href="https://learn.uptodate.com/ind_uptodate_brand/brand?utm_source=bing&utm_medium=cpc&utm_campaign=IND_UpToDate_Brand&utm_content=&utm_term=uptodate&msclkid=a6e7d79534911d300c7cbfbe82378ae6">UpToDate<span class="sr-only"> (opens in new tab)</span></a>. Doctors use it all the time. But generative AI systems like ChatGPT are different. There&#8217;s therefore a challenge in how to break out of the old-fashioned mindset of search to get the full value out of generative AI.</p>



<p>The other big takeaway for me was that Ethan pointed out while it&#8217;s easy to see productivity gains from AI at the individual level, those same gains, at least today, don&#8217;t often translate automatically to organization-wide or system-wide gains. And one, of course, has to conclude that it takes more than just making individuals more productive; the whole system also has to adjust to the realities of AI.</p>



<p>Here&#8217;s now my interview with Azeem Azhar:</p>



<p><strong>LEE:</strong> Azeem, welcome.</p>



<p><strong>AZEEM AZHAR: </strong>Peter, thank you so much for having me.&nbsp;</p>



<p><strong>LEE:</strong> You know, I think you&#8217;re extremely well known in the world. But still, some of the listeners of this podcast series might not have encountered you before.</p>



<p>And so one of the ways I like to ask people to introduce themselves is, how do you explain to your parents what you do every day?</p>



<p><strong>AZHAR: </strong>Well, I&#8217;m very lucky in that way because my mother was the person who got me into computers more than 40 years ago. And I still have that first computer, a ZX81 with a Z80 chip …</p>



<p><strong>LEE: </strong>Oh wow.</p>



<p><strong>AZHAR:</strong> … to this day. It sits in my study, all seven and a half thousand transistors and Bakelite plastic that it is. And my parents were both economists, and economics is deeply connected with technology in some sense. And I grew up in the late ’70s and the early ’80s. And that was a time of tremendous optimism around technology. It was space opera, science fiction, robots, and of course, the personal computer and, you know, Bill Gates and Steve Jobs. So that&#8217;s where I started.</p>



<p>And so, in a way, my mother and my dad, who passed away a few years ago, had always known me as someone who was fiddling with computers but also thinking about economics and society. And so, in a way, it&#8217;s easier to explain to them because they&#8217;re the ones who nurtured the environment that allowed me to research technology and AI and think about what it means to firms and to the economy at large.</p>



<p><strong>LEE:</strong> I always like to understand the origin story. And what I mean by that is, you know, what was your first encounter with generative AI? And what was that like? What did you go through?</p>



<p><strong>AZHAR:</strong> The first real moment was when Midjourney and Stable Diffusion emerged in that summer of 2022. I&#8217;d been away on vacation, and I came back—and I&#8217;d been off grid, in fact—and the world had really changed.</p>



<p>Now, I&#8217;d been aware of GPT-3 and GPT-2, which I played around with and with BERT, the original transformer paper about seven or eight years ago, but it was the moment where I could talk to my computer, and it could produce these images, and it could be refined in natural language that really made me think we&#8217;ve crossed into a new domain. We&#8217;ve gone from AI being highly discriminative to AI that&#8217;s able to explore the world in particular ways. And then it was a few months later that ChatGPT came out—November, the 30th.</p>



<p>And I think it was the next day or the day after that I said to my team, everyone has to use this, and we have to meet every morning and discuss how we experimented the day before. And we did that for three or four months. And, you know, it was really clear to me in that interface at that point that, you know, we&#8217;d absolutely pass some kind of threshold.</p>



<p><strong>LEE:</strong> And who&#8217;s the <em>we</em> that you were experimenting with?</p>



<p><strong>AZHAR:</strong> So I have a team of four who support me. They&#8217;re mostly researchers of different types. I mean, it&#8217;s almost like one of those jokes. You know, I have a sociologist, an economist, and an astrophysicist. And, you know, they walk into the bar, [LAUGHTER] or they walk into our virtual team room, and we try to solve problems.</p>



<p><strong>LEE: </strong>Well, so let&#8217;s get now into brass tacks here. And I think I want to start maybe just with an exploration of the economics of all this and economic realities. Because I think in a lot of your work—for example, in your book—you look pretty deeply at how automation generally and AI specifically are transforming certain sectors like finance, manufacturing, and you have a really, kind of, insightful focus on what this means for productivity and which ways, you know, efficiencies are found. &nbsp;</p>



<p>And then you, sort of, balance that with risks, things that can and do go wrong. And so as you take that background and looking at all those other sectors, in what ways are the same patterns playing out or likely to play out in healthcare and medicine?</p>



<p><strong>AZHAR:</strong> I&#8217;m sure we will see really remarkable parallels but also new things going on. I mean, medicine has a particular quality compared to other sectors in the sense that it&#8217;s highly regulated, market structure is very different country to country, and it&#8217;s an incredibly broad field. I mean, just think about taking a Tylenol and going through laparoscopic surgery. Having an MRI and seeing a physio. I mean, this is all medicine. I mean, it&#8217;s hard to imagine a sector that is [LAUGHS] more broad than that.</p>



<p>So I think we can start to break it down, and, you know, where we&#8217;re seeing things with generative AI will be that the, sort of, softest entry point, which is the medical scribing. And I&#8217;m sure many of us have been with clinicians who have a medical scribe running alongside—they&#8217;re all on Surface Pros I noticed, right? [LAUGHTER] They&#8217;re on the tablet computers, and they&#8217;re scribing away.</p>



<p>And what that&#8217;s doing is, in the words of my friend Eric Topol, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.nytimes.com/2019/03/11/well/live/how-artificial-intelligence-could-transform-medicine.html" target="_blank" rel="noreferrer noopener">it&#8217;s giving the clinician time back<span class="sr-only"> (opens in new tab)</span></a>, right. They have time back from days that are extremely busy and, you know, full of administrative overload. So I think you can obviously do a great deal with reducing that overload.</p>



<p>And within my team, we have a view, which is if you do something five times in a week, you should be writing an automation for it. And if you&#8217;re a doctor, you&#8217;re probably reviewing your notes, writing the prescriptions, and so on several times a day. So those are things that can clearly be automated, and the human can be in the loop. But I think there are so many other ways just within the clinic that things can help.</p>



<p>So, one of my friends, my friend from my junior school—I&#8217;ve known him since I was 9—is an oncologist who&#8217;s also deeply into machine learning, and he&#8217;s in Cambridge in the UK. And <a href="https://www.microsoft.com/en-us/research/podcast/collaborators-project-innereye-with-javier-alvarez-and-raj-jena/">he built with Microsoft Research a suite of imaging AI tools</a> from his own discipline, which they then open sourced.</p>



<p>So that&#8217;s another way that you have an impact, which is that you actually enable the, you know, generalist, specialist, polymath, whatever they are in health systems to be able to get this technology, to tune it to their requirements, to use it, to encourage some grassroots adoption in a system that&#8217;s often been very, very heavily centralized.</p>



<p><strong>LEE: </strong>Yeah.</p>



<p><strong>AZHAR:</strong> And then I think there are some other things that are going on that I find really, really exciting. So one is the consumerization of healthcare. So I have one of those sleep tracking rings, the <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://ouraring.com/" target="_blank" rel="noreferrer noopener">Oura<span class="sr-only"> (opens in new tab)</span></a>.</p>



<p><strong>LEE:</strong> Yup.</p>



<p><strong>AZHAR:</strong> That is building a data stream that we&#8217;ll be able to apply more and more AI to. I mean, right now, it&#8217;s applying traditional, I suspect, machine learning, but you can imagine that as we start to get more data, we start to get more used to measuring ourselves, we create this sort of pot, a personal asset that we can turn AI to.</p>



<p>And there&#8217;s still another category. And that other category is one of the completely novel ways in which we can enable patient care and patient pathway. And there&#8217;s a fantastic startup in the UK called <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.nekohealth.com/se/en?ref=seesaw" target="_blank" rel="noreferrer noopener">Neko Health<span class="sr-only"> (opens in new tab)</span></a>, which, I mean, does physicals, MRI scans, and blood tests, and so on.</p>



<p>It&#8217;s hard to imagine Neko existing without the sort of advanced data, machine learning, AI that we&#8217;ve seen emerge over the last decade. So, I mean, I think that there are so many ways in which the temperature is slowly being turned up to encourage a phase change within the healthcare sector.</p>



<p>And last but not least, I do think that these tools can also be very, very supportive of a clinician&#8217;s life cycle. I think we, as patients, we&#8217;re a bit …&nbsp; I don’t know if we&#8217;re as grateful as we should be for our clinicians who are putting in 90-hour weeks. [LAUGHTER] But you can imagine a world where AI is able to support not just the clinicians’ workload but also their sense of stress, their sense of burnout.</p>



<p>So just in those five areas, Peter, I sort of imagine we could start to fundamentally transform over the course of many years, of course, the way in which people think about their health and their interactions with healthcare systems</p>



<p><strong>LEE:</strong> I love how you break that down. And I want to press on a couple of things.</p>



<p>You also touched on the fact that medicine is, at least in most of the world, is a highly regulated industry. I guess finance is the same way, but they also feel different because the, like, finance sector has to be very responsive to consumers, and consumers are sensitive to, you know, an abundance of choice; they are sensitive to price. Is there something unique about medicine besides being regulated?</p>



<p><strong>AZHAR:</strong> I mean, there absolutely is. And in finance, as well, you have much clearer end states. So if you&#8217;re not in the consumer space, but you&#8217;re in the, you know, asset management space, you have to essentially deliver returns against the volatility or risk boundary, right. That&#8217;s what you have to go out and do. And I think if you&#8217;re in the consumer industry, you can come back to very, very clear measures, net promoter score being a very good example.</p>



<p>In the case of medicine and healthcare, it is much more complicated because as far as the clinician is concerned, people are individuals, and we have our own parts and our own responses. If we didn&#8217;t, there would never be a need for a differential diagnosis. There&#8217;d never be a need for, you know, <em>Let&#8217;s try azithromycin first, and then if that doesn&#8217;t work, we&#8217;ll go to vancomycin,</em> or, you know, whatever it happens to be. You would just know. But ultimately, you know, people are quite different. The symptoms that they&#8217;re showing are quite different, and also their compliance is really, really different.</p>



<p>I had a back problem that had to be dealt with by, you know, a physio and extremely boring exercises four times a week, but I was ruthless in complying, and my physio was incredibly surprised. He&#8217;d say well no one ever does this, and I said, well you know the thing is that I kind of just want to get this thing to go away.</p>



<p><strong>LEE:</strong> Yeah.</p>



<p><strong>AZHAR:</strong> And I think that that&#8217;s why medicine is and healthcare is so different and more complex. But I also think that&#8217;s why AI can be really, really helpful. I mean, we didn&#8217;t talk about, you know, AI in its ability to potentially do this, which is to extend the clinician&#8217;s presence throughout the week.</p>



<p><strong>LEE: </strong>Right. Yeah.</p>



<p><strong>AZHAR:</strong> The idea that maybe some part of what the clinician would do if you could talk to them on Wednesday, Thursday, and Friday could be delivered through an app or a chatbot just as a way of encouraging the compliance, which is often, especially with older patients, one reason why conditions, you know, linger on for longer.</p>



<p><strong>LEE:</strong> You know, just staying on the regulatory thing, as I&#8217;ve thought about this, the one regulated sector that I think seems to have some parallels to healthcare is energy delivery, energy distribution.</p>



<p>Because like healthcare, as a consumer, I don&#8217;t have choice in who delivers electricity to my house. And even though I care about it being cheap or at least not being overcharged, I don&#8217;t have an abundance of choice. I can&#8217;t do price comparisons.</p>



<p>And there&#8217;s something about that, just speaking as a consumer of both energy and a consumer of healthcare, that feels similar. Whereas other regulated industries, you know, somehow, as a consumer, I feel like I have a lot more direct influence and power. Does that make any sense to someone, you know, like you, who&#8217;s really much more expert in how economic systems work?</p>



<p><strong>AZHAR:</strong> I mean, in a sense, one part of that is very, very true. You have a limited panel of energy providers you can go to, and in the US, there may be places where you have no choice.</p>



<p>I think the area where it&#8217;s slightly different is that as a consumer or a patient, you can actually make meaningful choices and changes yourself using these technologies, and people used to joke about you know asking Dr. Google. But Dr. Google is not terrible, particularly if you go to WebMD. And, you know, when I look at long-range change, many of the regulations that exist around healthcare delivery were formed at a point before people had access to good quality information at the touch of their fingertips or when educational levels in general were much, much lower. And many regulations existed because of the incumbent power of particular professional sectors.</p>



<p>I&#8217;ll give you an example from the United Kingdom. So I have had asthma all of my life. That means I&#8217;ve been taking my inhaler, Ventolin, and maybe a steroid inhaler for nearly 50 years. That means that I know … actually, I&#8217;ve got more experience, and I—in some sense—know more about it than a general practitioner.</p>



<p><strong>LEE:</strong> Yeah.</p>



<p><strong>AZHAR:</strong> And until a few years ago, I would have to go to a general practitioner to get this drug that I&#8217;ve been taking for five decades, and there they are, age 30 or whatever it is. And a few years ago, the regulations changed. And now pharmacies can &#8230; or pharmacists can prescribe those types of drugs under certain conditions directly.</p>



<p><strong>LEE:</strong> Right.</p>



<p><strong>AZHAR:</strong> That was not to do with technology. That was to do with incumbent lock-in. So when we look at the medical industry, the healthcare space, there are some parallels with energy, but there are a few little things that the ability that the consumer has to put in some effort to learn about their condition, but also the fact that some of the regulations that exist just exist because certain professions are powerful.</p>



<p><strong>LEE:</strong> Yeah, one last question while we&#8217;re still on economics. There seems to be a conundrum about productivity and efficiency in healthcare delivery because I&#8217;ve never encountered a doctor or a nurse that wants to be able to handle even more patients than they’re doing on a daily basis.</p>



<p>And so, you know, if productivity means simply, well, your rounds can now handle <em>16</em> patients instead of eight patients, that doesn&#8217;t seem necessarily to be a desirable thing. So how can we or should we be thinking about efficiency and productivity since obviously costs are, in most of the developed world, are a huge, huge problem?</p>



<p><strong>AZHAR:</strong> Yes, and when you described doubling the number of patients on the round, I imagined you buying them all roller skates so they could just whizz around [LAUGHTER] the hospital faster and faster than ever before.</p>



<p>We can learn from what happened with the introduction of electricity. Electricity emerged at the end of the 19th century, around the same time that cars were emerging as a product, and car makers were very small and very artisanal. And in the early 1900s, some really smart car makers figured out that electricity was going to be important. And they bought into this technology by putting pendant lights in their workshops so they could “visit more patients.” Right?</p>



<p><strong>LEE:</strong> Yeah, yeah.</p>



<p><strong>AZHAR:</strong> They could effectively spend more hours working, and that was a productivity enhancement, and it was noticeable. But, of course, electricity <em>fundamentally</em> changed the productivity by orders of magnitude of people who made cars starting with Henry Ford because he was able to reorganize his factories around the electrical delivery of power and to therefore have the moving assembly line, which 10xed the productivity of that system.</p>



<p>So when we think about how AI will affect the clinician, the nurse, the doctor, it&#8217;s much easier for us to imagine it as the pendant light that just has them working later …</p>



<p><strong>LEE:</strong> Right.</p>



<p><strong>AZHAR:</strong> … than it is to imagine a reconceptualization of the relationship between the clinician and the people they care for.</p>



<p>And I&#8217;m not sure. I don&#8217;t think anybody knows what that looks like. But, you know, I do think that there will be a way that this changes, and you can see that scale out factor. And it may be, Peter, that what we end up doing is we end up saying, OK, because we have these brilliant AIs, there&#8217;s a lower level of training and cost and expense that&#8217;s required for a broader range of conditions that need treating. And that expands the market, right. That expands the market hugely. It&#8217;s what has happened in the market for taxis or ride sharing. The introduction of Uber and the GPS system …</p>



<p><strong>LEE:</strong> Yup.</p>



<p><strong>AZHAR:</strong> &#8230; has meant many more people now earn their living driving people around in their cars. And at least in London, you had to be reasonably highly trained to do that.</p>



<p>So I can see a reorganization is possible. Of course, entrenched interests, the economic flow &#8230; and there are many entrenched interests, particularly in the US between the health systems and the, you know, professional bodies that might slow things down. But I think a reimagining is possible.</p>



<p>And if I may, I&#8217;ll give you one example of that, which is, if you go to countries outside of the US where there are many more sick people per doctor, they have incentives to change the way they deliver their healthcare. And well before there was AI of this quality around, there was a few cases of health systems in India—<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://aravind.org/" target="_blank" rel="noreferrer noopener">Aravind Eye Care<span class="sr-only"> (opens in new tab)</span></a> was one, and Narayana Hrudayalaya [now known as <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.narayanahealth.org/" target="_blank" rel="noreferrer noopener">Narayana Health<span class="sr-only"> (opens in new tab)</span></a>] was another. And in the latter, they were a cardiac care unit where you couldn&#8217;t get enough heart surgeons.</p>



<p><strong>LEE: </strong>Yeah, yep.</p>



<p><strong>AZHAR:</strong> So specially trained nurses would operate under the supervision of a single surgeon who would supervise many in parallel. So there are ways of increasing the quality of care, reducing the cost, but it does require a systems change. And we can&#8217;t expect a single bright algorithm to do it on its own.</p>



<p><strong>LEE:</strong> Yeah, really, really interesting. So now let&#8217;s get into regulation. And let me start with this question. You know, there are several startup companies I&#8217;m aware of that are pushing on, I think, a near-term future possibility that a medical AI for consumer might be allowed, say, to prescribe a medication for you, something that would normally require a doctor or a pharmacist, you know, that is certified in some way, licensed to do. Do you think we&#8217;ll get to a point where for certain regulated activities, humans are more or less cut out of the loop?</p>



<p><strong>AZHAR:</strong> Well, humans would have been in the loop because they would have provided the training data, they would have done the oversight, the quality control. But to your question in general, would we delegate an important decision entirely to a tested set of algorithms? I&#8217;m sure we will. We already do that. I delegate less important decisions like, <em>What time should I leave for the airport </em>to Waze. I delegate more important decisions to the automated braking in my car. We will do this at certain levels of risk and threshold.</p>



<p>If I come back to my example of prescribing Ventolin. It&#8217;s really unclear to me that the prescription of Ventolin, this incredibly benign bronchodilator that is only used by people who&#8217;ve been through the asthma process, needs to be prescribed by someone who&#8217;s gone through 10 years or 12 years of medical training. And why that couldn&#8217;t be prescribed by an algorithm or an AI system.</p>



<p><strong>LEE:</strong> Right. Yep. Yep.</p>



<p><strong>AZHAR:</strong> So, you know, I absolutely think that that will be the case and could be the case. I can&#8217;t really see what the objections are. And the real issue is where do you draw the line of where you say, “Listen, this is too important,” or “The cost is too great,” or “The side effects are too high,” and therefore this is a point at which we want to have some, you know, human taking personal responsibility, having a liability framework in place, having a sense that there is a person with legal agency who signed off on this decision. And that line I suspect will start fairly low, and what we&#8217;d expect to see would be that that would rise progressively over time.</p>



<p><strong>LEE: </strong>What you just said, that scenario of your personal asthma medication, is really interesting because your personal AI might have the benefit of 50 years of your own experience with that medication. So, in a way, there is at least the data potential for, let&#8217;s say, the next prescription to be more personalized and more tailored specifically for you.</p>



<p><strong>AZHAR:</strong> Yes. Well, let&#8217;s dig into this because I think this is super interesting, and we can look at how things have changed. So 15 years ago, if I had a bad asthma attack, which I might have once a year, I would have needed to go and see my general physician.</p>



<p>In the UK, it&#8217;s very difficult to get an appointment. I would have had to see someone privately who didn&#8217;t know me at all because I&#8217;ve just walked in off the street, and I would explain my situation. It would take me half a day. Productivity lost. I&#8217;ve been miserable for a couple of days with severe wheezing. Then a few years ago the system changed, a protocol changed, and now I have a thing called a rescue pack, which includes prednisolone steroids. It includes something else I&#8217;ve just forgotten, and an antibiotic in case I get an upper respiratory tract infection, and I have an “algorithm.” It&#8217;s called a protocol. It&#8217;s printed out. It&#8217;s a flowchart</p>



<p>I answer various questions, and then I say, “I&#8217;m going to prescribe this to myself.” You know, UK doctors don&#8217;t prescribe prednisolone, or prednisone as you may call it in the US, at the drop of a hat, right. It&#8217;s a powerful steroid. I can self-administer, and I can now get that repeat prescription without seeing a physician a couple of times a year. And the algorithm, the “AI” is, it&#8217;s obviously been done in PowerPoint naturally, and it&#8217;s a bunch of arrows. [LAUGHS]</p>



<p>Surely, surely, an AI system is going to be more sophisticated, more nuanced, and give me more assurance that I&#8217;m making the right decision around something like that.</p>



<p><strong>LEE:</strong> Yeah. Well, at a minimum, the AI should be able to make that PowerPoint the next time. [LAUGHS]</p>



<p><strong>AZHAR:</strong> Yeah, yeah. Thank god for Clippy. Yes.</p>



<p><strong>LEE:</strong> So, you know, I think in our book, we had a lot of certainty about most of the things we&#8217;ve discussed here, but one chapter where I felt we really sort of ran out of ideas, frankly, was on regulation. And, you know, what we ended up doing for that chapter is &#8230; I can&#8217;t remember if it was Carey&#8217;s or Zak’s idea, but we asked GPT-4 to have a conversation, a debate with itself [LAUGHS], about regulation. And we made some minor commentary on that.</p>



<p>And really, I think we took that approach because we just didn&#8217;t have much to offer. By the way, in our defense, I don&#8217;t think anyone else had any better ideas anyway.</p>



<p><strong>AZHAR:</strong> Right.</p>



<p><strong>LEE:</strong> And so now two years later, do we have better ideas about the need for regulation, the frameworks around which those regulations should be developed, and, you know, what should this look like?</p>



<p><strong>AZHAR:</strong> So regulation is going to be in some cases very helpful because it provides certainty for the clinician that they&#8217;re doing the right thing, that they are still insured for what they&#8217;re doing, and it provides some degree of confidence for the patient. And we need to make sure that the claims that are made stand up to quite rigorous levels, where ideally there are RCTs [randomized control trials], and there are the classic set of processes you go through.</p>



<p>You do also want to be able to experiment, and so the question is: as a regulator, how can you enable conditions for there to be experimentation? And what is experimentation? Experimentation is learning so that every element of the system can learn from this experience.</p>



<p>So finding that space where there can be bit of experimentation, I think, becomes very, very important. And a lot of this is about experience, so I think the first digital therapeutics have received FDA approval, which means there are now people within the FDA who understand how you go about running an approvals process for that, and what that ends up looking like—and of course what we&#8217;re very good at doing in this sort of modern hyper-connected world—is we can share that expertise, that knowledge, that experience very, very quickly.</p>



<p>So you go from one approval a year to a hundred approvals a year to a thousand approvals a year. So we will then actually, I suspect, need to think about what is it to approve digital therapeutics because, unlike big biological molecules, we can generate these digital therapeutics at the rate of knots [very rapidly].</p>



<p><strong>LEE: </strong>Yes.</p>



<p><strong>AZHAR:</strong> Every road in Hayes Valley in San Francisco, right, is churning out new startups who will want to do things like this. So then, I think about, what does it mean to get approved if indeed it gets approved? But we can also go really far with things that don&#8217;t require approval.</p>



<p>I come back to my sleep tracking ring. So I&#8217;ve been wearing this for a few years, and when I go and see my doctor or I have my annual checkup, one of the first things that he asks is how have I been sleeping. And in fact, I even sync my sleep tracking data to their medical record system, so he&#8217;s saying &#8230; hearing what I&#8217;m saying, but he&#8217;s actually pulling up the real data going, <em>This patient&#8217;s lying to me again. </em>Of course, I&#8217;m very truthful with my doctor, as we should all be. [LAUGHTER]</p>



<p><strong>LEE: </strong>You know, actually, that brings up a point that consumer-facing health AI has to deal with pop science, bad science, you know, weird stuff that you hear on Reddit. And because one of the things that consumers want to know always is, you know, what&#8217;s the truth?</p>



<p><strong>AZHAR:</strong> Right.</p>



<p><strong>LEE:</strong> What can I rely on? And I think that somehow feels different than an AI that you actually put in the hands of, let&#8217;s say, a licensed practitioner. And so the regulatory issues seem very, very different for these two cases somehow.</p>



<p><strong>AZHAR:</strong> I agree, they&#8217;re very different. And I think for a lot of areas, you will want to build AI systems that are first and foremost for the clinician, even if they have patient extensions, that idea that the clinician can still be with a patient during the week.</p>



<p>And you&#8217;ll do that anyway because you need the data, and you also need a little bit of a liability shield to have like a sensible person who&#8217;s been trained around that. And I think that&#8217;s going to be a very important pathway for many AI medical crossovers. We&#8217;re going to go through the clinician.</p>



<p><strong>LEE: </strong>Yeah.</p>



<p><strong>AZHAR:</strong> But I also do recognize what you say about the, kind of, kooky quackery that exists on Reddit. Although on Creatine, Reddit may yet prove to have been right. [LAUGHTER]</p>



<p><strong>LEE:</strong> Yeah, that&#8217;s right. Yes, yeah, absolutely. Yeah.</p>



<p><strong>AZHAR:</strong> Sometimes it&#8217;s right. And I think that it serves a really good role as a field of extreme experimentation. So if you&#8217;re somebody who makes a continuous glucose monitor traditionally given to diabetics but now lots of people will wear them—and sports people will wear them—you probably gathered a lot of extreme tail distribution data by reading the Reddit/biohackers …</p>



<p><strong>LEE: </strong>Yes.</p>



<p><strong>AZHAR:</strong> … for the last few years, where people were doing things that you would never want them to really do with the CGM [continuous glucose monitor]. And so I think we shouldn&#8217;t understate how important that petri dish can be for helping us learn what could happen next.</p>



<p><strong>LEE: </strong>Oh, I think it&#8217;s absolutely going to be essential and a bigger thing in the future. So I think I just want to close here then with one last question. And I always try to be a little bit provocative with this.</p>



<p>And so as you look ahead to what doctors and nurses and patients might be doing two years from now, five years from now, 10 years from now, do you have any kind of firm predictions?</p>



<p><strong>AZHAR:</strong> I&#8217;m going to push the boat out, and I&#8217;m going to go further out than closer in.</p>



<p><strong>LEE: </strong>OK. [LAUGHS]</p>



<p><strong>AZHAR: </strong>As patients, we will have many, many more touch points and interaction with our biomarkers and our health. We&#8217;ll be reading how well we feel through an array of things. And some of them we&#8217;ll be wearing directly, like sleep trackers and watches.</p>



<p>And so we&#8217;ll have a better sense of what&#8217;s happening in our lives. It&#8217;s like the moment you go from paper bank statements that arrive every month to being able to see your account in real time.</p>



<p><strong>LEE: </strong>Yes.</p>



<p><strong>AZHAR: </strong>And I suspect we&#8217;ll have &#8230; we&#8217;ll still have interactions with clinicians because societies that get richer see doctors more, societies that get older see doctors more, and we&#8217;re going to be doing both of those over the coming 10 years. But there will be a sense, I think, of continuous health engagement, not in an overbearing way, but just in a sense that we know it&#8217;s there, we can check in with it, it&#8217;s likely to be data that is compiled on our behalf somewhere centrally and delivered through a user experience that reinforces agency rather than anxiety.</p>



<p>And we&#8217;re learning how to do that slowly. I don&#8217;t think the health apps on our phones and devices have yet quite got that right. And that could help us personalize problems before they arise, and again, I use my experience for things that I&#8217;ve tracked really, really well. And I know from my data and from how I&#8217;m feeling when I&#8217;m on the verge of one of those severe asthma attacks that hits me once a year, and I can take a little bit of preemptive measure, so I think that that will become progressively more common and that sense that we will know our baselines.</p>



<p>I mean, when you think about being an athlete, which is something I think about, but I could never ever do, [LAUGHTER] but what happens is you start with your detailed baselines, and that&#8217;s what your health coach looks at every three or four months. For most of us, we have no idea of our baselines. You we get our blood pressure measured once a year. We will have baselines, and that will help us on an ongoing basis to better understand and be in control of our health. And then if the product designers get it right, it will be done in a way that doesn&#8217;t feel invasive, but it&#8217;ll be done in a way that feels enabling. We&#8217;ll still be engaging with clinicians augmented by AI systems more and more because they will also have gone up the stack. They won&#8217;t be spending their time on just “take two Tylenol and have a lie down” type of engagements because that will be dealt with earlier on in the system. And so we will be there in a very, very different set of relationships. And they will feel that they have different ways of looking after our health.</p>



<p><strong>LEE: </strong>Azeem, it&#8217;s so comforting to hear such a wonderfully optimistic picture of the future of healthcare. And I actually agree with everything you&#8217;ve said.</p>



<p>Let me just thank you again for joining this conversation. I think it&#8217;s been really fascinating. And I think somehow the systemic issues, the systemic issues that you tend to just see with such clarity, I think are going to be the most, kind of, profound drivers of change in the future. So thank you so much.</p>



<p><strong>AZHAR:</strong> Well, thank you, it&#8217;s been my pleasure, Peter, thank you.</p>



<p>[TRANSITION MUSIC] &nbsp;</p>



<p>I always think of Azeem as a systems thinker. He&#8217;s always able to take the experiences of new technologies at an individual level and then project out to what this could mean for whole organizations and whole societies.</p>



<p>In our conversation, I felt that Azeem really connected some of what we learned in a previous episode—for example, from Chrissy Farr—on the evolving consumerization of healthcare to the broader workforce and economic impacts that we&#8217;ve heard about from Ethan Mollick. &nbsp;</p>



<p>Azeem’s personal story about managing his asthma was also a great example. You know, he imagines a future, as do I, where personal AI might assist and remember decades of personal experience with a condition like asthma and thereby know more than any human being could possibly know in a deeply personalized and effective way, leading to better care. Azeem’s relentless optimism about our AI future was also so heartening to hear.</p>



<p>Both of these conversations leave me really optimistic about the future of AI in medicine. At the same time, it is pretty sobering to realize just how much we&#8217;ll all need to change in pretty fundamental and maybe even in radical ways. I think a big insight I got from these conversations is how we interact with machines is going to have to be altered not only at the individual level, but at the company level and maybe even at the societal level.</p>



<p>Since my conversation with Ethan and Azeem, there have been some pretty important developments that speak directly to this. Just last week at <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" target="_blank" href="https://build.microsoft.com/en-US/home">Build<span class="sr-only"> (opens in new tab)</span></a>, which is Microsoft&#8217;s yearly developer conference, we announced a slew of AI agent technologies. Our CEO, Satya Nadella, in fact, started his keynote by going online in a GitHub developer environment and then assigning a coding task to an AI agent, basically treating that AI as a full-fledged member of a development team. Other agents, for example, a meeting facilitator, a data analyst, a business researcher, travel agent, and more were also shown during the conference.</p>



<p>But pertinent to healthcare specifically, what really blew me away was the demonstration of a healthcare orchestrator agent. And the specific thing here was in Stanford&#8217;s cancer treatment center, when they are trying to decide on potentially experimental treatments for cancer patients, they convene a meeting of experts. That is typically called a tumor board. And so this AI healthcare orchestrator agent actually participated as a full-fledged member of a tumor board meeting to help bring data together, make sure that the latest medical knowledge was brought to bear, and to assist in the decision-making around a patient&#8217;s cancer treatment. It was pretty amazing.</p>



<p>[THEME MUSIC]</p>



<p>A big thank-you again to Ethan and Azeem for sharing their knowledge and understanding of the dynamics between AI and society more broadly. And to our listeners, thank you for joining us. I’m really excited for the upcoming episodes, including discussions on medical students’ experiences with AI and AI’s influence on the operation of health systems and public health departments. We hope you&#8217;ll continue to tune in.</p>



<p>Until next time.</p>



<p>[MUSIC FADES]</p>

				</span>
			</div>
			<button
				class="action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle"
				aria-expanded="false"
				data-show-less-text="Show less"
				type="button"
				aria-controls="show-more-show-less-toggle-9"
				aria-label="Show more content"
				data-alternate-aria-label="Show less content">
				Show more			</button>
		</div>
	</div>
</div>
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/podcast/what-ais-impact-on-individuals-means-for-the-health-workforce-and-industry/">What AI&#8217;s impact on individuals means for the health workforce and industry</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
					
		
		
			</item>
	</channel>
</rss>
