<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>Microsoft Research</title>
	<atom:link href="https://www.microsoft.com/en-us/research/feed/" rel="self" type="application/rss+xml" />
	<link>https://www.microsoft.com/en-us/research/</link>
	<description></description>
	<lastBuildDate>Thu, 07 Aug 2025 14:31:30 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.8.2</generator>
	<item>
		<title>Reimagining healthcare delivery and public health with AI</title>
		<link>https://www.microsoft.com/en-us/research/podcast/reimagining-healthcare-delivery-and-public-health-with-ai/</link>
		
		<dc:creator><![CDATA[Peter Lee, Dr. Umair Shah, Dr. Gianrico Farrugia]]></dc:creator>
		<pubDate>Thu, 07 Aug 2025 16:00:00 +0000</pubDate>
				<category><![CDATA[Microsoft Research Podcast]]></category>
		<guid isPermaLink="false"></guid>

					<description><![CDATA[<p>Former Washington State Secretary of Health Dr. Umair Shah and Mayo Clinic CEO Dr. Gianrico Farrugia explore how healthcare leaders are approaching AI when it comes to public health, care delivery, the healthcare-research connection, and the patient experience.</p>
<p>The post <a href="https://www.microsoft.com/en-us/research/podcast/reimagining-healthcare-delivery-and-public-health-with-ai/">Reimagining healthcare delivery and public health with AI</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img fetchpriority="high" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Episode10-PeterUmairGianrico-AIRevolution_Hero_Feature_No_Text_1400x788.jpg" alt="Illustrated headshots of Peter Lee, Umair Shah, Gianrico Farrugia" class="wp-image-1147485" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Episode10-PeterUmairGianrico-AIRevolution_Hero_Feature_No_Text_1400x788.jpg 1400w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Episode10-PeterUmairGianrico-AIRevolution_Hero_Feature_No_Text_1400x788-300x169.jpg 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Episode10-PeterUmairGianrico-AIRevolution_Hero_Feature_No_Text_1400x788-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Episode10-PeterUmairGianrico-AIRevolution_Hero_Feature_No_Text_1400x788-768x432.jpg 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Episode10-PeterUmairGianrico-AIRevolution_Hero_Feature_No_Text_1400x788-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Episode10-PeterUmairGianrico-AIRevolution_Hero_Feature_No_Text_1400x788-655x368.jpg 655w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Episode10-PeterUmairGianrico-AIRevolution_Hero_Feature_No_Text_1400x788-240x135.jpg 240w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Episode10-PeterUmairGianrico-AIRevolution_Hero_Feature_No_Text_1400x788-640x360.jpg 640w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Episode10-PeterUmairGianrico-AIRevolution_Hero_Feature_No_Text_1400x788-960x540.jpg 960w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Episode10-PeterUmairGianrico-AIRevolution_Hero_Feature_No_Text_1400x788-1280x720.jpg 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure>


<div class="wp-block-msr-podcast-container my-4">
	<iframe src="https://player.blubrry.com/?podcast_id=147585250&modern=1" class="podcast-player" frameborder="0" height="164px" width="100%" scrolling="no" title="Podcast Player"></iframe>
</div>



<p>In November 2022, OpenAI’s ChatGPT kick-started a new era in AI. This was followed less than a half year later by the release of GPT-4. In the months leading up to GPT-4’s public release, Peter Lee, president of Microsoft Research, cowrote a book full of optimism for the potential of advanced AI models to transform the world of healthcare. What has happened since? In this special podcast series, <em>The AI Revolution in Medicine, Revisited</em>, Lee revisits the book, exploring how patients, providers, and other medical professionals are experiencing and using generative AI today while examining what he and his coauthors got right—and what they didn’t foresee.&nbsp;</p>



<p>In this episode, healthcare leaders <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.linkedin.com/in/umair-a-shah-md-mph/" target="_blank" rel="noreferrer noopener">Dr. Umair Shah<span class="sr-only"> (opens in new tab)</span></a> and <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" target="_blank" href="https://www.mayoclinic.org/content/dam/media/global/documents/trustees/bios/gianrico-farrugia.pdf">Dr. Gianrico Farrugia<span class="sr-only"> (opens in new tab)</span></a> join Lee to discuss AI’s impact on the business of public health and healthcare delivery, the healthcare-research connection, and the patient experience. Shah, a healthcare strategic consultant and former state secretary of health, explores the role of public health in the larger ecosystem and why it might not get the attention it needs or deserves and how AI could be leveraged to assist in data analysis, to help better engage with people on matters of public health, and to help narrow gaps between care delivery and public health responses during health emergencies. Farrugia, president and CEO of Mayo Clinic, traces AI’s path from predictive to generative and discusses how that progress has helped usher in a new healthcare architecture for Mayo Clinic and its partners, one powered by the goal of longer, healthier lives for patients, and how AI is also changing Mayo Clinic’s research and the education it provides, including the offering of masters and PhDs in AI and other emerging technologies.&nbsp;</p>



<div class="wp-block-group msr-pattern-link-list is-layout-flow wp-block-group-is-layout-flow">
<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading h5" id="learn-more-1">Learn more:</h2>



<ul class="wp-block-list list-unstyled">
<li><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://rickshawhealth.com/" target="_blank" rel="noreferrer noopener">Rickshaw Health<span class="sr-only"> (opens in new tab)</span></a> (Shah)&nbsp;<br>Homepage</li>



<li><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://doh.wa.gov/emergencies/covid-19/covid-19-after-action-report" target="_blank" rel="noreferrer noopener">COVID-19 After-Action Report<span class="sr-only"> (opens in new tab)</span></a> (Shah)&nbsp;<br>Washington State Department of Health | March 2024</li>



<li><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.mayoclinicplatform.org/" target="_blank" rel="noreferrer noopener">Mayo Clinic Platform<span class="sr-only"> (opens in new tab)</span></a> (Farrugia)&nbsp;<br>Homepage</li>



<li><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://arxiv.org/abs/2501.05409" target="_blank" rel="noreferrer noopener">Atlas: A Novel Pathology Foundation Model by Mayo Clinic, Charité, and Aignostics<span class="sr-only"> (opens in new tab)</span></a> (Farrugia)&nbsp;<br>Publication | January 2025</li>



<li><a href="https://www.microsoft.com/en-us/research/publication/maira-2-grounded-radiology-report-generation/" target="_blank" rel="noreferrer noopener">MAIRA-2: Grounded Radiology Report Generation</a> (Farrugia)<br>Publication | June 2024</li>



<li><a href="https://www.microsoft.com/en-us/research/publication/the-ai-revolution-in-medicine-gpt-4-and-beyond/" target="_blank" rel="noreferrer noopener">The AI Revolution in Medicine: GPT-4 and Beyond</a>&nbsp;<br>Book | Peter Lee, Carey Goldberg, Isaac Kohane | April 2023&nbsp;</li>
</ul>



<div style="height:25px" aria-hidden="true" class="wp-block-spacer"></div>
</div>



<section class="wp-block-msr-subscribe-to-podcast subscribe-to-podcast">
	<div class="subscribe-to-podcast__inner border-top border-bottom border-width-2">
		<h2 class="h5 subscribe-to-podcast__heading">
			Subscribe to the <a href="https://www.microsoft.com/en-us/research/podcast">Microsoft Research Podcast</a>:		</h2>
		<ul class="subscribe-to-podcast__list list-unstyled">
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://itunes.apple.com/us/podcast/microsoft-research-a-podcast/id1318021537?mt=2" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="black" viewBox="0 0 32 32">  <path d="M7.12 0c-3.937-0.011-7.131 3.183-7.12 7.12v17.76c-0.011 3.937 3.183 7.131 7.12 7.12h17.76c3.937 0.011 7.131-3.183 7.12-7.12v-17.76c0.011-3.937-3.183-7.131-7.12-7.12zM15.817 3.421c3.115 0 5.932 1.204 8.079 3.453 1.631 1.693 2.547 3.489 3.016 5.855 0.161 0.787 0.161 2.932 0.009 3.817-0.5 2.817-2.041 5.339-4.317 7.063-0.812 0.615-2.797 1.683-3.115 1.683-0.12 0-0.129-0.12-0.077-0.615 0.099-0.792 0.192-0.953 0.64-1.141 0.713-0.296 1.932-1.167 2.677-1.911 1.301-1.303 2.229-2.932 2.677-4.719 0.281-1.1 0.244-3.543-0.063-4.672-0.969-3.595-3.907-6.385-7.5-7.136-1.041-0.213-2.943-0.213-4 0-3.636 0.751-6.647 3.683-7.563 7.371-0.245 1.004-0.245 3.448 0 4.448 0.609 2.443 2.188 4.681 4.255 6.015 0.407 0.271 0.896 0.547 1.1 0.631 0.447 0.192 0.547 0.355 0.629 1.14 0.052 0.485 0.041 0.62-0.072 0.62-0.073 0-0.62-0.235-1.199-0.511l-0.052-0.041c-3.297-1.62-5.407-4.364-6.177-8.016-0.187-0.943-0.224-3.187-0.036-4.052 0.479-2.323 1.396-4.135 2.921-5.739 2.199-2.319 5.027-3.543 8.172-3.543zM16 7.172c0.541 0.005 1.068 0.052 1.473 0.14 3.715 0.828 6.344 4.543 5.833 8.229-0.203 1.489-0.713 2.709-1.619 3.844-0.448 0.573-1.537 1.532-1.729 1.532-0.032 0-0.063-0.365-0.063-0.803v-0.808l0.552-0.661c2.093-2.505 1.943-6.005-0.339-8.296-0.885-0.896-1.912-1.423-3.235-1.661-0.853-0.161-1.031-0.161-1.927-0.011-1.364 0.219-2.417 0.744-3.355 1.672-2.291 2.271-2.443 5.791-0.348 8.296l0.552 0.661v0.813c0 0.448-0.037 0.807-0.084 0.807-0.036 0-0.349-0.213-0.683-0.479l-0.047-0.016c-1.109-0.885-2.088-2.453-2.495-3.995-0.244-0.932-0.244-2.697 0.011-3.625 0.672-2.505 2.521-4.448 5.079-5.359 0.547-0.193 1.509-0.297 2.416-0.281zM15.823 11.156c0.417 0 0.828 0.084 1.131 0.24 0.645 0.339 1.183 0.989 1.385 1.677 0.62 2.104-1.609 3.948-3.631 3.005h-0.015c-0.953-0.443-1.464-1.276-1.475-2.36 0-0.979 0.541-1.828 1.484-2.328 0.297-0.156 0.709-0.235 1.125-0.235zM15.812 17.464c1.319-0.005 2.271 0.463 2.625 1.291 0.265 0.62 0.167 2.573-0.292 5.735-0.307 2.208-0.479 2.765-0.905 3.141-0.589 0.52-1.417 0.667-2.209 0.385h-0.004c-0.953-0.344-1.157-0.808-1.553-3.527-0.452-3.161-0.552-5.115-0.285-5.735 0.348-0.823 1.296-1.285 2.624-1.291z"/></svg>
						<span class="subscribe-to-podcast__link-text">Apple Podcasts</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://subscribebyemail.com/www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M6.4 6a2.392 2.392 0 00-2.372 2.119L16 15.6l11.972-7.481A2.392 2.392 0 0025.6 6H6.4zM4 10.502V22.8a2.4 2.4 0 002.4 2.4h19.2a2.4 2.4 0 002.4-2.4V10.502l-11.365 7.102a1.2 1.2 0 01-1.27 0L4 10.502z"/></svg>
						<span class="subscribe-to-podcast__link-text">Email</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://subscribeonandroid.com/www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M12.414 4.02c-.062.012-.126.023-.18.06a.489.489 0 00-.12.675L13.149 6.3c-1.6.847-2.792 2.255-3.18 3.944h13.257c-.388-1.69-1.58-3.097-3.179-3.944l1.035-1.545a.489.489 0 00-.12-.675.492.492 0 00-.675.135l-1.14 1.68a7.423 7.423 0 00-2.55-.45c-.899 0-1.758.161-2.549.45l-1.14-1.68a.482.482 0 00-.494-.195zm1.545 3.824a.72.72 0 110 1.44.72.72 0 010-1.44zm5.278 0a.719.719 0 110 1.44.719.719 0 110-1.44zM8.44 11.204A1.44 1.44 0 007 12.644v6.718c0 .795.645 1.44 1.44 1.44.168 0 .33-.036.48-.09v-9.418a1.406 1.406 0 00-.48-.09zm1.44 0V21.76c0 .793.646 1.44 1.44 1.44h10.557c.793 0 1.44-.647 1.44-1.44V11.204H9.878zm14.876 0c-.169 0-.33.035-.48.09v9.418c.15.052.311.09.48.09a1.44 1.44 0 001.44-1.44v-6.719a1.44 1.44 0 00-1.44-1.44zM11.8 24.16v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84zm5.759 0v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84z"/></svg>
						<span class="subscribe-to-podcast__link-text">Android</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://open.spotify.com/show/4ndjUXyL0hH1FXHgwIiTWU" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M16 4C9.383 4 4 9.383 4 16s5.383 12 12 12 12-5.383 12-12S22.617 4 16 4zm5.08 17.394a.781.781 0 01-1.086.217c-1.29-.86-3.477-1.434-5.303-1.434-1.937.002-3.389.477-3.403.482a.782.782 0 11-.494-1.484c.068-.023 1.71-.56 3.897-.562 1.826 0 4.365.492 6.171 1.696.36.24.457.725.217 1.085zm1.56-3.202a.895.895 0 01-1.234.286c-2.338-1.457-4.742-1.766-6.812-1.747-2.338.02-4.207.466-4.239.476a.895.895 0 11-.488-1.723c.145-.041 2.01-.5 4.564-.521 2.329-.02 5.23.318 7.923 1.995.419.26.547.814.286 1.234zm1.556-3.745a1.043 1.043 0 01-1.428.371c-2.725-1.6-6.039-1.94-8.339-1.942h-.033c-2.781 0-4.923.489-4.944.494a1.044 1.044 0 01-.474-2.031c.096-.023 2.385-.55 5.418-.55h.036c2.558.004 6.264.393 9.393 2.23.497.292.663.931.371 1.428z"/></svg>
						<span class="subscribe-to-podcast__link-text">Spotify</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M6.667 4a2.676 2.676 0 00-2.612 2.13v.003c-.036.172-.055.35-.055.534v18.666c0 .183.019.362.055.534v.003a2.676 2.676 0 002.076 2.075h.002c.172.036.35.055.534.055h18.666A2.676 2.676 0 0028 25.333V6.667a2.676 2.676 0 00-2.13-2.612h-.003A2.623 2.623 0 0025.333 4H6.667zM8 8h1.333C17.42 8 24 14.58 24 22.667V24h-2.667v-1.333c0-6.618-5.382-12-12-12H8V8zm0 5.333h1.333c5.146 0 9.334 4.188 9.334 9.334V24H16v-1.333A6.674 6.674 0 009.333 16H8v-2.667zM10 20a2 2 0 11-.001 4.001A2 2 0 0110 20z"/></svg>
						<span class="subscribe-to-podcast__link-text">RSS Feed</span>
					</a>
				</li>
					</ul>
	</div>
</section>


<div class="wp-block-msr-show-more">
	<div class="bg-neutral-100 p-5">
		<div class="show-more-show-less" data-mount="show-more-show-less">
			<div>
				<span>
					

<h2 class="wp-block-heading" id="transcript">Transcript&nbsp;</h2>



<p>[MUSIC] </p>



<p>[BOOK PASSAGE]&nbsp;</p>



<p><strong>PETER LEE:</strong> “In US healthcare, quality ratings are increasingly used to tie the improvement in patient health outcomes to the reimbursement rates that healthcare providers can receive. The ability of GPT-4 to understand these systems and give concrete advice … has a chance to make it easier for providers to achieve success in both dimensions.”&nbsp;</p>



<p>[END OF BOOK PASSAGE]</p>



<p>[THEME MUSIC]</p>



<p>This is <em>The AI Revolution in Medicine, Revisited</em>. I’m your host, Peter Lee. </p>



<p>Shortly after OpenAI&#8217;s GPT-4 was publicly released, Carey Goldberg, Dr. Zak Kohane, and I published <em>The AI Revolution in Medicine </em>to help educate the world of healthcare and medical research about the transformative impact this new generative AI technology could have. But because we wrote the book when GPT-4 was still a secret, we had to speculate. Now, two years later, what did we get right, and what did we get wrong? </p>



<p>In this series, we’ll talk to clinicians, patients, hospital administrators, and others to understand the reality of AI in the field and where we go from here.</p>



				</span>
				<span id="show-more-show-less-toggle-1" class="show-more-show-less-toggleable-content">
					



<p>[THEME MUSIC FADES]&nbsp;</p>



<p>The book passage I read at the top is from Chapter 7, “The Ultimate Paperwork Shredder.” </p>



<p>Public health officials and healthcare system leaders influence the well-being and health of people at the population level. They help shape people’s perceptions and responses to public health emergencies, as well as to chronic disease. They help determine the type, quality, and availability of treatment. All this is critical for maintaining good public health, as well as aligning better health and financial outcomes. That, of course, is the main goal of the concept of value-based care. AI can definitely have significant ramifications for achieving this.&nbsp;</p>



<p>Joining us today to talk about how leaders in public health and healthcare systems are thinking about and acting on this new generation of AI is Dr. Umair Shah and Dr. Gianrico Farrugia.&nbsp;</p>



<p>Dr. Umair Shah is a nationally recognized health leader and innovator. He led one of America’s top-rated pandemic responses as Washington State’s secretary of health, a position he held from 2020 to 2025. Umair previously directed Harris County Public Health in Texas, overseeing large-scale emergency response for the nation’s third-largest county, while building an emergency-care career spanning 20-plus years. He now advises organizations on health innovation and strategy as founder and principal of Rickshaw Health.&nbsp;</p>



<p>Dr. Gianrico Farrugia is the president and CEO of Mayo Clinic, the world&#8217;s top-ranked hospital for seven consecutive years, and a pioneer in technology-forward, platform-based healthcare. Under his leadership, Mayo has built and deployed the Mayo Clinic Platform. The platform enables Mayo and its partners to gain practical insights from a comprehensive repository of longitudinal de-identified clinical data spanning four continents. Gianrico is also a Mayo Clinic physician and professor and an author.&nbsp;</p>



<p>Umair and Gianrico are CEO-level leaders representing some of the best of the worlds of public health, healthcare delivery, medical research, and medical education.&nbsp;</p>



<p>[TRANSITION MUSIC]&nbsp;</p>



<p>Here is my interview with Dr. Umair Shah:&nbsp;</p>



<p><strong>LEE:</strong> Umair, it&#8217;s really great to have you here.&nbsp;</p>



<p><strong>UMAIR SHAH:</strong> Peter, it&#8217;s my pleasure. I&#8217;ve been looking forward to this conversation, and I hope you are well today.&nbsp;</p>



<p><strong>LEE: </strong>[LAUGHS] I am doing extremely well.</p>



<p>So, you know, what I&#8217;d like to do in these conversations is first just to start, a little bit about you.</p>



<p><strong>SHAH:</strong> Sure.&nbsp;</p>



<p><strong>LEE:</strong> You served actually during a really tumultuous time as the secretary of health in the State of Washington. But you recently stepped away from that and you started your own firm, Rickshaw Health. So can we start there? What&#8217;s that all about?&nbsp;</p>



<p><strong>SHAH:</strong> Yeah, no, absolutely. First of all, you know, I would say that the transition from Texas to Washington could not have been more geopolitically different, [LAUGHTER] as you can imagine.</p>



<p><strong>LEE:</strong> Sure.&nbsp;</p>



<p><strong>SHAH:</strong> You know, if you like the red-blue paradigms, you couldn’t be more, you know, red and you couldn’t be more blue, I think.&nbsp;</p>



<p><strong>LEE:</strong> Yes.&nbsp;</p>



<p><strong>SHAH:</strong> But what happened is, back in November this past year, as I saw some of the playout of continuation of this red-blue dynamic, I made the decision to step down. And Jan. 15, I stepped down, as you mentioned, and I spent some time really thinking about what I wanted to do next and was looking at a number of opportunities.&nbsp;</p>



<p>And then a moment in time, there were some things happening in our—my wife and our family&#8217;s personal lives that sort of made me think that I wanted to focus a little bit more on family. And I felt the universe was saying, “Stay still.” [LAUGHTER]&nbsp;</p>



<p>And I launched <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://rickshawhealth.com/" target="_blank" rel="noreferrer noopener">Rickshaw Health<span class="sr-only"> (opens in new tab)</span></a> and the notion that, as you know, Peter, rickshaws are oftentimes known across the globe as these modes of transport that reliably get you through ever-changing streets and traffic patterns and all sorts of ecosystems that are evolving at all times. And they get you to the other side and they get you also with a sense of exhilaration. Like when I took my boys to Karachi, and we were—you know, they jumped in a rickshaw and the, you know, open air [LAUGHTER] and they felt this incredible excitement.&nbsp;</p>



<p>And so Rickshaw Health was speaking to the three wheels of a rickshaw that symbolize the three children that we have and the real notion of how do we bring balance and agility and performance to the forefront and then move in an ever—just like streets—ever-changing healthcare environment that is constantly evolving, and we too must evolve with it. And that&#8217;s what Rickshaw Health is all about, is taking clients to that next level of trying to navigate, especially at this time, a very, very different landscape than even several months ago. So, excited about it.&nbsp;</p>



<p><strong>LEE:</strong> Yeah, absolutely. You know, you made this transition from Texas to the State of Washington. And for people who listen to this podcast and don&#8217;t know, the particular part of Texas where you were—Harris County—is <em>really big</em>, very, very important in that state. That&#8217;s just not, you know, the normal county in Texas.&nbsp;</p>



<p><strong>SHAH:</strong> Yeah. [LAUGHS]&nbsp;</p>



<p><strong>LEE: </strong>It&#8217;s actually … it&#8217;s actually known as quite a forward-looking place, technologically.&nbsp;</p>



<p><strong>SHAH:</strong> That’s right.&nbsp;</p>



<p><strong>LEE: </strong>So what was, you know, the transition like, then, going from, you know, possibly the most, sort of, maybe advanced county in the State of Texas, a large place, to the State of Washington?&nbsp;</p>



<p><strong>SHAH:</strong> Yeah, you know, Harris County is the third-largest county in the US. So it had close to five million. And now it&#8217;s probably … it&#8217;s exceeded the five million people, and a very diverse, very forward-looking, as you mentioned, technologically very, very much looking at what&#8217;s the next horizon, and home to Texas Medical Center [TMC] as well, which is …&nbsp;</p>



<p><strong>LEE: </strong>Right.&nbsp;</p>



<p><strong>SHAH: </strong>… the largest medical center. Of course, it had to be Texas. So it can’t be the largest in the state or the country [LAUGHTER]—the largest in the world, right.&nbsp;</p>



<p>And TMC also had a number of different initiatives related to startups and venture capital and VC. And so they had launched something called TMCX. And that was a real opportunity—and I know you&#8217;re familiar with it—an opportunity to really look at how do you incubate all sorts of different innovations and bringing private sector, public sector as well as healthcare delivery alongside these startups to really look at the landscape.&nbsp;</p>



<p>And so when I left Houston and came to Washington, I realized that obviously, I was in the backyard … I mean, you know, you all at Microsoft Research and the work that you&#8217;re all doing is part of an ecosystem of advanced innovation that&#8217;s occurring in the Pacific Northwest that, you know, when we see all the players that are here, all the, you know, ones that do so many different things, but they&#8217;re doing them with an eye towards technology, advancements, and adoptions, it&#8217;s been quite amazing.&nbsp;</p>



<p>When I made that transition, it was really about, you know, the vaccines and what was happening with, you know, with COVID and fighting the—you know, remember, this was the state that had the first case in the continental United States, had the first outbreak, and the first [lab-confirmed] death. And fast-forward a few years later, we had the fifth-lowest death rate in the US. And that was because we all came together to do so much.</p>



<p><strong>LEE: </strong>Yeah, well maybe that gets us into a question that I ask a lot of our guests, which is, you know, and maybe let&#8217;s, since we&#8217;re on your time as the secretary of health in Washington State, [start] with that job. I ask, how would you explain to your mother what you do every day?&nbsp;</p>



<p><strong>SHAH:</strong> [LAUGHS] I laugh because that&#8217;s been such a fascinating conversation in public health because we have oftentimes been—it&#8217;s been really hard to describe what that is.&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>SHAH:</strong> And, you know, there are so many metaphors and, you know, analogies that we&#8217;ve used. I&#8217;ve always wondered why we do not have more television shows or sitcoms or dramas that are about the public health workforce or the work that we do in the field, because you have, you know, all sorts of healthcare delivery ones, right.&nbsp;</p>



<p><strong>LEE: </strong>Yup.&nbsp;</p>



<p><strong>SHAH:</strong> As a practicing physician for 20 years, I realized that people knew what doctors did; they knew what nurses did, right. They intimately touch the healthcare system.&nbsp;</p>



<p><strong>LEE: </strong>Yes.&nbsp;</p>



<p><strong>SHAH:</strong> They understood, you know, that an ambulance picks you up at your home or somewhere else, transports you … gets you to the emergency department. The emergency department, they do some things to you or within the four walls of that ER, and then you&#8217;re either admitted, sent home, and several days, weeks, whatever later, you get home if you&#8217;re admitted, and you start your, you know, post-hospital stay at home or your rehab or what have you. And that all is known to people.&nbsp;</p>



<p>But when you ask your mother, your grandmother, or your, you know, your uncle, or your brother, your neighbor, your coworker about what is public health, they have a very quizzical look on their face of what that is.&nbsp;</p>



<p><strong>LEE:</strong> Right.&nbsp;</p>



<p><strong>SHAH:</strong> And so what I&#8217;ve …&nbsp;</p>



<p><strong>LEE:</strong> You know, just one thing I&#8217;ve learned is: it&#8217;s not just all the people you mentioned. Even healthcare professionals sometimes have that quizzical look.&nbsp;</p>



<p><strong>SHAH:</strong> Yeah, good point. That&#8217;s right. Good point. And a lot of it is because we don&#8217;t get exposed to it or trained in it. You know, we think about public health when we&#8217;re in our training. And, you know, I&#8217;m sure you had a very similar piece of this is that, you know, you see it as, oh, that&#8217;s the health department that takes care of, you know, STDs, or it takes care, you know, it does the immunizations, or, you know, maybe they do some water quality, or maybe they do mosquitoes [mosquito control], and things like that. But the reality is, we do <em>all</em> of those things and more.&nbsp;</p>



<p>So my metaphor has been that we are the offensive line of a football team, and the healthcare delivery is the quarterback. So everybody focuses on, you know, from a few years back, everybody knows Tom Brady, right.&nbsp;</p>



<p><strong>LEE:</strong> Yeah. [LAUGHS]&nbsp;</p>



<p><strong>SHAH:</strong> He won the Super Bowls, everybody knows what … but if you asked people who was number 75 on the offensive line of the New England Patriots …&nbsp;</p>



<p><strong>LEE: </strong>Right.&nbsp;</p>



<p><strong>SHAH:</strong> … or name your favorite football team. And the answer would be: you would not be able to likely answer that question. You would know Tom Brady, the quarterback, and that&#8217;s healthcare delivery, the ER doc or the hospitalist or the nurse or the, you know, the medical assistant, or the people that are doing all the work in the field that are the ones that are more visible, but the invisible workforce of the offensive line, that&#8217;s who we don&#8217;t know. And yet these are the people that are blocking and sweating and doing all things to complement the work and make sure the quarterback is successful.&nbsp;</p>



<p>And here&#8217;s where the metaphor breaks down, that when Tom Brady wins the Super Bowl, we continue to invest in the offensive line because we recognize the value of it and we want the quarterback to be successful the next season. But in public health or in society, we do the exact opposite.&nbsp;</p>



<p>When tuberculosis rates come down, we say, well, you know what? We&#8217;ve solved the problem; we don&#8217;t need it anymore.&nbsp;</p>



<p><strong>LEE: </strong>Right.&nbsp;</p>



<p><strong>SHAH:</strong> Or you have another, you know, environmental issue that&#8217;s no longer there, you say, “We don&#8217;t need it anymore.” And we <em>disinvest</em> from public health or that offensive line. And then you start to see those rates go back up.&nbsp;</p>



<p>And so my answer to Mom and Grandma and Dad and Grandpa is we are <em>critical</em> to your health because we touch you every single day. And so please invest in us.&nbsp;</p>



<p><strong>LEE: </strong>Yeah. And, you know, I think I&#8217;m going to want to get a little deeper on that in just a few minutes here, because, I think especially during the pandemic, that issue of not understanding the importance of that offensive lineman actually really came to the forefront.&nbsp;</p>



<p>And so I&#8217;d like to get into that. But the, kind of, second, kind of, standard thing I&#8217;ve been probing with people is still just focusing on you and your background is what touchpoints or experiences you&#8217;ve had with AI in the past.&nbsp;</p>



<p>And not everyone has. Like, it maybe isn&#8217;t too surprising that doctors and healthcare developers, tech developers, have lots of contact with AI, but would the top dog, you know, at a public health agency ever have had significant contact with AI? What about you?&nbsp;</p>



<p><strong>SHAH:</strong> You know, it&#8217;s interesting. Several years ago, I was in the audience with the [then] FEMA director, [Rich Serino], who just did such an incredible job. And I remember he made this comment at that time. And, Peter, this may have been like … I don’t know—I&#8217;m dating myself—10, 15, maybe even 20 years ago, and he said, “Everybody in the audience, there&#8217;s this, you know, app called Twitter.” And, you know, “How many people in the audience have ever sent a tweet or know about this?” And I don&#8217;t know, maybe—it was a public health audience—maybe about 15% of the people raised their hands.&nbsp;</p>



<p>He said, “I challenge you to right now, pick up your phone, download the app, and go ahead and send a tweet right now.”&nbsp;</p>



<p>And I remember I sent my first tweet at that time. And it was so thought provoking for me was that he was saying you need to be engaged in social media, but the other 85% of the audience had not even done that or had …&nbsp;</p>



<p><strong>LEE: </strong>Right.&nbsp;</p>



<p><strong>SHAH:</strong> … even understood the importance of social media at that time. Or maybe they understood, but they had restrictions on how to utilize, right.&nbsp;</p>



<p>So that has stayed with me because that&#8217;s very much about this revolution of AI that I know that public health and population health practitioners like myself who have been in the trenches and understand the importance of it, they really believe in the importance or think they know the importance.&nbsp;</p>



<p>But NACCHO, the National Association of County and City Health Officials, had done a survey of local health agencies. And about two-thirds, if not three-quarters, of local health agencies reported that they had an AI capacity that was low or lower than ideal.&nbsp;</p>



<p><strong>LEE: </strong>Hmm. Yeah. Yeah.&nbsp;</p>



<p><strong>SHAH:</strong> And that is very much where I come from. When I was in public sector and at the state health agency, our transformation was very much about how do we advance the work, and how do we utilize this in a population health standpoint?&nbsp;</p>



<p>And I was fortunate to have a chief of innovation at Washington State Department of Health, Les Becker, who understood the value of AI. And as you know, we did also hold a AI science convening that …&nbsp;</p>



<p><strong>LEE: </strong>Yep. Yeah.&nbsp;</p>



<p><strong>SHAH:</strong> … your team was there with University of Washington. And that was really an opportunity for us to say that AI is here. It&#8217;s not tomorrow. It&#8217;s not next year. It&#8217;s not the future. It&#8217;s already here. We need to embrace it.&nbsp;</p>



<p>But here&#8217;s the problem, Peter, far too few people in our field understand just how to embrace it.&nbsp;</p>



<p><strong>LEE: </strong>Right.&nbsp;</p>



<p><strong>SHAH:</strong> So I have become a markedly more champion of AI. One, since I read your book. So I think there’s that. So thank you for writing it. But two, since I really recognize that when I became a solo or a primary-few practitioner in my own realm, I needed to force-amplify the work that I was doing.&nbsp;</p>



<p>And when I look back, and I continue to stay in touch with my colleagues in the field of public health, what they&#8217;re also struggling with is that you have an epidemiologist who&#8217;s got a mound of information—data, statistics, etc.—that they are going through, and they&#8217;re doing everything in their power to get that processed and analyzed.&nbsp;</p>



<p><strong>LEE: </strong>Yep. Yep.&nbsp;</p>



<p><strong>SHAH:</strong> AI can take 80% of that and do it. And that epidemiologist can now turn to more of an overseer and a gatekeeper and to really recognize the patterns …&nbsp;</p>



<p><strong>LEE: </strong>Yep.&nbsp;</p>



<p><strong>SHAH:</strong> … and let AI be able to do the, you know, grunt work. And similarly, as you know, measles—with the outbreaks that we&#8217;ve seen, especially in Texas but elsewhere—you&#8217;ve got an opportunity where our communications people who are saying, “Look, we&#8217;re about to have, or we know we&#8217;re about to announce that there&#8217;s a measles outbreak in, you know, in our community or our state or what have you—our region.”&nbsp;</p>



<p>And they can have AI go through different press briefings and/or press releases and say, “Give me the state of the art on how I should communicate this message to the community.”&nbsp;</p>



<p><strong>LEE: </strong>Hmm.&nbsp;</p>



<p><strong>SHAH:</strong> And bam! You can do that. And now you can oversee that work, as well. And then the third example is that we are always looking at how do we find ways to have a deeper connection with those who come to our, you know, our websites or come to our engagement tools—with bots and things like that. AI can really accelerate that work, as well. So there&#8217;s so many use cases that AI has for population health or public health.&nbsp;</p>



<p><strong>LEE: </strong>Yeah.&nbsp;</p>



<p><strong>SHAH:</strong> But I think the challenge is that we just don&#8217;t have enough adoption because they&#8217;re … one, we&#8217;ve had funding cuts, but two is that there is this real hesitation on, what is it that we can do? And I argue—the last thing I&#8217;ll say about this, Peter—is that I argue that AI is happening right now. The discussions, the technology advancements, the work, the policy work, all that&#8217;s happening right now. If public health practitioners are not at the table, if they&#8217;re not part of the, …&nbsp;</p>



<p><strong>LEE:</strong> Right.&nbsp;</p>



<p><strong>SHAH:</strong> … &#8220;What does this look like? How does it work in our field?&#8221; &#8230; guess what? It&#8217;s going to be done <em>to</em> us and <em>for</em> us rather than with us. And if we do not get with that and get to the table, then unfortunately it may not be exactly what we want it to be at the end of the day.&nbsp;</p>



<p><strong>LEE:</strong> I find it really interesting that you are using the terms “public health” and “population health” …&nbsp;</p>



<p><strong>SHAH:</strong> Yeah.&nbsp;</p>



<p><strong>LEE: </strong>… pretty much interchangeably here. And I think that that&#8217;s something that I think touches on an assumption that was both implicit and explicit in the book that we wrote, which is: we were making some predictions that our ability to extract insights and knowledge from population health data would be enhanced through the use of AI. And I think that it looks to me like that has been more challenging and has come along more slowly over the past two years. But what is your view?&nbsp;</p>



<p><strong>SHAH:</strong> Yeah, I think part of, and I think you and I have had this conversation, you know, in bits and pieces. I think one of the real challenges is that when even tech companies, and you can name all of them, when they look at what they&#8217;re doing in the AI space, they gravitate towards healthcare delivery.&nbsp;</p>



<p><strong>LEE: </strong>Yes.&nbsp;</p>



<p><strong>SHAH:</strong> Right? That&#8217;s, it&#8217;s …&nbsp;</p>



<p><strong>LEE: </strong>And in fact, it&#8217;s not even delivery. I think techies—I did this, too—tend to gravitate specifically to diagnosis.&nbsp;</p>



<p><strong>SHAH:</strong> Yes, that&#8217;s right. That&#8217;s right. You know, I think that&#8217;s a really good point. And, you know, when you look at sepsis or you look at pneumonia or try to figure out ways that, you know, radiologists or x-rays or CT scans can be read, it&#8217;s, I mean, there are so many use cases that are within the healthcare sector. And I think that gets back to this inequity that we have when we look at population health or, you know, this broad, um, swath of land that is, oftentimes, left behind or unexplored, and you have healthcare delivery. Now, healthcare delivery we know gets 95 cents or 96 cents of every dollar. So it makes sense why, right. But we also know that, at the end of the day, we&#8217;re looking at value-based outcomes, and you cannot be successful in the healthcare delivery system unless we are truly looking at prevention and what&#8217;s happening in the community and the population.&nbsp;</p>



<p><strong>LEE:</strong> Right.&nbsp;</p>



<p><strong>SHAH: </strong>And that&#8217;s why I use it interchangeably, but I know that “public health” has got a very specific term, and “population health” is a different set of ways of looking at the world. The reason that people try to shy away from pop health in essence is that you could talk about population health as being my population of patients in a clinic. It could be my health systems population. It could be an insurance company saying, these are the lives covered, right. So it becomes, what is population? When we think of public health, we think of the entirety of the population, right. In the State of Washington, eight million people. Harris County, five million people. Or in the US, 300—whatever the number of millions of people that—we think of the entire population. And what is it that actually impacts the health and well-being of that population is really what that&#8217;s about.&nbsp;</p>



<p>Yet here&#8217;s the challenge. When we then talk to those of our partners and our colleagues in the tech field, there are two things happening. One is, there&#8217;s a motivation because of the amount of dollars that are in [the] healthcare sector. And number two is, because it&#8217;s more familiar, right.&nbsp;</p>



<p><strong>LEE: </strong>Right.&nbsp;</p>



<p><strong>SHAH:</strong> And so there are very few practitioners similar to me that are out there, that are in the pop health who kind of know healthcare delivery because they&#8217;ve also seen patients, but they&#8217;re also—they worked at that federal, state, local level, community level—they&#8217;ve, you know, they&#8217;ve done you know various different kinds of environments.&nbsp;</p>



<p>And they say, “Look, I&#8217;ve got a perspective to really help a tech company or somebody see the rest of it,” but you have to have both partners coming together to see that. And I think that&#8217;s one of the real challenges that we have.&nbsp;</p>



<p><strong>LEE: </strong>Yeah.&nbsp;</p>



<p>And so now I&#8217;m going to want to go into specific problems, …&nbsp;</p>



<p><strong>SHAH:</strong> Yeah. Sure.&nbsp;</p>



<p><strong>LEE: </strong>… and maybe COVID is a good thing to focus on—the breadth of problems that had to get solved in pandemic response and where the gaps between healthcare delivery and public health were really exposed.&nbsp;</p>



<p>And so the first problem that I remember really keenly that just seemed so vexing was understanding where the PPE was, the <em>personal protective equipment</em> &#8230;&nbsp;</p>



<p><strong>SHAH:</strong> Hmm. Yeah.&nbsp;</p>



<p><strong>LEE: </strong>…<strong> </strong>and where it needed to be.&nbsp;</p>



<p><strong>SHAH:</strong> Yes.&nbsp;</p>



<p><strong>LEE:</strong> And so that turned out … you would think just getting masks and gowns and gloves to the right places at the right times or even understanding where they are so that, you know … and being able to predict, you know, what hospitals, what clinics are most likely to get a big influx of patients during the height of the pandemic would be something that would be straightforward to solve, but that turned out to be an extremely difficult problem.&nbsp;</p>



<p>But how did it look from where you were sitting? Because you were sitting at the helm having to deal with these problems.&nbsp;</p>



<p><strong>SHAH:</strong> Yeah, we were constantly chasing data and information. And oftentimes, you know, because a lot of these data systems in the public health sector have been underinvested in over the decades, then, you know, you had our biggest emergency crisis of our time, and a lot of public health agencies were either getting, you know, thrown a whole host of resources or had to create things on the fly.&nbsp;</p>



<p>And whether that was at Harris County or in the State of Washington, I will tell you that what I saw was that, you know, a lot of agencies across the country were still using fax machines, you know, to get data that were coming in.&nbsp;</p>



<p>And I remember actually—it&#8217;s kind of a funny story—there was a fax machine that was highlighted down in our agency in Texas. And we actually had this fax machine, had mounds of, you know, data … sorry, <em>papers</em> that were next to … <em>faxes</em> that were coming in and all these things.&nbsp;</p>



<p>And you would have, you know, <em>Mr. Peter Lee</em> listed as a patient. And then the next, you know, transmission would have <em>Pete Lee</em>. And then the next transmission would have <em>Peter Lee</em>, but instead of L-E-E, it was L-E-A-H or something, or L-I or something, right. And it was just …&nbsp;</p>



<p><strong>LEE: </strong>Right.&nbsp;</p>



<p><strong>SHAH:</strong> &#8230; or you had a date of birth missing, or you had, you know, an address that was off. And what we realized is that over time, a lot of the data that were coming in were just incomplete data, and being able to chase that was really hard.&nbsp;</p>



<p>And so, you know, I think AI has that potential to really organize it, and to stratify it, and to especially get you to a point of at least cleaning it up. So I don&#8217;t think it&#8217;s just that AI … AI doesn&#8217;t just save <em>time</em>; it saves <em>lives</em>. Truly used …&nbsp;</p>



<p><strong>LEE: </strong>Hmm. Yeah.&nbsp;</p>



<p><strong>SHAH: </strong>… that&#8217;s, I think, where we&#8217;re talking here.&nbsp;</p>



<p>And so when you have PPE and things of that nature, as you talked about, here in the State of Washington or what we were trying to do to get vaccines out or everything we&#8217;re doing to try to get communication messages to the public. And we did a fantastic job of that, although not ideal.&nbsp;</p>



<p>I mean, there are so many things that I could point to that we could have done better—all of us in the field of public health and healthcare delivery alike.&nbsp;</p>



<p>I will tell you that the one thing that stays with me is that if we had those tools <em>then</em>, and we had them in place <em>then</em>, and we had invested in them at that time in advance of, I think there was a real opportunity for us to be able to move ahead and even be better at how we affected the health outcomes of the very populations that we were trying to get to.&nbsp;</p>



<p>And I think it&#8217;s [that] AI allows us to shift from reactive to proactive systems, catching health issues before they escalate and allow us to really communicate with empathy <em>at scale</em>.&nbsp;</p>



<p><strong>LEE: </strong>Right.&nbsp;</p>



<p><strong>SHAH:</strong> And when we can do those things, whether it&#8217;s opioids or whether it&#8217;s, you know, something that&#8217;s happening related to an infectious disease, or, you know, even this, the new agenda with <em>Make America Healthy Again</em>—which by the way, as you know, we had a <em>Be Well, WA</em> &#8230; <em>Be Well,</em> <em>Washington</em> …&nbsp;</p>



<p><strong>LEE: </strong>Right. Yes.&nbsp;</p>



<p><strong>SHAH:</strong> … very much that was about, you know, looking at, you know, physical health and nutritional health and emotional well-being and social connectedness—that there is a real opportunity for us to address the very drivers of ill health. And when we can do that, and AI can help us accelerate that, I think we truly have the ability to drive down costs and increase the value that&#8217;s returned to all of us.&nbsp;</p>



<p><strong>LEE: </strong>What is your assessment of public health agencies’ readiness to use technology like AI? Because if there&#8217;s one thing AI is good at, it&#8217;s predicting things. Are they [public health agencies] in a better position to predict things now?&nbsp;</p>



<p><strong>SHAH:</strong> You know, I think it&#8217;s a tale of two cities.&nbsp;</p>



<p>I think on the one hand, we&#8217;re better because we have the tools. On the other hand, we&#8217;ve lost the capacity to be able to utilize those tools. So, you know, it&#8217;s a plus and a minus.&nbsp;</p>



<p>Many, many years ago, there was the buzzword of what we called <em>syndromic surveillance</em>. And, Peter, you know this term well.&nbsp;</p>



<p>It was like you would have, you know, a whole host of accumulation of data points in, let&#8217;s say, a hospital setting or an emergency department …&nbsp;</p>



<p><strong>LEE: </strong>Yup. Yup.&nbsp;</p>



<p><strong>SHAH: </strong>… where, you know, you’d have runny nose, you&#8217;d have cough, you&#8217;d have a fever, and you would take that, what was happening and people presenting to the emergency department, with what was happening in the area pharmacies where people were going to get Kleenexes and tissues …&nbsp;</p>



<p><strong>LEE: </strong>Yep.&nbsp;</p>



<p><strong>SHAH:</strong> … and buying over-the-counter, you know, medication, and things of that nature, Tylenol, etc.&nbsp;</p>



<p>And you would say … you would put those two things together, and you would come up with a quote-unquote “syndrome,” and you would say our ability to say there was an alert to that syndrome allows us to say something<em> uh-oh</em> is going on in the community, and we got many, many advancements related to wastewater surveillance over the last several years as you know …&nbsp;</p>



<p><strong>LEE:</strong> Yep. Yep. Well, also, wasn&#8217;t patient number one in the United States discovered also because of the Seattle Flu Study, or at least that sort of syndromic surveillance.&nbsp;</p>



<p><strong>SHAH:</strong> That&#8217;s right.&nbsp;</p>



<p><strong>LEE: </strong>They weren&#8217;t even looking for COVID. They were just taking, you know, snot samples from people.&nbsp;</p>



<p><strong>SHAH:</strong> That&#8217;s right. That&#8217;s right. That&#8217;s right.&nbsp;</p>



<p>And so that&#8217;s the kind of thing that you, you know, we underappreciate. Is you have to have a smart, intelligent, agile practitioner, right.&nbsp;</p>



<p>So if I think about down in Dallas when Ebola was, you know, the gentleman who was, you know, the index case for Ebola was sent out of the emergency department and came back several days later.&nbsp;</p>



<p>And it was the nurse who picked up this time because the practitioner, the provider, the healthcare provider, the doc missed it. And I wouldn&#8217;t want to say in a negative way. It was just, like, not obvious. You aren&#8217;t thinking of Ebola in the middle of Texas. And it was the nurse who picked up: <em>there&#8217;s something wrong here</em>.&nbsp;</p>



<p>And what AI has the ability to do is to pick up those symptoms &#8230;&nbsp;</p>



<p><strong>LEE: </strong>Yeah.&nbsp;</p>



<p><strong>SHAH:</strong> … or those patterns and be able to recognize the importance of those and be able to then alert the practitioner. So what I … we call it <em>artificial intelligence</em>—it almost becomes artificial wisdom.&nbsp;</p>



<p><strong>LEE: </strong>Hmm. Yeah, interesting. So that actually reminds me of my next question, which is another thing that I watched you and public health officials do is try to play “what if” games.&nbsp;</p>



<p>So, for example, I think one decision you were involved in had to do with, you know, what would be the impact if we put a ban on large gatherings like concerts or movie theaters or imposed an 8 PM curfew on restaurants, and you were trying to play “what if” games. Like, what would be the impact on the spread of the pandemic there?&nbsp;</p>



<p>So now, again, today with AI, would that aspect of what you did play out differently than it did during the pandemic?&nbsp;</p>



<p><strong>SHAH:</strong> As you know, COVID was the most studied condition on the planet at one point. And it was, you know, things that usually we would learn over years or months, we were learning in weeks or days or hours.&nbsp;</p>



<p>And I remember in Houston, I would say something in the morning, and I would always try to give the caveat, “This is the best information we know right now,” because it kept changing, whether it was around masks or whether it was around, you know, the way the virus was operating, whether it was around &#8230;&nbsp;</p>



<p>I remember even … I was just watching something recently where I was asked to comment about whether spiders could transmit COVID-19. You know, just questions that were just evolving, evolving, evolving. And the information was evolving. By morning, you would say something. By evening, it would change.&nbsp;</p>



<p>And why I say that is that it would have been great in the pandemic if we could have said, if you could give us all the information that&#8217;s happening across the globe, synthesize that information, and be able to help us forecast the right decisions that we should be making and help us model that information so we could decide: if you did a curfew, or if you did, you know, a mask, or if you could, you know, change something else related to policy—what are the impacts of it?&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>SHAH: </strong>What we found constantly in public health was that we were weighing decisions in incomplete data, incomplete information.&nbsp;</p>



<p>So great now that everybody can armchair quarterback looking back three, five years ago and say, “I would have done it this way,” or “I would have done it that way.” Gosh, I would have as well. But guess what—we didn&#8217;t have that information at that time. And so you had to make the best decisions you could with incomplete data.&nbsp;</p>



<p>But what AI has the potential to do is to help <em>complete</em> the incomplete data. Now, it&#8217;s not going to get 100%.&nbsp;</p>



<p><strong>LEE: </strong>Right.&nbsp;</p>



<p><strong>SHAH:</strong> And I think, Peter, you know, the one thing we&#8217;ve got to be really mindful [of] is phantom information, or information where it sort of makes up things, or may somehow get you incomplete information, or skews it a certain way.&nbsp;</p>



<p>This is why we can&#8217;t take the person out of it yet.&nbsp;</p>



<p><strong>LEE: </strong>Right.&nbsp;</p>



<p><strong>SHAH:</strong> Now, maybe one day we can.&nbsp;</p>



<p>I&#8217;m not one of those Pollyanna-ish that people will never be replaced. I actually believe that those people who are skilled with AI and the tools will eventually have a competitive advantage over those who are not. Just like if I had a physician who knows how to use their smartphone or knows how to use a word processor or knows how to do a PowerPoint presentation is going to replace the ones that use scantrons &#8230;&nbsp;</p>



<p><strong>LEE: </strong>Yeah. Yeah.&nbsp;</p>



<p><strong>SHAH:</strong> … or the ones that write it on pieces of paper—that eventually it makes it more efficient and effective, but we&#8217;re not there yet. But I think that the potential is <em>absolutely</em> there.&nbsp;</p>



<p><strong>LEE: </strong>So I have one more question. And you can, kind of, tell I&#8217;m trying to expand people&#8217;s understanding of just the incredible breadth of what goes on in public health, you know, all of these sorts of different issues.&nbsp;</p>



<p>And again, just sticking to COVID, but this is a much broader issue. Another thing you had to cope with were significant rise of misinformation …&nbsp;</p>



<p><strong>SHAH:</strong> Yes.&nbsp;</p>



<p><strong>LEE: </strong>… and maybe going along with that, very, very significant inequities in outcomes in the COVID response. And when you think about AI there, I think you can argue it both ways, that it both exacerbates the problem but also gives you new tools to mitigate the problems.&nbsp;</p>



<p>What is your view?&nbsp;</p>



<p><strong>SHAH:</strong> I think you … I don&#8217;t even have to say it … I think you hit on it, is that, you know, it really is two sides of one coin.&nbsp;</p>



<p>On the one hand, it has the power of really advancing and allowing us to move forward in a way that incredibly accelerates and accentuates, but on the other hand, in the case of inequities, right? So if you have inequitable information data that&#8217;s already out in the literature or already out in the, you know, media, or what have you, about a certain population or people or certain kinds of ideas or thoughts, etc., then AI will tend to accumulate that. You&#8217;re going to take that information, thinking that&#8217;s the best out there, but it may have missed out on information and now you go with it. And that&#8217;s a potential problem.&nbsp;</p>



<p>And I think it&#8217;s the same thing on information is that when we have people that are able to classify or misclassify information, I think it really becomes hard because it can accelerate the inequities of trust or inequities of trusted sources of information. It can also close the gap.&nbsp;</p>



<p>So I think, you know, it&#8217;s really up to us and this responsible AI to really think about how we can go about doing this in a way that&#8217;s going to allow us to further the advancements but also be careful of those, you know, those kind of places where we&#8217;re going to step into that are not going to be well received or successful.&nbsp;</p>



<p>You know, the one thing that&#8217;s really fascinating about this whole conversation is that this is why we&#8217;ve got to be at the table, Peter.&nbsp;</p>



<p><strong>LEE: </strong>Yep. Yep.&nbsp;</p>



<p><strong>SHAH:</strong> Because if we&#8217;re not at the table, you know, what&#8217;s the, you know, or if tech companies that are out there doing this work and aren&#8217;t even seeing a field of practitioners that are actually wrestling with the same problems but just cannot actually get to the solutions, we&#8217;re just going to continue to accentuate the problems.&nbsp;</p>



<p>And that&#8217;s why I&#8217;m a firm proponent of: we&#8217;ve got to be at the table.&nbsp;</p>



<p>And so even when we&#8217;ve seen in, and this is going to be a little controversial, but governmental spaces where, you know, policymakers have said, “Look, we are not going to let you do certain things,” or they say to public health practitioners or even healthcare delivery practitioners in certain spaces, “You cannot even play with this. You cannot have it on your phones. You can&#8217;t do any &#8230; ”&nbsp;</p>



<p>You know, what I really believe it does is that it takes [an] almost like we put our head in the sand type of approach rather than saying, “What is it that we can do to help improve AI and make it work for all of us?” What we&#8217;re doing is we&#8217;re essentially saying, “We&#8217;re going to let the tech companies and all the other developers come up with the solutions, but it&#8217;s not going to be informed by the people in the field.” And that&#8217;s dangerous. We have to do both. We have to be working together.&nbsp;</p>



<p><strong>LEE: </strong>Umair, that&#8217;s really so well said, and I think a great way to wrap things up. I&#8217;ve certainly learned a lot from this conversation. So thank you again.&nbsp;</p>



<p><strong>SHAH:</strong> It&#8217;s been a pleasure to be with you this morning. Thank you so much for the time. And I&#8217;m looking forward to further conversations.&nbsp;</p>



<p>[TRANSITION MUSIC] </p>



<p>I live in the State of Washington and because of that, I&#8217;ve been able to watch Umair in action as our state&#8217;s former secretary of health. And some of that action was pretty intense to say the least because his tenure as secretary of health spanned the period of the COVID pandemic.&nbsp;</p>



<p>Now, as a dyed-in-the-wool techie, I have to admit that at the beginning, I don&#8217;t think I really understood the scope and importance of the field of public health. But as the conversation with Umair showed, it&#8217;s really important and it is arguably both an underfunded and underappreciated part of our healthcare system.&nbsp;</p>



<p>Now, public health is also very much an area that&#8217;s ripe for advancement and transformation through AI. As Umair explained in our discussion, the core of public health is the idea of population health, the idea of extracting new health insights from signals from population-scale data. And already we&#8217;re starting to see AI making a difference.&nbsp;</p>



<p>Now here&#8217;s my interview with Dr. Gianrico Farrugia.&nbsp;</p>



<p><strong>LEE:</strong> Gianrico, it&#8217;s really great to have you here today.&nbsp;</p>



<p><strong>GIANRICO FARRUGIA:</strong> Peter, thanks for having me. Thanks for making me part of your podcast.&nbsp;</p>



<p><strong>LEE:</strong> You know, what I&#8217;d like to do in these conversations is, you know, we&#8217;ll definitely want to talk about the overall healthcare system, the state of healthcare, and what AI could or might do to help or even hurt all of that. But I always like to start with a sharper focus just on you specifically. And my first question always is, you know, I think people imagine what a hospital or a health system president and CEO does, but not really. And so how would you explain to your mother what you do every day?&nbsp;</p>



<p><strong>FARRUGIA:</strong> So, Peter, my mother’s 88 years old. She lives in Malta, and she’s visiting at the moment, …&nbsp;</p>



<p><strong>LEE:</strong> Oh, wow.&nbsp;</p>



<p><strong>FARRUGIA:</strong> … which is kind of nice, really.&nbsp;</p>



<p><strong>LEE: </strong>Wow, that is amazing.&nbsp;</p>



<p><strong>FARRUGIA: </strong>I&#8217;m proud that she&#8217;s still proud of me. So she does ask. I&#8217;ll tell her the scope of Mayo Clinic. We serve patients across the globe. We have about 83,000 staff members that work with us, and we&#8217;re very proud of the work we do in research, education, and the practice.&nbsp;</p>



<p>Mayo Clinic is built to serve people with serious disease. So what I tell my mother is that here we are. We&#8217;re a healthcare organization that knows what it needs to do: keep patients as the North Star. The needs of the patient come first. We have 83,000 people who want to do that, several thousand physicians and scientists. My job is to look slightly ahead and then share what I&#8217;m seeing and then, sort of, smooth the way for others to make sure Mayo remains true to its mission but also true to the fact that at the moment, we are in a category of one. We need to remain there not just from an ego standpoint, but really from a “do good to the world” standpoint.&nbsp;</p>



<p>At that point, invariably my mother will tell me that I&#8217;m working too hard. [LAUGHTER] And then of course, I change the subject, and I ask her what she cooked today because my mother, who’s 88, cooks for the whole family in Malta, and there are usually four generations eating around the table. So I tell her what she does for the family is what I do for the Mayo family.&nbsp;</p>



<p><strong>LEE:</strong> Wow, that&#8217;s a great way to put it. And it sounds like you actually have a good chance to have some good genes if she&#8217;s still that active at age 88.&nbsp;</p>



<p><strong>FARRUGIA:</strong> I think I chose a little more stressful job that may limit [that]. I will tell you very briefly is that one of the AI algorithms we have estimates biological age from an electrocardiogram. My biological age jumped by 3.7 years when I became CEO.&nbsp;</p>



<p><strong>LEE:</strong> [LAUGHS] Oh no.&nbsp;</p>



<p><strong>FARRUGIA:</strong> I&#8217;m hoping it will reverse on the other side.&nbsp;</p>



<p><strong>LEE: </strong>To stick with you just for one more moment here, second question I ask is about your origin story with respect to AI. And typically, for most people, there is AI before ChatGPT and generative AI and then after the generative AI revolution. So can you share a little bit about this? Because it must be the case that you&#8217;ve been thinking about this a long time since you&#8217;ve really led Mayo Clinic to be so tech forward in this way.&nbsp;</p>



<p><strong>FARRUGIA:</strong> Well, I&#8217;ve been, as you said, a physician for way too long. I got my MD degree in ’87. So that sort of dates me. But it also means that I saw a lot of the promise for AI that never seemed to pan out for decades and decades and decades like you did.&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>FARRUGIA:</strong> Around 10 years ago, Mayo could sense that there was something different, that something was changing, that we actually—at that time, predictive AI—could make a big difference. And I think that&#8217;s the moment where I and others jumped in and said Mayo Clinic needs to be involved.&nbsp;</p>



<p>And then about six years ago, when—six and a half years ago—I became CEO, it was clear that there was the right confluence of data, knowledge, tech expertise, that we could deal with what was increasingly bothering me, which is that we knew what was coming from a technology standpoint and we knew the current healthcare system could not deliver on what patients need and want within that current system. And so the answer is, how could a place like Mayo Clinic with our reputation not jump in and say there has to be a better way of doing things? I&#8217;ve always said that it is impossible for me to understand that every single government employee is incompetent. Every physician is greedy. Something&#8217;s wrong here.&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>FARRUGIA:</strong> And that wrong was the architecture was wrong. And we knew that we could incorporate AI and make it better. So for me, that journey was one of <em>wait</em>, <em>wait</em>, <em>wait</em>. 10 years ago, begin to jump in. Six years ago, really jump in with our platform. And then, of course, in November 2022, things changed again.&nbsp;</p>



<p><strong>LEE:</strong> Yeah. When did this idea of a data platform, what you now call the <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.mayoclinicplatform.org/" target="_blank" rel="noreferrer noopener">Mayo Clinic Platform<span class="sr-only"> (opens in new tab)</span></a>—by the way, I refer to this as <em>MCP</em>, …&nbsp;</p>



<p><strong>FARRUGIA:</strong> Yeah, I know. [LAUGHS]&nbsp;</p>



<p><strong>LEE:</strong> [LAUGHS] … which I always smirk a little bit because, of course, for those of us in computer science research, the AI research, <em>MCP</em> has also become quite a hot topic because of the model context protocol version of this. But for Mayo&#8217;s MCP, when did that become a serious, defined initiative?&nbsp;</p>



<p><strong>FARRUGIA:</strong> So around the end of ’18, 2018, beginning of 2019. At that point, we knew that we were going to do something differently. We came up with a strategic plan, as I took on the job, that we needed to cure more patients. There’s just not enough cures in the world. There&#8217;s too much suffering. And that we had all these chronic diseases that people have accepted are chronic, but really the only reason that disease is chronic is you haven&#8217;t cured it.&nbsp;</p>



<p>And physicians have been afraid to talk about cure because, of course, eventually everybody passes away.&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>FARRUGIA:</strong> But I really pushed hard to say, no, it&#8217;s OK to talk about cure. It&#8217;s OK to aspire to cure. The second was connect—connecting people with data to create new knowledge. And that&#8217;s where it became clear that data were not currently in a format that were particularly useful. By the way, you&#8217;ll hear me talk about <em>data</em> in the singular and the plural. I&#8217;m old school. I talk about <em>data</em> as plural, but I know that most younger people now use <em>data</em> singular. [LAUGHTER] And I apologize if I&#8217;ll go through that.&nbsp;</p>



<p>And then the third was transform. Let&#8217;s use Mayo&#8217;s resources to transform healthcare for ourselves and for others. And that&#8217;s the concept of, if we are able to use data in a different way, let&#8217;s create a different architecture. And that architecture had to be very closely linked to using artificial intelligence in order to create better outcomes for patients. So patients can live not only longer lives but healthier lives. And that&#8217;s the genesis of MCP, <em>Mayo Clinic Platform</em>, so I&#8217;ll timestamp that as end of 2018, beginning of 2019.&nbsp;</p>



<p><strong>LEE:</strong> So I&#8217;m really wanting to delve in in this episode, in this conversation, you know, [into the] mindset of a health system or hospital CEO. And so you&#8217;re obviously thinking about, I guess, machine learning and predictive analytics and so on. What were the, kind of, like … in 2018, what were the outcomes that you were dreaming about from this? So if you had this thing, you know, what were the things that you were hoping to be able to show or, kind of, produce as results?&nbsp;</p>



<p><strong>FARRUGIA:</strong> So first of all, I think all of us who work at Mayo Clinic, and this tends to be a bit sugary, but it&#8217;s true, strongly feel that we have a responsibility to leave the place better than when we started. And so the Mayo brothers, when they started, did two really important things. The first was that they created the first integrated healthcare system. And the second, they created the first unified record. And that record was, of course, paper at that point.&nbsp;</p>



<p>Part of that is to say, OK, what does it look like now versus how can we improve what we have if … it&#8217;d be blasphemy to say, let&#8217;s think of ourselves as the Mayo brothers, but let&#8217;s think of ourselves as reasonably smart people at Mayo Clinic, really lucky to be surrounded by very smart people with resources. What will we do? And so we said let&#8217;s not aim for the low-hanging fruit. Let&#8217;s aim to get at whatever you want to call it, the intractable knot, the hardest problem, and that is clinical care. Let&#8217;s improve clinical care. Yes, we can deal with burnout. Yes, we can deal with administrative burden. But let&#8217;s not focus on that. Let&#8217;s really create an architecture that allows us to tackle better clinical outcomes.&nbsp;</p>



<p>And by starting there, then everything flows from that. That it&#8217;s not really worth doing unless at the end of the day, people are experiencing better health.&nbsp;</p>



<p><strong>LEE:</strong> And so I know a very good colleague and friend of mine, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.mayoclinicplatform.org/our-team/john-d-halamka-md-ms/" target="_blank" rel="noreferrer noopener">John Halamka<span class="sr-only"> (opens in new tab)</span></a>, you ended up hiring. I thought he was a very interesting choice because he is, of course, in terms of technology, quite deep and very expert, but he&#8217;s, I think, first and foremost, a doctor. And so I assume you must have had to decide what type of person you would bring in and what kinds of people you would bring in to try to create such a thing. What was your thinking around the choice of someone like John?&nbsp;</p>



<p><strong>FARRUGIA:</strong> It was one of the harder decisions. First of all, [I&#8217;m] a physician myself. We tend to want to maintain some control. And so now I am the CEO, [LAUGHTER] and I have to give this baby to somebody else. That&#8217;s very hard. Second is Mayo Clinic is really good because it is flat, and we run a lot by committee. But it also means that, therefore, you have to work really hard at change, and you cannot change by fiat. You have to change by convincing people.&nbsp;</p>



<p>So I just … I&#8217;ve always made the point that the right change agent is a servant leader because that&#8217;s how change becomes embedded. But it also means you&#8217;ve got to have that personality, the Mayo personality. And it became clear when we interviewed [that] there were some people that were really hardcore tech; others that were passionate about social issues. But John really fit that of being, as you said, deep in IT but also himself very aligned with the Mayo Clinic values. It&#8217;s as if he was a Mayo Clinic physician even though he wasn&#8217;t.&nbsp;</p>



<p>And that came together, and I felt, <em>we</em> felt, that as we were hiring, that we could do it. And then we did something interesting. We paired John with a … we created the role of a chief medical officer for the platform, which was a longstanding Mayo Clinic physician. And so we brought them together so we could get the past and the present and the future working together.&nbsp;</p>



<p><strong>LEE:</strong> So I&#8217;m going to ask you about what has come out of this. But before that, let&#8217;s get back to this origin story. So now, all of that is being set up starting around 2018. But then, you know, in 2022, there is generative AI. Now you were already experimenting with transformers, starting with BERT out of Google there. So maybe that&#8217;s a couple of years earlier. But still, there has to come a point where things are feeling very disrupted.&nbsp;</p>



<p><strong>FARRUGIA:</strong> Yeah, so, you know, it really wasn&#8217;t. It, to me, was a relief because it gave this … we were feeling pretty good about what we&#8217;re doing. We were feeling a little impatient, but, in true Mayo fashion, were willing to, sort of, do everything, take its time, take it to the right committees, get the right approvals, and get it done.&nbsp;</p>



<p>And so when generative AI came, for us, it&#8217;s like, I wouldn&#8217;t say we told you so, but it&#8217;s like, ah, there you go. Here&#8217;s another tool. This is what we&#8217;ve been talking about. Now we can do it even better. Now we can move even faster. Now we can do more for our patients. It truly never was disruptive. It truly immediately became enabling, which is strange, right, …&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>FARRUGIA:</strong> … because something as disruptive as that instantly became enabling at Mayo Clinic. And I&#8217;ll take … as I think about it with you and take a moment to think and reflect on it, I think there were a couple of decisions we made earlier on that really helped us. We made the decision <em>against</em> the advice of any consulting firm to completely decentralize AI at Mayo Clinic six years ago. And we told our clinical department, you need to own this. You need to hire basic scientists in AI. We&#8217;ll help you by creating the infrastructure. We&#8217;ll help you by doing all the rest. We&#8217;ll have the compute. We&#8217;ll have the partners. You need to do this on your own. You need to treat this the same way as if a new radiological technique happened or a new surgical technique happened.&nbsp;</p>



<p>And so there was a lot of expertise already present in a very diffused way that then we were able to layer on generative AI onto that. And we found a very willingness to embrace it. In fact, I would argue initially a bit too willing because as you know, we haven&#8217;t quite figured out what&#8217;s legitimate use, what&#8217;s not use.&nbsp;We all learned together.</p>



<p><strong>LEE:</strong> Right. Yep. Yep.&nbsp;</p>



<p><strong>FARRUGIA:</strong> But it was mostly energy, which is really interesting. It was mostly energy.</p>



<p><strong>LEE:</strong> Wow. And, you know, it&#8217;s an amazing thing to hear because one common theme that we hear is that the initial reaction is oftentimes one of skepticism. In fact, I&#8217;ve been very open that even I initially had some skepticism. Was that not present in your mind or on your team&#8217;s mind at all at the beginning?&nbsp;</p>



<p><strong>FARRUGIA:</strong> So you&#8217;re asking a physician if they are skeptical about something. [LAUGHTER] Yeah. I wonder what the answer to that is. Absolutely. The first hallucination, the first wrong reference. Can you imagine if you write the grant and the wrong reference comes. As you know, …&nbsp;</p>



<p><strong>LEE:</strong> Right.&nbsp;</p>



<p><strong>FARRUGIA:</strong> … earlier on when some references were being made up. So massive amounts of skepticism. But the energy was such there that the people [who] were skeptical were also at the same time saying, “Let&#8217;s do a RAG [retrieval augmented generation] to clean up those references. Let&#8217;s create …” We were experimenting with discharge summaries, but let&#8217;s use AI to police AI, and let&#8217;s see what&#8217;s going on. So there was more massive skepticism, but the energy was pushing that skepticism into a positive versus into a negative frame. Now, I say that summarizing in hindsight.&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>FARRUGIA:</strong> Day to day, much more complicated than that. But overall, if you just … and remember, I had been at the World Economic Forum many years ago and had said, healthcare needs to run towards AI.&nbsp;</p>



<p><strong>LEE:</strong> Yes.&nbsp;</p>



<p><strong>FARRUGIA:</strong> If healthcare was perfect, we would wait. Healthcare is not perfect by any means, therefore let&#8217;s run and embrace AI. And, sort of, that mentality was part of who we were because at the same time, we were also saying the other thing, that we need to be the ones to lead validation. We need to be the ones that set the rules. We need to be participating in the creation of <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.chai.org/" target="_blank" rel="noreferrer noopener">CHAI [Coalition for Health AI]<span class="sr-only"> (opens in new tab)</span></a>. We need to be participating as the <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" target="_blank" href="https://nam.edu/">[National] Academy of Medicine<span class="sr-only"> (opens in new tab)</span></a>.&nbsp;</p>



<p>So people did feel that Mayo was being fairly responsible about it, but that urge to, the needs of the patient come first, was the driver that kept people wanting to say, “Not ready yet, but let&#8217;s make it ready.” And we now have 320 algorithms in the practice, and they run and we constantly are looking and seeing what else we can do to improve. But as you well know, things evolve and change. And we&#8217;re also looking and seeing which ones work and which ones don&#8217;t and which ones we have to work together on to make better.&nbsp;</p>



<p><strong>LEE:</strong> Yeah, you know, of course Mayo has such a, you know, such a reputation and is so influential, but in the world of healthcare broadly, let&#8217;s just focus on the United States to start. How common is this experience? You know, so if you are at a meeting with fellow CEOs of hospitals and health systems, what is the attitude and what is the, kind of … how common is the approach to all of this?&nbsp;</p>



<p><strong>FARRUGIA:</strong> I think it&#8217;s more common now, but going back a few years, I think it&#8217;s fair to say that it was scary for people to know how it&#8217;s going to change things. Healthcare runs on very narrow margins. It&#8217;s very expensive. So your expenses and your revenue are both massive, and they are very close to each other. So anything that changes that balance is really scary.&nbsp;</p>



<p>Because it&#8217;s not like you have the opportunity to erode into a margin or get it right the second time. So I think that is what drove a lot of the initial hesitancy. Was, one, is lack of knowledge and, two, understanding that you didn&#8217;t have a lot of room to make a mistake.&nbsp;</p>



<p><strong>LEE:</strong> On the economics of this, when you are embarking on what I suspect is a very expensive initiative like Mayo Clinic Platform, how on earth do you justify that early on?&nbsp;</p>



<p><strong>FARRUGIA:</strong> So again, I&#8217;m trying hard to try and remember how things were versus how I think about them now. [LAUGHTER] It goes back to our history. Mayo has always invested in what it thinks is the right thing that is coming. And that&#8217;s how we&#8217;ve stayed where we are. So the investment really was having an open discussion: is this worth it for our patients? And once that discussion was over, then the board was saying, <em>go</em>, <em>go</em>, <em>go</em>.&nbsp;</p>



<p>Now we are lucky in that we have the size that we&#8217;re able to hire and absorb. We&#8217;re lucky in that the people [who] came before us have been financially astute, and one of our values is stewardship. And we&#8217;re lucky that we had a lot of patients at Mayo Clinic who were able to listen, be inspired by, and be willing to help support. And so that gave us the ability to build what we&#8217;re doing not only into the long-range plan but actually into the yearly plan. And so we built it into the yearly plan. We set up a center for digital health. We set up the platform. And then we set up the budgets to be able to do that. And the budgets came from assets we&#8217;ve had, assets that we would get as the year came by, and then from philanthropy.&nbsp;</p>



<p>We also had a really powerful calling card. And that&#8217;s one advantage I had, and that&#8217;s … and I&#8217;d been very open when I was speaking to other CEOs that would use it is that right at that very beginning, really, really in 2019, our cardiologists, both the researchers and the clinicians, had come together and had used electrocardiograms to create an AI algorithm.&nbsp;</p>



<p>The first one was for diagnosing from an electrocardiogram, which is very cheap, very easy to do, left ventricular dysfunction. That&#8217;s how hard the left part of the heart contracts. If it doesn&#8217;t do well, you get heart failure. And they were able to show that that algorithm was already making nurses better than the physician without the algorithm. And after that went on to show that you could do it from a single strip, really with an area under the curve for that single strip on a watch, that was as good as mammograms or pap smears. And so we already had that proof.&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>FARRUGIA:</strong> That quickly then came into Mayo. We put it into it so that any patient now can benefit from it. And now there are, I think, 14 algorithms just from that same one.&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>FARRUGIA:</strong> So we had a proof of concept thanks to those really far-seeing cardiologists that enabled things to happen a little faster and also, as I talked to other CEOs, enabled me to say, “This actually works. This is the path forward.” I have recently been vocal about also saying, we are at a point now where I believe that for some medical conditions, it is not right to not use AI to help treat them.&nbsp;</p>



<p><strong>LEE: </strong>Wow, that&#8217;s so interesting. So I think I want to get into another topic here, which is when you think about the use of AI and data, what are some of the results that maybe are top of mind for you or you think are particularly important? And if you don&#8217;t mind, I&#8217;d like to see if we can think about this not only in terms of results in terms of patient outcomes but in your other activities, core activities, like research, in the education mission, and then even in the broader impacts on the healthcare system. But maybe we start with on patient outcomes.&nbsp;</p>



<p><strong>FARRUGIA:</strong> Yeah, they&#8217;re all linked, right.&nbsp;</p>



<p><strong>LEE:</strong> Yes.&nbsp;</p>



<p><strong>FARRUGIA:</strong> They&#8217;re part of the same ecosystem. We think of ourselves as three shields— research, education, and the practice—and that one goes into the other. So, as I said, we have about 320 AI algorithms from the practice. Some run on every patient; some run on some patients. And we have good evidence for what they do. So some specific examples, and then I&#8217;ll get into the transformer part of this.&nbsp;</p>



<p>We have a program called CEDAR [Clinical Detection and Response (tool)], and like most other people, I like acronyms for things. [LAUGHTER] But what it is, in our hospitals with patient consent, we monitor vitals. We monitor in the patient room—not in the ICU [intensive care unit], in the patient room. We monitor all sorts of things. But there&#8217;s a camera in the room, and we have a team of intensivists—nurses and physicians—who do not have any patient responsibilities but are just monitoring the algorithms, and when the algorithms are predicting decompensation, they&#8217;re able to get into the room. And what we&#8217;ve shown, for example, with that algorithm, is we&#8217;ve shown we&#8217;ve decreased length of stay in the hospital, decreased transfers into the intensive care units, and interestingly, decreased mortality and morbidity, which is not easy to show. I talked about the electrocardiogram as a good example. Of course, everybody knows about the radiology things.&nbsp;</p>



<p>We&#8217;ve created … taken part of this and said, if we can do this in the hospital, why cannot we do it in patients&#8217; homes? So being very active in looking after patients that would come to the ED, emergency room, would normally be admitted, and we say, no, here are the things we can give you. Go home if you want to, and we will safely look after you at your home. And we recently have been, looking at the last two years of data, been able to show that we&#8217;re also successfully able to give intravenous chemotherapy in patients&#8217; homes because we can monitor; we can do all the things that we can do.&nbsp;</p>



<p>Now, with generative AI, that gave us many other opportunities. One biggest opportunity for me has always been digital pathology. When we see how pathology’s currently run with a glass slide, not much has changed …&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>FARRUGIA:</strong> … in many, many, many years, right.&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>FARRUGIA:</strong> And so really we have made a massive push to digitize pathology not just for us but for others. But talking about ourselves, we started by saying, it has to be very cheap to digitize. So we worked and created a company with partners called <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.pramana.ai/" target="_blank" rel="noreferrer noopener">Pramana<span class="sr-only"> (opens in new tab)</span></a> that allows us to digitize slides relatively cheaply using AI algorithms that can take away the dirt, the fingerprint. And so we end up with 21 million of our slides digitized, and that gives you now a massive opportunity. Worked with another company called <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.aignostics.com/" target="_blank" rel="noreferrer noopener">Aignostics<span class="sr-only"> (opens in new tab)</span></a> to create a, what we call, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://arxiv.org/abs/2501.05409" target="_blank" rel="noreferrer noopener">Atlas<span class="sr-only"> (opens in new tab)</span></a>, which is an LLM that allows us to then build upon it.&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>FARRUGIA:</strong> And we, a hundred and, I think, 120 years ago, invented frozen sections at Mayo Clinic. So what that is, is that while the patient&#8217;s still on the table, you can take a piece of tissue, look at it, and tell the surgeon the margins of what you&#8217;re trying to resect are clear or not. But as a result of that, because you have to hurry, you get no information as a surgeon about, is it an invasive cancer, is it noninvasive cancer, or other things. So we&#8217;ve just found a way to digitize our frozen section practice and will completely go across the enterprise with AI-enabled digitized frozen sections, which then enables us to then do it for anybody across the globe if we need to.&nbsp;</p>



<p>And then in the genomic space, we&#8217;re working to create a true exomic transformer that is short range. And we originally started doing it to see if we can test it against the fact that 40% of people with rheumatoid arthritis don&#8217;t respond to the first-line therapy, …&nbsp;</p>



<p><strong>LEE:</strong> Right.&nbsp;</p>



<p><strong>FARRUGIA:</strong> … but you have to wait six months to find out. And we found that we can actually do that. But it has much greater uses, of course.&nbsp;</p>



<p>And then we&#8217;re working with you—I don&#8217;t know how much you want to get into this, Peter, or [if] you want to talk about it yourself—<a href="https://www.microsoft.com/en-us/research/publication/maira-2-grounded-radiology-report-generation/" target="_blank" rel="noreferrer noopener">MAIRA-2</a>, which is really exciting, about how taking a simple problem—can you create a transformer that is able to detect if lines on the chest are in the right place, breathing tube is in the right place?—and then do it in a way that then can be used for many, many other things.&nbsp;</p>



<p>And then, Peter, because you asked about education and research, …&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>FARRUGIA:</strong> … imagine what this does now to the education system, right. And so we&#8217;ve got to train our physicians differently. We now have an AI curriculum for all our medical students. We offer masters and PhDs in AI. We think it&#8217;s essential for the people who want to be able to truly become experts, the same way I became an expert in my area of research.&nbsp;</p>



<p>And then from a research standpoint, when you think about all the registries that exist in people&#8217;s labs, all the spatial genomics, all the epigenomics, all the omics that exist. And if you are able to coalesce them into one big, what we call, an <em>atlas</em>, how that could really spur research at a scale that we haven&#8217;t thought of before. And so that is our aim at the moment.&nbsp;</p>



<p>From a research standpoint, we are, with Vijay Shah, who&#8217;s our dean of research, is to say, let&#8217;s make the effort of making sure all the data are available to be able to use and enable for us to take advantage of AI. And that is not easy because, of course, people have collected the data. They tend to want to embrace it.&nbsp;</p>



<p><strong>LEE: </strong>Yep.&nbsp;</p>



<p><strong>FARRUGIA: </strong>So there have to be the right incentives, the right privacy, and the right ways of doing it. And we think we&#8217;re on the way there, and we’re already seeing some advantages from doing it this way.&nbsp;</p>



<p><strong>LEE: </strong>So we&#8217;re running short on time. And so I always like to end with one or two more provocative questions. And, you know, it&#8217;s tempting to ask you the provocative question of whether you think AI will ever replace human doctors, but I don&#8217;t want to go there with you. In fact, as I thought about our discussion, I was reflecting. We were at a conference together once, and I was on stage in a fireside chat. And then, you know, after the fireside chat, there were audience questions, and I don&#8217;t remember any of the questions from the audience except <em>yours</em>.&nbsp;</p>



<p>And just to remind you, you know, I think when I was on stage, we were talking about a lot of practical uses of AI to, let&#8217;s say, reduce administrative burdens and so on in healthcare. But you got up and you, I won&#8217;t say you scolded me, but you more or less said, is it the right idea to use AI to optimize today&#8217;s somewhat broken healthcare system, or should we be thinking more boldly about, you know, a more fundamental transformation?&nbsp;</p>



<p>And so what I thought I would try to close with here is to hear what was really behind that question. You know, what were you trying to get me to think about when you asked that question?&nbsp;</p>



<p><strong>FARRUGIA:</strong> So first of all, darn your great memory [LAUGHTER]. Belated apologies … I probably should have &#8230;&nbsp;</p>



<p><strong>LEE:</strong> It was by far the best and most sophisticated and, I think, thought-provoking question of all of the ones that came out of the audience.&nbsp;</p>



<p><strong>FARRUGIA:</strong> What I was trying to get to is actually trying to clarify it in my own head and then in the head of others is that we do not need to have a linear path to get to where we want to get to. And we seemed to be on a linear path, which is, let&#8217;s try and reduce administrative burden. Let&#8217;s try and truly be a companion to a physician or other provider. Let&#8217;s make their problems better, make them feel better about providing healthcare. And then in the next step, we keep going until we get to, now we can call it agentic AI, whatever we want to talk about. And my view was, <em>no</em>, is that let&#8217;s start with that aim, the last aim, and do the others because the others will come automatically if you&#8217;re working on that harder problem.&nbsp;</p>



<p>Because one, to get to that harder problem, you&#8217;ll find all the other solutions. I was just trying to push that here&#8217;s this wonderful tool that&#8217;s been given to us. Let&#8217;s take advantage of it as quickly as we can. I think we had gotten a little too sensitized to need to say the right things. “Careful, be very careful” versus saying, “Massive opportunity. Do it right, and healthcare will be much better. Go for it.”&nbsp;</p>



<p><strong>LEE:</strong> Well, I think I understand better now where the vision, insight, and frankly, courage to take on something as ambitious and transformational as the Mayo Clinic Platform and really all of your leadership in your tenure as the president and CEO of Mayo Clinic. I think I understand it much better now.&nbsp;</p>



<p>Gianrico, it&#8217;s just always such a privilege to interact with you and now to have a chance to work with you more closely. So thank you for everything that you do and thank you for joining us today.&nbsp;</p>



<p><strong>FARRUGIA:</strong> Thank you for making it so easy, and thanks for giving us this opportunity to do good for the world.&nbsp;</p>



<p>[TRANSITION MUSIC] </p>



<p><strong>LEE: </strong>Gianrico leads what is arguably the crown jewel of the world&#8217;s healthcare systems, and so I feel it&#8217;s such a privilege to be able to talk and sometimes even brainstorm with him.&nbsp;</p>



<p>Our conversation, I think, exposed just how tech forward Gianrico is as he charts the strategies for healthcare delivery well into the future. And as I&#8217;ve interacted with many others, what I&#8217;ve learned is that this is a common trait among major health system CEOs. Roughly speaking, like we&#8217;ve seen in previous episodes where doctors and med students are polymath clinician-technologists, the same thing is true of health system CEOs and other leaders.&nbsp;</p>



<p>AI in the mind of a health system CEO today is not only a technology that can transform diagnosis and treatment, but it&#8217;s also something that can have a huge impact on the business of healthcare delivery, the connection of healthcare to medical research, and the journeys that patients go through as they seek better health.&nbsp;</p>



<p>These two conversations show that virtually all leaders in health and medicine are confronting head-on the opportunities, challenges, and the reality of AI, and they see a future that is potentially very different than what we have today.&nbsp;</p>



<p>[THEME MUSIC]&nbsp;</p>



<p>I&#8217;d like to thank Umair and Gianrico again for their time and insights. And to our listeners, thank you for joining us. We hope you&#8217;ll tune in to our final episode of the series. My coauthors, Carey and Zak, will be back to examine the takeaways from our most recent conversations.&nbsp;</p>



<p>Until next time.&nbsp;</p>



<p>[MUSIC FADES]&nbsp;</p>

				</span>
			</div>
			<button
				class="action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle"
				aria-expanded="false"
				data-show-less-text="Show less"
				type="button"
				aria-controls="show-more-show-less-toggle-1"
				aria-label="Show more content"
				data-alternate-aria-label="Show less content">
				Show more			</button>
		</div>
	</div>
</div>



<div class="wp-block-buttons is-layout-flex wp-block-buttons-is-layout-flex">
<div class="wp-block-button is-style-outline is-style-outline--2"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/story/the-ai-revolution-in-medicine-revisited/">AI Revolution in Medicine podcast series</a></div>
</div>



<p></p>
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/podcast/reimagining-healthcare-delivery-and-public-health-with-ai/">Reimagining healthcare delivery and public health with AI</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Self-adaptive reasoning for science</title>
		<link>https://www.microsoft.com/en-us/research/blog/self-adaptive-reasoning-for-science/</link>
		
		<dc:creator><![CDATA[Newman Cheng, Gordon Broadbent, Steven Truitt, William Chappell]]></dc:creator>
		<pubDate>Wed, 06 Aug 2025 16:00:00 +0000</pubDate>
				<category><![CDATA[Research Blog]]></category>
		<guid isPermaLink="false">https://www.microsoft.com/en-us/research/?p=1145083</guid>

					<description><![CDATA[<p>Microsoft is pioneering a vision for a self-adapting AI system that can adapt to the dynamic nature of scientific discovery, promoting deeper, more refined reasoning in complex scientific domains.</p>
<p>The post <a href="https://www.microsoft.com/en-us/research/blog/self-adaptive-reasoning-for-science/">Self-adaptive reasoning for science</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/MDQ-BlogHeroFeature-1400x788-1.jpg" alt="A gradient background transitioning from blue to pink with three white icons: a DNA double helix, a light bulb with rays, and a stylized path with arrows and nodes." class="wp-image-1146704" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/MDQ-BlogHeroFeature-1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/MDQ-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/MDQ-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/MDQ-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/MDQ-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/MDQ-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/MDQ-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/MDQ-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/MDQ-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/MDQ-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure>



<h2 class="wp-block-heading" id="unlocking-self-adaptive-cognitive-behavior-that-is-more-controllable-and-explainable-than-reasoning-models-in-challenging-scientific-domains">Unlocking self-adaptive cognitive behavior that is more controllable and explainable than reasoning models in challenging scientific domains</h2>



<p>Long-running LLM agents equipped with strong reasoning, planning, and execution skills have the potential to transform scientific discovery with high-impact advancements, such as developing new materials or pharmaceuticals. As these agents become more autonomous, ensuring effective human oversight and clear accountability becomes increasingly important, presenting challenges that must be addressed to unlock their full transformative power. Today’s approaches to long-term reasoning are established during the post-training phase, prior to end-user deployment and typically by the model provider. As a result, the expected actions of these agents are pre-baked by the model developer, offering little to no control from the end user.</p>



<p>At Microsoft, we are pioneering a vision for a continually steerable virtual scientist. In line with this vision, we created the ability to have a non-reasoning model develop thought patterns that allow for control and customizability by scientists. Our approach, a cognitive loop via in-situ optimization (CLIO), does not rely on reinforcement learning post-training to develop reasoning patterns yet still yields equivalent performance as demonstrated through our evaluation on Humanity’s Last Exam (HLE). Notably, we increased OpenAI GPT-4.1’s base model accuracy on text-only biology and medicine from <strong>8.55%</strong> to <strong>22.37%</strong>, an absolute increase of<strong> 13.82%</strong> (<strong>161.64% </strong>relative), surpassing o3 (high). This demonstrates that an optimization-based, self-adaptive AI system developed without further post-training can rival post-trained models in domains where adaptability, explainability, and control matter most.</p>



<figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1911" height="1070" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/MDQ_Figure-1_Updated.png" alt="Bar chart that represents the Head-to-head comparison of OpenAI’s GPT-4.1 with CLIO, o3, and GPT-4.1 with no tools on HLE biology and medicine questions" class="wp-image-1146748" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/MDQ_Figure-1_Updated.png 1911w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/MDQ_Figure-1_Updated-300x168.png 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/MDQ_Figure-1_Updated-1024x573.png 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/MDQ_Figure-1_Updated-768x430.png 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/MDQ_Figure-1_Updated-1536x860.png 1536w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/MDQ_Figure-1_Updated-655x368.png 655w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/MDQ_Figure-1_Updated-240x134.png 240w" sizes="auto, (max-width: 1911px) 100vw, 1911px" /><figcaption class="wp-element-caption">Figure 1. Head-to-head comparison of OpenAI’s GPT-4.1 with CLIO, o3, and GPT-4.1 with no tools on HLE biology and medicine questions</figcaption></figure>



<h3 class="wp-block-heading" id="in-situ-optimization-with-internal-self-reflection-to-enable-self-adaptive-reasoning">In-situ optimization with internal self-reflection to enable self-adaptive reasoning</h3>



<p>Model development has advanced from using reinforcement learning human feedback (RLHF) for answer alignment to external grading in reinforcement learning (RLVR). Recent approaches show promise in the utilization of intrinsic rewards for training reasoning models (RLIR). Traditionally, these reasoning processes are learned during the post-training process before any user interaction. While today’s reasoning models require additional data in the training phase and limit user control during the reasoning generation process, CLIO’s approach enables users to steer reasoning from scratch without additional data. Rather, CLIO generates its own necessary data by creating reflection loops at runtime. These reflection loops are utilized for a wide array of activities that CLIO self-defines, encompassing idea exploration, memory management, and behavior control. Most interesting is CLIO’s ability to leverage prior inferences to adjust future behaviors, handling uncertainties and raising flags for correction when necessary. Through this open architecture approach to reasoning, we alleviate the necessity for further model post-training to achieve desired reasoning behavior. Performing novel scientific discoveries often has no prior established patterns for reasoning, much less a large enough corpus of high-quality data to train on.&nbsp;</p>



<p>CLIO reasons by continuously reflecting on progress, generating hypotheses, and evaluating multiple discovery strategies. For the HLE test, CLIO was specifically steered to follow the scientific method as a guiding framework. Our research shows that equipping language models with self-adapting reasoning enhances their problem-solving ability. It provides a net benefit in quality for science questions, as well as providing exposure and control to the end user.</p>



<figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="2560" height="1169" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/MDQ_FIG2-2-scaled.png" alt="Figure 2. CLIO can raise key areas of uncertainty within its self-formulated reasoning process, balancing multiple different viewpoints using graph structures." class="wp-image-1146740" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/MDQ_FIG2-2-scaled.png 2560w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/MDQ_FIG2-2-300x137.png 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/MDQ_FIG2-2-1024x468.png 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/MDQ_FIG2-2-768x351.png 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/MDQ_FIG2-2-1536x702.png 1536w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/MDQ_FIG2-2-2048x935.png 2048w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/MDQ_FIG2-2-240x110.png 240w" sizes="auto, (max-width: 2560px) 100vw, 2560px" /><figcaption class="wp-element-caption">Figure 2. CLIO can raise key areas of uncertainty within its self-formulated reasoning process, balancing multiple different viewpoints using graph structures.</figcaption></figure>



<h3 class="wp-block-heading" id="control-over-uncertainty-building-trust-in-ai">Control over uncertainty: Building trust in AI&nbsp;</h3>



<p>Orchestrated reasoning systems like CLIO are valuable for scientific discovery, as they provide features beyond accuracy alone. Capabilities such as explaining the outcomes of internal reasoning are standard in the scientific field and are present in current reasoning model approaches. However, elements like displaying complete work, including final outcomes, internal thought processes, and uncertainty thresholds to support reproducibility or correction, as well as indicating uncertainty, are not yet universally implemented. Current models and systems do not have this same innate humility.&nbsp; Rather, we are left with models that produce confident results, whether correct or incorrect. When correct, it is valuable. When incorrect, it is dangerous to the scientific process. Hence, understanding a model or system’s uncertainty is a crucial aspect that we have developed natively into CLIO.</p>



<p>On the other end of the spectrum, orchestrated reasoning systems tend to oversaturate the user by raising too many flags. We enable prompt-free control knobs within CLIO to set thresholds for raising uncertainty flags. This allows CLIO to flag uncertainty for itself and the end user at the proper point in time. This also enables scientists to revisit CLIO’s reasoning path with critiques, edit beliefs during the reasoning process, and re-execute them from the desired point in time. Ultimately, this builds a foundational level of trust with scientists to use them in a scientifically defensible and rigorous way.&nbsp;</p>



<h3 class="wp-block-heading" id="how-does-clio-perform">How does&nbsp;CLIO&nbsp;perform?&nbsp;</h3>



<p>We evaluate CLIO against text-based biology and medicine questions from HLE. For this domain, we demonstrate a <strong>61.98%</strong> relative increase or an <strong>8.56%</strong> net increase<strong> </strong>in accuracy over OpenAI’s o3 and substantially outperform base completion models like OpenAI’s GPT-4.1, while enabling the requisite explainability and control. This technique applies to all models, showing similar increases in OpenAI’s GPT-4o model, which we observe performs poorly on HLE-level questions. On average, GPT-4.1 is not considered competent for HLE scale questions (<9%), and GPT-4o is natively at less than 2%. By utilizing CLIO, we bring these to near state-of-the-art performance against top reasoning models. CLIO&#8217;s recursive nature enables the system to think broader and more deeply, ensuring coverage of the question when answered. In GPT-4.1, we see an increase of 5.92% in accuracy for overall performance using just the cognitive loop recursion. To think more deeply, we allow CLIO to ensemble different evolutions and intelligently choose from the best approach using <a href="https://www.microsoft.com/en-us/research/project/graphrag/" target="_blank" rel="noreferrer noopener">GraphRAG</a>. This extension of the cognition pattern provides a further 7.90% over a non-ensembled approach. &nbsp;</p>



<figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1915" height="1074" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/MDQ_Fig3.png" alt="Waterfall chart that demonstrates the impact of thinking effort on CLIO’s effectiveness." class="wp-image-1146714" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/MDQ_Fig3.png 1915w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/MDQ_Fig3-300x168.png 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/MDQ_Fig3-1024x574.png 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/MDQ_Fig3-768x431.png 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/MDQ_Fig3-1536x861.png 1536w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/MDQ_Fig3-655x368.png 655w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/MDQ_Fig3-240x135.png 240w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/MDQ_Fig3-640x360.png 640w" sizes="auto, (max-width: 1915px) 100vw, 1915px" /><figcaption class="wp-element-caption">Figure 3. The impact of thinking effort on CLIO’s effectiveness.</figcaption></figure>



<p>Furthermore, CLIO’s design offers different knobs of control, for example, how much time to think and which technique to utilize for a given problem. In Figure 3, we demonstrate these knobs of control and their increase on GPT-4.1 and GPT-4o&#8217;s performance. In this case, we analyze performance for a subset of biomedical questions, those focused on immunology. CLIO increases GPT-4o&#8217;s base performance to be at par with the best reasoning models for immunology questions. We observe a <strong>13.60%</strong> improvement over the base model, GPT-4o. This result shows CLIO to be model agnostic, similar to <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://microsoft.ai/new/the-path-to-medical-superintelligence/" target="_blank" rel="noreferrer noopener">Microsoft AI Diagnostic Orchestrator&#8217;s (MAI-DxO)<span class="sr-only"> (opens in new tab)</span></a>&#8216;s approach and corresponding performance boost.&nbsp;</p>



<h3 class="wp-block-heading" id="implications-for-science-and-trustworthy-discovery">Implications for science and trustworthy discovery</h3>



<p>The future of scientific discovery demands more than reasoning over knowledge and raw computational power alone. Here, we demonstrate how CLIO not only increases model performance but establishes new layers of control for scientists. In our upcoming work, we will demonstrate how CLIO increases tool utility for highly valuable scientific questions in the drug discovery space which requires precise tools designed for the language of science. While our experiments focus on scientific discovery, we believe CLIO can apply in a domain-agnostic fashion. Experts tackling problems in domains such as financial analysis, engineering, and legal services could potentially benefit from AI systems with a transparent, steerable reasoning approach. Ultimately, we envision CLIO as an enduring control-layer in hybrid AI stacks that combine traditional completion and reasoning models, with external memory systems, and advanced tool calling. These continuous checks and balances that CLIO enables will continue to remain valuable even as components within the AI stacks evolve. This combination of intelligent and steerable scientific decision making and tool optimization is the basis of the recently announced <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://azure.microsoft.com/en-us/blog/transforming-rd-with-agentic-ai-introducing-microsoft-discovery/?msockid=394581ce06c567df2171946b073d6601" target="_blank" rel="noreferrer noopener">Microsoft Discovery platform<span class="sr-only"> (opens in new tab)</span></a>.</p>



<p>At Microsoft, we’re committed to advancing AI research that earns the trust of scientists, empowering them to discover new frontiers of knowledge. Our work is a testament to what’s possible when we blend innovation with trustworthiness and a human-centered vision for the future of AI-assisted scientific discovery. We invite the research and scientific community to join us in shaping that future.</p>



<p><strong>Further information:</strong></p>



<p>To learn more details about our approach, please read our <a href="https://www.microsoft.com/en-us/research/publication/cognitive-loop-via-in-situ-optimization-self-adaptive-reasoning-for-science/">pre-print paper</a> published alongside this blog. We are in the process of submitting this work for external peer review and encourage partners to explore the utilization of CLIO in Microsoft Discovery. To learn more about Microsoft’s research on this or contact our team, please reach out to <a href="mailto:discoverylabs@microsoft.com" target="_blank" rel="noreferrer noopener">discoverylabs@microsoft.com</a>. </p>



<h2 class="wp-block-heading" id="acknowledgements">Acknowledgements</h2>



<p>We are grateful for Jason Zander and Nadia Karim’s support. We extend our thanks to colleagues both inside and outside Microsoft Discovery and Quantum for sharing their insights and feedback, including Allen Stewart, Yasser Asmi, David Marvin, Harsha Nori, Scott Lundberg, and Phil Waymouth.&nbsp;</p>
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/blog/self-adaptive-reasoning-for-science/">Self-adaptive reasoning for science</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Project Ire autonomously identifies malware at scale</title>
		<link>https://www.microsoft.com/en-us/research/blog/project-ire-autonomously-identifies-malware-at-scale/</link>
		
		<dc:creator><![CDATA[Brian Caswell, Dustin Fraze, Sarah Smith, Rodrigo Racanicci, Tim Middleton-Sally, Shelby Hayes, Stanley He, Katy Smith, Bhakta Pradhan, Mike Walker]]></dc:creator>
		<pubDate>Tue, 05 Aug 2025 16:00:00 +0000</pubDate>
				<category><![CDATA[Research Blog]]></category>
		<guid isPermaLink="false">https://www.microsoft.com/en-us/research/?p=1145100</guid>

					<description><![CDATA[<p>Designed to classify software without context, Project Ire replicates the gold standard in malware analysis through reverse engineering. It streamlines a complex, expert-driven process, making large-scale malware detection faster &#038; more consistent.</p>
<p>The post <a href="https://www.microsoft.com/en-us/research/blog/project-ire-autonomously-identifies-malware-at-scale/">Project Ire autonomously identifies malware at scale</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/IreSocial-BlogHeroFeature-1400x788-1.jpg" alt="Stylized digital illustration of a multi-layered circuit board. A glowing blue microchip sits at the top center, with intricate circuitry radiating outward. Beneath it, four stacked layers transition in color from blue to orange, each featuring circuit-like patterns. Smaller rectangular and circular components are connected around the layers, all set against a dark background with scattered geometric shapes." class="wp-image-1145541" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/IreSocial-BlogHeroFeature-1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/IreSocial-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/IreSocial-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/IreSocial-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/IreSocial-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/IreSocial-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/IreSocial-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/IreSocial-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/IreSocial-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/IreSocial-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w" sizes="auto, (max-width: 1400px) 100vw, 1400px" /></figure>



<p>Today, we are excited to introduce an autonomous AI agent that can analyze and classify software without assistance, a step forward in cybersecurity and malware detection. The prototype, <a href="https://www.microsoft.com/en-us/research/project/project-ire/">Project Ire</a>, automates what is considered the gold standard in malware classification: fully reverse engineering a software file without any clues about its origin or purpose. It uses decompilers and other tools, reviews their output, and determines whether the software is malicious or benign.</p>



<p>Project Ire&nbsp;emerged&nbsp;from a collaboration&nbsp;between&nbsp;Microsoft Research, Microsoft Defender Research, and Microsoft Discovery & Quantum, bringing together security&nbsp;expertise, operational knowledge, data from global malware telemetry, and AI research. It is built on the same collaborative and agentic foundation behind&nbsp;<a href="https://www.microsoft.com/en-us/research/project/graphrag/" target="_blank" rel="noreferrer noopener">GraphRAG<span class="sr-only"> (opens in new tab)</span></a>&nbsp;and&nbsp;<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://azure.microsoft.com/en-us/blog/transforming-rd-with-agentic-ai-introducing-microsoft-discovery/#:~:text=Get%20started%20today%20by%20using%20Azure%20HPC%20and%20Azure%20AI%20Foundry%20infrastructure.&text=Microsoft%20Discovery%20is%20built%20on,make%20any%20adjustments%20as%20needed." target="_blank" rel="noreferrer noopener">Microsoft Discovery<span class="sr-only"> (opens in new tab)</span></a>.&nbsp;The system&nbsp;uses advanced language models and a suite of callable reverse engineering and binary analysis tools to drive investigation and adjudication.</p>



<p>As of this writing, Project Ire has achieved a <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://en.wikipedia.org/wiki/Precision_and_recall" target="_blank" rel="noreferrer noopener">precision<span class="sr-only"> (opens in new tab)</span></a> of 0.98 and a <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://en.wikipedia.org/wiki/Precision_and_recall" target="_blank" rel="noreferrer noopener">recall<span class="sr-only"> (opens in new tab)</span></a> of 0.83 using public datasets of Windows drivers. It was the first reverse engineer at Microsoft, human or machine, to author a conviction case—a detection strong enough to justify automatic blocking—for a specific advanced persistent threat (APT) malware sample, which has since been identified and blocked by Microsoft Defender.&nbsp;</p>



<h2 class="wp-block-heading" id="malware-classification-at-a-global-scale">Malware classification at a global scale</h2>



<p>Microsoft’s Defender platform scans more than <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" target="_blank" href="https://news.microsoft.com/apac/2020/03/17/windows-10-powering-the-world-with-one-billion-monthly-active-devices/">one billion monthly<span class="sr-only"> (opens in new tab)</span></a> active devices through the company’s Defender suite of products, which routinely require manual review of software by experts.</p>



<p>This kind of work is challenging. Analysts often face error and alert fatigue, and there’s no easy way to compare and standardize how different people review and classify threats over time. For both of these reasons, today&#8217;s overloaded experts are vulnerable to <a href="https://www.microsoft.com/en-us/security/blog/2020/08/31/microsoft-security-cultivate-diverse-cybersecurity-team/" target="_blank" rel="noreferrer noopener">burnout</a>, a well-documented issue in the field.</p>



<p>Unlike other AI applications in security, malware classification lacks a computable <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.blackhat.com/us-25/briefings/schedule/#ai-agents-for-offsec-with-zero-false-positives-46559" target="_blank" rel="noreferrer noopener">validator<span class="sr-only"> (opens in new tab)</span></a>. The AI must make judgment calls without definitive validation beyond expert review. Many behaviors found in software, like reverse engineering protections, don’t clearly indicate whether a sample is malicious or benign.&nbsp;</p>



<p>This ambiguity requires analysts to investigate each sample incrementally, building enough evidence to determine whether it’s malicious or benign despite opposition from adaptive, active adversaries. This&nbsp;has long made it difficult to automate and scale what is inherently a complex and expensive process.</p>



<h2 class="wp-block-heading" id="technical-foundation">Technical foundation</h2>



<p>Project Ire attempts to address these challenges by acting as an autonomous system that uses specialized tools to reverse engineer software. The system’s architecture allows for reasoning at multiple levels, from low-level binary analysis to control flow reconstruction and high-level interpretation of code behavior.</p>



<p>Its tool-use API enables the system to update its understanding of a file using a wide range of reverse engineering tools, including Microsoft memory analysis sandboxes based on <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://aka.ms/freta/intro" target="_blank" rel="noreferrer noopener">Project Freta<span class="sr-only"> (opens in new tab)</span></a>, custom and open-source tools, documentation search, and multiple decompilers.&nbsp;&nbsp;</p>



<h2 class="wp-block-heading" id="reaching-a-verdict">Reaching a verdict&nbsp;</h2>



<p>The evaluation process begins with a triage, where automated reverse engineering tools identify the file type, its structure, and potential areas of interest. From there, the system reconstructs the software’s control flow graph using frameworks such as <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://angr.io/" target="_blank" rel="noreferrer noopener">angr<span class="sr-only"> (opens in new tab)</span></a> and <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/NationalSecurityAgency/ghidra" target="_blank" rel="noreferrer noopener">Ghidra<span class="sr-only"> (opens in new tab)</span></a>, building a graph that forms the backbone of Project Ire’s memory model and guides the rest of the analysis.&nbsp;&nbsp;</p>



<p>Through iterative function analysis, the LLM calls specialized tools through an API to identify and summarize key functions. Each result feeds into a “chain of evidence,” a detailed, auditable trail that shows how the system reached its conclusion. This traceable evidence log supports secondary review by security teams and helps refine the system in cases of misclassification.&nbsp;&nbsp;</p>



<p>To verify its findings, Project Ire can invoke a validator tool that cross-checks claims in the report against the chain of evidence. This tool draws on expert statements from malware reverse engineers on the Project Ire team. Drawing on this evidence and its internal model, the system creates a final report and classifies the sample as malicious or benign.</p>



	<div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="999693">
		

		<p class="msr-promo__label text-gray-800 text-center text-uppercase">
		<span class="px-4 bg-white display-inline-block font-weight-semibold small">Spotlight: Event Series</span>
	</p>
	
	<div class="row pt-3 pb-4 align-items-center">
						<div class="msr-promo__media col-12 col-md-5">
				<a class="bg-gray-300 display-block" href="https://www.microsoft.com/en-us/research/event/microsoft-research-forum/?OCID=msr_researchforum_MCR_Blog_Promo" aria-label="Microsoft Research Forum" data-bi-cN="Microsoft Research Forum" target="_blank">
					<img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/Research-Forum-hero_1400x788.jpg" alt="Research Forum | abstract background with colorful hexagons" />
				</a>
			</div>
			
			<div class="msr-promo__content p-3 px-5 col-12 col-md">

									<h2 class="h4">Microsoft Research Forum</h2>
				
								<p id="microsoft-research-forum" class="large">Join us for a continuous exchange of ideas about research in the era of general AI. Watch the first four episodes on demand.</p>
				
								<div class="wp-block-buttons justify-content-center justify-content-md-start">
					<div class="wp-block-button">
						<a href="https://www.microsoft.com/en-us/research/event/microsoft-research-forum/?OCID=msr_researchforum_MCR_Blog_Promo" aria-describedby="microsoft-research-forum" class="btn btn-brand glyph-append glyph-append-chevron-right" data-bi-cN="Microsoft Research Forum" target="_blank">
							Watch on-demand						</a>
					</div>
				</div>
							</div><!--/.msr-promo__content-->
	</div><!--/.msr-promo__inner-wrap-->
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span>	</div><!--/.msr-promo-->
	


<h2 class="wp-block-heading" id="preliminary-testing-shows-promise">Preliminary testing shows promise&nbsp;</h2>



<p>Two early evaluations tested Project Ire’s effectiveness as an autonomous malware classifier. In the first, we assessed Project Ire on a dataset of publicly accessible Windows drivers, some known to be malicious, others benign. Malicious samples came from the <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/magicsword-io/LOLDrivers/blob/e2e48f15a0885e8b2ad2fb81255089845f5c183c/detections/hashes/samples_malicious.sha256" target="_blank" rel="noreferrer noopener"><em>Living off the Land Drivers</em><span class="sr-only"> (opens in new tab)</span></a> database, which includes a collection of Windows drivers used by attackers to bypass security controls, while known benign drivers were sourced from Windows Update.&nbsp;</p>



<p>This classifier performed well, correctly identifying 90% of all files and flagging only 2% of benign files as threats. It achieved a precision of 0.98 and a recall of 0.83. This low false-positive rate suggests clear potential for deployment in security operations, alongside expert reverse engineering reviews.&nbsp;</p>



<p>For each file it analyzes, Project Ire generates a report that includes an evidence section, summaries of all examined code functions, and other technical artifacts.&nbsp;&nbsp;</p>



<p>Figures 1 and 2 present reports for two successful malware classification cases generated during testing. The first involves a kernel-level rootkit, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.virustotal.com/gui/file/86047bb1969d1db455493955fd450d18c62a3f36294d0a6c3732c88dfbcc4f62" target="_blank" rel="noreferrer noopener"><em>Trojan:Win64/Rootkit.EH!MTB</em><span class="sr-only"> (opens in new tab)</span></a>. The system identified several key features, including jump-hooking, process termination, and web-based command and control. It then correctly flagged the sample as malicious.</p>



<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Figure 1 Analysis</title>
  <style>
    body { font-family: Arial, sans-serif; background: #f8f8f8; }
    .code-block {
      background: #23272e;
      color: #e6e6e6;
      font-family: 'Fira Mono', 'Consolas', 'Monaco', monospace;
      font-size: 1em;
      padding: 24px 28px;
      border-radius: 10px;
      box-shadow: 0 2px 8px rgba(0,0,0,0.10);
      border: 1px solid #444;
      margin: 40px auto;
      max-width: 900px;
      line-height: 1.7;
      word-break: break-word;
    }
    .code-block p {
      margin: 0 0 18px 0;
      text-indent: 0;
    }
  </style>
</head>
<body>
  <div class="code-block">
    <p>The binary contains a function named &#8216;MonitorAndTerminateExplorerThread_16f64&#8217; that runs an infinite loop waiting on synchronization objects and terminates system threads upon certain conditions. It queries system or process information, iterates over processes comparing their names case-insensitively to &#8216;Explorer.exe&#8217;, and manipulates registry values related to &#8216;Explorer.exe&#8217;. This function appears to monitor and potentially terminate or manipulate the &#8216;Explorer.exe&#8217; process, a critical Windows shell process. Such behavior is suspicious and consistent with malware that aims to disrupt or control system processes.</p>
    <p>Another function, &#8216;HttpGetRequestAndResponse_174a4&#8217;, performs HTTP GET requests by parsing URLs, resolving hostnames, opening sockets, sending requests, and reading responses. This network communication capability could be leveraged for command and control or data exfiltration, common in malware.</p>
    <p>The binary also includes a function &#8216;PatchProcessEntryPointWithHook_12b5c&#8217; that patches the entry point of a process by writing a hook or trampoline that redirects execution to a specified address. This technique is commonly used for process injection or hooking, allowing malware to alter process behavior or inject malicious code.</p>
    <p>Other functions related to sending IOCTL requests to device drivers were identified, but their maliciousness could not be conclusively determined without additional context.</p>
    <p>Overall, the binary exhibits multiple indicators of malicious behavior, including process manipulation, network communication, and code injection techniques, suggesting it is likely malware designed to interfere with system processes and communicate with remote servers.</p>
  </div>
</body>
</html>
<figure class="wp-block-video aligncenter"><figcaption class="wp-element-caption">Figure 1. Project Ire report, sample with SHA256: <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.virustotal.com/gui/file/86047bb1969d1db455493955fd450d18c62a3f36294d0a6c3732c88dfbcc4f62" target="_blank" rel="noreferrer noopener">86047bb1969d1db455493955fd450d18c62a3f36294d0a6c3732c88dfbcc4f62<span class="sr-only"> (opens in new tab)</span></a></figcaption></figure>



<p>The second sample, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.virustotal.com/gui/file/b6cb163089f665c05d607a465f1b6272cdd5c949772ab9ce7227120cf61f971a" target="_blank" rel="noreferrer noopener"><em>HackTool:Win64/KillAV!MTB</em><span class="sr-only"> (opens in new tab)</span></a>, was designed to disable antivirus software. Project Ire correctly identified the code that locates and disables antivirus programs, providing evidence that the file was malicious.&nbsp;&nbsp;</p>



<p>In one section of the code, however, the system misidentified a function as anti-debugging behavior. To maintain accuracy, the system used the validator tool to flag the claim as unsupported. The issue was later resolved by updating decompiler rules, but this example illustrates how Project Ire navigates uncertainty during analysis. Figure 2 shows the corresponding report.&nbsp;</p>



<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Figure 2 Analysis</title>
  <style>
    body { font-family: Arial, sans-serif; background: #f8f8f8; }
    .code-block {
      background: #23272e;
      color: #e6e6e6;
      font-family: 'Fira Mono', 'Consolas', 'Monaco', monospace;
      font-size: 1em;
      padding: 24px 28px;
      border-radius: 10px;
      box-shadow: 0 2px 8px rgba(0,0,0,0.10);
      border: 1px solid #444;
      margin: 40px auto;
      max-width: 900px;
      line-height: 1.7;
      word-break: break-word;
    }
    .code-block p {
      margin: 0 0 18px 0;
      text-indent: 0;
    }
  </style>
</head>
<body>
  <div class="code-block">
    <p>The binary contains several functions indicative of malicious intent. The function register_and_log_known_processes_140001000 logs and registers process names associated with antivirus and security software, such as &#8216;avp.exe&#8217;, &#8216;avpui.exe&#8217;, and &#8216;360Tray.exe&#8217;. It calls another function, TerminateProcessesByNameSubstring_1400010f4, which enumerates system processes and terminates those whose names contain specified substrings. This behavior is typical of malware attempting to disable or evade security software by killing their processes.</p>
    <p>Another function, check_and_handle_special_state_14000502c, performs checks on a global variable and triggers software interrupts if certain conditions are not met. While the exact purpose of these interrupts (int 0x29 and int 0x3) is unclear, they could represent an anti-debug or anti-analysis mechanism to detect or interfere with debugging or tampering attempts. However, this assumption could not be fully validated against expert statements.</p>
    <p>Other functions include initialization routines and simple logging wrappers, but the core malicious behavior centers on process termination targeting security software. This indicates the binary is designed to compromise system security by disabling protective processes, a hallmark of malware such as trojans or rootkits.</p>
  </div>
</body>
</html>
<figure class="wp-block-video aligncenter"><figcaption class="wp-element-caption">Figure 2. Project Ire report, sample with SHA256: <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.virustotal.com/gui/file/b6cb163089f665c05d607a465f1b6272cdd5c949772ab9ce7227120cf61f971a" target="_blank" rel="noreferrer noopener">b6cb163089f665c05d607a465f1b6272cdd5c949772ab9ce7227120cf61f971a<span class="sr-only"> (opens in new tab)</span></a></figcaption></figure>



<h2 class="wp-block-heading" id="real-world-evaluation-with-microsoft-defender">Real-world evaluation with Microsoft Defender&nbsp;</h2>



<p>The more demanding test involved nearly 4,000 “hard-target” files not classified by automated systems and slated for manual review by expert reverse engineers.</p>



<p>In this real-world scenario, Project Ire operated fully autonomously on files created after the language models’ training cutoff, files that no other automated tools at Microsoft could classify at the time.</p>



<p>The system achieved a high precision score of 0.89, meaning nearly 9 out of 10 files flagged malicious were correctly identified as malicious. Recall was 0.26, indicating that under these challenging conditions, the system detected roughly a quarter of all actual malware.</p>



<p>The system correctly identified many of the malicious files, with few false alarms, just a 4% false positive rate. While overall performance was moderate, this combination of accuracy and a low error rate suggests real potential for future deployment.</p>



<h2 class="wp-block-heading" id="looking-ahead">Looking ahead&nbsp;</h2>



<p>Based on these early successes, the Project Ire prototype will be leveraged inside Microsoft’s Defender organization as <em>Binary Analyzer</em> for threat detection and software classification.</p>



<p>Our goal is to scale the system’s speed and accuracy so that it can correctly classify files from any source, even on first encounter. Ultimately, our vision is to detect novel malware directly <a href="https://www.microsoft.com/en-us/research/blog/toward-trusted-sensing-for-the-cloud-introducing-project-freta/?lang=fr_ca">in memory,</a> at scale.</p>



<h2 class="wp-block-heading" id="acknowledgements">Acknowledgements&nbsp;</h2>



<p>Project Ire acknowledges the following additional developers that contributed to the results in this publication: Dayenne de Souza, Raghav Pande, Ryan Terry, Shauharda Khadka, and Bob Fleck for their independent review of the system.</p>



<p>The system incorporates multiple tools, including the&nbsp;angr&nbsp;framework developed by&nbsp;<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://emotionlabs.io/" target="_blank" rel="noreferrer noopener">Emotion Labs<span class="sr-only"> (opens in new tab)</span></a>. Microsoft has collaborated extensively with Emotion Labs, a pioneer in cyber autonomy, throughout the development of Project Ire, and thanks them for the innovations and insights that contributed to the successes reported here.&nbsp;</p>
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/blog/project-ire-autonomously-identifies-malware-at-scale/">Project Ire autonomously identifies malware at scale</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>VeriTrail: Detecting hallucination and tracing provenance in multi-step AI workflows</title>
		<link>https://www.microsoft.com/en-us/research/blog/veritrail-detecting-hallucination-and-tracing-provenance-in-multi-step-ai-workflows/</link>
		
		<dc:creator><![CDATA[Dasha Metropolitansky]]></dc:creator>
		<pubDate>Tue, 05 Aug 2025 16:00:00 +0000</pubDate>
				<category><![CDATA[Research Blog]]></category>
		<guid isPermaLink="false">https://www.microsoft.com/en-us/research/?p=1145803</guid>

					<description><![CDATA[<p>VeriTrail, new from Microsoft Research, can detect AI-generated content that is not supported by the source text, trace the provenance of content from final output back to the source, and locate where errors were likely introduced.</p>
<p>The post <a href="https://www.microsoft.com/en-us/research/blog/veritrail-detecting-hallucination-and-tracing-provenance-in-multi-step-ai-workflows/">VeriTrail: Detecting hallucination and tracing provenance in multi-step AI workflows</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/VeriTrail-BlogHeroFeature-1400x788-1.jpg" alt="Alt text: Two white icons on a blue-to-green gradient background—one showing a central figure linked to others, representing a network, and the other depicting lines connecting to a document, symbolizing data flow." class="wp-image-1145818" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/VeriTrail-BlogHeroFeature-1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/VeriTrail-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/VeriTrail-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/VeriTrail-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/VeriTrail-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/VeriTrail-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/VeriTrail-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/VeriTrail-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/VeriTrail-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/VeriTrail-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w" sizes="auto, (max-width: 1400px) 100vw, 1400px" /></figure>



<div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-16018d1d wp-block-buttons-is-layout-flex">
<div class="wp-block-button"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/video/veritrail-detect-hallucination-and-trace-provenance-in-ai-workflows/">Watch VeriTrail Explainer</a></div>
</div>



<p>Many applications of language models (LMs) involve generating content based on source material, such as answering questions, summarizing information, and drafting documents. A critical challenge for these applications is that LMs may produce content that is not supported by the source text – a phenomenon known as “closed-domain hallucination.”<a id="_ftnref1" href="#_ftn1"><sup>1</sup></a></p>



<p>Existing methods for detecting closed-domain hallucination typically compare a given LM output to the source text, implicitly assuming that there is only a single output to evaluate. However, applications of LMs increasingly involve processes with multiple generative steps: LMs generate intermediate outputs that serve as inputs to subsequent steps and culminate in a final output. Many agentic workflows follow this paradigm (e.g., each agent is responsible for a specific document or sub-task, and their outputs are synthesized into a final response). &nbsp;</p>



<p>In our paper “<a href="https://www.microsoft.com/en-us/research/publication/veritrail-closed-domain-hallucination-detection-with-traceability/" target="_blank" rel="noreferrer noopener">VeriTrail: Closed-Domain Hallucination Detection with Traceability</a>,” we argue that, given the complexity of processes with multiple generative steps, detecting hallucination in the final output is necessary but not sufficient. We also need <strong>traceability</strong>, which has two components:&nbsp;</p>



<ol start="1" class="wp-block-list">
<li><strong>Provenance: </strong>if the final output is supported by the source text, we should be able to trace its path through the intermediate outputs to the source.&nbsp;</li>



<li><strong>Error Localization: </strong>if the final output is not supported by the source text, we should be able to trace where the error was likely introduced.</li>
</ol>



<p>Our paper presents VeriTrail, the first closed-domain hallucination detection method designed to provide traceability for processes with any number of generative steps. We also demonstrate that VeriTrail outperforms baseline methods commonly used for hallucination detection. In this blog post, we provide an overview of VeriTrail’s design and performance.<a id="_ftnref2" href="#_ftn2"><sup>2</sup></a></p>



<h2 class="wp-block-heading" id="veritrail-s-hallucination-detection-process">VeriTrail’s hallucination detection process</h2>



<p>A key idea leveraged by VeriTrail is that a wide range of generative processes can be represented as a <strong>directed acyclic graph (DAG)</strong>. Each <strong>node </strong>in the DAG represents a piece of text (i.e., source material, an intermediate output, or the final output) and each <strong>edge </strong>from node A to node B indicates that A was used as an input to produce B. Each node is assigned a unique ID, as well as a <strong>stage</strong> reflecting its position in the generative process. &nbsp;</p>



<p>An example of a process with multiple generative steps is <a href="https://www.microsoft.com/en-us/research/project/graphrag/" target="_blank" rel="noreferrer noopener">GraphRAG</a>. A DAG representing a GraphRAG run is illustrated in Figure 1, where the boxes and arrows correspond to nodes and edges, respectively.<a id="_ftnref3" href="#_ftn3"><sup>3</sup></a></p>



<figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="881" height="542" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/VeriTrail-blog-figure-1.jpg" alt="A GraphRAG run is depicted as a directed acyclic graph. The Stage 1 nodes represent source text chunks. Each Stage 1 node has an edge pointing to a Stage 2 node, which corresponds to an entity or a relationship. Entity 3 was extracted from two source text chunks, so its descriptions are summarized. The summarized entity description forms a Stage 3 node. The Stage 2 and 3 nodes have edges pointing to Stage 4 nodes, which represent community reports. The Stage 4 nodes have edges pointing to Stage 5 nodes, which correspond to map-level answers. The Stage 5 nodes each have an edge pointing to the terminal node, which represents the final answer. The terminal node is the only node in Stage 6." class="wp-image-1145841" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/VeriTrail-blog-figure-1.jpg 881w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/VeriTrail-blog-figure-1-300x185.jpg 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/VeriTrail-blog-figure-1-768x472.jpg 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/VeriTrail-blog-figure-1-240x148.jpg 240w" sizes="auto, (max-width: 881px) 100vw, 881px" /><figcaption class="wp-element-caption">Figure 1: GraphRAG splits the source text into chunks (Stage 1). For each chunk, an LM extracts entities and relationships (the latter are denoted by “⭤ “), along with short descriptions (Stage 2). If an entity or a relationship was extracted from multiple chunks, an LM summarizes the descriptions (Stage 3). A knowledge graph is constructed from the final set of entities and relationships, and a community detection algorithm, such as Leiden clustering, groups entities into communities. For each community, an LM generates a “community report” that summarizes the entities and relationships (Stage 4). To answer a user’s question, an LM generates “map-level answers” based on groups of community reports (Stage 5), then synthesizes them into a final answer (Stage 6).</figcaption></figure>



<p>VeriTrail takes as input a DAG representing a completed generative process and aims to determine whether the final output is fully supported by the source text. It begins by extracting claims (i.e., self-contained, verifiable statements) from the final output using <a href="https://www.microsoft.com/en-us/research/blog/claimify-extracting-high-quality-claims-from-language-model-outputs/" target="_blank" rel="noreferrer noopener">Claimify</a>. VeriTrail verifies claims in the reverse order of the generative process: it starts from the final output and moves toward the source text. Each claim is verified separately. Below, we include two case studies that illustrate how VeriTrail works, using the DAG from Figure 1. </p>



<h3 class="wp-block-heading" id="case-study-1-a-fully-supported-claim">Case study 1: A “Fully Supported” claim</h3>



<figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1280" height="720" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/VeriTrail-blog-figure-2.jpg" alt="An example of VeriTrail's claim verification process where the claim is found “Fully Supported.” A claim extracted from the terminal node, Node 17, is “Legislative efforts have been made to address the high cost of diabetes-related supplies in the US.” In Iteration 1, VeriTrail checks Nodes 15 and 16, which are the source nodes of the terminal node. The sentence “The general assembly in North Carolina is considering legislation to set a cap on insulin prices, which indicates that high insulin prices are a contributing factor to the high cost of diabetes-related supplies in the US” is selected as evidence from Node 15. The tentative verdict is “Fully Supported.” In Iteration 2, VeriTrail checks Nodes 12 and 13, which are the source nodes of Node 15. The sentence “The General Assembly in North Carolina is considering legislation to set a cap on insulin prices” is selected as evidence from Node 13. The verdict remains “Fully Supported.” In Iteration 3, VeriTrail checks Nodes 4, 5, and 11, which are the source nodes of Node 13. The sentence “The General Assembly is the legislative body in North Carolina considering legislation to cap insulin prices” is selected as evidence from Node 4. The verdict is still “Fully Supported.” In Iteration 4, VeriTrail checks Node 1, which is the source node of Node 4. The selected evidence is “‘There’s actually legislation in North Carolina at the General Assembly to set a cap on insulin…’ Stein said.” The corresponding verdict is “Fully Supported.” Since Node 1 represents a raw text chunk, it does not have any source nodes to check. Therefore, verification terminates and the “Fully Supported” verdict is deemed final." class="wp-image-1145843" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/VeriTrail-blog-figure-2.jpg 1280w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/VeriTrail-blog-figure-2-300x169.jpg 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/VeriTrail-blog-figure-2-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/VeriTrail-blog-figure-2-768x432.jpg 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/VeriTrail-blog-figure-2-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/VeriTrail-blog-figure-2-655x368.jpg 655w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/VeriTrail-blog-figure-2-240x135.jpg 240w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/VeriTrail-blog-figure-2-640x360.jpg 640w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/VeriTrail-blog-figure-2-960x540.jpg 960w" sizes="auto, (max-width: 1280px) 100vw, 1280px" /><figcaption class="wp-element-caption">Figure 2: Left: GraphRAG as a DAG. Right: VeriTrail’s hallucination detection process for a “Fully Supported” claim.</figcaption></figure>



<p>Figure 2 shows an example of a claim that VeriTrail determined was not hallucinated: </p>



<ul class="wp-block-list">
<li>In Iteration 1, VeriTrail identified the nodes that were used as inputs for the final answer: Nodes 15 and 16. Each identified node was split into sentences, and each sentence was programmatically assigned a unique ID.
<ul class="wp-block-list">
<li>An LM then performed <strong>Evidence Selection</strong>, selecting all sentence IDs that strongly implied the truth or falsehood of the claim. The LM also generated a summary of the selected sentences (not shown in Figure 2). In this example, a sentence was selected from Node 15.</li>



<li>Next, an LM performed <strong>Verdict Generation</strong>. If no sentences had been selected in the Evidence Selection step, the claim would have been assigned a “Not Fully Supported” verdict. Instead, an LM was prompted to classify the claim as “Fully Supported,” “Not Fully Supported,” or “Inconclusive” based on the evidence. In this case, the verdict was “Fully Supported.”</li>
</ul>
</li>



<li>Since the verdict in Iteration 1 was “Fully Supported,” VeriTrail proceeded to Iteration 2. It considered the nodes from which at least one sentence was selected in the latest Evidence Selection step (Node 15) and identified their input nodes (Nodes 12 and 13). VeriTrail repeated Evidence Selection and Verdict Generation for the identified nodes. Once again, the verdict was “Fully Supported.” This process – identifying candidate nodes, performing Evidence Selection and Verdict Generation – was repeated in Iteration 3, where the verdict was still “Fully Supported,” and likewise in Iteration 4. </li>



<li>In Iteration 4, a single source text chunk was verified. Since the source text, by definition, does not have any inputs, verification terminated and the verdict was deemed final.</li>
</ul>



<h3 class="wp-block-heading" id="case-study-2-a-not-fully-supported-claim">Case study 2: A “Not Fully Supported” claim</h3>



<figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1280" height="515" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/VerTrail-blog-figure-3.jpg" alt="An example of VeriTrail's claim verification process where the claim is found “Not Fully Supported.” We assume that the maximum number of consecutive “Not Fully Supported” verdicts was set to 2. A claim extracted from the terminal node, Node 17, is “Challenges related to electric vehicle battery repairability contribute to sluggish retail auto sales in China.” In Iteration 1, VeriTrail checks Nodes 15 and 16, which are the source nodes of the terminal node. Two sentences are selected as evidence. The first sentence is “Challenges with electric vehicle (EV) battery disposal and repair may also contribute to the sluggishness in retail auto sales.” The second sentence is “Junkyards are accumulating discarded EV battery packs, while collision shops face limitations in repairing EV battery packs, which could affect consumer confidence and demand.” These sentences are both from Node 15. The tentative verdict is “Not Fully Supported.” In Iteration 2, VeriTrail checks Nodes 12, 13, and 14. Nodes 12 and 13 are the source nodes of Node 15. Node 14 is the source node of Node 16, which was checked in Iteration 1. The sentence “The electric vehicle market in China is influenced by challenges associated with EV battery disposal and repair” is selected as evidence from Node 12. The verdict remains “Not Fully Supported.” Since two consecutive “Not Fully Supported” verdicts have been reached, which was the maximum, verification terminates and the final verdict is “Not Fully Supported.”" class="wp-image-1145842" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/VerTrail-blog-figure-3.jpg 1280w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/VerTrail-blog-figure-3-300x121.jpg 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/VerTrail-blog-figure-3-1024x412.jpg 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/VerTrail-blog-figure-3-768x309.jpg 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/VerTrail-blog-figure-3-240x97.jpg 240w" sizes="auto, (max-width: 1280px) 100vw, 1280px" /><figcaption class="wp-element-caption">Figure 3: Left: GraphRAG as a DAG. Right: VeriTrail’s hallucination detection process for a “Not Fully Supported” claim, where the maximum number of consecutive “Not Fully Supported” verdicts was set to 2. </figcaption></figure>



<p>Figure 3 provides an example of a claim where VeriTrail identified hallucination:</p>



<ul class="wp-block-list">
<li>In Iteration 1, VeriTrail identified the nodes used as inputs for the final answer: Nodes 15 and 16. After Evidence Selection and Verdict Generation, the verdict was “Not Fully Supported.” Users can configure the maximum number of consecutive “Not Fully Supported” verdicts permitted. If the maximum had been set to 1, verification would have terminated here, and the verdict would have been deemed final. Let’s assume the maximum was set to 2, meaning that VeriTrail had to perform at least one more iteration.</li>



<li>Even though evidence was selected only from Node 15 in Iteration 1, VeriTrail checked the input nodes for both Node 15 and Node 16 (i.e., Nodes 12, 13, and 14) in Iteration 2. Recall that in Case Study 1 where the verdict was “Fully Supported,” VeriTrail only checked the input nodes for Node 15. Why was the “Not Fully Supported” claim handled differently? If the Evidence Selection step overlooked relevant evidence, the “Not Fully Supported” verdict might be incorrect. In this case, continuing verification based solely on the selected evidence (i.e., Node 15) would propagate the mistake, defeating the purpose of repeated verification.</li>



<li>In Iteration 2, Evidence Selection and Verdict Generation were repeated for Nodes 12, 13, and 14. Once again, the verdict was “Not Fully Supported.” Since this was the second consecutive “Not Fully Supported” verdict, verification terminated and the verdict was deemed final.</li>
</ul>



	<div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="670821">
		

		<p class="msr-promo__label text-gray-800 text-center text-uppercase">
		<span class="px-4 bg-white display-inline-block font-weight-semibold small">Spotlight: Microsoft research newsletter</span>
	</p>
	
	<div class="row pt-3 pb-4 align-items-center">
						<div class="msr-promo__media col-12 col-md-5">
				<a class="bg-gray-300 display-block" href="https://info.microsoft.com/ww-landing-microsoft-research-newsletter.html" aria-label="Microsoft Research Newsletter" data-bi-cN="Microsoft Research Newsletter" target="_blank">
					<img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2019/09/Newsletter_Banner_08_2019_v1_1920x1080.png" alt="" />
				</a>
			</div>
			
			<div class="msr-promo__content p-3 px-5 col-12 col-md">

									<h2 class="h4">Microsoft Research Newsletter</h2>
				
								<p id="microsoft-research-newsletter" class="large">Stay connected to the research community at Microsoft.</p>
				
								<div class="wp-block-buttons justify-content-center justify-content-md-start">
					<div class="wp-block-button is-style-fill-chevron">
						<a href="https://info.microsoft.com/ww-landing-microsoft-research-newsletter.html" aria-describedby="microsoft-research-newsletter" class="btn btn-brand glyph-append glyph-append-chevron-right" data-bi-cN="Microsoft Research Newsletter" target="_blank">
							Subscribe today						</a>
					</div>
				</div>
							</div><!--/.msr-promo__content-->
	</div><!--/.msr-promo__inner-wrap-->
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span>	</div><!--/.msr-promo-->
	


<h2 class="wp-block-heading" id="providing-traceability">Providing traceability</h2>



<p>In addition to assigning a final “Fully Supported,” “Not Fully Supported,” or “Inconclusive” verdict to each claim, VeriTrail returns (a) all Verdict Generation results and (b) an evidence trail composed of all Evidence Selection results: the selected sentences, their corresponding node IDs, and the generated summaries. Collectively, these outputs provide traceability:&nbsp;</p>



<ol start="1" class="wp-block-list">
<li><strong>Provenance: </strong>For “Fully Supported” and “Inconclusive” claims, the evidence trail traces a path from the source material to the final output, helping users understand how the output may have been derived. For example, in Case Study 1, the evidence trail consists of Sentence 8 from Node 15, Sentence 11 from Node 13, Sentence 26 from Node 4, and Sentence 79 from Node 1.</li>



<li><strong>Error Localization: </strong>For “Not Fully Supported” claims, VeriTrail uses the Verdict Generation results to identify the stage(s) of the process where the unsupported content was likely introduced. For instance, in Case Study 2, where none of the verified intermediate outputs supported the claim, VeriTrail would indicate that the hallucination occurred in the final answer (Stage 6). Error stage identification helps users address hallucinations and understand where in the process they are most likely to occur.&nbsp;</li>
</ol>



<p>The evidence trail also helps users verify the verdict: instead of reading through all nodes – which may be infeasible for processes that generate large amounts of text – users can simply review the evidence sentences and summaries. </p>



<h2 class="wp-block-heading" id="key-design-features">Key design features</h2>



<p>VeriTrail’s design prioritizes reliability, efficiency, scalability, and user agency. Notable features include: </p>



<ul class="wp-block-list">
<li>During Evidence Selection (introduced in Case Study 1), the sentence IDs returned by the LM are checked against the programmatically assigned IDs. If a returned ID does not match an assigned ID, it is discarded; otherwise, it is mapped to its corresponding sentence. This approach <strong>guarantees that the sentences included in the evidence trail are not hallucinated</strong>.</li>



<li>After a claim is assigned an interim “Fully Supported” or “Inconclusive” verdict (as in Case Study 1), VeriTrail verifies the input nodes of only the nodes from which evidence was previously selected – not all possible input nodes. By progressively narrowing the search space, VeriTrail limits the number of nodes the LM must evaluate. In particular, since VeriTrail starts from the final output and moves toward the source text, it tends to verify a smaller proportion of nodes as it approaches the source text. Nodes closer to the source text tend to be larger (e.g., a book chapter should be larger than its summary), so verifying fewer of them helps <strong>reduce computational cost</strong>.</li>



<li>VeriTrail is designed to <strong>handle input graphs with any number of nodes</strong>, regardless of whether they fit in a single prompt. Users can specify an input size limit per prompt. For Evidence Selection, inputs that exceed the limit are split across multiple prompts. If the resulting evidence exceeds the input size limit for Verdict Generation, VeriTrail reruns Evidence Selection to compress the evidence further. Users can configure the maximum number of Evidence Selection reruns.  </li>



<li>The configurable maximum number of consecutive “Not Fully Supported” verdicts (introduced in Case Study 2) allows the user to find their desired <strong>balance between computational cost and how conservative VeriTrail is in flagging hallucinations</strong>. A lower maximum reduces cost by limiting the number of checks. A higher maximum increases confidence that a flagged claim is truly hallucinated since it requires repeated confirmation of the “Not Fully Supported” verdict. </li>
</ul>



<h2 class="wp-block-heading" id="evaluating-veritrail-s-performance">Evaluating VeriTrail’s performance</h2>



<p>We tested VeriTrail on two datasets covering distinct generative processes (hierarchical summarization<a id="_ftnref4" href="#_ftn4"><sup>4</sup></a> and GraphRAG), tasks (summarization and question-answering), and types of source material (fiction novels and news articles). For the source material, we focused on long documents and large collections of documents (i.e., >100K tokens), where hallucination detection is especially challenging and processes with multiple generative steps are typically most valuable. The resulting DAGs were much more complex than the examples provided above (e.g., in one of the datasets, the average number of nodes was 114,368).</p>



<p>We compared VeriTrail to three types of baseline methods commonly used for closed-domain hallucination detection: Natural Language Inference models (<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://aclanthology.org/2023.acl-long.634/" target="_blank" rel="noreferrer noopener">AlignScore</a> and <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://aclanthology.org/2024.eacl-long.102/" target="_blank" rel="noreferrer noopener">INFUSE</a>); Retrieval-Augmented Generation; and long-context models (Gemini 1.5 Pro and GPT-4.1 mini). Across both datasets and all language models tested, VeriTrail outperformed the baseline methods in detecting hallucination.<a id="_ftnref5" href="#_ftn5"><sup>5</sup></a></p>



<p>Most importantly, VeriTrail traces claims through intermediate outputs – unlike the baseline methods, which directly compare the final output to the source material. As a result, it can identify where hallucinated content was likely introduced and how faithful content may have been derived from the source. By providing traceability, VeriTrail brings transparency to generative processes, helping users understand, verify, debug, and, ultimately, trust their outputs. &nbsp;</p>



<p>For an in-depth discussion of VeriTrail, please see our paper “<a href="https://www.microsoft.com/en-us/research/publication/veritrail-closed-domain-hallucination-detection-with-traceability/" target="_blank" rel="noreferrer noopener">VeriTrail: Closed-Domain Hallucination Detection with Traceability.</a>”</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p><a id="_ftn1" href="#_ftnref1"><sup>1</sup><span class="sr-only"> (opens in new tab)</span></a> The term “closed-domain hallucination” was introduced by OpenAI in the <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://arxiv.org/abs/2303.08774" target="_blank" rel="noreferrer noopener">GPT-4 Technical Report<span class="sr-only"> (opens in new tab)</span></a>.</p>



<p><sup><a id="_ftn2" href="#_ftnref2">2</a></sup> VeriTrail is currently used for research purposes only and is not available commercially.</p>



<p><sup><a id="_ftn3" href="#_ftnref3">3</a></sup> We focus on GraphRAG’s global search method.</p>



<p><sup><a id="_ftn4" href="#_ftnref4">4<span class="sr-only"> (opens in new tab)</span></a></sup> In hierarchical summarization, an LM summarizes each source text chunk individually, then the resulting summaries are repeatedly grouped and summarized until a final summary is produced (<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://arxiv.org/abs/2109.10862" target="_blank" rel="noreferrer noopener">Wu et al., 2021<span class="sr-only"> (opens in new tab)</span></a>; <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://arxiv.org/abs/2310.00785" target="_blank" rel="noreferrer noopener">Chang et al., 2023<span class="sr-only"> (opens in new tab)</span></a>).</p>



<p><sup><a id="_ftn5" href="#_ftnref5">5</a></sup> The only exception was the mistral-large-2411 model, where VeriTrail had the highest balanced accuracy, but not the highest macro F1 score.</p>
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/blog/veritrail-detecting-hallucination-and-tracing-provenance-in-multi-step-ai-workflows/">VeriTrail: Detecting hallucination and tracing provenance in multi-step AI workflows</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Navigating medical education in the era of generative AI</title>
		<link>https://www.microsoft.com/en-us/research/podcast/navigating-medical-education-in-the-era-of-generative-ai/</link>
		
		<dc:creator><![CDATA[Peter Lee, Dr. Morgan Cheatham, Daniel Chen]]></dc:creator>
		<pubDate>Thu, 24 Jul 2025 20:06:32 +0000</pubDate>
				<category><![CDATA[Microsoft Research Podcast]]></category>
		<guid isPermaLink="false">https://www.microsoft.com/en-us/research/?p=1145558</guid>

					<description><![CDATA[<p>Next-generation physicians Morgan Cheatham and Daniel Chen discuss how generative AI is transforming medical education, exploring how students and attending physicians integrate new tools while navigating questions on trust, training, and responsibility.</p>
<p>The post <a href="https://www.microsoft.com/en-us/research/podcast/navigating-medical-education-in-the-era-of-generative-ai/">Navigating medical education in the era of generative AI</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Episode9-PeterMorganDaniel-AIRevolution_Hero_Feature_No_Text_1400x788.jpg" alt="AI Revolution | Illustrated headshots of Daniel Chen, Peter Lee, and Dr. Morgan Cheatham" class="wp-image-1145642" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Episode9-PeterMorganDaniel-AIRevolution_Hero_Feature_No_Text_1400x788.jpg 1400w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Episode9-PeterMorganDaniel-AIRevolution_Hero_Feature_No_Text_1400x788-300x169.jpg 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Episode9-PeterMorganDaniel-AIRevolution_Hero_Feature_No_Text_1400x788-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Episode9-PeterMorganDaniel-AIRevolution_Hero_Feature_No_Text_1400x788-768x432.jpg 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Episode9-PeterMorganDaniel-AIRevolution_Hero_Feature_No_Text_1400x788-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Episode9-PeterMorganDaniel-AIRevolution_Hero_Feature_No_Text_1400x788-655x368.jpg 655w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Episode9-PeterMorganDaniel-AIRevolution_Hero_Feature_No_Text_1400x788-240x135.jpg 240w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Episode9-PeterMorganDaniel-AIRevolution_Hero_Feature_No_Text_1400x788-640x360.jpg 640w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Episode9-PeterMorganDaniel-AIRevolution_Hero_Feature_No_Text_1400x788-960x540.jpg 960w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Episode9-PeterMorganDaniel-AIRevolution_Hero_Feature_No_Text_1400x788-1280x720.jpg 1280w" sizes="auto, (max-width: 1400px) 100vw, 1400px" /></figure>


<div class="wp-block-msr-podcast-container my-4">
	<iframe loading="lazy" src="https://player.blubrry.com/?podcast_id=147270100&modern=1" class="podcast-player" frameborder="0" height="164px" width="100%" scrolling="no" title="Podcast Player"></iframe>
</div>



<p>In November 2022, OpenAI’s ChatGPT kick-started a new era in AI. This was followed less than a half year later by the release of GPT-4. In the months leading up to GPT-4’s public release, Peter Lee, president of Microsoft Research, cowrote a book full of optimism for the potential of advanced AI models to transform the world of healthcare. What has happened since? In this special podcast series, <em>The AI Revolution in Medicine, Revisited</em>, Lee revisits the book, exploring how patients, providers, and other medical professionals are experiencing and using generative AI today while examining what he and his coauthors got right—and what they didn’t foresee.&nbsp;&nbsp;&nbsp;</p>



<p>In this episode, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.linkedin.com/in/morgancheatham/" target="_blank" rel="noreferrer noopener">Dr. Morgan Cheatham<span class="sr-only"> (opens in new tab)</span></a> and <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.linkedin.com/in/dxchen99/" target="_blank" rel="noreferrer noopener">Daniel Chen<span class="sr-only"> (opens in new tab)</span></a>, two rising physicians and experts in both medicine and technology, join Lee to explore how generative AI is reshaping medical education. Cheatham, a partner and head of healthcare and life sciences at Breyer Capital and a resident physician at Boston Children’s Hospital, discusses how AI is changing how clinicians acquire and apply medical knowledge at the point of care, emphasizing the need for training and curriculum changes to help ensure AI is used responsibly and that clinicians are equipped to maximize its potential. Chen, a medical student at the Kaiser Permanente Bernard J. Tyson School of Medicine, shares how he and his peers use AI tools as study aids, clinical tutors, and second opinions and reflects on the risks of overreliance and the importance of preserving critical thinking.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading h5" id="learn-more">Learn more:</h2>



<p><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://pubmed.ncbi.nlm.nih.gov/40375359/" target="_blank" rel="noreferrer noopener">Perspectives on the Current and Future State of Artificial Intelligence in Medical Genetics<span class="sr-only"> (opens in new tab)</span></a>&nbsp;(Cheatham)<br>Publication | May 2025</p>



<p><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://journals.plos.org/digitalhealth/article?id=10.1371/journal.pdig.0000198" target="_blank" rel="noreferrer noopener">Performance of ChatGPT on USMLE: Potential for AI-assisted medical education using large language models<span class="sr-only"> (opens in new tab)</span></a> (Cheatham)&nbsp;<br>Publication | February 2023&nbsp;</p>



<p><a href="https://www.microsoft.com/en-us/research/publication/the-ai-revolution-in-medicine-gpt-4-and-beyond/" target="_blank" rel="noreferrer noopener">The AI Revolution in Medicine: GPT-4 and Beyond</a>&nbsp;<br>Book | Peter Lee, Carey Goldberg, Isaac Kohane | April 2023&nbsp;</p>



<div style="height:25px" aria-hidden="true" class="wp-block-spacer"></div>



<section class="wp-block-msr-subscribe-to-podcast subscribe-to-podcast">
	<div class="subscribe-to-podcast__inner border-top border-bottom border-width-2">
		<h2 class="h5 subscribe-to-podcast__heading">
			Subscribe to the <a href="https://www.microsoft.com/en-us/research/podcast">Microsoft Research Podcast</a>:		</h2>
		<ul class="subscribe-to-podcast__list list-unstyled">
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://itunes.apple.com/us/podcast/microsoft-research-a-podcast/id1318021537?mt=2" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="black" viewBox="0 0 32 32">  <path d="M7.12 0c-3.937-0.011-7.131 3.183-7.12 7.12v17.76c-0.011 3.937 3.183 7.131 7.12 7.12h17.76c3.937 0.011 7.131-3.183 7.12-7.12v-17.76c0.011-3.937-3.183-7.131-7.12-7.12zM15.817 3.421c3.115 0 5.932 1.204 8.079 3.453 1.631 1.693 2.547 3.489 3.016 5.855 0.161 0.787 0.161 2.932 0.009 3.817-0.5 2.817-2.041 5.339-4.317 7.063-0.812 0.615-2.797 1.683-3.115 1.683-0.12 0-0.129-0.12-0.077-0.615 0.099-0.792 0.192-0.953 0.64-1.141 0.713-0.296 1.932-1.167 2.677-1.911 1.301-1.303 2.229-2.932 2.677-4.719 0.281-1.1 0.244-3.543-0.063-4.672-0.969-3.595-3.907-6.385-7.5-7.136-1.041-0.213-2.943-0.213-4 0-3.636 0.751-6.647 3.683-7.563 7.371-0.245 1.004-0.245 3.448 0 4.448 0.609 2.443 2.188 4.681 4.255 6.015 0.407 0.271 0.896 0.547 1.1 0.631 0.447 0.192 0.547 0.355 0.629 1.14 0.052 0.485 0.041 0.62-0.072 0.62-0.073 0-0.62-0.235-1.199-0.511l-0.052-0.041c-3.297-1.62-5.407-4.364-6.177-8.016-0.187-0.943-0.224-3.187-0.036-4.052 0.479-2.323 1.396-4.135 2.921-5.739 2.199-2.319 5.027-3.543 8.172-3.543zM16 7.172c0.541 0.005 1.068 0.052 1.473 0.14 3.715 0.828 6.344 4.543 5.833 8.229-0.203 1.489-0.713 2.709-1.619 3.844-0.448 0.573-1.537 1.532-1.729 1.532-0.032 0-0.063-0.365-0.063-0.803v-0.808l0.552-0.661c2.093-2.505 1.943-6.005-0.339-8.296-0.885-0.896-1.912-1.423-3.235-1.661-0.853-0.161-1.031-0.161-1.927-0.011-1.364 0.219-2.417 0.744-3.355 1.672-2.291 2.271-2.443 5.791-0.348 8.296l0.552 0.661v0.813c0 0.448-0.037 0.807-0.084 0.807-0.036 0-0.349-0.213-0.683-0.479l-0.047-0.016c-1.109-0.885-2.088-2.453-2.495-3.995-0.244-0.932-0.244-2.697 0.011-3.625 0.672-2.505 2.521-4.448 5.079-5.359 0.547-0.193 1.509-0.297 2.416-0.281zM15.823 11.156c0.417 0 0.828 0.084 1.131 0.24 0.645 0.339 1.183 0.989 1.385 1.677 0.62 2.104-1.609 3.948-3.631 3.005h-0.015c-0.953-0.443-1.464-1.276-1.475-2.36 0-0.979 0.541-1.828 1.484-2.328 0.297-0.156 0.709-0.235 1.125-0.235zM15.812 17.464c1.319-0.005 2.271 0.463 2.625 1.291 0.265 0.62 0.167 2.573-0.292 5.735-0.307 2.208-0.479 2.765-0.905 3.141-0.589 0.52-1.417 0.667-2.209 0.385h-0.004c-0.953-0.344-1.157-0.808-1.553-3.527-0.452-3.161-0.552-5.115-0.285-5.735 0.348-0.823 1.296-1.285 2.624-1.291z"/></svg>
						<span class="subscribe-to-podcast__link-text">Apple Podcasts</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://subscribebyemail.com/www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M6.4 6a2.392 2.392 0 00-2.372 2.119L16 15.6l11.972-7.481A2.392 2.392 0 0025.6 6H6.4zM4 10.502V22.8a2.4 2.4 0 002.4 2.4h19.2a2.4 2.4 0 002.4-2.4V10.502l-11.365 7.102a1.2 1.2 0 01-1.27 0L4 10.502z"/></svg>
						<span class="subscribe-to-podcast__link-text">Email</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://subscribeonandroid.com/www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M12.414 4.02c-.062.012-.126.023-.18.06a.489.489 0 00-.12.675L13.149 6.3c-1.6.847-2.792 2.255-3.18 3.944h13.257c-.388-1.69-1.58-3.097-3.179-3.944l1.035-1.545a.489.489 0 00-.12-.675.492.492 0 00-.675.135l-1.14 1.68a7.423 7.423 0 00-2.55-.45c-.899 0-1.758.161-2.549.45l-1.14-1.68a.482.482 0 00-.494-.195zm1.545 3.824a.72.72 0 110 1.44.72.72 0 010-1.44zm5.278 0a.719.719 0 110 1.44.719.719 0 110-1.44zM8.44 11.204A1.44 1.44 0 007 12.644v6.718c0 .795.645 1.44 1.44 1.44.168 0 .33-.036.48-.09v-9.418a1.406 1.406 0 00-.48-.09zm1.44 0V21.76c0 .793.646 1.44 1.44 1.44h10.557c.793 0 1.44-.647 1.44-1.44V11.204H9.878zm14.876 0c-.169 0-.33.035-.48.09v9.418c.15.052.311.09.48.09a1.44 1.44 0 001.44-1.44v-6.719a1.44 1.44 0 00-1.44-1.44zM11.8 24.16v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84zm5.759 0v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84z"/></svg>
						<span class="subscribe-to-podcast__link-text">Android</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://open.spotify.com/show/4ndjUXyL0hH1FXHgwIiTWU" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M16 4C9.383 4 4 9.383 4 16s5.383 12 12 12 12-5.383 12-12S22.617 4 16 4zm5.08 17.394a.781.781 0 01-1.086.217c-1.29-.86-3.477-1.434-5.303-1.434-1.937.002-3.389.477-3.403.482a.782.782 0 11-.494-1.484c.068-.023 1.71-.56 3.897-.562 1.826 0 4.365.492 6.171 1.696.36.24.457.725.217 1.085zm1.56-3.202a.895.895 0 01-1.234.286c-2.338-1.457-4.742-1.766-6.812-1.747-2.338.02-4.207.466-4.239.476a.895.895 0 11-.488-1.723c.145-.041 2.01-.5 4.564-.521 2.329-.02 5.23.318 7.923 1.995.419.26.547.814.286 1.234zm1.556-3.745a1.043 1.043 0 01-1.428.371c-2.725-1.6-6.039-1.94-8.339-1.942h-.033c-2.781 0-4.923.489-4.944.494a1.044 1.044 0 01-.474-2.031c.096-.023 2.385-.55 5.418-.55h.036c2.558.004 6.264.393 9.393 2.23.497.292.663.931.371 1.428z"/></svg>
						<span class="subscribe-to-podcast__link-text">Spotify</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M6.667 4a2.676 2.676 0 00-2.612 2.13v.003c-.036.172-.055.35-.055.534v18.666c0 .183.019.362.055.534v.003a2.676 2.676 0 002.076 2.075h.002c.172.036.35.055.534.055h18.666A2.676 2.676 0 0028 25.333V6.667a2.676 2.676 0 00-2.13-2.612h-.003A2.623 2.623 0 0025.333 4H6.667zM8 8h1.333C17.42 8 24 14.58 24 22.667V24h-2.667v-1.333c0-6.618-5.382-12-12-12H8V8zm0 5.333h1.333c5.146 0 9.334 4.188 9.334 9.334V24H16v-1.333A6.674 6.674 0 009.333 16H8v-2.667zM10 20a2 2 0 11-.001 4.001A2 2 0 0110 20z"/></svg>
						<span class="subscribe-to-podcast__link-text">RSS Feed</span>
					</a>
				</li>
					</ul>
	</div>
</section>


<div class="wp-block-msr-show-more">
	<div class="bg-neutral-100 p-5">
		<div class="show-more-show-less" data-mount="show-more-show-less">
			<div>
				<span>
					

<h2 class="wp-block-heading" id="transcript">Transcript</h2>



<p>[MUSIC]    &nbsp;</p>



<p>[BOOK PASSAGE]&nbsp;</p>



<p><strong>PETER LEE: </strong>“Medicine often uses the training approach when trying to assess multipurpose talent. To ensure students can safely and effectively take care of patients, we have them jump through quite a few hoops, &#8230; [and] they need good evaluations once they reach the clinic, passing grades on more exams like the USMLE [United States Medical Licensing Examination]. &#8230; [But] GPT-4 gets more than 90 percent of questions on licensing exams correct. &#8230; Does that provide any level of comfort in using GPT-4 in medicine?”&nbsp;</p>



<p>[END OF BOOK PASSAGE]    &nbsp;</p>



<p>[THEME MUSIC]    &nbsp;</p>



<p>This is <em>The AI Revolution in Medicine, Revisited</em>. I’m your host, Peter Lee.    &nbsp;</p>



<p>Shortly after OpenAI&#8217;s GPT-4 was publicly released, Carey Goldberg, Dr. Zak Kohane, and I published <em>The AI Revolution in Medicine </em>to help educate the world of healthcare and medical research about the transformative impact this new generative AI technology could have. But because we wrote the book when GPT-4 was still a secret, we had to speculate. Now, two years later, what did we get right, and what did we get wrong?     &nbsp;</p>



<p>In this series, we’ll talk to clinicians, patients, hospital administrators, and others to understand the reality of AI in the field and where we go from here.</p>



				</span>
				<span id="show-more-show-less-toggle-3" class="show-more-show-less-toggleable-content">
					



<p>[THEME MUSIC FADES] &nbsp;</p>



<p>The book passage I read at the top is from Chapter 4, “Trust but Verify.” In it, we explore how AI systems like GPT-4 should be evaluated for performance, safety, and reliability and compare this to how humans are both trained and assessed for readiness to deliver healthcare.&nbsp;</p>



<p>In previous conversations with guests, we’ve spoken a lot about AI in the clinic as well as in labs and companies developing AI-driven tools. We’ve also talked about AI in the hands of patients and consumers. But there has been some discussion also about AI’s role in medical training. And, as a founding board member of a new medical school at Kaiser Permanente, I definitely have my own thoughts about this. But today, I’m excited to welcome two guests who represent the next generation of medical professionals for their insights, Morgan Cheatham and Daniel Chen.&nbsp;</p>



<p>Morgan Cheatham is a graduate of Brown University&#8217;s Warren Alpert Medical School with clinical training in genetics at Harvard and is a clinical fellow at Boston Children&#8217;s Hospital. While Morgan is a bona fide doctor in training, he’s also amazingly an influential health technology strategist. He was recently named partner and head of healthcare and life sciences at Breyer Capital and has led investments in several healthcare AI companies that have eclipsed multibillion-dollar valuations.&nbsp;&nbsp;</p>



<p>Daniel Chen is finishing his second year as a medical student at the Kaiser Permanente Bernard J. Tyson School of Medicine. He holds a neuroscience degree from the University of Washington and was a research assistant in the Raskind Lab at the UW School of Medicine, working with imaging and genetic data analyses for biomedical research. Prior to med school, Daniel pursued experiences that cultivated his interest in the application of AI in medical practice and education.&nbsp;&nbsp;</p>



<p>Daniel and Morgan exemplify the real-world future of healthcare, a student entering his third year of medical school and a fresh medical-school graduate who is starting a residency while at the same time continuing his work on investing in healthcare startups.&nbsp;</p>



<p>[TRANSITION MUSIC] </p>



<p>Here is my interview with Morgan Cheatham:&nbsp;</p>



<p><strong>LEE:</strong> Morgan, thanks for joining. Really, really looking forward to this chat.&nbsp;</p>



<p><strong>MORGAN CHEATHAM: </strong>Peter, it&#8217;s a privilege to be here with you. Thank you.&nbsp;</p>



<p><strong>LEE:</strong> So are there any other human beings who are partners at big-league venture firms, residents at, you know, a Harvard-affiliated medical center, author, editor for a leading medical journal? I mean, who are your … who&#8217;s your cohort? Who are your peers?&nbsp;</p>



<p><strong>CHEATHAM: </strong>I love this question. There are so many people who I consider peers that I look up to who have paved this path. And I think what is distinct about each of them is they have this physician-plus orientation. They are multilingual in terms of knowing the language of medicine but having learned other disciplines. And we share a common friend, Dr. Zak Kohane, who was among the first to really show how you can meld two worlds as a physician and make significant contributions to the intersections thereof.&nbsp;&nbsp;</p>



<p>I also deeply, in the world of business, respect physicians like Dr. Krishna Yeshwant at Google Ventures, who simultaneously pursued residency training and built what is now, you know, a large and enduring venture firm.&nbsp;&nbsp;</p>



<p>So there are plenty of people out there who&#8217;ve carved their own path and become these multilingual beings, and I aspire to be one.&nbsp;</p>



<p><strong>LEE:</strong> So, you know, one thing I&#8217;ve been trying to explore with people are their origins with respect to the technology of AI. And there&#8217;s two eras for that. There&#8217;s AI <em>before</em> ChatGPT and before, you know, generative AI really became a big thing, and then afterwards.&nbsp;&nbsp;</p>



<p>So let&#8217;s start first before ChatGPT. You know, what was your contact? What was, you know, your knowledge of AI and machine learning?&nbsp;</p>



<p><strong>CHEATHAM: </strong>Sure, so my experiences in computer science date back to high school. I went to Thomas Jefferson, which is a high school in Alexandria, Virginia, that prides itself on requiring students to take computer science in their first year of high school as kind of a required torturous experience. [LAUGHTER] And I remember that fondly. Our final project was Brick Breaker. It was actually, I joke, all hard coded. So there was nothing intelligent about the Brick Breaker that we built. But that was my first exposure.&nbsp;&nbsp;</p>



<p>I was a classics nerd, and I was really interested in biology and chemistry as a pre-medical student. So I really wouldn&#8217;t intersect with this field again until I was shadowing at Inova Hospital, which was a local hospital near me. And it was interesting because, at the time—I was shadowing in the anesthesia department—they were actually implementing their first instance of Epic.&nbsp;</p>



<p><strong>LEE:</strong> Mmm. Wow.&nbsp;</p>



<p><strong>CHEATHAM: </strong>And I remember that experience fondly because the entire hospital was going from analog—they were going from paper-based charts—to this new digital system. And I didn&#8217;t quite know in that moment what it would mean for the field or for my career, but I knew it was a big deal because a lot of people had a lot of emotion around what was going on, and it was in that experience that I kind of decided to attach myself to the intersection of computation and medicine. So when I got to undergrad, I was a pre-medical student. I was very passionate about studying the sacred physician-patient relationship and everything that had to go on in that exam room to provide excellent care.&nbsp;&nbsp;</p>



<p>But there were a few formative experiences: one, working at a physician-founded startup that was using at the time we called it <em>big data</em>, if you remember, …&nbsp;</p>



<p><strong>LEE: </strong>Yup.&nbsp;</p>



<p><strong>CHEATHAM: </strong>… to match the right patient to the right provider at the right time. And it was in that moment that I realized that as a physician, I could utilize technology to scale that sacred one-to-one patient-provider interaction in nonlinear ways. So that was, kind of, the first experience where I saw deployed systems that were using patient data and clinical information in an intelligent format.&nbsp;</p>



<p><strong>LEE:</strong> Yeah. And so you&#8217;re a pre-medical student, but you have this computer science understanding. You have an intuition, I guess is the right way to say it, that the clinical data becoming digital is going to be important. So then what happens from there to your path to medical school?&nbsp;</p>



<p><strong>CHEATHAM: </strong>Yeah, so I had a few formative research experiences in my undergraduate years. You know, nothing that ever amounted to a significant publication, but I was toying around with SVMs [support vector machines] for sepsis and working with the MIMIC [Medical Information Mart for Intensive Care] database early days and really just trying to understand what it meant that medical data was becoming digitized.&nbsp;&nbsp;</p>



<p>And at the same time, again, I was rather unsatisfied doing that purely in an academic context. And I so early craved seeing how this would roll out in the wild, roll out in a clinical setting that I would soon occupy. And that was really what drove me to work at this company called Kyruus [Health] and understand how these systems, you know, scaled. Obviously, that&#8217;s something with AI that we&#8217;re now grappling with in a real way because it looks much different.&nbsp;&nbsp;</p>



<p><strong>LEE:</strong> Right. Yep.&nbsp;</p>



<p><strong>CHEATHAM:</strong> So the other experience I had, which is less relevant to AI, but I did do a summer in banking. And I mention this because what I learned in the experience was … it was a master class in business. And I learned that there was another scaling factor that I should appreciate as we think about medicine, and that was capital and business formation. And that was also something that could scale nonlinearly.&nbsp;&nbsp;</p>



<p>So when you married that with technology, it was, kind of, a natural segue for me before going to med school to think about venture capital and partnering with founders who were going to be building these technologies for the long term. And so that&#8217;s how I landed on the venture side.&nbsp;</p>



<p><strong>LEE:</strong> And then how long of a break before you started your medical studies?&nbsp;</p>



<p><strong>CHEATHAM: </strong>It was about four years. Originally, it was going to be a two-year deferral, and the pandemic happened. Our space became quite active in terms of new companies and investment. So it was about four years before I went back.&nbsp;</p>



<p><strong>LEE:</strong> I see. And so you&#8217;re in medical school. ChatGPT happened <em>while</em> you were in medical school, is that right?&nbsp;</p>



<p><strong>CHEATHAM: </strong>That&#8217;s right. That&#8217;s right. Right before I was studying for Step 1. So the funny story, Peter, that I like to share with folks is …&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>CHEATHAM:</strong> … I was just embarking on designing my Step 1 study plan with my mentor. And I went to NeurIPS [Conference] for the first time. And that was in 2022, when, of course, ChatGPT was released.&nbsp;&nbsp;</p>



<p>And for the remainder of that fall period, you know, I should have been studying for these shelf exams and, you know, getting ready …&nbsp;&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>CHEATHAM:</strong> … for this large board exam. And I was fortunate to partner, actually, with one of our portfolio company CEOs who is a physician—he is an MD/PhD—to work on the <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://journals.plos.org/digitalhealth/article?id=10.1371/journal.pdig.0000198" target="_blank" rel="noreferrer noopener">first paper that showed that ChatGPT could pass the US Medical Licensing Exam<span class="sr-only"> (opens in new tab)</span></a>.&nbsp;&nbsp;</p>



<p><strong>LEE:</strong> Yes.&nbsp;</p>



<p><strong>CHEATHAM:</strong> And that was a riveting experience for a number of reasons. I joke with folks that it was both the best paper I was ever, you know, a part of and proud to be a coauthor of, but also the worst for a lot of reasons that we could talk about.&nbsp;&nbsp;</p>



<p>It was the best in terms of canonical metrics like citations, but the worst in terms of, wow, did we spend six months as a field thinking this was the right benchmark … [LAUGHTER]&nbsp;</p>



<p><strong>LEE:</strong> Right.&nbsp;</p>



<p><strong>CHEATHAM:</strong> … for how to assess the performance of these models. And I&#8217;m so encouraged …&nbsp;</p>



<p><strong>LEE:</strong> You shouldn&#8217;t feel bad that way because, you know, at that time, I was secretly, you know, assessing what we now know of as GPT-4 in that period. And what was the first thing <em>I</em> tried to do? Step 1 medical exam.&nbsp;&nbsp;</p>



<p>By the way, just for our listeners who don&#8217;t understand about medical education—in the US, there&#8217;s a three-part exam that extends over a couple of years of medical school. Step 1, Step 2, Step 3. And Step 1 and Step 2 in particular are multiple-choice exams.&nbsp;</p>



<p>And they are very high stakes when you&#8217;re in medical school. And you really have to have a command of quite a lot of clinical knowledge to pass these. And it&#8217;s funny to hear you say what you were just sharing there because it was also the first impulse I had with GPT-4. And in retrospect, I feel silly about that.&nbsp;</p>



<p><strong>CHEATHAM: </strong>I think many of us do, but I&#8217;ve been encouraged over the last two years, to your point, that we really have moved our discourse beyond these exams to thinking about more robust systems for the evaluation of performance, which becomes even more interesting as you and I have spoken about these multi-agent frameworks that we are now, you know, compelled to explore further.&nbsp;</p>



<p><strong>LEE:</strong> Yeah. Well, and even though I know you&#8217;re a little sheepish about it now, I think in the show notes, we&#8217;ll link to that paper because it really was one of the seminal moments when we think about AI, AI in medicine.</p>



<p>And so you&#8217;re seeing this new technology, and it&#8217;s happening at a moment when you <em>yourself</em> have to confront taking the Step 1 exam. So how did that feel?&nbsp;</p>



<p><strong>CHEATHAM: </strong>It was humbling. It was shocking. What I had worked two years for, grueling over textbooks and, you know, flashcards and all of the things we do as medical students, to see a system emerge out of thin air that was arguably going to perform far better than I ever would, no matter how much …&nbsp;&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>CHEATHAM:</strong> … I was going to study for that exam, it set me back. It forced me to interrogate what my role in medicine would be. And it dramatically changed the specialties that I considered for myself long term.&nbsp;&nbsp;</p>



<p>And I hope we talk about, you know, how I stumbled upon genetics and why I&#8217;m so excited about that field and its evolution in this computational landscape. I had to do a lot of soul searching to relinquish what I thought it meant to be a physician and how I would adapt in this new environment.&nbsp;</p>



<p><strong>LEE:</strong> You know, one of the things that we wrote in our book, I think it was in a chapter that I contributed, I was imagining that students studying for Step 1 would be able to do it more actively.&nbsp;&nbsp;</p>



<p>Or you could even do sort of a pseudo-Step 3 exam by having a conversation. You provide the presentation of a patient and then have an encounter, you know, where the ChatGPT is the patient, and then you pretend to be the doctor.&nbsp;And then in the example that we published, then you say, “End of encounter.” And then you ask ChatGPT for an assessment of things.&nbsp;&nbsp;</p>



<p>So, you know, maybe it all came too late for Step 1 for you because you were already very focused and, you know, had your own kind of study framework. But did you have an influence or use of this kind of technology for Step 2 and Step 3?&nbsp;</p>



<p><strong>CHEATHAM:</strong> So even for Step 1, I would say, it [ChatGPT], you know, dropped in November. I took it [Step 1 exam] in the spring, so I was able to use it to study. But the lesson I learned in that moment, Peter, was really about the importance of trust with AI and clinicians or clinicians in training, because we all have the same resources that we use for these board exams, right. UWorld is this question bank. It&#8217;s been around forever. If you&#8217;re not using UWorld, like, <em>good luck</em>. And so why would you deviate off of a well-trodden path to study for this really important exam?&nbsp;&nbsp;</p>



<p>And so I kind of adjunctively used GPT alongside UWorld to come up with more personalized explanations for concepts that I wasn&#8217;t understanding, and I found that it was pretty good and it was certainly helpful for me.&nbsp;&nbsp;</p>



<p>Fortunately, I was, you know, able to pass, but I was very intentional about dogfooding AI when I was a medical student, and part of that was because I had been a venture capitalist, and I&#8217;d made investments in companies whose products I could actually use.&nbsp;&nbsp;</p>



<p>And so, you know, Abridge is a company in the scribing space that you and I have talked about.&nbsp;&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>CHEATHAM:</strong> I was so fortunate in the early days of their product to not just be a user but to get to bring their product across the hospital. I could bring the product to the emergency department one week, to neurology another week, to the PICU [pediatric intensive care unit], you know, the next week, and assess the relative performance of, you know, how it handled really complex genetics cases …&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>CHEATHAM:</strong> … versus these very challenging social situations that you often find yourself navigating in primary care. So not only was I emotional about this technology, but I was a voracious adopter in the moment.&nbsp;</p>



<p><strong>LEE:</strong> Yeah, right. And you had a financial interest then on top of that, right?&nbsp;</p>



<p><strong>CHEATHAM: </strong>I was not paid by Abridge to use the product, but, you know, I joke that the team was probably sick of me. [LAUGHTER]&nbsp;</p>



<p><strong>LEE:</strong> No, no, but you were working for a venture firm that was invested in these, right? So all of these things are wrapped up together. You know, you&#8217;re having to get licensed as a doctor while doing all of this.&nbsp;&nbsp;</p>



<p>So I want to get into that investment and new venture stuff there, but let&#8217;s stick just for a few more minutes on medical education. So I mentioned, you know, what we wrote in the book, and I remember writing the example, you know, of an encounter. Is that at all realistic? Is anything like that … that was pure speculation on our part. What&#8217;s really happening?&nbsp;&nbsp;</p>



<p>And then after we talk about what&#8217;s really happening, what do you think should happen in medical education given the reality of generative AI?&nbsp;</p>



<p><strong>CHEATHAM:</strong> I&#8217;ve been pleasantly surprised talking with my colleagues about AI in clinical settings, how curious people are and how curious they&#8217;ve been over the last two years. I think, oftentimes, we say, oh, you know, this technology really is stratified by age and the younger clinicians are using it more and the older physicians are ignoring it. And, you know, maybe that&#8217;s true in some regards, but I&#8217;ve seen, you know, many, you know, senior attendings pulling up Perplexity, GPT, more recently <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.openevidence.com/" target="_blank" rel="noreferrer noopener">OpenEvidence<span class="sr-only"> (opens in new tab)</span></a>, which has been a really essential tool for me personally at the point of care, to come up with the best decisions for our patients.&nbsp;&nbsp;</p>



<p>The general skepticism arises when people reflect on their own experience in training and they think, “Well, I had to learn how to do it this way.”&nbsp;&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>CHEATHAM: </strong>“And therefore, <em>you</em> using an AI scribe to document this encounter doesn&#8217;t feel right to me because I didn&#8217;t get to do that.” And I did face some of those critiques or criticisms, where you need to learn how to do it the old-school way first and then you can use an AI scribe.&nbsp;&nbsp;</p>



<p>And I haven&#8217;t yet seen—maybe even taking a step back—I haven&#8217;t seen a lot of integration of AI into the core medical curriculum, period.&nbsp;&nbsp;</p>



<p><strong>LEE: </strong>Yeah.&nbsp;</p>



<p><strong>CHEATHAM:</strong> And, as you know, if you want to add something to medical school curriculum, you can get in a long line of people who also want to do that.&nbsp;</p>



<p><strong>LEE:</strong> Yes. Yeah.</p>



<p><strong>CHEATHAM: </strong>But it is urgent that our medical schools do create formalized required trainings for this technology because people are already using it.&nbsp;&nbsp;</p>



<p><strong>LEE:</strong> Yes.&nbsp;</p>



<p><strong>CHEATHAM: </strong>I think what we will need to determine is how much of the old way do people need to learn in order to earn the right to use AI at the point of care and how much of that old understanding, that prior experience, is essential to be able to assess the performance of these tools and whether or not they are having the intended outcome.&nbsp;&nbsp;</p>



<p>I kind of joke it&#8217;s like learning cursive, right?&nbsp;</p>



<p><strong>LEE:</strong> Yes.&nbsp;</p>



<p><strong>CHEATHAM: </strong>I&#8217;m old enough to have had to learn cursive. I don&#8217;t think people really have to learn it these days. When do I use it? Well, when I&#8217;m signing something. I don&#8217;t even really sign checks anymore, but &#8230;&nbsp;</p>



<p><strong>LEE:</strong> Well … the example I&#8217;ve used, which you&#8217;ve heard, is, I&#8217;m sure you were still taught the technique of manual palpation, even though …&nbsp;</p>



<p><strong>CHEATHAM: </strong>Of course.&nbsp;</p>



<p><strong>LEE: </strong>… you have access to technologies like ultrasound. And in fact, you would use ultrasound in many cases.&nbsp;&nbsp;</p>



<p>And so I need to pin <em>you</em> down. What is your opinion on these things? Do you need to be trained in the old ways?&nbsp;</p>



<p><strong>CHEATHAM:</strong> When it comes to understanding the architecture of the medical note, I believe it is important for clinicians in training to know how that information is generated, how it&#8217;s characterized, and how to go from a very broad-reaching conversation to a distilled clinical document that serves many functions.&nbsp;</p>



<p>Does that mean that you should be forced to practice without an AI scribe for the entirety of your medical education? No. And I think that as you are learning the architecture of that document, you should be handed an AI scribe and you should be empowered to have visits with patients both in an analog setting—where you are transcribing and generating that note—and soon thereafter, I&#8217;m talking in a matter of weeks, working with an AI scribe. That&#8217;s my personal belief.&nbsp;&nbsp;</p>



<p><strong>LEE:</strong> Yeah, yeah.<strong> </strong>So you&#8217;re going to &#8230; well, first off, congratulations on landing a residency at Boston Children&#8217;s [Hospital].&nbsp;&nbsp;</p>



<p><strong>CHEATHAM: </strong>Thank you, Peter.&nbsp;</p>



<p><strong>LEE:</strong> I understand there were only two people selected for this and super competitive. You know, with that perspective, you know, how do you see your future in medicine, just given everything that&#8217;s happening with AI right now?&nbsp;&nbsp;</p>



<p>And are there things that you would urge, let&#8217;s say, the dean of the Brown Medical School to consider or to change? Or maybe not the dean of Brown but the head of the LCME [Liaison Committee on Medical Education], the accrediting body for US medical schools. What in your mind needs to change?&nbsp;</p>



<p><strong>CHEATHAM:</strong> Sure. I&#8217;ll answer your first question first and then talk about the future.&nbsp;&nbsp;</p>



<p><strong>LEE: </strong>Yeah.&nbsp;</p>



<p><strong>CHEATHAM: </strong>For me personally, I fell into the field of genomics. And so my training program will cover both pediatrics as well as clinical genetics and genomics.&nbsp;&nbsp;</p>



<p>And I alluded to this earlier, but one of the reasons I&#8217;m so excited to join the field is because I really feel like the field of genetics not only is focused on a very underserved patient population, but not in how we typically think of underserved. I&#8217;m talking about underserved as in patients who don&#8217;t always have answers. Patients for whom the current guidelines don&#8217;t offer information or comfort or support.&nbsp;</p>



<p>Those are patients that are extremely underserved. And I think in this moment of AI, there&#8217;s a unique opportunity to utilize the computational systems that we now have access to, to provide these answers more precisely, more quickly.&nbsp;&nbsp;</p>



<p>And so I&#8217;m excited to marry those two fields. And genetics has long been a field that has adopted technology. We just think about the foundational technology of genomic sequencing and variant interpretation. And so it&#8217;s a kind of natural evolution of the field, I believe, to integrate AI and specifically generative AI.&nbsp;</p>



<p>If I were speaking directly to the LCME, I mean, I would just have to encourage the organization, as well as medical societies who partner with attending physicians across specialties, to lean in here.</p>



<p>When I think about prior revolutions in technology and medicine, physicians were not always at the helm. We have a unique opportunity now, and you talk about companies like Abridge in the AI space, companies like Viz.ai, Cleerly—I mean, I could go on: Iterative Health … I could list 20 organizations that are bringing AI to the point of care that are founded by physicians.</p>



<p>This is our moment to have a seat at the table and to shape not only the discourse but the deployment. And the unique lens, of course, that a physician brings is that of prioritizing the patient, and with AI and this time around, we have to do that.</p>



<p><strong>LEE: </strong>So LCME for our listeners is, I think it stands for the <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://lcme.org/" target="_blank" rel="noreferrer noopener">Liaison Committee on Medical Education<span class="sr-only"> (opens in new tab)</span></a>. It&#8217;s basically the accrediting body for US medical schools, and it&#8217;s very high stakes. It&#8217;s very, very rigorous, which I think is a good thing, but it&#8217;s also a bit of a straitjacket.&nbsp;&nbsp;</p>



<p>So if you are on the LCME, are there specific new curricular elements that you would demand that LCME, you know, add to its accreditation standards?&nbsp;</p>



<p><strong>CHEATHAM: </strong>We need to unbundle the different components of the medical appointment and think about the different functions of a human clinician to answer that question.&nbsp;&nbsp;</p>



<p>There are a couple of areas that are top of mind for me, the first being medical search. There are large organizations and healthcare incumbents that have been around for many decades, companies like UpToDate or even, you know, the guidelines that are housed by our medical societies, that need to respond to the information demands of clinicians at the point of care in a new way with AI.&nbsp;&nbsp;</p>



<p>And so I would love to see our medical institutions teaching more students how to use AI for medical search problems at the point of care. How to not only, you know, from a prompt perspective, ask questions about patients in a high-efficacy way, but also to interpret the outputs of these systems to inform downstream clinical decision-making.&nbsp;&nbsp;</p>



<p>People are already adopting, as you know, GPT, OpenEvidence, Perplexity, all of these tools to make these decisions now.&nbsp;&nbsp;</p>



<p>And so by not—again, it&#8217;s a moral imperative of the LCME—by not having curriculum and support for clinicians doing that, we run the risk of folks not utilizing these tools properly but also to their greatest potential.&nbsp;</p>



<p><strong>LEE: </strong>Yeah, then, but zooming forward then, what about board certification?&nbsp;</p>



<p><strong>CHEATHAM:</strong> Board certification today is already transitioning to an open-book format for many specialties, is my understanding. And in talking to some of my fellow geneticists, who, you know, that&#8217;s a pretty challenging board exam in clinical genetics or biochemical genetics. They are using OpenEvidence during those open-book exams.&nbsp;&nbsp;</p>



<p>So what I would like to see us do is move from a system of rote memorization and regurgitation of fact to an assessment framework that is adaptive, is responsive, and assesses for your ability to use the tools that we now have at our disposal to make sound clinical decisions.&nbsp;</p>



<p><strong>LEE:</strong> Yeah. We&#8217;ve heard from Sara Murray, you know, that when she&#8217;s doing her rounds, she consults routinely with ChatGPT. And that was something we also predicted, especially Carey Goldberg in our book, you know, wrote this fictional account.&nbsp;&nbsp;</p>



<p>Is that the primary real-world use of AI? Not only by clinicians, but also by medical students &#8230; are medical students, you know, engaged with ChatGPT or, you know, similar?&nbsp;</p>



<p><strong>CHEATHAM: </strong>Absolutely. I&#8217;ve listed some of the tools. I think there, in general, Peter, there is this new clinician stack that is emerging of these tools that people are trying, and I think the cycles of iteration are quick, right. Some folks are using Claude [Claude.ai] one week, and they&#8217;re trying Perplexity, or they&#8217;re trying OpenEvidence, they&#8217;re trying GPT for a different task.&nbsp;&nbsp;</p>



<p>There&#8217;s this kind of moment in medicine that every clinician experiences where you&#8217;re on rounds, and there&#8217;s that very senior attending. And you&#8217;ve just presented a patient to them, and you think you did an elegant job, and you&#8217;ve summarized all the information, and you really feel good about your differential, and they ask you, like, the one question you didn&#8217;t think to address. [LAUGHTER]&nbsp;</p>



<p>And I&#8217;ll tell you, some of the funniest moments I&#8217;ve had using AI in the hospital has been, and let me take a step back, that process of an attending physician interrogating a medical student is called “pimping,” for lack of a better phrase.&nbsp;&nbsp;</p>



<p>And some of the funniest use cases I&#8217;ve had for AI in that setting is actually using OpenEvidence or GPT as defense against pimping. [LAUGHTER] So quickly while they&#8217;re asking me the question, I put it in, and I&#8217;m actually able to answer it right away. So it&#8217;s been effective for that. But I would say, you know, [in] the halls of most of the hospitals where I&#8217;ve trained, I&#8217;m seeing this technology in the wild.</p>



<p><strong>LEE:</strong> So now you&#8217;re so tech-forward, but that off-label use of AI, we also, when we wrote our book, we weren&#8217;t sure that at least top health systems would tolerate this. Do you have an opinion about this? Should these things be better regulated or controlled by the CIOs of Boston Children&#8217;s?&nbsp;</p>



<p><strong>CHEATHAM:</strong> I&#8217;m a big believer that transparency encourages good behaviors.&nbsp;</p>



<p>And so the first time I actually tried to use ChatGPT in a clinical setting, it was at a hospital in Rhode Island. I will not name which hospital. But the site was actually blocked. I wasn&#8217;t able to access it from a desktop. That was the hospital&#8217;s first response to this technology was, let&#8217;s make sure none of our clinicians can access it. It has so much potential for medicine. The irony of that today.&nbsp;&nbsp;</p>



<p>And it&#8217;s since, you know, become unblocked. But I was able to use it on my phone. So, to your point, if there&#8217;s a will, there&#8217;s a way. And we will utilize this technology if we are seeing perceived value.&nbsp;</p>



<p><strong>LEE:</strong> So, yeah, no, absolutely. So now, you know, in some discussions, one superpower that seems to be common across people who are really leading the charge here is they seem to be very good readers and students.&nbsp;&nbsp;</p>



<p>And I understand you also as a voracious reader. In fact, you&#8217;re even on an editorial team for a major medical journal. To what extent does that help?&nbsp;&nbsp;</p>



<p>And then from your vantage point at <em>New England Journal of Medicine AI</em>—and I&#8217;ll have a chance to ask Zak Kohane as the editor in chief the same question—you know, what&#8217;s your assessment as you reflect over the last two years for the submitted manuscripts? Are you overall surprised at what you&#8217;re seeing? Disappointed? Any kind of notable hits or misses, just in the steady stream of research papers that are getting submitted to that leading journal?&nbsp;</p>



<p><strong>CHEATHAM:</strong> I would say overall, the field is becoming more expansive in the kinds of questions that people are asking.<strong>&nbsp;</strong>&nbsp;</p>



<p>Again, when we started, it was this very myopic approach of: “Can we pass these medical licensing exams? Can we benchmark this technology to how we benchmark our human clinicians?” I think that&#8217;s a trap. Some folks call this the Turing Trap, right, of let&#8217;s just compare everything to what a human is capable of.&nbsp;&nbsp;</p>



<p>Instead of interrogating what is the unique, as you all talk about in the book, what are the unique attributes of this new substrate for computation and what new behaviors emerge from it, whether that&#8217;s from a workflow perspective in the back office, or—as I&#8217;m personally more passionate and as we&#8217;re seeing more people focus on in the literature—what are the diagnostic capabilities, right.&nbsp;</p>



<p>I love Eric Topol&#8217;s framework for “machine eyes,” right, as this notion of like, yes, we as humans have eyes, and we have looked at medical images for many, many decades, but these machines can take a different approach to a retinal image, right.&nbsp;&nbsp;</p>



<p>It&#8217;s not just what you can diagnose in terms of an ophthalmological disease but maybe a neurologic disease or, you know, maybe liver disease, right.&nbsp;</p>



<p>So I think the literature is, in general, moving to this place of expansion, and I&#8217;m excited by that.&nbsp;</p>



<p><strong>LEE:</strong> Yeah, I kind of have referred to that as triangulation. You know, one of the things I think a trap that specialists in medicine can fall into, like a cardiologist will see everything in terms of the cardiac system. And … whereas a nephrologist will see things in a certain lens.&nbsp;&nbsp;</p>



<p>And one of the things that you oftentimes see in the responses from a large language model is that more expansive view. At the same time, you know, I wonder … we have medical specialties for good reason. And, you know, at times I do wonder, you know, if there can be confusion that builds up.&nbsp;&nbsp;</p>



<p><strong>CHEATHAM:</strong> This is an under-discussed area of AI—AI collapses medical specialties onto themselves, right.&nbsp;</p>



<p>You have the canonical example of the cardiologist, you know, arguing that, you know, we should diuresis and maybe the nephrologist arguing that we should, you know, protect the kidneys. And how do two disciplines disagree on what is right for the patient when in theory, there is an objective best answer given that patient&#8217;s clinical status?&nbsp;</p>



<p>My understanding is that the emergence of medical specialties was a function of the cognitive overload of medicine in general and how difficult it was to keep all of the specifics of a given specialty in the mind. Of course, general practitioners are tasked with doing this at some level, but they&#8217;re also tasked with knowing when they&#8217;ve reached their limit and when they need to refer to a specialist.&nbsp;&nbsp;</p>



<p>So I&#8217;m interested in this question of whether medical specialties themselves need to evolve.&nbsp;&nbsp;</p>



<p>And if we look back in the history of medical technology, there are many times where a new technology forced a medical specialty to evolve, whether it was certain diagnostic tools that have been introduced or, as we&#8217;re seeing now with GLP-1s, the entire cardiometabolic field …&nbsp;</p>



<p><strong>LEE:</strong> Right.&nbsp;</p>



<p><strong>CHEATHAM:</strong> … is having to really reimagine itself with these new tools. So I think AI will look very similar, and we should not hold on to this notion of classical medical specialties simply out of convention.&nbsp;&nbsp;</p>



<p><strong>LEE:</strong> Right. All right. So now you&#8217;re starting your residency. You&#8217;re, you know, basically leading a charge in health and life sciences for a leading venture firm. I&#8217;d like you to predict what the world of healthcare is going to look like, you know, two years from now, five years from now, 10 years from now. And to frame that, to make it a little more specific, you know, what do you think will be possible that <em>you</em>, as a doctor and an investor, will be able to do two years from now, five years from now, 10 years from now that you can&#8217;t do today?&nbsp;&nbsp;</p>



<p><strong>CHEATHAM: </strong>Two years from now, I&#8217;m optimistic we&#8217;ll have greater adoption of AI by clinicians, both for back-office use cases. So whether that&#8217;s the scribe and the generation of the note for billing purposes, but also now thinking about that for patient-facing applications.&nbsp;&nbsp;</p>



<p>We&#8217;re already doing this with drafting of notes. I think we&#8217;ll see greater proliferation of those more obvious use cases over the next two years. And hopefully we&#8217;re seeing that across hospital systems, not just large well-funded academics, but really reaching our community hospitals, our rural hospitals, our under-resourced settings.&nbsp;&nbsp;</p>



<p>I think hopefully we&#8217;ll see greater conversion. Right now, we have this challenge of “pilotitis,” right. A lot of people are trying things, but the data shows that only one in three pilots are really converting to production use. So hopefully we&#8217;ll kind of move things forward that are working and pare back on those that are not.&nbsp;</p>



<p>We will not solve the problem of payment models in the next two years. That is a prediction I have.&nbsp;&nbsp;</p>



<p>Over the next five years, I suspect that, with the help of regulators, we will identify better payment mechanisms to support the adoption of AI because it cannot and will not sustain itself simply by asking health systems and hospitals to pay for it. That is not a scalable solution.&nbsp;&nbsp;</p>



<p><strong>LEE:</strong> Yes. Right. Yep. In fact, I think there have to be new revenue-positive incentives if providers are asked to do more in the adoption of technology.&nbsp;</p>



<p><strong>CHEATHAM:</strong> Absolutely. But as we appreciate, some of the most promising applications of AI have nothing to do with revenue. It might simply be providing a diagnosis to somebody, you know, for whom that might drive additional intervention, but may also not.&nbsp;&nbsp;</p>



<p>And we have to be OK with that because that&#8217;s the right thing to do. It&#8217;s our moral imperative as clinicians to implement this where it provides value to the patient.</p>



<p>Over the next 10 years, what I—again, being a techno-optimist—am hopeful we start to see is a dissolving of the barrier that exists between care delivery and biomedical discovery.&nbsp;&nbsp;</p>



<p>This is the vision of the learning health system that was written over 10 years ago, and we have not realized it in practice. I&#8217;m a big proponent of ensuring that every single patient that enters our healthcare system not only receives the best care, but that we learn from the experiences of that individual to help the next.&nbsp;</p>



<p>And in our current system, that is not how it works. But, with AI, that now becomes possible.&nbsp;</p>



<p><strong>LEE:</strong> Well, I think connecting healthcare experiences to medical discovery—I think that that is really such a great vision for the future. And I do agree [that] AI really gives us real hope that we can make it true.&nbsp;&nbsp;</p>



<p>Morgan, I think we could talk for a few hours more. It&#8217;s just incredible what you&#8217;re up to nowadays. Thank you so much for this conversation. I&#8217;ve learned a lot talking to you.&nbsp;</p>



<p><strong>CHEATHAM: </strong>Peter, thank you so much for your time. I will be clutching my signed copy of <em>The AI Revolution in Medicine </em>for many years to come.&nbsp;&nbsp;</p>



<p>[TRANSITION MUSIC]&nbsp;</p>



<p><strong>LEE: </strong>Morgan obviously is not an ordinary med school graduate. In previous episodes, one of the things we&#8217;ve seen is that people on the leading edge of real-world AI in medicine oftentimes are both practicing doctors as well as technology developers. Morgan is another example of this type of polymath, being both a med student and a venture capitalist.&nbsp;</p>



<p>One thing that struck me about Morgan is he&#8217;s just incredibly hands-on. He goes out, finds leading-edge tools and technologies, and often these things, even though they&#8217;re experimental, he takes them into his education and into his clinical experiences. I think this highlights a potentially important point for medical schools, and that is, it might be incredibly important to provide the support—and, let&#8217;s be serious, the <em>permission</em>—to students to access and use new tools and technologies. Indeed, the insight for me when I interact with Morgan is that in these early days of AI in medicine, there is no substitute for hands-on experimentation, and that is likely best done while in medical school.</p>



<p>Here&#8217;s my interview with Daniel Chen:&nbsp;</p>



<p><strong>LEE:</strong> Daniel, it&#8217;s great to have you here.&nbsp;</p>



<p><strong>DANIEL CHEN: </strong>Yeah, it&#8217;s a pleasure being here.&nbsp;</p>



<p><strong>LEE:</strong> Well, you know, I normally get started in these conversations by asking, you know, how do you explain to your mother what you do all day? And the reason that that&#8217;s a good question is a lot of the people we have on this podcast have fancy titles and unusual jobs, but I&#8217;m guessing that your mother would have already a preconceived notion of what a medical student does. So I&#8217;d like to twist the question around a little bit for you and ask, what does your mother not realize about how you spend your days at school?&nbsp;&nbsp;</p>



<p>Or does she get it all right? [LAUGHS]&nbsp;</p>



<p><strong>CHEN: </strong>Oh, no, she is very observant. I&#8217;ll say that off the bat. But I think something that she might not realize, is the amount of efforts spent, kind of, outside the classroom or outside the hospital. You know, she&#8217;s always, like, saying you have such long days in the hospital. You&#8217;re there so early in the morning.&nbsp;&nbsp;</p>



<p>But what she doesn&#8217;t realize is that maybe when I come back from the hospital, it&#8217;s not just like, oh, I&#8217;m done for the day. Let&#8217;s wind down, go to bed. But it&#8217;s more like, OK, I have some more practice questions I need to get through; I didn&#8217;t get through my studying. Let me write on, like wrap up this research project I&#8217;m working on, get that back to the PI [principal investigator]. It&#8217;s never ending to a certain extent. Those are some things she doesn&#8217;t realize.&nbsp;</p>



<p><strong>LEE:</strong> Yeah, I think, you know, all the time studying, I think, is something that people expect of second-year medical students. And even nowadays at the top medical schools like this one, being involved in research is also expected.&nbsp;&nbsp;</p>



<p>I think one thing that is a little unusual is that you are actually in clinic, as well, as a second-year student. How has that gone for you?&nbsp;</p>



<p><strong>CHEN: </strong>Yeah, I mean, it&#8217;s definitely interesting. I would say I spend my time, especially this year, it&#8217;s kind of three things. There&#8217;s the preclinical stuff I&#8217;m doing. So that&#8217;s your classic, you know, you&#8217;re learning from the books, though I don&#8217;t feel like many of us do have textbooks anymore. [LAUGHTER]&nbsp;</p>



<p>There&#8217;s the clinical aspect, which you mentioned, which is we have an interesting model, longitudinal integrated clerkships. We can talk about that. And the last component is the research aspect, right. The extracurriculars.&nbsp;&nbsp;</p>



<p>But I think starting out as a second year and doing your rotations, probably early on in, kind of, the clinical medical education, has been really interesting, especially with our format, because typically med students have two years to read up on all the material and, like, get some foundational knowledge. With us, it&#8217;s a bit more, we have maybe one year under our belt before we&#8217;re thrown into like, OK, go talk to this patient; they have ankle pain, right. But we might have not even started talking about ankle pain in class, right. Well, where do I begin?&nbsp;&nbsp;</p>



<p>So I think starting out, it&#8217;s kind of, like, you know, the classic drinking from a fire hydrant. But you also, kind of, have that embarrassment of you&#8217;re talking to the patient like, I have no clue what&#8217;s happening [LAUGHTER] or you might have … my differentials all over the place, right.&nbsp;&nbsp;</p>



<p>But I think the beauty of the longitudinal aspect is that now that we&#8217;re, like, in our last trimester, everything&#8217;s kind of coming together. Like, OK, I can start to see, you know, here&#8217;s what you&#8217;re telling me. Here&#8217;s what the physical exam findings are. I&#8217;m starting to form a differential. Like, OK, I think these are the top three things.&nbsp;</p>



<p>But in addition to that, I think these are the next steps you should take so we can really focus and hone in on what exact diagnosis this might be.&nbsp;</p>



<p><strong>LEE:</strong> All right. So, of course, what we&#8217;re trying to get into is about AI.&nbsp;&nbsp;</p>



<p>And, you know, the funny thing about AI and the book that Carey, Zak, and I wrote is we actually didn&#8217;t think too much about medical education, although we did have some parts of our book where we, well, first off, we made the guess that medical students would find AI to be useful. And we even had some examples, you know, where, you know, you would have a vignette of a mythical patient, and you would ask the AI to pretend to be that patient.&nbsp;&nbsp;</p>



<p>And then you would have an interaction and have to have an encounter. And so I want to delve into whether any of that is happening. How real it is. But before we do that, let&#8217;s get into first off, your own personal contact with AI. So let me start with a very simple question. Do you ever use generative AI systems like ChatGPT or similar?&nbsp;</p>



<p><strong>CHEN: </strong>All the time, if not every day.&nbsp;</p>



<p><strong>LEE: </strong>[LAUGHS] Every day, OK. And when did that start?&nbsp;</p>



<p><strong>CHEN:</strong> I think when it first launched with GPT-3.5, I was, you know, curious. All my friends work in tech. You know, they&#8217;re either software engineers, PMs. They&#8217;re like, “Hey, Daniel, take a look at this,” and at first, I thought it was just more of a glorified search engine. You know, I was actually looking back.&nbsp;&nbsp;</p>



<p>My first question to ChatGPT was, what was the weather going to be like the next week, you know? Something very, like, something easily you could have looked up on Google or your phone app, right.&nbsp;&nbsp;</p>



<p>I was like, oh, this is pretty cool. But then, kind of, fast-forwarding to, I think, the first instance I was using it in med school. I think the first, like, thing that really helped me was actually a coding problem. It was for a research project. I was trying to use SQL.&nbsp;&nbsp;</p>



<p>Obviously, I&#8217;ve never taken a SQL class in my life. So I asked Chat like, “Hey, can you write me this code to maybe morph two columns together,” right? Something that might have taken me hours to maybe Google on YouTube or like try to read some documentation which just goes through my head.</p>



<p>But ChatGPT was able to, you know, not only produce the code, but, like, walk me through like, OK, you&#8217;re going to launch SQL. You&#8217;re going to click on this menu, [LAUGHTER] put the code in here, make sure your file names are correct. And it worked.&nbsp;&nbsp;</p>



<p>So it&#8217;s been a very powerful tool in that way in terms of, like, giving me expertise in something that maybe I traditionally had no training in.&nbsp;</p>



<p><strong>LEE:</strong> And so while you&#8217;re doing this, I assume you had fellow students, friends, and others. And so what were you observing about their contact with AI? I assume you weren&#8217;t alone in this.&nbsp;</p>



<p><strong>CHEN:</strong> Yeah, yeah, I think, &#8230; I&#8217;m not too sure in terms of what they were doing when it first came out, but I think if we were talking about present day, um, a lot of it&#8217;s kind of really spot on to what you guys talked about in the book.&nbsp;&nbsp;</p>



<p>Um, I think the idea around this personal tutor, personal mentor, is something that we&#8217;re seeing a lot. Even if we&#8217;re having in-class discussions, the lecturer might be saying something, right. And then I might be or I see a friend in ChatGPT or some other model looking up a question.&nbsp;&nbsp;</p>



<p>And you guys talked about, you know, how it can, like, explain a concept at different levels, right. But honestly, sometimes if there&#8217;s a complex topic, I ask ChatGPT, like, can you explain this to me as if I was a 6-year-old?&nbsp;&nbsp;</p>



<p><strong>LEE: </strong>Yeah. [LAUGHS]&nbsp;&nbsp;</p>



<p><strong>CHEN:</strong> Breaking down complex topics. Yeah. So I think it&#8217;s something that we see in the pre-clinical space, in lecture, but also even in the clinical space, there&#8217;s a lot of teaching, as well.&nbsp;</p>



<p>Sometimes if my preceptor is busy with patients, but I had maybe a question, I would maybe converse with ChatGPT, like, “Hey, what are your thoughts about this?” Or, like, a common one is, like, medical doctors love to use abbreviations, …&nbsp;</p>



<p><strong>LEE: </strong>Yes.&nbsp;&nbsp;</p>



<p><strong>CHEN:</strong> … and these abbreviations are sometimes only very niche and unique to their specialty, right. [LAUGHTER]&nbsp;</p>



<p>And I was reading this note from a urogynecologist. [In] the entire first sentence, I think there were, like, 10 abbreviations. Obviously, I compile lists and ask ChatGPT, like, “Hey, in the context of urogynecology, can you define what these could possibly mean,” right? Instead of hopelessly searching in a Google or maybe, embarrassing, asking the preceptor. So in these instances, it&#8217;s played a huge role.&nbsp;</p>



<p><strong>LEE:</strong> Yeah. And when you&#8217;re doing things like that, it can make mistakes. And so what are your views of the reliability of generative AI, at least in the form of ChatGPT?&nbsp;</p>



<p><strong>CHEN: </strong>Yeah, I think into the context of medicine, right, we fear a lot about the hallucinations that these models might have. And it&#8217;s something I&#8217;m always checking for. When I talk with peers about this, we find it most helpful when the model gives us a source linking it back. I think the gold standard nowadays in medicine is using something called <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://learn.uptodate.com/ind_uptodate_brand/brand?utm_source=bing&utm_medium=cpc&utm_campaign=IND_UpToDate_Brand&utm_content=&utm_term=uptodate&msclkid=f6f6c2868b5316eb7278aa06862897fd" target="_blank" rel="noreferrer noopener">UpToDate<span class="sr-only"> (opens in new tab)</span></a> that&#8217;s written by clinicians, for clinicians.&nbsp;</p>



<p>But sometimes searching on UpToDate can be a lot of time as well because it&#8217;s a lot of information to, like, sort through. But nowadays a lot of us are using something called OpenEvidence, which is also an LLM. But they always cite their citations with, like, published literature, right.&nbsp;&nbsp;</p>



<p>So I think being able to be conscious of the downfalls of these models and also being able to have the critical understanding of, like, analyzing the actual literature. I think double checking is just something that we&#8217;ve been also getting really good at.&nbsp;</p>



<p><strong>LEE:</strong> How would you assess student attitudes—med student attitudes—about AI? Is it … the way you&#8217;re coming across is it&#8217;s just a natural part of life. But do people have firm opinions, you know, pro or con, when it comes to AI, and especially AI <em>in</em> medicine?&nbsp;</p>



<p><strong>CHEN:</strong> I think it&#8217;s pretty split right now. I think there&#8217;s the half, kind of, like us, where we&#8217;re very optimistic—cautiously optimistic about, you know, the potential of this, right. It&#8217;s able to, you know, give us that extra information, of being that extra tutor, right. It&#8217;s also able to give us information very quickly, as well.&nbsp;&nbsp;&nbsp;</p>



<p>But I think the other flip side of what a lot of students hesitate to, which I agree, is this loss of the ability to critically think. Something that you can easily do is, you know, give these models, like, relevant information about the patient history and be like, “Give me a 10-list differential,” right.</p>



<p><strong>LEE:</strong> Yes.&nbsp;&nbsp;</p>



<p><strong>CHEN:</strong> And I think it&#8217;s very easy as a student to, you know, [say], “This is difficult. Let me just use what the model says, and we&#8217;ll go with that,” right.&nbsp;</p>



<p>So I think being able to separate that, you know, medical school is a time where, you know, you&#8217;re learning to become a good doctor. And part of that requires the ability to be observant and critically think. Having these models simultaneously might hinder the ability to do that.&nbsp;&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>CHEN:</strong> So I think, you know, the next step is, like, these models can be great—a great tool, absolutely wonderful. But how do you make sure that it&#8217;s not hindering these abilities to critically think?&nbsp;</p>



<p><strong>LEE:</strong> Right. And so when you&#8217;re doing your LIC [longitudinal integrated clerkship] work, these longitudinal experiences, and you&#8217;re in clinic, are you pulling the phone out of your pocket and consulting with AI?&nbsp;</p>



<p><strong>CHEN:</strong> Definitely. And I think my own policy for this, to kind of counter this, is that the night before when I&#8217;m looking over the patient list, the clinic [schedule] of who&#8217;s coming, I&#8217;m always giving it my best effort first.&nbsp;&nbsp;</p>



<p>Like, OK, the chief complaint is maybe just a runny nose for a kid in a pediatric clinic. What could this possibly be? Right? At this point, we&#8217;ve seen a lot. Like, OK, it could be URI [upper respiratory infection], it could be viral, it could be bacterial, you know, and then I go through the—you know, I try to do my due diligence of, like, going through the history and everything like that, right.&nbsp;</p>



<p>But sometimes if it&#8217;s a more complex case, something maybe a presentation I&#8217;ve never seen before, I&#8217;ll still kind of do my best coming up with maybe a differential that might not be amazing. But then I&#8217;ll ask, you know, ChatGPT like, OK, in addition to these ideas, what do you think?&nbsp;&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>CHEN:</strong> Am I missing something? You know, and usually, it gives a pretty good response.&nbsp;</p>



<p><strong>LEE:</strong> You know, that particular idea is something that I think Carey, Zak, and I thought would be happening a lot more today than we&#8217;re observing. And it&#8217;s the idea of a second set of eyes on your work. And somehow, at least our observation is that that isn&#8217;t happening quite as much by today as we thought it might.&nbsp;&nbsp;</p>



<p>And it just seems like one of the really safest and most effective use cases. When you go and you&#8217;re looking at yourself and other fellow medical students, other second-year students, what do you see when it comes to the “second set of eyes” idea?&nbsp;</p>



<p><strong>CHEN:</strong> I think, like, a lot of students are definitely consulting ChatGPT in that regard because, you know, even in the very beginning, we&#8217;re taught to be, like, never miss these red flags, right. So these red flags are always on our differential, but sometimes, it can be difficult to figure out where to place them on that, right.&nbsp;&nbsp;</p>



<p>So I think in addition to, you know, coming up with these differentials, something I&#8217;ve been finding a lot of value [in] is just chatting with these tools to get their rationale behind their thinking, you know.&nbsp;&nbsp;</p>



<p>Something I find really helpful—I think this is also a part of the, kind of, <em>art</em> of medicine—is figuring out what to order, right, what labs to order.&nbsp;&nbsp;</p>



<p><strong>LEE: </strong>Right.</p>



<p><strong>CHEN:</strong> Obviously, you have your order sets that automate some of the things, like in the ED [emergency department], or, like, there are some gold standard imaging things you should do for certain presentations.&nbsp;</p>



<p>But then you chat to, like, 10 different physicians on maybe the next steps after that, and they give you 10 different answers.&nbsp;&nbsp;</p>



<p><strong>LEE:</strong> Yes.&nbsp;&nbsp;</p>



<p><strong>CHEN:</strong> But there&#8217;s never &#8230; I never understand exactly why. It&#8217;s always like, I&#8217;ve just been doing this for all my training, or that&#8217;s how I was taught.&nbsp;&nbsp;</p>



<p>So asking ChatGPT, like, “Why would you do this next?” Or, like, “Is this a good idea?” And seeing the pros and cons has also been really helpful in my learning.&nbsp;</p>



<p><strong>LEE:</strong> Yeah, wow, that&#8217;s super interesting. So now, you know, I&#8217;d like to get into the education you&#8217;re receiving. And, you know, I think it&#8217;s fair to say Kaiser Permanente is very progressive in really trying to be very cutting-edge in how the whole curriculum is set up.&nbsp;&nbsp;</p>



<p>And for the listeners who don&#8217;t know this, I&#8217;m actually on the board of directors of the school and have been since the founding of the school. And I think one of the reasons why I was invited to be on the board is the school really wanted to think ahead and be cutting edge when it comes to technology.&nbsp;&nbsp;</p>



<p>So from where I&#8217;ve sat, I&#8217;ve never been completely satisfied with the amount of tech that has made it into the curriculum. But at the same time, I&#8217;ve also made myself feel better about that just understanding that it&#8217;s sort of unstoppable, that students are so tech-forward already.&nbsp;&nbsp;</p>



<p>But I wanted to delve into a little bit here into what your honest opinions are and your fellow students&#8217; opinions are about whether you feel like you&#8217;re getting adequate training and background <em>formally </em>as part of your medical education when it comes to things like artificial intelligence or other technologies.&nbsp;&nbsp;</p>



<p>What do you think? Are you … would you wish the curriculum would change?&nbsp;</p>



<p><strong>CHEN:</strong> Yeah, I think that&#8217;s a great question.&nbsp;&nbsp;</p>



<p>I think from a tech perspective, the school is very good about implementing, you know, opportunities for us to learn. Like, for example, learning how to use Epic, right, or at Kaiser Permanente, what we call HealthConnect, right. These electronic health records. That, my understanding is, a lot of schools maybe don&#8217;t teach that.&nbsp;&nbsp;</p>



<p>That&#8217;s something where we get training sessions maybe once or twice a year, like, “Hey, here&#8217;s how to make a shortcut in the environment,” right.&nbsp;&nbsp;</p>



<p>So I think from that perspective, the school is really proactive in providing those opportunities, and they make it very easy to find resources for that, too. I think it &#8230;&nbsp;</p>



<p><strong>LEE: </strong>Yeah, I think you&#8217;re pretty much guaranteed to be an Epic black belt by the time you [LAUGHS] finish your degree.&nbsp;&nbsp;</p>



<p><strong>CHEN:</strong> Yes, yes.&nbsp;&nbsp;</p>



<p>But then I think in terms of the aspects of artificial intelligence, I think the school&#8217;s taken a more cautiously optimistic viewpoint. They&#8217;re just kind of looking around right now.&nbsp;&nbsp;</p>



<p>Formally in the curriculum, there hasn&#8217;t been anything around this topic. I believe the fourth-year students last year got a student-led lecture around this topic.&nbsp;&nbsp;</p>



<p>But talking to other peers at other institutions, it looks like it&#8217;s something that&#8217;s very slowly being built into the curriculum, and it seems like a lot of it is actually student-led, you know.&nbsp;&nbsp;</p>



<p>You know, my friend at Feinberg [School of Medicine] was like we just got a session before clerkship about best practices on how to use these tools.&nbsp;&nbsp;</p>



<p>I have another friend at Pitt talking about how they’re leading efforts of maybe incorporating some sort of LLM into their in-house curriculum where students can, instead of clicking around the website trying to find the exact slide, they can just ask this tool, like, “OK. We had class this day. They talked about this &#8230; but can you provide more information?” and it can pull from that.&nbsp;&nbsp;</p>



<p>So I think a lot of this, a lot of it is student-driven. Which I think is really exciting because it begs the question, I think, you know current physicians may not be very well equipped with these tools as well, right?&nbsp;&nbsp;</p>



<p>So maybe they don&#8217;t have a good idea of what exactly is the next steps or what does the curriculum look like. So I think the future in terms of this AI curriculum is really student-led, as well.&nbsp;</p>



<p><strong>LEE:</strong> Yeah, yeah, it&#8217;s really interesting.&nbsp;&nbsp;</p>



<p>I think one of the reasons I think also that that happens is [that] it&#8217;s not just necessarily the curriculum that lags but the accreditation standards. You know, accreditation is really important for medical schools because you want to make sure that anyone who holds an MD, you know, is a bona fide doctor, and so accreditation standards are pretty strictly monitored in most countries, including the United States.&nbsp;&nbsp;</p>



<p>And I think accreditation standards are also—my observation—are slow to understand how to adopt or integrate AI. And it&#8217;s not meant as a criticism. It&#8217;s a big unknown. No one knows exactly what to do and how to do. And so it&#8217;s really interesting to see that, as far as I can tell, I&#8217;ve observed the same thing that you just have seen, that most of the innovation in this area about how AI should be integrated into medical education is coming from the students themselves.&nbsp;&nbsp;</p>



<p>It seems, I think, I&#8217;d like to think it&#8217;s a healthy development. [LAUGHS]</p>



<p><strong>CHEN:</strong> Something tells me maybe the students are a bit better at using these tools,<strong> </strong>as well.&nbsp;&nbsp;</p>



<p>You know, I talk to my preceptors because KP [Kaiser Permanente] also has their own version …&nbsp;</p>



<p><strong>LEE:</strong> Preceptor, maybe we should explain what that is.&nbsp;</p>



<p><strong>CHEN:</strong> Yeah, sorry. So a preceptor is an attending physician, fully licensed, finished residency, and they are essentially your kind of teacher in the clinical environment.&nbsp;&nbsp;</p>



<p>So KP has their own version of some ambient documentation device, as well. And something I always like to ask, you know, like, “Hey, what are your thoughts on these tools,” right?&nbsp;&nbsp;</p>



<p>And it&#8217;s always so polarizing, as well, even among the same specialty. Like, if you ask psychiatrists, which I think is a great use case of these tools, right. My preceptor hates it. Another preceptor next door loves it. [LAUGHTER]&nbsp;</p>



<p>So I think a lot of it’s, like, it’s still, like, a lot of unknowns, like you were mentioning.&nbsp;</p>



<p><strong>LEE:</strong> Right. Well, in fact, I&#8217;m glad you brought that up because one thing that we&#8217;ve been hearing from previous guests a lot when it comes to AI in clinic is about ambient listening by AI, for example, to help set up a clinical note or even write a clinical note.&nbsp;&nbsp;</p>



<p>And another big use case that we heard a lot about that seems to be pretty popular is the use of generative AI to respond to patient messages.&nbsp;&nbsp;</p>



<p>So let&#8217;s start with the clinical note thing. First off, do you have opinions about that technology?&nbsp;</p>



<p><strong>CHEN: </strong>I think it&#8217;s definitely good.&nbsp;&nbsp;</p>



<p>I think especially where, you know, if you&#8217;re in the family medicine environment or pediatric environment where you&#8217;re spending so much time with patients, a note like that is great, right.&nbsp;</p>



<p>I think coming from a strictly medical student standpoint, I think it&#8217;s—honestly, it&#8217;d be great to have—but I think there&#8217;s a lot of learning when you write the note, you know. There&#8217;s a lot of, you know, all of my preceptors talk about, like, when I read your note, you should present it in a way where I can see your thoughts and then once I get to the assessment and plan, it&#8217;s kind of funneling down towards a single diagnosis or a handful of diagnoses. And that&#8217;s, I think, a skill that requires you to practice over time, right.&nbsp;&nbsp;</p>



<p>So a part of me thinks, like, if I had this tool where [it] can just automatically give me a note as a first year, then it takes away from that learning experience, you know.&nbsp;</p>



<p>Even during our first year throughout school, we frequently get feedback from professors and doctors about these notes. And it&#8217;s a lot of feedback. [LAUGHTER] It&#8217;s like, “I don&#8217;t think you should have written that,” “That should be in this section ” … you know, like a medical note or a <em>SOAP</em> note [Subjective, Objective, Assessment, and Plan], where, you know, the <em>subjective</em> is, like, what the patient tells you. <em>Objective </em>is what the physical findings are, and then your assessment of what&#8217;s happening, and then your plan. Like, it&#8217;s very particular, and then I think medicine is so structured in a way, that&#8217;s kind of, like, how everyone does it, right. So kind of going back to the question, I think it&#8217;s a great tool, but I don&#8217;t think it&#8217;s appropriate for a medical student.&nbsp;</p>



<p><strong>LEE:</strong> Yeah, it&#8217;s so interesting to hear you say that. I was … one of our previous guests is the head of R&D at Epic, Seth Hain. He said, “You know, Peter, doctors do a lot of their thinking when they write the note.”&nbsp;</p>



<p>And, of course, Epic is providing ambient, you know, clinical notetaking automation. But he was urging caution because, you know, you&#8217;re saying, well, this is where you&#8217;re learning a lot. But actually, it&#8217;s also a point where, as a doctor, you&#8217;re thinking about the patient. And we do probably have to be careful with how we automate parts of that.&nbsp;&nbsp;</p>



<p>All right. So you&#8217;re gearing up for Step 1 of the USMLE [United States Medical Licensing Examination]. That&#8217;ll be a big multiple-choice exam. Then Step 2 is similar: very, very focused on advanced clinical knowledge. And then Step 3, you know, is a little more interactive.&nbsp;&nbsp;</p>



<p>And so one question that people have had about AI is, you know, how do we regulate the use of AI in medicine? And one of the famous papers that came out of both academia and industry was the concept that you might be able to treat AI like a person and have it go through the same licensing. And this is something that Carey, Zak, and I contemplated in our book.&nbsp;&nbsp;</p>



<p>In the end, at the time we wrote the book, I personally rejected the idea, but I think it&#8217;s still alive. And so I’ve wondered if you have any &#8230; you know, first off, are you opinionated at all about, what should the requirements be for the allowable use of AI in the kind of work that you&#8217;re going to be doing?&nbsp;</p>



<p><strong>CHEN:</strong> Yeah, I think it&#8217;s a tough question because, like, where do you draw that line, right? If you apply the human standards of it&#8217;s passing exams, then yes, in theory, it could be maybe a medical doctor, as well, right? It&#8217;s more empathetic than medical doctors, right? So where do you draw that line?&nbsp;&nbsp;</p>



<p>I think, you know, part of me thinks it&#8217;s maybe it is that human aspect that patients like to connect with, right. And maybe this really is just, like, these tools are just aids in helping, you know, maybe load off some cognitive load, right.&nbsp;&nbsp;</p>



<p>But I think the other part of me, I&#8217;m thinking about this is the next generation who are growing up with this technology, right. They&#8217;re interacting with applications all day. Maybe they&#8217;re on their iPads. They&#8217;re talking to chatbots. They&#8217;re using ChatGPT. This is, kind of, the environment they grew up with. Does that mean they also have increased, like, trust in these tools that maybe our generation or the generations above us don&#8217;t have that value that human connection? Would they value human connection less?&nbsp;&nbsp;</p>



<p>You know, I think those are some troubling thoughts that, you know, yes, at end of the day, maybe I&#8217;m not as smart as these tools, but I can still provide that human comfort. But if, at the end of the day, the future generation doesn&#8217;t really care about that or they perfectly trust these tools because that&#8217;s all they&#8217;ve kind of known, then where do human doctors stand?&nbsp;&nbsp;</p>



<p>I think part of that is, there would be certain specialties where maybe the human connection is more important. The longitudinal aspect of building that trust, I think is important. Family medicine is a great example. I think hematology oncology with cancer treatment.&nbsp;&nbsp;</p>



<p>Obviously, I think anyone&#8217;s not going to be thrilled to hear cancer diagnosis, but something tells me that seeing that on a screen versus maybe a physician prompting you and telling you about that tells me that maybe in those aspects, you know, the human nature, the human touch plays an important role there, too.&nbsp;</p>



<p><strong>LEE: </strong>Yeah, you know, I think it strikes me that it&#8217;s going to be your generation that really is going to set the pattern probably for the next 50 years about how this goes. And it&#8217;s just so interesting because I think a lot will depend on your reactions to things.&nbsp;&nbsp;</p>



<p>So, for example, you know, one thing that is already starting to happen are patients who are coming in armed, you know, with a differential [LAUGHS], you know, that they&#8217;ve developed themselves with the help of ChatGPT. So let me &#8230; you must have thought about these things. So, in fact, has it happened in your clinical work already?&nbsp;</p>



<p><strong>CHEN: </strong>Yeah, I&#8217;ve seen people come into the ED during my ED shift, like emergency department, and they’ll be like, “Oh, I have neck pain and here are all the things that, you know, Chat told me, ChatGPT told me. What do you think &#8230; do I need? I want this lab ordered, that lab ordered.”&nbsp;&nbsp;</p>



<p><strong>LEE: </strong>Right.&nbsp;</p>



<p><strong>CHEN: </strong>And I think my initial reaction is, “Great. Maybe we should do that.” But I think the other reaction is understanding that not everyone has the clinical background of understanding what&#8217;s most important, what do we need to absolutely rule out, right?&nbsp;&nbsp;&nbsp;</p>



<p>So, I think in some regards, I would think that maybe ChatGPT errs on the side of caution, &#8230;&nbsp;</p>



<p><strong>LEE:</strong> Yes.&nbsp;&nbsp;</p>



<p><strong>CHEN: </strong>&#8230; giving maybe patients more extreme examples of what this could be just to make sure that it&#8217;s, in a way, is not missing any red flags as well, right.&nbsp;&nbsp;</p>



<p><strong>LEE:</strong> Right. Yeah.&nbsp;&nbsp;</p>



<p><strong>CHEN:</strong> But I think a lot of this is … what we&#8217;ve been learning is it&#8217;s all about shared decision making with the patient, right. Being able to acknowledge like, “Yeah, [in] that list, most of the stuff is very plausible, but maybe you didn&#8217;t think about this one symptom you have.”&nbsp;&nbsp;</p>



<p>So I think part of it, maybe it&#8217;s a sidebar here, is the idea of prompting, right. You know, they&#8217;ve always talked about all these, you know, prompt engineers, you know, how well can you, like, give it context to answer your question?&nbsp;</p>



<p><strong>LEE: </strong>Yeah.&nbsp;</p>



<p><strong>CHEN:</strong> So I think being able to give these models the correct information and the relevant information and keyword <em>relevant</em>, because relevant is, I guess, where your clinical expertise comes in. Like, what do you give the model, what do you not give? So I think that difference between a medical provider versus maybe your patients is ultimately the difference.&nbsp;</p>



<p><strong>LEE:</strong> Let me press on that a little bit more because you brought up the issue of trust, and trust is <em>so</em> essential for patients to feel good about their medical care.&nbsp;&nbsp;</p>



<p>And I can imagine you&#8217;re a medical student seeing a patient for the first time. So you don&#8217;t have a trust relationship with that patient. And the patient comes in maybe trusting ChatGPT more than you.&nbsp;</p>



<p><strong>CHEN:</strong> Very valid. No. I mean, I get that a lot, surprisingly, you know. [LAUGHTER] Sometimes [they’re] like, “Oh, I don&#8217;t want to see the medical student,” because we always give the patient an option, right. Like, it&#8217;s their time, whether it&#8217;s a clinic visit.&nbsp;&nbsp;</p>



<p>But yeah, those patients, I think it&#8217;s perfectly reasonable. If I heard a second-year medical student was going to be part of my care team, taking that history, I&#8217;d be maybe a little bit concerned, too. Like, are they asking all the right questions? Are they relaying that information back to their attending physician correctly?&nbsp;&nbsp;</p>



<p>So I think a lot of it is, at least from a medical student perspective, is framing it so the patient understands that this is a learning opportunity for the students. And something I do a lot is tell them like, “Hey, like, you know, at the end of the day, there is someone double-checking all my work.”&nbsp;&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>CHEN:</strong> But for those that come in with a list, I sometimes sit down with them, and we&#8217;ll have a discussion, honestly.&nbsp;&nbsp;</p>



<p>I’ll be like, “I don&#8217;t think you have meningitis because you&#8217;re not having a fever. Some of the physical exam maneuvers we did were also negative. So I don&#8217;t think you have anything to worry about that,” you know.&nbsp;&nbsp;</p>



<p>So I think it&#8217;s having that very candid conversation with the patient that helps build that initial trust. Telling them like, “Hey … ”&nbsp;</p>



<p><strong>LEE:</strong> It&#8217;s impressive to hear how even keeled you are about this. You know, I think, of course, and you&#8217;re being very humble saying, well, you know, as a second-year medical student, of course, someone might not, you know, have complete trust. But I think that we will be entering into a world where no doctor is going to be, no matter how experienced or how skilled, is going to be immune from this issue.&nbsp;</p>



<p>So we&#8217;re starting to run toward the end of our time together. And I like to end with one or two more provocative questions.&nbsp;&nbsp;</p>



<p>And so let me start with this one. Undoubtedly, I mean, you&#8217;re close enough to tech and digital stuff, digital health, that you&#8217;re undoubtedly familiar with famous predictions, you know, by Turing and Nobel laureates that someday certain medical specialties, most notably radiology, would be completely supplanted by machines. And more recently, there have been predictions by others, like, you know, Elon Musk, that maybe even some types of surgery would be replaced by machines.&nbsp;&nbsp;</p>



<p>What do you think? Do you have an opinion?&nbsp;</p>



<p><strong>CHEN:</strong> I think <em>replace</em> is a strong term, right. To say that doctors are completely obsolete, I think, is unlikely.&nbsp;&nbsp;</p>



<p>If anything, I think there might be a shift maybe in what it means to be a doctor, right. Undoubtedly, maybe the demands of radiologists are going to go down because maybe more of the simple things can truly be automated, right. And you just have a supervising radiologist whose output is maybe 10 times as maybe 10 single radiologists, right.&nbsp;&nbsp;</p>



<p>So I definitely see a future where the demand of certain specialties might go down.&nbsp;&nbsp;</p>



<p>And I think when I talk about a shift of what it means to be a physician, maybe it&#8217;s not so much diagnostic anymore, right, if these models get so good at, like, just taking in large amounts of information, but maybe it pivots to being really good at understanding the limitations of these models and knowing when to intervene is what it means to be the kind of the next generation of physicians.&nbsp;&nbsp;</p>



<p>I think in terms of surgery, yeah, I think it&#8217;s a concern, but maybe not in the next 50 years. Like those Da Vinci robots are great. I think out of Mayo Clinic, they were demoing some videos of these robots leveraging computer vision to, like, close portholes, like laparoscopic scars. And that&#8217;s something I do in the OR [operating room], right. And we&#8217;re at the same level at this point. [LAUGHTER] So at that point, maybe.&nbsp;&nbsp;</p>



<p>But I think robotics still has to address the understanding of like, what if something goes wrong, right? Who&#8217;s responsible? And I don&#8217;t see a future where a robot is able to react to these, you know, dangerous situations when maybe something goes wrong. You still have to have a surgeon on board to, kind of, take over. So in that regard, that&#8217;s kind of where I see maybe the future going.&nbsp;</p>



<p><strong>LEE:</strong> So last question. You know, when you are thinking about the division of time, one of the themes that we&#8217;ve seen in the previous guests is more and more doctors are doing more technology work, like writing code and so on. And more and more technologists are thinking deeply and getting educated in clinical and preclinical work.&nbsp;&nbsp;</p>



<p>So for you, let&#8217;s look ahead 10 years. What do you see your division of labor to be? Or, you know, how would you … what would you tell your mom then about how you spend a typical day?&nbsp;</p>



<p><strong>CHEN:</strong> Yeah, I mean, I think for me, technology is something I definitely want to be involved in in my line of work, whether it&#8217;s, you know, AI work, whether it&#8217;s improving quality of healthcare through technology.&nbsp;&nbsp;</p>



<p>My perfect division would be maybe still being able to see patients but also balancing some maybe more of these higher-level kind of larger projects. But I think having that division would be something nice.&nbsp;</p>



<p><strong>LEE:</strong> Yeah, well, I think you would be great just from the little bit I know about you. And, Daniel, it&#8217;s been really great chatting with you. I wish you the best of luck, you know, with your upcoming exams and getting past this year two of your medical studies. And perhaps someday I&#8217;ll be your patient.&nbsp;</p>



<p>[TRANSITION MUSIC] &nbsp;</p>



<p><strong>CHEN:</strong> Thank you so much.&nbsp;</p>



<p><strong>LEE:</strong> You know, one of the lucky things about my job is that I pretty regularly get to talk to students at all levels, spanning high school to graduate school. And when I get to talk especially to med students, I&#8217;m always impressed with their intelligence, just how serious they are, and their high energy levels. Daniel is absolutely a perfect example of all that.&nbsp;&nbsp;</p>



<p>Now, it comes across as trite to say that the older generation is less adept at technology adoption than younger people. But actually, there probably is a lot of truth to that. And in the conversation with Daniel, I think he was actually being pretty diplomatic but also clear that he and his fellow med students don&#8217;t necessarily expect the professors in their med school to understand AI as well as they do.&nbsp;</p>



<p>There&#8217;s no doubt in my mind that medical education will have to evolve a lot to help prepare doctors and nurses for an AI future. But where will this evolution come from?&nbsp;&nbsp;</p>



<p>As I reflect on my conversations with Morgan and Daniel, I start to think that it&#8217;s most likely to come from the students themselves. And when you meet people like Morgan and Daniel, it&#8217;s impossible to not be incredibly optimistic about the next generation of clinicians.&nbsp;</p>



<p>[THEME MUSIC]&nbsp;</p>



<p>Another big thank-you to Morgan and Daniel for taking time to share their experiences with us. And to our listeners, thank you for joining us. We have just a couple of episodes left, one on AI’s impact on the operation of public health departments and healthcare systems and another coauthor roundtable. We hope you&#8217;ll continue to tune in.&nbsp;&nbsp;</p>



<p>Until next time.&nbsp;</p>



<p>[MUSIC FADES]&nbsp;</p>

				</span>
			</div>
			<button
				class="action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle"
				aria-expanded="false"
				data-show-less-text="Show less"
				type="button"
				aria-controls="show-more-show-less-toggle-3"
				aria-label="Show more content"
				data-alternate-aria-label="Show less content">
				Show more			</button>
		</div>
	</div>
</div>



<div class="wp-block-buttons is-layout-flex wp-block-buttons-is-layout-flex">
<div class="wp-block-button is-style-outline is-style-outline--4"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/story/the-ai-revolution-in-medicine-revisited/">AI Revolution in Medicine podcast series</a></div>
</div>
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/podcast/navigating-medical-education-in-the-era-of-generative-ai/">Navigating medical education in the era of generative AI</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Xinxing Xu bridges AI research and real-world impact at Microsoft Research Asia &#8211; Singapore</title>
		<link>https://www.microsoft.com/en-us/research/blog/xinxing-xu-bridges-ai-research-and-real-world-impact-at-microsoft-research-asia-singapore/</link>
		
		<dc:creator><![CDATA[Xinxing Xu]]></dc:creator>
		<pubDate>Thu, 24 Jul 2025 01:30:00 +0000</pubDate>
				<category><![CDATA[Research Blog]]></category>
		<guid isPermaLink="false">https://www.microsoft.com/en-us/research/?p=1145385</guid>

					<description><![CDATA[<p>Xinxing Xu is helping shape the work of Microsoft Research Asia – Singapore by turning advanced AI research into real-world solutions. Learn how he collaborates across sectors and disciplines to drive responsible innovation throughout Southeast Asia.</p>
<p>The post <a href="https://www.microsoft.com/en-us/research/blog/xinxing-xu-bridges-ai-research-and-real-world-impact-at-microsoft-research-asia-singapore/">Xinxing Xu bridges AI research and real-world impact at Microsoft Research Asia &#8211; Singapore</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<p>AI has made remarkable progress in recent years, but turning experimental models into tools that work in the real world is still a major challenge. Bridging this gap between innovation and application has shaped the career of Xinxing Xu, principal researcher at <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" target="_blank" href="https://news.microsoft.com/source/asia/2025/07/24/microsoft-research-asia-launches-singapore-lab-to-drive-ai-innovation-industrial-transformation-and-talent-development/?msockid=3b78cf39416866772e40db2040e7673b">Microsoft Research Asia – Singapore<span class="sr-only"> (opens in new tab)</span></a>, and underpins the mission of the lab’s newly established presence in the region.</p>



<figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="960" height="540" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Xinxing-Xu-1-1.jpg" alt="photo of Xinxing Xu standing against a gray background" class="wp-image-1145600" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Xinxing-Xu-1-1.jpg 960w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Xinxing-Xu-1-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Xinxing-Xu-1-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Xinxing-Xu-1-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Xinxing-Xu-1-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Xinxing-Xu-1-1-640x360.jpg 640w" sizes="auto, (max-width: 960px) 100vw, 960px" /><figcaption class="wp-element-caption">Xinxing Xu, Principal Researcher, Microsoft Research Asia – Singapore</figcaption></figure>



<p>“Innovative algorithms can only demonstrate their true value when tested with real-world data and in actual scenarios, where they can be continuously optimized through iteration,” he says.</p>



<p>Xu’s commitment to balancing algorithmic innovation with practical application has shaped his entire career. During his PhD studies at Nanyang Technological University, Singapore, Xu focused on emerging technologies like multiple kernel learning methods and multimodal machine learning. Today he’s applying these techniques to real-world use cases like image recognition and video classification.</p>



<p>After completing his doctorate, he joined the Institute of High Performance Computing at Singapore’s Agency for Science, Technology and Research (A*STAR), where he worked on interdisciplinary projects ranging from medical image recognition to AI systems for detecting defects on facade of buildings. These experiences broadened his perspective and deepened his passion for translating AI into real-world impact.</p>



<p>In 2024, Xu joined Microsoft Research Asia where he began a new chapter focused on bridging between academic research and real-world AI applications.</p>



<p>“Microsoft Research Asia is committed to integrating scientific exploration with real-world applications, which creates a unique research environment,” Xu says. “It brings together top talent and resources, and Microsoft&#8217;s engineering and product ecosystem strongly supports turning research into impactful technology. The lab’s open and inclusive culture encourages innovation with broader societal impact. It reflects the approach to research I’ve always hoped to contribute to.”</p>



	<div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="999693">
		

		<p class="msr-promo__label text-gray-800 text-center text-uppercase">
		<span class="px-4 bg-white display-inline-block font-weight-semibold small">Spotlight: Event Series</span>
	</p>
	
	<div class="row pt-3 pb-4 align-items-center">
						<div class="msr-promo__media col-12 col-md-5">
				<a class="bg-gray-300 display-block" href="https://www.microsoft.com/en-us/research/event/microsoft-research-forum/?OCID=msr_researchforum_MCR_Blog_Promo" aria-label="Microsoft Research Forum" data-bi-cN="Microsoft Research Forum" target="_blank">
					<img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/05/Research-Forum-hero_1400x788.jpg" alt="Research Forum | abstract background with colorful hexagons" />
				</a>
			</div>
			
			<div class="msr-promo__content p-3 px-5 col-12 col-md">

									<h2 class="h4">Microsoft Research Forum</h2>
				
								<p id="microsoft-research-forum" class="large">Join us for a continuous exchange of ideas about research in the era of general AI. Watch the first four episodes on demand.</p>
				
								<div class="wp-block-buttons justify-content-center justify-content-md-start">
					<div class="wp-block-button">
						<a href="https://www.microsoft.com/en-us/research/event/microsoft-research-forum/?OCID=msr_researchforum_MCR_Blog_Promo" aria-describedby="microsoft-research-forum" class="btn btn-brand glyph-append glyph-append-chevron-right" data-bi-cN="Microsoft Research Forum" target="_blank">
							Watch on-demand						</a>
					</div>
				</div>
							</div><!--/.msr-promo__content-->
	</div><!--/.msr-promo__inner-wrap-->
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span>	</div><!--/.msr-promo-->
	


<h2 class="wp-block-heading" id="bringing-cross-domain-expertise-to-ai-s-real-world-frontiers">Bringing cross-domain expertise to AI’s real-world frontiers</h2>



<p>As a key hub in Microsoft Research’s network across Asia, the Singapore lab is guided by a three-part mission: to drive industry-transforming AI deployment, pursue fundamental breakthroughs in the field, and promote responsible, socially beneficial applications of the technology.</p>



<p>To reach these goals, Xu and his colleagues are working closely with local collaborators, combining cross-disciplinary expertise to tackle complex, real-world challenges.</p>



<p>To deliver on that mission, Xinxing Xu and his colleagues are working closely with local collaborators, drawing on cross-disciplinary expertise to solve real-world problems. One key focus is healthcare, where Xu leads a collaboration with Singapore’s SingHealth to explore how AI can support precision medicine. By combining SingHealth’s clinical data with advanced AI models, the team aims to deliver more personalized analyses and sharper diagnostic tools—laying the groundwork for improved patient outcomes.&nbsp;</p>



<p>Beyond healthcare, the team is also targeting key sectors like finance and logistics. By developing domain-specific foundation models and AI agents, they aim to support smarter decision-making and accelerate digital transformation across industries. “Singapore has a strong foundation in these sectors,” Xu notes, “making it an ideal environment for technology validation and iteration.”</p>



<p>The team is also partnering with leading academic institutions, including the National University of Singapore (NUS) and Nanyang Technological University, Singapore (NTU Singapore), to advance the field of spatial intelligence. Their goal is to develop embodied intelligence systems capable of carrying out complex tasks in smart environments.</p>



<p>As AI becomes more deeply embedded in everyday life, researchers at the Singapore lab are also increasingly focused on what they call “societal AI”—building AI systems that are culturally relevant and trustworthy within Southeast Asia’s unique cultural and social contexts. In collaboration with global colleagues, they’re helping to advance a more culturally grounded and responsible approach to AI research in the region.</p>



<h2 class="wp-block-heading" id="microsoft-research-asia-singapore-expanding-global-reach-connecting-regional-innovation">Microsoft Research Asia – Singapore: Expanding global reach, connecting regional innovation&nbsp;</h2>



<p>Realizing AI’s full potential requires more than technical breakthroughs. It also depends on collaboration—across industries, academia, and policy. Only through this intersection of forces can AI move beyond the lab to deliver meaningful societal value.&nbsp;</p>



<p>Singapore’s strengths in science, engineering, and digital governance make it an ideal setting for this kind of work. Its collaborative culture, robust infrastructure, international talent pool, and strong policy support for science and technology make it fertile ground for interdisciplinary research.&nbsp;</p>



<p>This is why Microsoft Research Asia continues to collaborate closely with Singapore’s top universities, research institutions, and industry partners. These partnerships support joint research, talent development, and technical exchange. Building on this foundation, Microsoft Research Asia – Singapore will further deepen its collaboration with NUS, NTU Singapore, and Singapore Management University (SMU) to advance both fundamental and applied research, while equipping the next generation of researchers with real-world experience. In addition, Microsoft Research Asia is fostering academic exchange and strengthening the research ecosystem through summer schools and joint workshops with NUS, NTU Singapore, and SMU.&nbsp;</p>



<p>The launch of the Singapore lab further marks an important step in expanding the company’s global research footprint, serving as a bridge between regional innovation and Microsoft’s global ecosystem. Through its integrated lab network, Microsoft Research fosters the sharing of technologies, methods, and real-world insights, creating a virtuous cycle of innovation.</p>



<p>“We aim to build a research hub in Singapore that is globally connected and deeply rooted in the local ecosystem,” Xu says. “Many breakthroughs come from interdisciplinary and cross-regional collaboration. By breaking boundaries—across disciplines, industries, and geographies—we can drive research that has lasting impact.”</p>



<p>As AI becomes more deeply woven into industry and everyday life, Xu believes that meaningful research must be closely connected to regional development and social well-being. “Microsoft Research Asia – Singapore is a future-facing lab,” he says. “While we push technological frontiers, we’re equally committed to the responsibility of technology—ensuring AI can help address society’s most pressing challenges.”</p>



<p>In a world shaped by global challenges, Xu sees collaboration and innovation as essential to real progress. With Singapore as a launchpad, he and his team are working to extend AI’s impact and value across Southeast Asia and beyond.</p>



<figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1024" height="768" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Xinxing-with-colleagues.jpg" alt="Xingxing Xu (center) with colleagues at Microsoft Research Asia - Singapore " class="wp-image-1145598" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Xinxing-with-colleagues.jpg 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Xinxing-with-colleagues-300x225.jpg 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Xinxing-with-colleagues-768x576.jpg 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Xinxing-with-colleagues-80x60.jpg 80w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Xinxing-with-colleagues-240x180.jpg 240w" sizes="auto, (max-width: 1024px) 100vw, 1024px" /><figcaption class="wp-element-caption">Xingxing Xu (center) with colleagues at Microsoft Research Asia &#8211; Singapore&nbsp;</figcaption></figure>



<h2 class="wp-block-heading" id="three-essential-strengths-for-the-next-generation-of-ai-researchers">Three essential strengths for the next generation of AI researchers</h2>



<p>AI’s progress depends not only on technical breakthroughs but also on the growth and dedication of talent. At Microsoft Research Asia, there is a strong belief that bringing research into the real world requires more than technical coordination—it depends on unlocking the full creativity and potential of researchers.</p>



<p>In Singapore—a regional innovation hub that connects Southeast Asia—Xu and his colleagues are working to push AI beyond the lab and into fields like healthcare, finance, and manufacturing. For young researchers hoping to shape the future of AI, this is a uniquely powerful stage.</p>



<p>To help guide the next generation, Xu shares three pieces of advice:</p>



<ul class="wp-block-list">
<li><strong>Build a strong foundation</strong> – “Core knowledge in machine learning, linear algebra, and probability and statistics is the bedrock of AI research,” Xu says. “A solid theoretical base is essential to remain competitive in a rapidly evolving field. Even today’s hottest trends in generative AI rely on longstanding principles of optimization and model architecture design.” While code generation tools are on the rise, Xu emphasizes that mathematical fundamentals remain essential for understanding and innovating in AI.</li>



<li><strong>Understand real-world applications</strong> – Technical skills alone aren’t enough. Xu encourages young researchers to deeply engage with the problems they’re trying to solve. Only by tightly integrating technology with its context can researchers create truly valuable solutions.<br><br>“In healthcare, for example, researchers may need to follow doctors in clinics to gain a true understanding of clinical workflows. That context helps identify the best entry points for AI deployment. Framing research problems around real-world needs is often more impactful than just tuning model parameters,” Xu says.</li>



<li><strong>Develop interdisciplinary thinking</strong> – Cross-disciplinary collaboration is becoming essential to AI innovation. Xu advises young researchers to learn how to work with experts from other fields to explore new directions together. “These kinds of interactions often spark fresh, creative ideas,” he says.<br><br>Maintaining curiosity is just as important. “Being open to new technologies and fields is what enables researchers to continually break new ground and produce original results.”</li>
</ul>



<p>Xu extends an open invitation to aspiring researchers from all backgrounds to join Microsoft Research Asia – Singapore. “We offer a unique platform that blends cutting-edge research with real-world impact,” he says. “It’s a place where you can work on the frontiers of AI—and see how your work can help transform industries and improve lives.”</p>



<p>To learn more about current openings at the Singapore lab, please visit our <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://jobs.careers.microsoft.com/global/en/job/1849717/Senior-Researcher" target="_blank" rel="noreferrer noopener">careers page<span class="sr-only"> (opens in new tab)</span></a>.&nbsp;</p>
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/blog/xinxing-xu-bridges-ai-research-and-real-world-impact-at-microsoft-research-asia-singapore/">Xinxing Xu bridges AI research and real-world impact at Microsoft Research Asia &#8211; Singapore</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Technical approach for classifying human-AI interactions at scale</title>
		<link>https://www.microsoft.com/en-us/research/blog/technical-approach-for-classifying-human-ai-interactions-at-scale/</link>
		
		<dc:creator><![CDATA[Amber Hoak, David Tittsworth, Kate Lytvynets, Scott Counts, Weiwei Yang, Ben Cutler, Jonathan McLean]]></dc:creator>
		<pubDate>Wed, 23 Jul 2025 16:00:00 +0000</pubDate>
				<category><![CDATA[Research Blog]]></category>
		<guid isPermaLink="false">https://www.microsoft.com/en-us/research/?p=1144422</guid>

					<description><![CDATA[<p>Semantic Telemetry helps LLMs run efficiently, reliably, and in near real-time. Learn about the engineering behind that system, including the trade-offs and lessons learned along the way—from batching strategies to token optimization and orchestration.</p>
<p>The post <a href="https://www.microsoft.com/en-us/research/blog/technical-approach-for-classifying-human-ai-interactions-at-scale/">Technical approach for classifying human-AI interactions at scale</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/SemanticTelemetry3-BlogHeroFeature-1400x788-1.jpg" alt="The image features four white icons on a gradient background that transitions from blue on the left to green on the right. The first icon is a network or molecule structure with interconnected nodes. The second icon shows a stylized person in front of a computer screen. The third icon shows an organization tree with one main node and three nodes branching out side by side below it." class="wp-image-1144473" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/SemanticTelemetry3-BlogHeroFeature-1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/SemanticTelemetry3-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/SemanticTelemetry3-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/SemanticTelemetry3-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/SemanticTelemetry3-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/SemanticTelemetry3-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/SemanticTelemetry3-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/SemanticTelemetry3-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/SemanticTelemetry3-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/SemanticTelemetry3-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w" sizes="auto, (max-width: 1400px) 100vw, 1400px" /></figure>



<p>As large language models (LLMs) become foundational to modern AI systems, the ability to run them at scale—efficiently, reliably, and in near real-time—is no longer a nice-to-have. It’s essential. The <a href="https://www.microsoft.com/en-us/research/project/semantic-telemetry/?msockid=153992cb7df169482b9487167c0968e9">Semantic Telemetry</a> project tackles this challenge by applying LLM-based classifiers to hundreds of millions of sampled, anonymized Bing Chat conversations each week. These classifiers extract signals like user expertise, primary topic, and satisfaction, enabling deeper insight into human-AI interactions and driving continuous system improvement.</p>



<p>But building a pipeline that can handle this volume isn’t just about plugging into an API. It requires a high-throughput, high-performance architecture that can orchestrate distributed processing, manage token and prompt complexity, and gracefully handle the unpredictability of remote LLM endpoints.</p>



<p>In this latest post in our series on Semantic Telemetry, we’ll walk through the engineering behind that system—how we designed for scale from the start, the trade-offs we made, and the lessons we learned along the way. From batching strategies and token optimization and orchestration, we’ll share what it takes to build a real-time LLM classification pipeline.</p>



<p>For additional project background: <a href="https://www.microsoft.com/en-us/research/blog/semantic-telemetry-understanding-how-users-interact-with-ai-systems/">Semantic Telemetry: Understanding how users interact with AI systems</a> and <a href="https://www.microsoft.com/en-us/research/blog/engagement-user-expertise-and-satisfaction-key-insights-from-the-semantic-telemetry-project/">Engagement, user expertise, and satisfaction: Key insights from the Semantic Telemetry Project</a>.</p>



<div class="wp-block-columns is-layout-flex wp-container-core-columns-is-layout-9d6595d7 wp-block-columns-is-layout-flex">
<div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow">
<div class="annotations " data-bi-aN="citation">
	<article class="annotations__list card depth-16 bg-body p-4 ">
		<div class="annotations__list-item">
						<span class="annotations__type d-block text-uppercase font-weight-semibold text-neutral-300 small">Blog</span>
			<a href="https://www.microsoft.com/en-us/research/blog/semantic-telemetry-understanding-how-users-interact-with-ai-systems/" target="_self" class="annotations__link font-weight-semibold text-decoration-none" data-bi-type="annotated-link" aria-label="Semantic Telemetry: Understanding how users interact with AI systems" data-bi-aN="citation" data-bi-cN="Semantic Telemetry: Understanding how users interact with AI systems">
				Semantic Telemetry: Understanding how users interact with AI systems&nbsp;<span class="glyph-append glyph-append-chevron-right glyph-append-xsmall"></span>
			</a>
					</div>
	</article>
</div>
</div>



<div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow">
<div class="annotations " data-bi-aN="citation">
	<article class="annotations__list card depth-16 bg-body p-4 ">
		<div class="annotations__list-item">
						<span class="annotations__type d-block text-uppercase font-weight-semibold text-neutral-300 small">Blog</span>
			<a href="https://www.microsoft.com/en-us/research/blog/engagement-user-expertise-and-satisfaction-key-insights-from-the-semantic-telemetry-project/" target="_self" class="annotations__link font-weight-semibold text-decoration-none" data-bi-type="annotated-link" aria-label="Engagement, user expertise, and satisfaction: Key insights from the Semantic Telemetry Project" data-bi-aN="citation" data-bi-cN="Engagement, user expertise, and satisfaction: Key insights from the Semantic Telemetry Project">
				Engagement, user expertise, and satisfaction: Key insights from the Semantic Telemetry Project&nbsp;<span class="glyph-append glyph-append-chevron-right glyph-append-xsmall"></span>
			</a>
					</div>
	</article>
</div>
</div>
</div>



<h2 class="wp-block-heading" id="system-architecture-highlights">System architecture highlights</h2>



<p>The <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://spark.apache.org/docs/latest/api/python/index.html" target="_blank" rel="noreferrer noopener">Semantic Telemetry pipeline<span class="sr-only"> (opens in new tab)</span></a> is a highly-scalable, highly-configurable, data transformation pipeline. While it follows a familiar ETL structure, several architectural innovations make it uniquely suited for high-throughput LLM integration:</p>



<ul class="wp-block-list">
<li><strong>Hybrid compute engine</strong><br>The pipeline combines the distributed power of PySpark with the speed and simplicity of Polars, enabling it to scale across large datasets or run lightweight jobs in Spark-less environments—without code changes.</li>



<li><strong>LLM-centric transformation layer</strong><br>At the core of the pipeline is a multi-stage transformation process tailored for running across multiple LLM endpoints such that:
<ul class="wp-block-list">
<li>Runs model agnostic. Provides a generic interface for LLMs and adopts model specific interfaces built from a generic interface.</li>



<li>Prompt templates are defined using the Prompty language specification for consistency and reuse, with options for users to include custom prompts.</li>



<li>Parsing and cleaning logic ensures structured, schema-aligned outputs, even when LLM responses are imperfect such as removing extra characters in output, resolving not-exact label matches (i.e. “create” versus “created”) and relabeling invalid classifications.</li>
</ul>
</li>
</ul>



<figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1400" height="650" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Semantic-Telemetry-Pipeline-2_1400px.png" alt="Figure 1. Architecture diagram of LLM workflow" class="wp-image-1144472" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Semantic-Telemetry-Pipeline-2_1400px.png 1400w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Semantic-Telemetry-Pipeline-2_1400px-300x139.png 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Semantic-Telemetry-Pipeline-2_1400px-1024x475.png 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Semantic-Telemetry-Pipeline-2_1400px-768x357.png 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Semantic-Telemetry-Pipeline-2_1400px-240x111.png 240w" sizes="auto, (max-width: 1400px) 100vw, 1400px" /><figcaption class="wp-element-caption">Figure 1. Architecture diagram</figcaption></figure>



<p>The pipeline supports multiple classification tasks (e.g., user expertise, topic, satisfaction) through modular prompt templates and configurable execution paths—making it easy to adapt to new use cases or environments.</p>



<h2 class="wp-block-heading" id="engineering-challenges-solutions">Engineering challenges & solutions</h2>



<p>Building a high-throughput, LLM-powered classification pipeline at scale introduced a range of engineering challenges—from managing latency and token limits to ensuring system resilience. Below are the key hurdles we encountered and how we addressed them.</p>



<h3 class="wp-block-heading" id="llm-endpoint-latency-variability">LLM endpoint latency & variability</h3>



<p><strong>Challenge</strong>: LLM endpoints, especially those hosted remotely (e.g., Azure OpenAI), introduce unpredictable latency due to model load, prompt complexity, and network variability. This made it difficult to maintain consistent throughput across the pipeline.</p>



<p><strong>Solution</strong>: We implemented a combination of:</p>



<ul class="wp-block-list">
<li><strong>Multiple Azure OpenAI endpoints</strong> in rotation to increase throughput and distribute workload. We can analyze throughput and redistribute as needed.</li>



<li><strong>Saving output in intervals</strong> to write data asynchronously in case of network errors.</li>



<li><strong>Utilizing models with higher tokens per minute (TPM)</strong> such as OpenAI’s GPT-4o mini. GPT-4o mini had a 2M TPM limit which is a 25x throughput increase from GPT-4 (80K TPM -> 2M TPM)</li>



<li><strong>Timeouts and retries</strong> with exponential backoff.</li>
</ul>



<h3 class="wp-block-heading" id="evolving-llm-models-prompt-alignment">Evolving LLM models & prompt alignment</h3>



<p><strong>Challenge</strong>: Each new LLM release—such as Phi, Mistral, DeepSeek, and successive generations of GPT (e.g., GPT-3.5, GPT-4, GPT-4 Turbo, GPT-4o)—brings improvements, but also subtle behavioral shifts. These changes can affect classification consistency, output formatting, and even the interpretation of prompts. Maintaining alignment with baseline expectations across models became a moving target.</p>



<p><strong>Solution</strong>: We developed a model evaluation workflow to test prompt alignment across LLM versions:</p>



<ul class="wp-block-list">
<li><strong>Small-sample testing</strong>: We ran the pipeline on a representative sample using the new model and compared the output distribution to a known baseline.</li>



<li><strong>Distribution analysis</strong>: If the new model’s output aligned closely, we scaled up testing. If not, we iteratively <strong>tuned the prompts</strong> and re-ran comparisons.</li>



<li><strong>Interpretation flexibility</strong>: We also recognized that a shift in distribution isn’t always a regression. Sometimes it reflects a more accurate or nuanced classification, especially as models improve.</li>
</ul>



<p>To support this process, we used tools like <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/sammo" target="_blank" rel="noreferrer noopener">Sammo<span class="sr-only"> (opens in new tab)</span></a>, which allowed us to compare outputs across multiple models and prompt variants. This helped us quantify the impact of prompt changes and model upgrades and make informed decisions about when to adopt a new model or adjust our classification schema.</p>



<h3 class="wp-block-heading" id="dynamic-concurrency-scaling-for-llm-calls">Dynamic concurrency scaling for LLM calls</h3>



<p><strong>Challenge</strong>: LLM endpoints frequently encounter rate limits and inconsistent response times under heavy usage. The models&#8217; speeds can also vary, complicating the selection of optimal concurrency levels. Furthermore, users may choose suboptimal settings due to lack of familiarity, and default concurrency configurations are rarely ideal for every situation. Dynamic adjustments based on throughput, measured in various ways, can assist in determining optimal concurrency levels.</p>



<p><strong>Solution</strong>: We implemented a dynamic concurrency control mechanism that proactively adjusts the number of parallel LLM calls based on real-time system behavior:</p>



<ul class="wp-block-list">
<li><strong>External task awareness</strong>: The system monitors the number of parallel tasks running across the pipeline (e.g., Spark executors or async workers) and uses this to inform the initial concurrency level.</li>



<li><strong>Success/failure rate monitoring</strong>: The system tracks the rolling success and failure rates of LLM calls. A spike in failures triggers a temporary reduction in concurrency, while sustained success allows for gradual ramp-up.</li>



<li><strong>Latency-based feedback loop</strong>: Instead of waiting for rate-limit errors, measure the response time of LLM calls. If latency increases, reduce concurrency; if latency decreases and success rates remain high, cautiously scale up.</li>
</ul>



	<div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="1144027">
		

		<p class="msr-promo__label text-gray-800 text-center text-uppercase">
		<span class="px-4 bg-white display-inline-block font-weight-semibold small">PODCAST SERIES</span>
	</p>
	
	<div class="row pt-3 pb-4 align-items-center">
						<div class="msr-promo__media col-12 col-md-5">
				<a class="bg-gray-300 display-block" href="https://www.microsoft.com/en-us/research/story/ai-testing-and-evaluation-learnings-from-science-and-industry/" aria-label="AI Testing and Evaluation: Learnings from Science and Industry" data-bi-cN="AI Testing and Evaluation: Learnings from Science and Industry" target="_blank">
					<img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP2-AI-TE_Hero_Feature_River_No_Text_1400x788.jpg" alt="Illustrated headshots of Daniel Carpenter, Timo Minssen, Chad Atalla, and Kathleen Sullivan for the Microsoft Research Podcast" />
				</a>
			</div>
			
			<div class="msr-promo__content p-3 px-5 col-12 col-md">

									<h2 class="h4">AI Testing and Evaluation: Learnings from Science and Industry</h2>
				
								<p id="ai-testing-and-evaluation-learnings-from-science-and-industry" class="large">Discover how Microsoft is learning from other domains to advance evaluation and testing as a pillar of AI governance.</p>
				
								<div class="wp-block-buttons justify-content-center justify-content-md-start">
					<div class="wp-block-button">
						<a href="https://www.microsoft.com/en-us/research/story/ai-testing-and-evaluation-learnings-from-science-and-industry/" aria-describedby="ai-testing-and-evaluation-learnings-from-science-and-industry" class="btn btn-brand glyph-append glyph-append-chevron-right" data-bi-cN="AI Testing and Evaluation: Learnings from Science and Industry" target="_blank">
							Listen now						</a>
					</div>
				</div>
							</div><!--/.msr-promo__content-->
	</div><!--/.msr-promo__inner-wrap-->
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span>	</div><!--/.msr-promo-->
	


<h2 class="wp-block-heading" id="optimization-experiments">Optimization experiments</h2>



<p>To further improve throughput and efficiency, we ran a series of optimization experiments. Each approach came with trade-offs that we carefully measured.</p>



<h3 class="wp-block-heading" id="batch-endpoints-azure-openai">Batch endpoints (Azure/OpenAI)</h3>



<p>Batch endpoints are a cost-effective, moderately high-throughput way of executing LLM requests. Batch endpoints process large lists of LLM prompts over a 24-hour period, recording responses in a file. They are about 50% cheaper than non-batch endpoints and have separate token limits, enabling increased throughput when used alongside regular endpoints. However, they require at least 24 hours to complete requests and provide lower overall throughput compared to non-batch endpoints, making them unsuitable for situations needing quick results.</p>



<h3 class="wp-block-heading" id="conversation-batching-in-prompts-during-pipeline-runtime">Conversation batching in prompts during pipeline runtime</h3>



<p>Batching multiple conversations for classification at once can significantly increase throughput and reduce token usage, but it may impact the accuracy of results. In our experiment with a domain classifier, classifying 10 conversations simultaneously led to an average of 15-20% of domain assignments changing between repeated runs of the same prompt. To address this, one mitigation approach is to use a grader LLM prompt: first classify the batch, then have the LLM identify any incorrectly classified conversations, and finally re-classify those as needed. While batching offers efficiency gains, it is important to monitor for potential drops in classification quality.</p>



<h3 class="wp-block-heading" id="combining-classifiers-in-a-single-prompt">Combining classifiers in a single prompt</h3>



<p>Combining multiple classifiers into a single prompt increases throughput by allowing one call to the LLM instead of multiple calls. This not only multiplies the overall throughput by the number of classifiers processed but also reduces the total number of tokens used, since the conversation text is only passed in once. However, this approach may compromise classification accuracy, so results should be closely monitored.</p>



<h3 class="wp-block-heading" id="classification-using-text-embeddings">Classification using text embeddings</h3>



<p>An alternative approach is to train custom neural network models for each classifier using only the text embeddings of conversations. This method delivers both cost and time savings by avoiding making multiple LLM requests for every classifier and conversation—instead, the system only needs to request conversation text embeddings once and can reuse these embeddings across all classifier models.</p>



<p>For example, starting with a set of conversations to validate and test the new model, run these conversations through the original prompt-based classifier to generate a set of golden classifications, then obtain text embeddings (using a tool like text-embedding-3-large) for each conversation. These embeddings and their corresponding classifications are used to train a model such as a multi-layer perceptron. In production, the workflow involves retrieving the text embedding for each conversation and passing it through the trained model; if there is a model for each classifier, a single embedding retrieval per conversation suffices for all classifiers.</p>



<p>The benefits of this approach include significantly increased throughput and cost savings—since it’s not necessary to call the LLM for every classifier and conversation. However, this setup can require GPU compute which can increase costs and infrastructure complexity, and the resulting models may not achieve the same accuracy as prompt-based classification methods.</p>



<h3 class="wp-block-heading" id="prompt-compression">Prompt compression</h3>



<p>Compressing prompts by eliminating unnecessary tokens or by using a tool such as <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/LLMLingua" target="_blank" rel="noreferrer noopener">LLMLingua<span class="sr-only"> (opens in new tab)</span></a> to automate prompt compression can optimize classification prompts either ahead of time or in real-time. This approach increases overall throughput and results in cost savings due to a reduced number of tokens, but there are risks: changes to the classifier prompt or conversation text may impact classification accuracy, and depending on the compression technique, it could even decrease throughput if the compression process takes longer than simply sending uncompressed text to the LLM.</p>



<h3 class="wp-block-heading" id="text-truncation">Text truncation</h3>



<p>Truncating conversations to a specific length limits the overall number of tokens sent through an endpoint, offering cost savings and increased throughput like prompt compression. By reducing the number of tokens per request, throughput rises because more requests can be made before reaching the endpoint’s tokens-per-minute (TPM) limit, and costs decrease due to fewer tokens being processed. However, the ideal truncation length depends on both the classifiers and the conversation content, so it’s important to assess how truncation affects output quality before implementation. While this approach brings clear efficiency benefits, it also poses a risk: long conversations may have their most important content cut off, which can reduce classification accuracy.</p>



<h2 class="wp-block-heading" id="conclusion">Conclusion</h2>



<p>Building a scalable, high-throughput pipeline for LLM-based classification is far from trivial. It requires navigating a constantly shifting landscape of model capabilities, prompt behaviors, and infrastructure constraints. As LLMs become faster, cheaper, and more capable, they’re unlocking new possibilities for real-time understanding of human-AI interactions at scale. The techniques we’ve shared represent a snapshot of what’s working today. But more importantly, they offer a foundation for what’s possible tomorrow.</p>
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/blog/technical-approach-for-classifying-human-ai-interactions-at-scale/">Technical approach for classifying human-AI interactions at scale</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>AI Testing and Evaluation: Reflections</title>
		<link>https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-reflections/</link>
		
		<dc:creator><![CDATA[Kathleen Sullivan, Amanda Craig Deckard]]></dc:creator>
		<pubDate>Mon, 21 Jul 2025 16:00:00 +0000</pubDate>
				<category><![CDATA[Microsoft Research Podcast]]></category>
		<guid isPermaLink="false">https://www.microsoft.com/en-us/research/?p=1145035</guid>

					<description><![CDATA[<p>In the series finale, Amanda Craig Deckard returns to examine what Microsoft has learned about testing as a governance tool. She also explores the roles of rigor, standardization, and interpretability in testing and what’s next for Microsoft’s AI governance work.</p>
<p>The post <a href="https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-reflections/">AI Testing and Evaluation: Reflections</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/EP4-AI-TE_Hero_Feature_1400x788.jpg" alt="Illustrated headshots of Amanda Craig Deckard and Kathleen Sullivan." class="wp-image-1145065" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/EP4-AI-TE_Hero_Feature_1400x788.jpg 1400w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/EP4-AI-TE_Hero_Feature_1400x788-300x169.jpg 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/EP4-AI-TE_Hero_Feature_1400x788-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/EP4-AI-TE_Hero_Feature_1400x788-768x432.jpg 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/EP4-AI-TE_Hero_Feature_1400x788-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/EP4-AI-TE_Hero_Feature_1400x788-655x368.jpg 655w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/EP4-AI-TE_Hero_Feature_1400x788-240x135.jpg 240w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/EP4-AI-TE_Hero_Feature_1400x788-640x360.jpg 640w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/EP4-AI-TE_Hero_Feature_1400x788-960x540.jpg 960w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/EP4-AI-TE_Hero_Feature_1400x788-1280x720.jpg 1280w" sizes="auto, (max-width: 1400px) 100vw, 1400px" /></figure>


<div class="wp-block-msr-podcast-container my-4">
	<iframe loading="lazy" src="https://player.blubrry.com/?podcast_id=147140045&modern=1" class="podcast-player" frameborder="0" height="164px" width="100%" scrolling="no" title="Podcast Player"></iframe>
</div>



<p>Generative AI presents a unique challenge and opportunity to reexamine governance practices for the responsible development, deployment, and use of AI. To advance thinking in this space, Microsoft has tapped into the experience and knowledge of experts across domains—from genome editing to cybersecurity—to investigate the role of testing and evaluation as a governance tool.&nbsp;<a href="https://www.microsoft.com/en-us/research/story/ai-testing-and-evaluation-learnings-from-science-and-industry/"><em>AI Testing and Evaluation: Learnings from Science and Industry</em></a>,&nbsp;hosted by Microsoft Research’s&nbsp;<a href="https://www.microsoft.com/en-us/research/people/kasull/">Kathleen Sullivan</a>, explores what the technology industry and policymakers can learn from these fields and how that might help shape the course of AI development.</p>



<p>In the series finale, <a href="https://www.microsoft.com/en-us/research/people/amcraig/" target="_blank" rel="noreferrer noopener">Amanda Craig Deckard</a>, senior director of public policy in Microsoft’s Office of Responsible AI, rejoins Sullivan to discuss what Microsoft has learned about testing as a governance tool and what’s next for the company&#8217;s work in the AI governance space. The pair explores high-level takeaways (i.e., testing is important and challenging!); the roles of rigor, standardization, and interpretability in making testing a reliable governance tool; and the potential for public-private partnerships to help advance not only model-level evaluation but deployment-level evaluation, too.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading h5" id="learn-more-1">Learn more:</h2>



<p><a href="https://www.microsoft.com/en-us/research/blog/learning-from-other-domains-to-advance-ai-evaluation-and-testing/" target="_blank" rel="noreferrer noopener">Learning from other domains to advance AI evaluation and testing</a>&nbsp;<br>Microsoft Research Blog | June 2025&nbsp;</p>



<p><a href="https://www.microsoft.com/en-us/ai/responsible-ai?ef_id=_k_cb05d5950e4f117c457ebda628845b7f_k_&OCID=AIDcmm1o1fzy5i_SEM__k_cb05d5950e4f117c457ebda628845b7f_k_&msclkid=cb05d5950e4f117c457ebda628845b7f" target="_blank" rel="noreferrer noopener">Responsible AI: Ethical policies and practices | Microsoft AI</a>&nbsp;</p>



<div style="height:25px" aria-hidden="true" class="wp-block-spacer"></div>



<section class="wp-block-msr-subscribe-to-podcast subscribe-to-podcast">
	<div class="subscribe-to-podcast__inner border-top border-bottom border-width-2">
		<h2 class="h5 subscribe-to-podcast__heading">
			Subscribe to the <a href="https://www.microsoft.com/en-us/research/podcast">Microsoft Research Podcast</a>:		</h2>
		<ul class="subscribe-to-podcast__list list-unstyled">
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://itunes.apple.com/us/podcast/microsoft-research-a-podcast/id1318021537?mt=2" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="black" viewBox="0 0 32 32">  <path d="M7.12 0c-3.937-0.011-7.131 3.183-7.12 7.12v17.76c-0.011 3.937 3.183 7.131 7.12 7.12h17.76c3.937 0.011 7.131-3.183 7.12-7.12v-17.76c0.011-3.937-3.183-7.131-7.12-7.12zM15.817 3.421c3.115 0 5.932 1.204 8.079 3.453 1.631 1.693 2.547 3.489 3.016 5.855 0.161 0.787 0.161 2.932 0.009 3.817-0.5 2.817-2.041 5.339-4.317 7.063-0.812 0.615-2.797 1.683-3.115 1.683-0.12 0-0.129-0.12-0.077-0.615 0.099-0.792 0.192-0.953 0.64-1.141 0.713-0.296 1.932-1.167 2.677-1.911 1.301-1.303 2.229-2.932 2.677-4.719 0.281-1.1 0.244-3.543-0.063-4.672-0.969-3.595-3.907-6.385-7.5-7.136-1.041-0.213-2.943-0.213-4 0-3.636 0.751-6.647 3.683-7.563 7.371-0.245 1.004-0.245 3.448 0 4.448 0.609 2.443 2.188 4.681 4.255 6.015 0.407 0.271 0.896 0.547 1.1 0.631 0.447 0.192 0.547 0.355 0.629 1.14 0.052 0.485 0.041 0.62-0.072 0.62-0.073 0-0.62-0.235-1.199-0.511l-0.052-0.041c-3.297-1.62-5.407-4.364-6.177-8.016-0.187-0.943-0.224-3.187-0.036-4.052 0.479-2.323 1.396-4.135 2.921-5.739 2.199-2.319 5.027-3.543 8.172-3.543zM16 7.172c0.541 0.005 1.068 0.052 1.473 0.14 3.715 0.828 6.344 4.543 5.833 8.229-0.203 1.489-0.713 2.709-1.619 3.844-0.448 0.573-1.537 1.532-1.729 1.532-0.032 0-0.063-0.365-0.063-0.803v-0.808l0.552-0.661c2.093-2.505 1.943-6.005-0.339-8.296-0.885-0.896-1.912-1.423-3.235-1.661-0.853-0.161-1.031-0.161-1.927-0.011-1.364 0.219-2.417 0.744-3.355 1.672-2.291 2.271-2.443 5.791-0.348 8.296l0.552 0.661v0.813c0 0.448-0.037 0.807-0.084 0.807-0.036 0-0.349-0.213-0.683-0.479l-0.047-0.016c-1.109-0.885-2.088-2.453-2.495-3.995-0.244-0.932-0.244-2.697 0.011-3.625 0.672-2.505 2.521-4.448 5.079-5.359 0.547-0.193 1.509-0.297 2.416-0.281zM15.823 11.156c0.417 0 0.828 0.084 1.131 0.24 0.645 0.339 1.183 0.989 1.385 1.677 0.62 2.104-1.609 3.948-3.631 3.005h-0.015c-0.953-0.443-1.464-1.276-1.475-2.36 0-0.979 0.541-1.828 1.484-2.328 0.297-0.156 0.709-0.235 1.125-0.235zM15.812 17.464c1.319-0.005 2.271 0.463 2.625 1.291 0.265 0.62 0.167 2.573-0.292 5.735-0.307 2.208-0.479 2.765-0.905 3.141-0.589 0.52-1.417 0.667-2.209 0.385h-0.004c-0.953-0.344-1.157-0.808-1.553-3.527-0.452-3.161-0.552-5.115-0.285-5.735 0.348-0.823 1.296-1.285 2.624-1.291z"/></svg>
						<span class="subscribe-to-podcast__link-text">Apple Podcasts</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://subscribebyemail.com/www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M6.4 6a2.392 2.392 0 00-2.372 2.119L16 15.6l11.972-7.481A2.392 2.392 0 0025.6 6H6.4zM4 10.502V22.8a2.4 2.4 0 002.4 2.4h19.2a2.4 2.4 0 002.4-2.4V10.502l-11.365 7.102a1.2 1.2 0 01-1.27 0L4 10.502z"/></svg>
						<span class="subscribe-to-podcast__link-text">Email</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://subscribeonandroid.com/www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M12.414 4.02c-.062.012-.126.023-.18.06a.489.489 0 00-.12.675L13.149 6.3c-1.6.847-2.792 2.255-3.18 3.944h13.257c-.388-1.69-1.58-3.097-3.179-3.944l1.035-1.545a.489.489 0 00-.12-.675.492.492 0 00-.675.135l-1.14 1.68a7.423 7.423 0 00-2.55-.45c-.899 0-1.758.161-2.549.45l-1.14-1.68a.482.482 0 00-.494-.195zm1.545 3.824a.72.72 0 110 1.44.72.72 0 010-1.44zm5.278 0a.719.719 0 110 1.44.719.719 0 110-1.44zM8.44 11.204A1.44 1.44 0 007 12.644v6.718c0 .795.645 1.44 1.44 1.44.168 0 .33-.036.48-.09v-9.418a1.406 1.406 0 00-.48-.09zm1.44 0V21.76c0 .793.646 1.44 1.44 1.44h10.557c.793 0 1.44-.647 1.44-1.44V11.204H9.878zm14.876 0c-.169 0-.33.035-.48.09v9.418c.15.052.311.09.48.09a1.44 1.44 0 001.44-1.44v-6.719a1.44 1.44 0 00-1.44-1.44zM11.8 24.16v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84zm5.759 0v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84z"/></svg>
						<span class="subscribe-to-podcast__link-text">Android</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://open.spotify.com/show/4ndjUXyL0hH1FXHgwIiTWU" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M16 4C9.383 4 4 9.383 4 16s5.383 12 12 12 12-5.383 12-12S22.617 4 16 4zm5.08 17.394a.781.781 0 01-1.086.217c-1.29-.86-3.477-1.434-5.303-1.434-1.937.002-3.389.477-3.403.482a.782.782 0 11-.494-1.484c.068-.023 1.71-.56 3.897-.562 1.826 0 4.365.492 6.171 1.696.36.24.457.725.217 1.085zm1.56-3.202a.895.895 0 01-1.234.286c-2.338-1.457-4.742-1.766-6.812-1.747-2.338.02-4.207.466-4.239.476a.895.895 0 11-.488-1.723c.145-.041 2.01-.5 4.564-.521 2.329-.02 5.23.318 7.923 1.995.419.26.547.814.286 1.234zm1.556-3.745a1.043 1.043 0 01-1.428.371c-2.725-1.6-6.039-1.94-8.339-1.942h-.033c-2.781 0-4.923.489-4.944.494a1.044 1.044 0 01-.474-2.031c.096-.023 2.385-.55 5.418-.55h.036c2.558.004 6.264.393 9.393 2.23.497.292.663.931.371 1.428z"/></svg>
						<span class="subscribe-to-podcast__link-text">Spotify</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M6.667 4a2.676 2.676 0 00-2.612 2.13v.003c-.036.172-.055.35-.055.534v18.666c0 .183.019.362.055.534v.003a2.676 2.676 0 002.076 2.075h.002c.172.036.35.055.534.055h18.666A2.676 2.676 0 0028 25.333V6.667a2.676 2.676 0 00-2.13-2.612h-.003A2.623 2.623 0 0025.333 4H6.667zM8 8h1.333C17.42 8 24 14.58 24 22.667V24h-2.667v-1.333c0-6.618-5.382-12-12-12H8V8zm0 5.333h1.333c5.146 0 9.334 4.188 9.334 9.334V24H16v-1.333A6.674 6.674 0 009.333 16H8v-2.667zM10 20a2 2 0 11-.001 4.001A2 2 0 0110 20z"/></svg>
						<span class="subscribe-to-podcast__link-text">RSS Feed</span>
					</a>
				</li>
					</ul>
	</div>
</section>


<div class="wp-block-msr-show-more">
	<div class="bg-neutral-100 p-5">
		<div class="show-more-show-less" data-mount="show-more-show-less">
			<div>
				<span>
					

<h2 class="wp-block-heading" id="transcript">Transcript</h2>



<p>[MUSIC]&nbsp;</p>



<p><strong>KATHLEEN SULLIVAN:</strong> Welcome to <em>AI Testing and Evaluation: Learnings from Science and Industry</em>. I’m your host, Kathleen Sullivan.&nbsp;</p>



<p>As generative AI continues to advance, Microsoft has gathered a range of experts—from genome editing to cybersecurity—to share how their fields approach evaluation and risk assessment. Our goal is to learn from their successes and their stumbles to move the science and practice of AI testing forward. In this series, we’ll explore how these insights might help guide the future of AI development, deployment, and responsible use.&nbsp;</p>



<p>[MUSIC ENDS]&nbsp;</p>



<p>For our final episode of the series, I’m thrilled to once again be joined by Amanda Craig Deckard, senior director of public policy in Microsoft’s Office of Responsible AI.&nbsp;</p>



<p>Amanda, welcome back to the podcast!</p>



				</span>
				<span id="show-more-show-less-toggle-5" class="show-more-show-less-toggleable-content">
					



<p><strong>AMANDA CRAIG DECKARD:</strong> Thank you so much.</p>



<p><strong>SULLIVAN:</strong> In our intro episode, you really helped set the stage for this series. And it’s been great, because since then, we’ve had the pleasure of speaking with governance experts about genome editing, pharma, medical devices, cybersecurity, and we’ve also gotten to spend some time with our own Microsoft responsible AI leaders and hear reflections from them.</p>



<p>And here’s what stuck with me, and I’d love to hear from you on this, as well: testing builds trust; context is shaping risk; and every field is really thinking about striking its own balance between pre-deployment testing and post-deployment monitoring.</p>



<p>So drawing on what you’ve learned from the workshop and the case studies, what headline insights do you think matter the most for AI governance?</p>



<p><strong>CRAIG DECKARD:</strong> It&#8217;s been really interesting to learn from all of these different domains, and there are, you know, lots of really interesting takeaways.&nbsp;</p>



<p>I think a starting point for me is actually pretty similar to where you landed, which is just that testing is really important for trust, and it&#8217;s also really <em>hard</em> [LAUGHS] to figure out exactly, you know, how to get it right, how to make sure that you&#8217;re addressing risks, that you&#8217;re not constraining innovation, that you are recognizing that a lot of the industry that&#8217;s impacted is really different. You have small organizations, you have large organizations, and you want to enable that opportunity that is enabled by the technology across the board.&nbsp;</p>



<p>And so it&#8217;s just difficult to, kind of, get all of these dynamics right, especially when, you know, I think we heard from other domains, testing is not some, sort of, like, oh, simple thing, right. There&#8217;s not this linear path from, like, A to B where you just test the one thing and you&#8217;re done.&nbsp;</p>



<p><strong>SULLIVAN: </strong>Right.</p>



<p><strong>CRAIG DECKARD:</strong> It&#8217;s complex, right. Testing is multistage. There&#8217;s a lot of testing by different actors. There are a lot of different purposes for which you might test. As I think it was Dan Carpenter who talked about it&#8217;s not just about testing for safety. It&#8217;s also about testing for efficacy and building confidence in the right dosage for pharmaceuticals, for example. And that&#8217;s across the board for all of these domains, right. That you&#8217;re really thinking about the performance of the technology. You&#8217;re thinking about safety. You&#8217;re trying to also calibrate for efficiency.</p>



<p>And so those tradeoffs, every expert shared that navigating those is really challenging. And also that there were real impacts to early choices in the, sort of, governance of risk in these different domains and the development of the testing, sort of, expectations, and that in some cases, this had been difficult to reverse, which also just layers on that complexity and that difficulty in a different way. So that’s the super high-level takeaway. But maybe if I could just quickly distill, like, three takeaways that I think really are applicable to AI in a bit more of a granular way.</p>



<p>You know, one is about, how is the testing exactly used? For what purpose? And the second is what emphasis there is on this pre- versus post-deployment testing and monitoring. And then the third is how rigid versus adaptive the, sort of, testing regimes or frameworks are in these different domains.&nbsp;</p>



<p>So on the first—how is testing used?—so is testing something that impacts market entry, for example? Or is it something that might be used more for informing how risk is evolving in the domain and how broader risk management strategies might need to be applied? We have examples, like the pharmaceutical or medical device industry experts with whom you spoke, that&#8217;s really, you know, testing … there is a pre-deployment requirement. So that&#8217;s one question.&nbsp;</p>



<p>The second is this emphasis on pre- versus post-deployment testing and monitoring, and we really did see across domains that in many cases, there is a desire for both pre- and post-deployment, sort of, testing and monitoring, but also that, sort of, naturally in these different domains, a degree of emphasis on one or the other had evolved and that had a real impact on governance and tradeoffs.&nbsp;</p>



<p>And the third is just how rigid versus adaptive these testing and evaluation regimes or frameworks are in these different domains. We saw, you know, in some domains, the testing requirements were more rigid as you might expect in more of the pharmaceutical or medical devices industries, for example. And in other domains, there was this more, sort of, adaptive approach to how testing might get used. So, for example, in the case of our other general-purpose technologies, you know, you spoke with Alta Charo on genome editing, and in our case studies, we also explored this in the context of nanotechnology. In those general-purpose technology domains, there is more emphasis on downstream or application-context testing that is more, sort of, adaptive to the use scenario of the technology and, you know, having that work in conjunction with testing more at the, kind of, level of the technology itself.</p>



<p><strong>SULLIVAN:</strong> I want to double-click on a number of the things we just talked about. But actually, before we go too much deeper, a question on if there&#8217;s anything that really surprised you or challenged maybe some of your own assumptions in this space from some of the discussions that we had over the series.&nbsp;</p>



<p><strong>CRAIG DECKARD:</strong> Yeah. You know, I know I&#8217;ve already just mentioned this pre- versus post-deployment testing and monitoring issue, but it was something that was very interesting to me and in some ways surprised me or made me just realize something that I hadn&#8217;t fully connected before, about how these, sort of, regimes might evolve in different contexts and why. And in part, I couldn&#8217;t help but bring the context I have from cybersecurity policy into this, kind of, processing of what we learned and reflection because there was a real contrast for me between the pharmaceutical industry and the cybersecurity domain when I think about the emphasis on pre- versus post-deployment monitoring.</p>



<p>And on the one hand, we have in the pharmaceutical domain a real emphasis that has developed around pre-market testing. And there is also an expectation in some circumstances in the pharmaceutical domain for post-deployment testing, as well. But as we learned from our experts in that domain, there has naturally been a real, kind of, emphasis on the pre-market portion of that testing. And in reality, <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/The-History-and-Evolution-of-Testing-in-Pharmaceutical-Regulation.pdf">even where post-market monitoring is required and post-market testing is required, it does not always actually happen</a>.<strong> </strong>And the experts really explained that, you know, part of it is just the incentive structure around the emphasis around, you know, the testing as a pre-market, sort of, entry requirement. And also just the resources that exist among regulators, right. There&#8217;s limited resources, right. And so there are just choices and tradeoffs that they need to make in their own, sort of, enforcement work.</p>



<p>And then on the other hand, you know, in cybersecurity, I never thought about the, kind of, emphasis on things like coordinated vulnerability disclosure and bug bounties that have really developed in the cybersecurity domain. But it&#8217;s a really important part of how we secure technology and enhance cybersecurity over time, where we have these norms that have developed where, you know, security researchers are doing really important research. They&#8217;re finding vulnerabilities in products. And we have norms developed where they report those to the companies that are in a position to address those vulnerabilities. And in some cases, those companies actually pay, through bug bounties, the researchers. And perhaps in some ways, the role of coordinated vulnerability disclosure and bug bounties has evolved the way that it has because there hasn&#8217;t been as much emphasis on the pre-market testing across the board at least in the context of software.</p>



<p>And so you look at those two industries and it was interesting to me to study them to some extent in contrast with each other as this way that the incentives and the resources that need to be applied to testing, sort of, evolve to address where there&#8217;s, kind of, more or less emphasis.</p>



<p><strong>SULLIVAN:</strong> It&#8217;s a great point. I mean, I think what we&#8217;re hearing—and what you&#8217;re saying—is just exactly this choice … like, is there a binary choice between focusing on pre-deployment testing or post-deployment monitoring? And, you know, I think our assumption is that we need to do both. But I&#8217;d love to hear from you on that.&nbsp;</p>



<p><strong>CRAIG DECKARD:</strong> Absolutely. I think we need to do both. I&#8217;m very persuaded by this inclination always that there&#8217;s value in trying to really do it all in a risk management context.&nbsp;</p>



<p>And also, we know one of the principles of risk management is you have to prioritize because there are finite resources. And I think that&#8217;s where we get to this challenge in really thinking deeply, especially as we&#8217;re in the early days of AI governance, and we need to be very thoughtful about, you know, tradeoffs that we may not want to be making but we are because, again, these are finite choices and we, kind of, can&#8217;t help but put our finger on the dial in different directions with our choices that, you know, it&#8217;s going to be very difficult to have, sort of, equal emphasis on both. And we need to invest in both, but we need to be very <em>deliberate</em> about the roles of each and how they complement each other and who does which and how we use what we learn from pre- versus post-deployment testing and monitoring.</p>



<p><strong>SULLIVAN:</strong> Maybe just spending a little bit more time here … you know, a lot of attention goes into testing models upstream, but risk often shows up once they&#8217;re wired into real products and workflows. How much does deployment context change the risk picture from your perspective?&nbsp;</p>



<p><strong>CRAIG DECKARD:</strong> Yeah, I … such an important question. I really agree that there has been a lot of emphasis to date on, sort of, testing models upstream, the AI model evaluation. And it&#8217;s also really important that we bring more attention into evaluation at the system or application level. And I actually see that in governance conversations, this <em>is</em> actually increasingly raised, this need to have system-level evaluation. We see this across regulation. We also see it in the context of just organizations trying to put in governance requirements for how their organization is going to operate in deploying this technology.&nbsp;</p>



<p>And there&#8217;s a gap today in terms of best practices around system-level testing, perhaps even more than model-level evaluation. And it&#8217;s really important because in a lot of cases, the deployment context really does impact the risk picture, especially with AI, which is a general-purpose technology, and we really saw this in our study of other domains that represented general-purpose technology.&nbsp;</p>



<p>So in the <a href="https://www.microsoft.com/en-us/research/publication/learning-from-other-domains-to-advance-ai-evaluation-and-testing-the-regulatory-landscape-of-nanoscience-and-nanotechnology-and-applications-to-future-ai-regulation/" target="_blank" rel="noreferrer noopener">case study that you can find online on nanotechnology</a>, you know, there&#8217;s a real distinction between the risk evaluation and the governance of nanotechnology in different deployment contexts. So the chapter that our expert on nanotechnology wrote really goes into incredibly interesting detail around, you know, deployment of nanotechnology in the context of, like, chemical applications versus consumer electronics versus pharmaceuticals versus construction and how the way that nanoparticles are basically delivered in all those different deployment contexts, as well as, like, what the risk of the actual use scenario is just varies so much. And so there&#8217;s a real need to do that kind of risk evaluation and testing in the deployment context, and this difference in terms of risks and what we learned in these other domains where, you know, there are these different approaches to trying to really think about and gain efficiencies and address risks at a horizontal level versus, you know, taking a real sector-by-sector approach. And to some extent, it seems like it&#8217;s more time intensive to do that sectoral deployment-specific work. And at the same time, perhaps there are efficiencies to be gained by actually doing the work in the context in which, you know, you have a better understanding of the risk that can result from really deploying this technology.&nbsp;</p>



<p>And ultimately, [LAUGHS] really what we also need to think about here is probably, in the end, just like pre- and post-deployment testing, you need both. Not probably; certainly!</p>



<p>So effectively we need to think about evaluation at the model level and the system level as being really important. And it&#8217;s really important to get system evaluation right so that we can actually get trust in this technology in deployment context so we enable adoption in low- and in high-risk deployments in a way that means that we&#8217;ve done risk evaluation in each of those contexts in a way that really makes sense in terms of the resources that we need to apply and ultimately we are able to unlock more applications of this technology in a risk-informed way.</p>



<p><strong>SULLIVAN:</strong> That&#8217;s great. I mean, I couldn&#8217;t agree more. I think these contexts, the approaches are so important for trust and adoption, and I&#8217;d love to hear from you, what do we need to advance AI evaluation and testing in our ecosystem? What are some of the big gaps that you&#8217;re seeing, and what role can different stakeholders play in filling them? And maybe an add-on, actually: is there some sort of network effect that could 10x our testing capacity?&nbsp;</p>



<p><strong>CRAIG DECKARD:</strong> Absolutely. So there&#8217;s a lot of work that needs to be done, and there&#8217;s a lot of work in process to really level up our whole evaluation and testing ecosystem. We learned, across domains, that there’s really a need to advance our thinking and our practice in three areas: rigor of testing; standardization of methodologies and processes; and interpretability of test results.&nbsp;</p>



<p>So what we mean by rigor is that we are ensuring that what we are ultimately evaluating in terms of risks is defined in a scientifically valid way and we are able to measure against that risk in a scientifically valid way.&nbsp;</p>



<p>By standardization, what we mean is that there&#8217;s really an accepted and well-understood and, again, a scientifically valid methodology for doing that testing and for actually producing artifacts out of that testing that are meeting those standards. And that sets us up for the final portion on interpretability, which is, like, really the process by which you can trust that the testing has been done in this rigorous and standardized way and that then you have artifacts that result from the testing process that can really be used in the risk management context because they can be interpreted, right.&nbsp;</p>



<p>We understand how to, like, apply weight to them for our risk-management decisions. We actually are able to interpret them in a way that perhaps they inform other downstream risk mitigations that address the risks that we see through the testing results and that we actually understand what limitations apply to the test results and why they may or may not be valid in certain, sort of, deployment contexts, for example, and especially in the context of other risk mitigations that we need to apply. So there&#8217;s a need to advance all three of those things—rigor, standardization, and interpretability—to level up the whole testing and evaluation ecosystem.&nbsp;</p>



<p>And when we think about what actors should be involved in that work … really <em>everybody</em>, which is both complex to orchestrate but also really important. And so, you know, you need to have the entire value chain involved in really advancing this work. You need the model developers, but you also need the system developers and deployers that are really engaged in advancing the science of evaluation and advancing how we are using these testing artifacts in the risk management process.&nbsp;</p>



<p>When we think about what could actually 10x our testing capacity—that&#8217;s the dream, right? We all want to accelerate our progress in this space. You know,&nbsp;I think we need work across all three of those areas of rigor, standardization, and interpretability, but I think one that will really help accelerate our progress across the board is that standardization work, because ultimately, you&#8217;re going to need to have these tests be done and applied across so many different contexts, and ultimately, while we want the whole value chain engaged in the development of the thinking and the science and the standards in this space, we also need to realize that not every organization is necessarily going to have the capacity to, kind of, contribute to developing the ways that we create and use these tests. And there are going to be many organizations that are going to benefit from there being standardization of the methodologies and the artifacts that they can pick up and use.</p>



<p>One thing that I know we&#8217;ve heard throughout this podcast series from our experts in other domains, including Timo [Minssen] in the medical devices context and Ciaran [Martin] in the cybersecurity context, is that there&#8217;s been a recognition, as those domains have evolved, that there&#8217;s a need to calibrate our, sort of, expectations for different actors in the ecosystem and really understand that small businesses, for example, just cannot apply the same degree of resources that others may be able to, to do testing and evaluation and risk management. And so the benefit of having standardized approaches is that those organizations are able to, kind of, integrate into the broader supply chain ecosystem and apply their own, kind of, risk management practices in their own context in a way that is more efficient.&nbsp;</p>



<p>And finally, the last stakeholder that I think is really important to think about in terms of partnership across the ecosystem to really advance the whole testing and evaluation work that needs to happen is government partners, right, and thinking beyond the value chain, the AI supply chain, and really thinking about public-private partnership. That&#8217;s going to be incredibly important to advancing this ecosystem.</p>



<p>You know, I think there&#8217;s been real progress already in the AI evaluation and testing ecosystem in the public-private partnership context. We have been really supportive of the work of the <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.nist.gov/system/files/documents/2024/11/20/Mission%20Statement%20-%20International%20Network%20of%20AISIs.pdf" target="_blank" rel="noreferrer noopener">International Network of AI Safety and Security Institutes<span class="sr-only"> (opens in new tab)</span></a><a id="_ftnref1" href="#_ftn1">[1]<span class="sr-only"> (opens in new tab)</span></a> and the <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.nist.gov/caisi" target="_blank" rel="noreferrer noopener">Center for AI Standards and Innovation<span class="sr-only"> (opens in new tab)</span></a> that all allow for that kind of public-private partnership on actually testing and advancing the science and best practices around standards.&nbsp;</p>



<p>And there are other innovative, kind of, partnerships, as well, in the ecosystem. You know, Singapore has recently launched their <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://aiverifyfoundation.sg/ai-assurance-pilot/" target="_blank" rel="noreferrer noopener">Global AI Assurance Pilot<span class="sr-only"> (opens in new tab)</span></a> findings. And that effort really paired application deployers and testers so that consequential impacts at deployment could really be tested. And that&#8217;s a really fruitful, sort of, effort that complements the work of these institutes and centers that are more focused on evaluation at the model level, for example.</p>



<p>And in general, you know, I think that there&#8217;s just really a lot of benefits for us thinking expansively about what we can accomplish through deep, meaningful public-private partnership in this space. I&#8217;m really excited to see where we can go from here with building on, you know, partnerships across AI supply chains and with governments and public-private partnerships.&nbsp;</p>



<p><strong>SULLIVAN:</strong> I couldn&#8217;t agree more. I mean, this notion of more engagement across the ecosystem and value chain is super important for us and informs how we think about the space completely.&nbsp;</p>



<p>If you could invite any other industry to the next workshop, maybe quantum safety, space tech, even gaming, who&#8217;s on your wish list? And maybe what are some of the things you&#8217;d want to go deeper on?&nbsp;</p>



<p><strong>CRAIG DECKARD:</strong> This is something that we really welcome feedback on if anyone listening has ideas about other domains that would be interesting to study. I will say, I think I shared at the outset of this podcast series, the domains that we added in this round of our efforts in studying other domains actually all came from feedback that we received from, you know, folks we’d engaged with our first study of other domains and multilateral, sort of, governance institutions. And so we&#8217;re really keen to think about what other domains could be interesting to study. And we are also keen to go deeper, building on what we learned in this round of effort going forward.&nbsp;</p>



<p>One of the areas that I am particularly really interested in is going deeper on, what, sort of, transparency and information sharing about risk evaluation and testing will be really useful to share in different contexts? So across the AI supply chain, what is the information that&#8217;s going to be really meaningful to share between developers and deployers of models and systems and those that are ultimately using this technology in particular deployment contexts? And, you know, I think that we could have much to learn from other general-purpose technologies like genome editing and nanotechnology and cybersecurity, where we could learn a bit more about the kinds of information that they have shared across the development and deployment life cycle and how that has strengthened risk management in general as well as provided a really strong feedback loop around testing and evaluation. What kind of testing is most useful to do at what point in the life cycle, and what artifacts are most useful to share as a result of that testing and evaluation work?</p>



<p>I&#8217;ll say, as Microsoft, we have been really investing in how we are sharing information with our various stakeholders. We also have been engaged with others in industry in reporting what we&#8217;ve done in the context of the <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.oecd.org/en/about/news/press-releases/2025/02/oecd-launches-global-framework-to-monitor-application-of-g7-hiroshima-ai-code-of-conduct.html" target="_blank" rel="noreferrer noopener">Hiroshima AI Process, or <em>HAIP</em>, Reporting Framework<span class="sr-only"> (opens in new tab)</span></a>. This is an effort that is really just in its first round of really exploring how this kind of reporting can be really additive to risk management understanding. And again, I think there&#8217;s real opportunity here to look at this kind of reporting and understand, you know, what&#8217;s valuable for stakeholders and where is there opportunity to go further in really informing value chains and policymakers and the public about AI risk and opportunity and what can we learn again from other domains that have done this kind of work over decades to really refine that kind of information sharing. </p>



<p><strong>SULLIVAN:</strong> It&#8217;s really great to hear about all the advances that we&#8217;re making on these reports. I&#8217;m guessing a lot of the metrics in there are technical, but sociotechnical impacts—jobs, maybe misinformation, well-being—are harder to score. What new measurement ideas are you excited about, and do you have any thoughts on, like, who needs to pilot those?</p>



<p><strong>CRAIG DECKARD:</strong> Yeah, it&#8217;s an incredibly interesting question that I think also just speaks to, you know, the breadth of, sort of, testing and evaluation that&#8217;s needed at different points along that AI life cycle and really not getting lost in one particular kind of testing or another pre- or post-deployment and thinking expansively about the risks that we&#8217;re trying to address through this testing.&nbsp;</p>



<p>You know, for example, even with the UK&#8217;s <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.aisi.gov.uk/" target="_blank" rel="noreferrer noopener">AI Security Institute<span class="sr-only"> (opens in new tab)</span></a> that has just recently launched a new program, a new team, that&#8217;s focused on societal resilience research. I think it&#8217;s going to be a really important area from a sociotechnical impact perspective to bring some focus into as this technology is more widely deployed. Are we understanding the impacts over time as different people and different cultures adopt and use this technology for different purposes?&nbsp;</p>



<p>And I think that&#8217;s an area where there really is opportunity for greater public-private partnership in this research. Because we all share this long-term interest in ensuring that this technology is really serving people and we have to understand the impacts so that we understand, you know, what adjustments we can actually pursue sooner upstream to address those impacts and make sure that this technology is really going to work for all of us and in a way that is consistent with the societal values that we want.&nbsp;</p>



<p><strong>SULLIVAN:</strong> So, Amanda, looking ahead, I would love to hear just what&#8217;s going to be on your radar? What&#8217;s top of mind for you in the coming weeks?</p>



<p><strong>CRAIG DECKARD:</strong> Well, we are certainly continuing to process all the learnings that we&#8217;ve had from studying these domains. It’s really been a rich set of insights that we want to make sure we, kind of, fully take advantage of. And, you know, I think these hard questions and, you know, real opportunities to be thoughtful in these early days of AI governance are not, sort of, going away or being easily resolved soon. And so I think we continue to see value in really learning from others, thinking about what&#8217;s distinct in the AI context, but also what we can apply in terms of what other domains have learned.</p>



<p><strong>SULLIVAN:</strong> Well, Amanda, it has been such a special experience for me to help illuminate the work of the Office of Responsible AI and our team in Microsoft Research, and [MUSIC] it&#8217;s just really special to see all of the work that we&#8217;re doing to help set the standard for responsible development and deployment of AI. So thank you for joining us today, and thanks for your reflections and discussion.</p>



<p>And to our listeners, thank you so much for joining us for the series. We really hope you enjoyed it!&nbsp;To check out all of our episodes, visit <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://aka.ms/AITestingandEvaluation" target="_blank" rel="noreferrer noopener">aka.ms/AITestingandEvaluation<span class="sr-only"> (opens in new tab)</span></a>, and if you want to learn more about how Microsoft approaches AI governance, you can visit <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://microsoft.com/RAI" target="_blank" rel="noreferrer noopener">microsoft.com/RAI<span class="sr-only"> (opens in new tab)</span></a>.&nbsp;</p>



<p>See you next time!&nbsp;</p>



<p>[MUSIC FADES] </p>

				</span>
			</div>
			<button
				class="action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle"
				aria-expanded="false"
				data-show-less-text="Show less"
				type="button"
				aria-controls="show-more-show-less-toggle-5"
				aria-label="Show more content"
				data-alternate-aria-label="Show less content">
				Show more			</button>
		</div>
	</div>
</div>



<div class="wp-block-buttons is-layout-flex wp-block-buttons-is-layout-flex">
<div class="wp-block-button is-style-outline is-style-outline--6"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/story/ai-testing-and-evaluation-learnings-from-science-and-industry/">AI Testing and Evaluation podcast series</a></div>
</div>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p><a id="_ftn1" href="#_ftnref1">[1]<span class="sr-only"> (opens in new tab)</span></a> Since the launch of the International Network of AI Safety Institutes, the <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.gov.uk/government/news/tackling-ai-security-risks-to-unleash-growth-and-deliver-plan-for-change" target="_blank" rel="noreferrer noopener">UK renamed its institute the AI Security Institute<span class="sr-only"> (opens in new tab)</span></a>.</p>
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-reflections/">AI Testing and Evaluation: Reflections</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>CollabLLM: Teaching LLMs to collaborate with users</title>
		<link>https://www.microsoft.com/en-us/research/blog/collabllm-teaching-llms-to-collaborate-with-users/</link>
		
		<dc:creator><![CDATA[Shirley Wu, Michel Galley, Baolin Peng, Swadheen Shukla, Jianfeng Gao]]></dc:creator>
		<pubDate>Tue, 15 Jul 2025 18:00:00 +0000</pubDate>
				<category><![CDATA[Research Blog]]></category>
		<guid isPermaLink="false">https://www.microsoft.com/en-us/research/?p=1144588</guid>

					<description><![CDATA[<p>Recipient of an ICML 2025 Outstanding Paper Award, CollabLLM improves how LLMs collaborate with users, including knowing when to ask questions and how to adapt tone and communication style to different situations. This approach helps move AI toward more user-centric and trustworthy systems.</p>
<p>The post <a href="https://www.microsoft.com/en-us/research/blog/collabllm-teaching-llms-to-collaborate-with-users/">CollabLLM: Teaching LLMs to collaborate with users</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM-BlogHeroFeature-1400x788_Update.jpg" alt="CollabLLM blog hero | flowchart diagram starting in the upper left corner with an icon of two overlapping chat bubbles; arrow pointing right to an LLM network node icon; branching down to show three simulated users; right arrow to a "Reward" box" class="wp-image-1144599" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM-BlogHeroFeature-1400x788_Update.jpg 1400w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM-BlogHeroFeature-1400x788_Update-300x169.jpg 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM-BlogHeroFeature-1400x788_Update-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM-BlogHeroFeature-1400x788_Update-768x432.jpg 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM-BlogHeroFeature-1400x788_Update-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM-BlogHeroFeature-1400x788_Update-655x368.jpg 655w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM-BlogHeroFeature-1400x788_Update-240x135.jpg 240w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM-BlogHeroFeature-1400x788_Update-640x360.jpg 640w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM-BlogHeroFeature-1400x788_Update-960x540.jpg 960w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM-BlogHeroFeature-1400x788_Update-1280x720.jpg 1280w" sizes="auto, (max-width: 1400px) 100vw, 1400px" /></figure>



<p>Large language models (LLMs) can solve complex puzzles in seconds, yet they sometimes struggle over simple conversations. When these AI tools make assumptions, overlook key details, or neglect to ask clarifying questions, the result can erode trust and derail real-world interactions, where nuance is everything.</p>



<p>A key reason these models behave this way lies in how they’re trained and evaluated. Most benchmarks use isolated, single-turn prompts with clear instructions. Training methods tend to optimize for the model&#8217;s next response, not its contribution to a successful, multi-turn exchange. But real-world interaction is dynamic and collaborative. It relies on context, clarification, and shared understanding.</p>



<h2 class="wp-block-heading" id="user-centric-approach-to-training">User-centric approach to training&nbsp;</h2>



<p>To address this, we’re exploring ways to train LLMs with users in mind. Our approach places models in simulated environments that reflect the back-and-forth nature of real conversations. Through reinforcement learning, these models improve through trial and error, for example, learning when to ask questions and how to adapt tone and communication style to different situations. This user-centric approach helps bridge the gap between how LLMs are typically trained and how people actually use them.  </p>



<p>This is the concept behind <a href="https://www.microsoft.com/en-us/research/publication/collabllm-from-passive-responders-to-active-collaborators/">CollabLLM<span class="sr-only"> (opens in new tab)</span></a>, recipient of an <a href="https://www.microsoft.com/en-us/research/event/icml-2025/">ICML<span class="sr-only"> (opens in new tab)</span></a> <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://icml.cc/virtual/2025/awards_detail" target="_blank" rel="noreferrer noopener">Outstanding Paper Award<span class="sr-only"> (opens in new tab)</span></a>. This training framework helps LLMs improve through simulated multi-turn interactions, as illustrated in Figure 1. The core insight behind CollabLLM is simple: in a constructive collaboration, the value of a response isn’t just in its immediate usefulness, but in how it contributes to the overall success of the conversation. A clarifying question might seem like a delay but often leads to better outcomes. A quick answer might appear useful but can create confusion or derail the interaction.</p>



<figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1365" height="486" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM_fig1.png" alt="Figure 1 compares two training strategies for Large Language Models: a standard non-collaborative method and our proposed collaborative method (CollabLLM). On the left, the standard method uses a preference/reward dataset with single-turn evaluations, resulting in a model that causes ineffective interactions. The user gives feedback, but the model generates multiple verbose and unsatisfactory responses, requiring many back-and-forth turns. On the right, CollabLLM incorporates collaborative simulation during training, using multi-turn interactions and reinforcement learning. After training, the model asks clarifying questions (e.g., tone preferences), receives focused user input, and quickly generates tailored, high-impact responses." class="wp-image-1144594" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM_fig1.png 1365w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM_fig1-300x107.png 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM_fig1-1024x365.png 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM_fig1-768x273.png 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM_fig1-240x85.png 240w" sizes="auto, (max-width: 1365px) 100vw, 1365px" /><figcaption class="wp-element-caption">Figure 1. Diagram comparing two training approaches for LLMs. (a) The standard method lacks user-agent collaboration and uses single-turn rewards, leading to an inefficient conversation. (b) In contrast, CollabLLM simulates multi-turn user-agent interactions during training, enabling it to learn effective collaboration strategies and produce more efficient dialogues.</figcaption></figure>



<p>CollabLLM puts this collaborative approach into practice with a simulation-based training loop, illustrated in Figure 2. At any point in a conversation, the model generates multiple possible next turns by engaging in a dialogue with a simulated user.</p>



<figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="970" height="438" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM_fig2.png" alt="Figure 2 illustrates the overall training procedure of CollabLLM. For a given conversational input, the LLM and a user simulator are used to sample conversation continuations. The sampled conversations are then scored using a reward model that utilizes various multiturn-aware rewards, which are then in turn used to update parameters of the LLM." class="wp-image-1144593" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM_fig2.png 970w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM_fig2-300x135.png 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM_fig2-768x347.png 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM_fig2-240x108.png 240w" sizes="auto, (max-width: 970px) 100vw, 970px" /><figcaption class="wp-element-caption">Figure 2: Simulation-based training process used in CollabLLM</figcaption></figure>



<p>The system uses a sampling method to extend conversations turn by turn, choosing likely responses for each participant (the AI agent or the simulated user), while adding some randomness to vary the conversational paths. The goal is to expose the model to a wide variety of conversational scenarios, helping it learn more effective collaboration strategies.</p>



	<div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="1144028">
		

		<p class="msr-promo__label text-gray-800 text-center text-uppercase">
		<span class="px-4 bg-white display-inline-block font-weight-semibold small">PODCAST SERIES</span>
	</p>
	
	<div class="row pt-3 pb-4 align-items-center">
						<div class="msr-promo__media col-12 col-md-5">
				<a class="bg-gray-300 display-block" href="https://www.microsoft.com/en-us/research/story/the-ai-revolution-in-medicine-revisited/" aria-label="The AI Revolution in Medicine, Revisited" data-bi-cN="The AI Revolution in Medicine, Revisited" target="_blank">
					<img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/Episode7-PeterBillSebastien-AIRevolution_Hero_Feature_River_No_Text_1400x788.jpg" alt="Illustrated headshot of Bill Gates, Peter Lee, and Sébastien Bubeck" />
				</a>
			</div>
			
			<div class="msr-promo__content p-3 px-5 col-12 col-md">

									<h2 class="h4">The AI Revolution in Medicine, Revisited</h2>
				
								<p id="the-ai-revolution-in-medicine-revisited" class="large">Join Microsoft’s Peter Lee on a journey to discover how AI is impacting healthcare and what it means for the future of medicine.</p>
				
								<div class="wp-block-buttons justify-content-center justify-content-md-start">
					<div class="wp-block-button">
						<a href="https://www.microsoft.com/en-us/research/story/the-ai-revolution-in-medicine-revisited/" aria-describedby="the-ai-revolution-in-medicine-revisited" class="btn btn-brand glyph-append glyph-append-chevron-right" data-bi-cN="The AI Revolution in Medicine, Revisited" target="_blank">
							Listen now						</a>
					</div>
				</div>
							</div><!--/.msr-promo__content-->
	</div><!--/.msr-promo__inner-wrap-->
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span>	</div><!--/.msr-promo-->
	


<p>To each simulated conversation, we applied multiturn-aware reward (MR) functions, which assess how the model’s response at the given turn influences the entire trajectory of the conversation. We sampled multiple conversational follow-ups from the model, such as statements, suggestions, questions, and used MR to assign a reward to each based on how well the conversation performed in later turns. We based these scores on automated metrics that reflect key factors like goal completion, conversational efficiency, and user engagement.</p>



<p>To score the sampled conversations, we used task-specific metrics and metrics from an LLM-as-a-judge framework, which supports efficient and scalable evaluation. For metrics like engagement, a judge model rates each sampled conversation on a scale from 0 to 1.</p>



<p>The MR of each model response was computed by averaging the scores from the sampled conversations, originating from the model response. Based on the score, the model updates its parameters using established reinforcement learning algorithms like Proximal Policy Optimization (PPO) or Direct Preference Optimization (DPO).</p>



<p>We tested CollabLLM through a combination of automated and human evaluations, detailed in the <a href="https://www.microsoft.com/en-us/research/publication/collabllm-from-passive-responders-to-active-collaborators/">paper</a>. One highlight is a user study involving 201 participants in a document co-creation task, shown in Figure 3. We compared CollabLLM to a baseline trained with single-turn rewards and to a second, more proactive baseline prompted to ask clarifying questions and take other proactive steps. CollabLLM outperformed both, producing higher-quality documents, better interaction ratings, and faster task completion times.</p>



<figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1860" height="492" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM_fig3.png" alt="Figure 3 shows the main results of our user study on a document co-creation task, by comparing a baseline, a proactive baseline, and CollabLLM. CollabLLM outperformed the two baselines. Relative to the best baseline, CollabLLM yields improved document quality rating (+0.12), interaction rating (+0.14), and a reduction of average time spent by the user (-129 seconds)." class="wp-image-1144597" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM_fig3.png 1860w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM_fig3-300x79.png 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM_fig3-1024x271.png 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM_fig3-768x203.png 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM_fig3-1536x406.png 1536w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM_fig3-240x63.png 240w" sizes="auto, (max-width: 1860px) 100vw, 1860px" /><figcaption class="wp-element-caption">Figure 3: Results of the user study in a document co-creation task comparing CollabLLM to a baseline trained with single-turn rewards.</figcaption></figure>



<h2 class="wp-block-heading" id="designing-for-real-world-collaboration">Designing for real-world collaboration</h2>



<p>Much of today’s AI research focuses on fully automated tasks, models working without input from or interaction with users. But many real-world applications depend on people in the loop: as users, collaborators, or decision-makers. Designing AI systems that treat user input not as a constraint, but as essential, leads to systems that are more accurate, more helpful, and ultimately more trustworthy.</p>



<p>This work is driven by a core belief: the future of AI depends not just on intelligence, but on the ability to collaborate effectively. And that means confronting the communication breakdowns in today’s systems.</p>



<p>We see CollabLLM as a step in that direction, training models to engage in meaningful multi-turn interactions, ask clarifying questions, and adapt to context. In doing so, we can build systems designed to work <em>with</em> people—not around them.</p>
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/blog/collabllm-teaching-llms-to-collaborate-with-users/">CollabLLM: Teaching LLMs to collaborate with users</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>AI Testing and Evaluation: Learnings from cybersecurity</title>
		<link>https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-cybersecurity/</link>
		
		<dc:creator><![CDATA[Kathleen Sullivan, Ciaran Martin, Tori Westerhoff]]></dc:creator>
		<pubDate>Mon, 14 Jul 2025 16:00:00 +0000</pubDate>
				<category><![CDATA[Microsoft Research Podcast]]></category>
		<guid isPermaLink="false">https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-cybersecurity/</guid>

					<description><![CDATA[<p>Drawing on his previous work as the UK’s cybersecurity chief, Professor Ciaran Martin explores differentiated standards and public-private partnerships in cybersecurity, and Microsoft’s Tori Westerhoff examines the insights through an AI red-teaming lens.</p>
<p>The post <a href="https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-cybersecurity/">AI Testing and Evaluation: Learnings from cybersecurity</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/EP3-AI-TE_Hero_Feature_1400x788-1.jpg" alt="Illustrated images of Kathleen Sullivan, Ciaran Martin, and Tori Westerhoff for the Microsoft Research podcast" class="wp-image-1144391" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/EP3-AI-TE_Hero_Feature_1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/EP3-AI-TE_Hero_Feature_1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/EP3-AI-TE_Hero_Feature_1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/EP3-AI-TE_Hero_Feature_1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/EP3-AI-TE_Hero_Feature_1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/EP3-AI-TE_Hero_Feature_1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/EP3-AI-TE_Hero_Feature_1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/EP3-AI-TE_Hero_Feature_1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/EP3-AI-TE_Hero_Feature_1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/EP3-AI-TE_Hero_Feature_1400x788-1-1280x720.jpg 1280w" sizes="auto, (max-width: 1400px) 100vw, 1400px" /></figure>


<div class="wp-block-msr-podcast-container my-4">
	<iframe loading="lazy" src="https://player.blubrry.com/?podcast_id=146975694&modern=1" class="podcast-player" frameborder="0" height="164px" width="100%" scrolling="no" title="Podcast Player"></iframe>
</div>



<p>Generative AI presents a unique challenge and opportunity to reexamine governance practices for the responsible development, deployment, and use of AI. To advance thinking in this space, Microsoft has tapped into the experience and knowledge of experts across domains—from genome editing to cybersecurity—to investigate the role of testing and evaluation as a governance tool.&nbsp;<a href="https://www.microsoft.com/en-us/research/story/ai-testing-and-evaluation-learnings-from-science-and-industry/"><em>AI Testing and Evaluation: Learnings from Science and Industry</em></a>,&nbsp;hosted by Microsoft Research’s&nbsp;<a href="https://www.microsoft.com/en-us/research/people/kasull/">Kathleen Sullivan</a>, explores what the technology industry and policymakers can learn from these fields and how that might help shape the course of AI development.</p>



<p>In this episode, Sullivan speaks with Professor <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.bsg.ox.ac.uk/people/ciaran-martin" target="_blank" rel="noreferrer noopener">Ciaran Martin<span class="sr-only"> (opens in new tab)</span></a> of the University of Oxford about risk assessment and testing in the field of cybersecurity. They explore the importance of differentiated standards for organizations of varying sizes, the role of public-private partnerships, and the opportunity to embed security into emerging technologies from the outset. Later, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.victoriawesterhoff.com/" target="_blank" rel="noreferrer noopener">Tori Westerhoff<span class="sr-only"> (opens in new tab)</span></a>, a principal director on the Microsoft AI Red Team, joins Sullivan to talk about identifying vulnerabilities in AI products and services. Westerhoff describes AI security in terms she’s heard cybersecurity professionals use for their work—a team sport—and points to cybersecurity’s establishment of a shared language and understanding of risk as a model for AI security.</p>



<div class="wp-block-group msr-pattern-link-list is-layout-flow wp-block-group-is-layout-flow">
<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading h5" id="learn-more-1">Learn more:</h2>



<ul class="wp-block-list list-unstyled">
<li><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" target="_blank" href="https://devblogs.microsoft.com/foundry/ai-red-teaming-agent-preview/">Introducing AI Red Teaming Agent: Accelerate your AI safety and security journey with Azure AI Foundry<span class="sr-only"> (opens in new tab)</span></a><br>Azure AI Foundry Blog | April 2025</li>



<li><a href="https://www.microsoft.com/en-us/research/publication/lessons-from-red-teaming-100-generative-ai-products/">Lessons From Red Teaming 100 Generative AI Products</a><br>Publication | January 2025</li>



<li><a href="https://www.microsoft.com/en-us/research/blog/learning-from-other-domains-to-advance-ai-evaluation-and-testing/">Learning from other domains to advance AI evaluation and testing</a><br>Microsoft Research Blog | June 2025</li>



<li><a href="https://www.microsoft.com/en-us/ai/responsible-ai?ef_id=_k_cb05d5950e4f117c457ebda628845b7f_k_&OCID=AIDcmm1o1fzy5i_SEM__k_cb05d5950e4f117c457ebda628845b7f_k_&msclkid=cb05d5950e4f117c457ebda628845b7f" target="_blank" rel="noreferrer noopener">Responsible AI: Ethical policies and practices | Microsoft AI</a></li>



<li><a href="https://www.microsoft.com/en-us/research/focus-area/ai-and-microsoft-research/" target="_blank" rel="noreferrer noopener">AI and Microsoft Research</a></li>
</ul>
</div>



<div style="height:25px" aria-hidden="true" class="wp-block-spacer"></div>



<section class="wp-block-msr-subscribe-to-podcast subscribe-to-podcast">
	<div class="subscribe-to-podcast__inner border-top border-bottom border-width-2">
		<h2 class="h5 subscribe-to-podcast__heading">
			Subscribe to the <a href="https://www.microsoft.com/en-us/research/podcast">Microsoft Research Podcast</a>:		</h2>
		<ul class="subscribe-to-podcast__list list-unstyled">
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://itunes.apple.com/us/podcast/microsoft-research-a-podcast/id1318021537?mt=2" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="black" viewBox="0 0 32 32">  <path d="M7.12 0c-3.937-0.011-7.131 3.183-7.12 7.12v17.76c-0.011 3.937 3.183 7.131 7.12 7.12h17.76c3.937 0.011 7.131-3.183 7.12-7.12v-17.76c0.011-3.937-3.183-7.131-7.12-7.12zM15.817 3.421c3.115 0 5.932 1.204 8.079 3.453 1.631 1.693 2.547 3.489 3.016 5.855 0.161 0.787 0.161 2.932 0.009 3.817-0.5 2.817-2.041 5.339-4.317 7.063-0.812 0.615-2.797 1.683-3.115 1.683-0.12 0-0.129-0.12-0.077-0.615 0.099-0.792 0.192-0.953 0.64-1.141 0.713-0.296 1.932-1.167 2.677-1.911 1.301-1.303 2.229-2.932 2.677-4.719 0.281-1.1 0.244-3.543-0.063-4.672-0.969-3.595-3.907-6.385-7.5-7.136-1.041-0.213-2.943-0.213-4 0-3.636 0.751-6.647 3.683-7.563 7.371-0.245 1.004-0.245 3.448 0 4.448 0.609 2.443 2.188 4.681 4.255 6.015 0.407 0.271 0.896 0.547 1.1 0.631 0.447 0.192 0.547 0.355 0.629 1.14 0.052 0.485 0.041 0.62-0.072 0.62-0.073 0-0.62-0.235-1.199-0.511l-0.052-0.041c-3.297-1.62-5.407-4.364-6.177-8.016-0.187-0.943-0.224-3.187-0.036-4.052 0.479-2.323 1.396-4.135 2.921-5.739 2.199-2.319 5.027-3.543 8.172-3.543zM16 7.172c0.541 0.005 1.068 0.052 1.473 0.14 3.715 0.828 6.344 4.543 5.833 8.229-0.203 1.489-0.713 2.709-1.619 3.844-0.448 0.573-1.537 1.532-1.729 1.532-0.032 0-0.063-0.365-0.063-0.803v-0.808l0.552-0.661c2.093-2.505 1.943-6.005-0.339-8.296-0.885-0.896-1.912-1.423-3.235-1.661-0.853-0.161-1.031-0.161-1.927-0.011-1.364 0.219-2.417 0.744-3.355 1.672-2.291 2.271-2.443 5.791-0.348 8.296l0.552 0.661v0.813c0 0.448-0.037 0.807-0.084 0.807-0.036 0-0.349-0.213-0.683-0.479l-0.047-0.016c-1.109-0.885-2.088-2.453-2.495-3.995-0.244-0.932-0.244-2.697 0.011-3.625 0.672-2.505 2.521-4.448 5.079-5.359 0.547-0.193 1.509-0.297 2.416-0.281zM15.823 11.156c0.417 0 0.828 0.084 1.131 0.24 0.645 0.339 1.183 0.989 1.385 1.677 0.62 2.104-1.609 3.948-3.631 3.005h-0.015c-0.953-0.443-1.464-1.276-1.475-2.36 0-0.979 0.541-1.828 1.484-2.328 0.297-0.156 0.709-0.235 1.125-0.235zM15.812 17.464c1.319-0.005 2.271 0.463 2.625 1.291 0.265 0.62 0.167 2.573-0.292 5.735-0.307 2.208-0.479 2.765-0.905 3.141-0.589 0.52-1.417 0.667-2.209 0.385h-0.004c-0.953-0.344-1.157-0.808-1.553-3.527-0.452-3.161-0.552-5.115-0.285-5.735 0.348-0.823 1.296-1.285 2.624-1.291z"/></svg>
						<span class="subscribe-to-podcast__link-text">Apple Podcasts</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://subscribebyemail.com/www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M6.4 6a2.392 2.392 0 00-2.372 2.119L16 15.6l11.972-7.481A2.392 2.392 0 0025.6 6H6.4zM4 10.502V22.8a2.4 2.4 0 002.4 2.4h19.2a2.4 2.4 0 002.4-2.4V10.502l-11.365 7.102a1.2 1.2 0 01-1.27 0L4 10.502z"/></svg>
						<span class="subscribe-to-podcast__link-text">Email</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://subscribeonandroid.com/www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M12.414 4.02c-.062.012-.126.023-.18.06a.489.489 0 00-.12.675L13.149 6.3c-1.6.847-2.792 2.255-3.18 3.944h13.257c-.388-1.69-1.58-3.097-3.179-3.944l1.035-1.545a.489.489 0 00-.12-.675.492.492 0 00-.675.135l-1.14 1.68a7.423 7.423 0 00-2.55-.45c-.899 0-1.758.161-2.549.45l-1.14-1.68a.482.482 0 00-.494-.195zm1.545 3.824a.72.72 0 110 1.44.72.72 0 010-1.44zm5.278 0a.719.719 0 110 1.44.719.719 0 110-1.44zM8.44 11.204A1.44 1.44 0 007 12.644v6.718c0 .795.645 1.44 1.44 1.44.168 0 .33-.036.48-.09v-9.418a1.406 1.406 0 00-.48-.09zm1.44 0V21.76c0 .793.646 1.44 1.44 1.44h10.557c.793 0 1.44-.647 1.44-1.44V11.204H9.878zm14.876 0c-.169 0-.33.035-.48.09v9.418c.15.052.311.09.48.09a1.44 1.44 0 001.44-1.44v-6.719a1.44 1.44 0 00-1.44-1.44zM11.8 24.16v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84zm5.759 0v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84z"/></svg>
						<span class="subscribe-to-podcast__link-text">Android</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://open.spotify.com/show/4ndjUXyL0hH1FXHgwIiTWU" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M16 4C9.383 4 4 9.383 4 16s5.383 12 12 12 12-5.383 12-12S22.617 4 16 4zm5.08 17.394a.781.781 0 01-1.086.217c-1.29-.86-3.477-1.434-5.303-1.434-1.937.002-3.389.477-3.403.482a.782.782 0 11-.494-1.484c.068-.023 1.71-.56 3.897-.562 1.826 0 4.365.492 6.171 1.696.36.24.457.725.217 1.085zm1.56-3.202a.895.895 0 01-1.234.286c-2.338-1.457-4.742-1.766-6.812-1.747-2.338.02-4.207.466-4.239.476a.895.895 0 11-.488-1.723c.145-.041 2.01-.5 4.564-.521 2.329-.02 5.23.318 7.923 1.995.419.26.547.814.286 1.234zm1.556-3.745a1.043 1.043 0 01-1.428.371c-2.725-1.6-6.039-1.94-8.339-1.942h-.033c-2.781 0-4.923.489-4.944.494a1.044 1.044 0 01-.474-2.031c.096-.023 2.385-.55 5.418-.55h.036c2.558.004 6.264.393 9.393 2.23.497.292.663.931.371 1.428z"/></svg>
						<span class="subscribe-to-podcast__link-text">Spotify</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M6.667 4a2.676 2.676 0 00-2.612 2.13v.003c-.036.172-.055.35-.055.534v18.666c0 .183.019.362.055.534v.003a2.676 2.676 0 002.076 2.075h.002c.172.036.35.055.534.055h18.666A2.676 2.676 0 0028 25.333V6.667a2.676 2.676 0 00-2.13-2.612h-.003A2.623 2.623 0 0025.333 4H6.667zM8 8h1.333C17.42 8 24 14.58 24 22.667V24h-2.667v-1.333c0-6.618-5.382-12-12-12H8V8zm0 5.333h1.333c5.146 0 9.334 4.188 9.334 9.334V24H16v-1.333A6.674 6.674 0 009.333 16H8v-2.667zM10 20a2 2 0 11-.001 4.001A2 2 0 0110 20z"/></svg>
						<span class="subscribe-to-podcast__link-text">RSS Feed</span>
					</a>
				</li>
					</ul>
	</div>
</section>


<div class="wp-block-msr-show-more">
	<div class="bg-neutral-100 p-5">
		<div class="show-more-show-less" data-mount="show-more-show-less">
			<div>
				<span>
					

<h2 class="wp-block-heading" id="transcript">Transcript</h2>



<p>[MUSIC]</p>



<p><strong>KATHLEEN SULLIVAN: </strong>Welcome to <em>AI Testing and Evaluation: Learnings from Science and Industry</em>. I&#8217;m your host, Kathleen Sullivan.</p>



<p>As generative AI continues to advance, Microsoft has gathered a range of experts—from genome editing to cybersecurity—to share how their fields approach evaluation and risk assessment. Our goal is to learn from their successes and their stumbles to move the science and practice of AI testing forward. In this series, we&#8217;ll explore how these insights might help guide the future of AI development, deployment, and responsible use.</p>



<p>[MUSIC ENDS]</p>



<p>Today, I&#8217;m excited to welcome Ciaran Martin to the podcast to explore testing and risk assessment in cybersecurity. Ciaran is a professor of practice in the management of public organizations at the University of Oxford. He had previously founded and served as chief executive of the National Cyber Security Centre within the UK&#8217;s intelligence, security, and cyber agency.</p>



<p>And after our conversation, we&#8217;ll talk to Microsoft&#8217;s Tori Westerhoff, a principal director on Microsoft’s AI Red Team, about how we should think about these insights in the context of AI.</p>



<p>Hi, Ciaran. Thank you so much for being here today.</p>



				</span>
				<span id="show-more-show-less-toggle-7" class="show-more-show-less-toggleable-content">
					



<p><strong>CIARAN MARTIN:</strong> Well, thanks so much for inviting me. It’s great to be here.</p>



<p><strong>SULLIVAN:</strong> Ciaran, before we get into some regulatory specifics, it&#8217;d be great to hear a little bit more about your origin story, and just take us to that day—who tapped you on the shoulder and said, “Ciaran, we need you to run a national cyber center! Do you fancy building one?”</p>



<p><strong>MARTIN:</strong> You could argue that I owe my job to Edward Snowden. Not an obvious thing to say. So the National Cyber Security Centre, which didn&#8217;t exist at the time—I was invited to join the British government&#8217;s cybersecurity effort in a leadership role—is now a subset of GCHQ. That&#8217;s the digital intelligence agency. The equivalent in the US obviously is the NSA [National Security Agency]. It had been convulsed by the Snowden disclosures. It was an unprecedented challenge.</p>



<p>I was a 17-year career government fixer with some national security experience. So I was asked to go out and help with the policy response, the media response, the legal response. But I said, look, any crisis, even one as big as this, is over one way or the other in six months. What should I do long term? And they said, well, we were thinking of asking you to try to help transform our cybersecurity mission. So the National Cyber Security Centre was born, and I was very proud to lead it, and all in all, I did it for seven years from startup to handing it on to somebody else.</p>



<p><strong>SULLIVAN:</strong> I mean, it&#8217;s incredible. And just building on that, people spend a significant portion of their lives online now with a variety of devices, and maybe for listeners who are newer to cybersecurity, could you give us the 90-second lightning talk? Kind of, what does risk assessment and testing look like in this space?</p>



<p><strong>MARTIN:</strong> Well, risk assessment and testing, I think, are two different things. You can&#8217;t defend everything. If you defend everything, you&#8217;re defending nothing. So broadly speaking, organizations face three threats. One is complete disruption of their systems. So just imagine not being able to access your system. The second is data protection, and that could be sensitive customer information. It could be intellectual property. And the third is, of course, you could be at risk of just straightforward being stolen from. I mean, you don&#8217;t want any of them to happen, but you have to have a hierarchy of harm.</p>



<p><strong>SULLIVAN: </strong>Yes.</p>



<p><strong>MARTIN: </strong>So that&#8217;s your risk assessment.</p>



<p>The testing side, I think, is slightly different. One of the paradoxes, I think, of cybersecurity is for such a scientific, data-rich subject, the sort of metrics about what works are very, very hard to come by. So you&#8217;ve got boards and corporate leadership and senior governmental structures, and they say, “Look, how do I run this organization safely and securely?” And a cybersecurity chief within the organization will say, “Well, we could get this capability in.” Well, the classic question for a leadership team to ask is, well, what risk and harm will this reduce, by how much, and what&#8217;s the cost-benefit analysis? And we find that <em>really</em> hard.</p>



<p>So that&#8217;s really where testing and assurance comes in. And also as technology changes so fast, we have to figure out, well, if we&#8217;re worried about post-quantum cryptography, for example, what standards does it have to meet? How do you assess whether it&#8217;s meeting those standards? So it&#8217;s a huge issue in cybersecurity and one that we&#8217;re always very conscious of. It’s really hard.</p>



<p><strong>SULLIVAN:</strong> Given the scope of cybersecurity, are there any differences in testing, let&#8217;s say, for maybe a small business versus a critical infrastructure operator? Are there any, sort of, metrics we can look at in terms of distinguishing risk or assessment?</p>



<p><strong>MARTIN:</strong> There have to be. One of the reasons I think why we have to be is that no small business can be expected to take on a hostile nation-state that&#8217;s well equipped. You have to be realistic.</p>



<p>If you look at government guidance, certainly in the UK 15 years ago on cybersecurity, you were telling small businesses that are living hand to mouth, week by week, trying to make payments at the end of each month, we were telling them they needed sort of nation-state-level cyber defenses. That was never going to happen, even if they could afford it, which they couldn&#8217;t. So you have to have some differentiation. So again, you&#8217;ve got assessment frameworks and so forth where you have to meet higher standards. So there absolutely has to be that distinction. Otherwise, you end up in a crazy world of crippling small businesses with just unmanageable requirements which they&#8217;re never going to meet.</p>



<p><strong>SULLIVAN:</strong> It&#8217;s such a great point. You touched on this a little bit earlier, as well, but just cybersecurity governance operates in a fast-moving technology and threat environment. How have testing standards evolved, and where do new technical standards usually originate?</p>



<p><strong>MARTIN:</strong> I keep saying this is very difficult, and it is. [LAUGHTER] So I think there are two challenges. One is actually about the balance, and this applies to the technology of today as well as the technology of tomorrow. This is about, how do you make sure things are good enough without crowding out new entrants? You want people to be innovative and dynamic. You want disruptors in this business.</p>



<p>But if you say to them, “Look, well, you have to meet these 14 impossibly high technical standards before you can even sell to anybody or sell to the government,” whatever, then you&#8217;ve got a problem. And I think we&#8217;ve wrestled with that, and there&#8217;s no perfect answer. You just have to try and go to … find the sweet spot between two ends of a spectrum. And that&#8217;s going to evolve.</p>



<p>The second point, which in some respects if you&#8217;ve got the right capabilities is slightly <em>easier</em> but still a big call, is around, you know, those newer and evolving technologies. And here, having, you know, been a bit sort of gloomy and pessimistic, here I think is actually an opportunity. So one of the things we always say in cybersecurity is that the internet was built and developed without security in mind. And that was kind of true in the ’90s and the noughties, as we call them over here.</p>



<p>But I think as you move into things like post-quantum computing, applied use of AI, and so on, you can actually set the standards at the beginning. And that&#8217;s really good because it&#8217;s saying to people that these are the things that are going to matter in the post-quantum age. Here&#8217;s the outline of the standards you&#8217;re going to have to meet; start looking at them. So there&#8217;s an opportunity actually to make technology safer by design, by getting ahead of it. And I think that&#8217;s the era we&#8217;re in now.</p>



<p><strong>SULLIVAN:</strong> That makes a lot of sense. Just building on that, do businesses and the public trust these standards? And I guess, which standard do you wish the world would just adopt already, and what&#8217;s the real reason they haven&#8217;t?</p>



<p><strong>MARTIN:</strong> Well, again, where do you start? I mean, most members of the public quite rightly haven&#8217;t heard of any of these standards. I think public trust and public capital in any society matters. But I think it is important that these things are credible.</p>



<p>And there&#8217;s quite a lot of convergence between, you know, the top-level frameworks. And obviously in the US, you know, the NIST [National Institute of Standards and Technology] framework is the one that&#8217;s most popular for cybersecurity, but it bears quite a strong resemblance to the international one, ISO[/IEC] 27001, and there are others, as well. But fundamentally, they boil down to kind of five things. Do a risk assessment; work out what your crown jewels are. Protect your perimeter as best you can. Those are the first two.</p>



<p>The third one then is when your perimeter&#8217;s breached, be able to detect it more times than not. And when you can&#8217;t do that, you go to the fourth one, which is, can you mitigate it? And when all else fails, how quickly can you recover and manage it? I mean, all the standards are expressed in way more technical language than that, but fundamentally, if everybody adopted those five things and operated them in a simple way, you wouldn&#8217;t eliminate the harm, but you would reduce it quite substantially.</p>



<p><strong>SULLIVAN:</strong> Which policy initiatives are most promising for incentivizing companies to undertake, you know, these cybersecurity testing parameters that you’ve just outlined? Governments, including the UK, have used carrots and sticks, but what do you think will actually move the needle?</p>



<p><strong>MARTIN:</strong> I think there are two answers to that, and it comes back to your split between smaller businesses and critically important businesses. In the critically important services, I think it&#8217;s easier because most industries are looking for a level playing field. In other words, they realize there have to be rules and they want to apply them to everyone.</p>



<p>We had a fascinating experience when I was in government back in around 2018 where the telecom sector, they came to us and they said, we&#8217;ve got a very good cooperative relationship with the British government, but it needs to be put on a proper legal footing because you&#8217;re just asking us nicely to do expensive things. And in a regulated sector, if you actually put in some rules—and please develop them jointly with us; that&#8217;s the crucial part—then that will help because it means that we&#8217;re not going to our boards and saying, or our shareholders, and saying that we should do this, and they&#8217;re saying, “Well, do you have to do it? Are our competitors doing it?” And if the answer to that is, yes, we have to, and, yes, our competitors are doing it, then it tends to be OK.</p>



<p>The harder nut to crack is the smaller business. And I think there&#8217;s a real mystery here: why has nobody cracked a really good and easy solution for small business? We need to be careful about this because, you know, you can&#8217;t throttle small businesses with onerous regulation. At the same time, we&#8217;re not brilliant, I think, in any part of the world at using the normal corporate governance rules to try and get people to figure out how to do cybersecurity.</p>



<p>There are initiatives there that are not the sort of pretty heavy stick that you might have to take to a critical function, but they could help. But that is a hard nut to crack. And I look around the world, and, you know, I think if this was easy, somebody would have figured it out by now. I think most of the developed economies around the world really struggle with cybersecurity for smaller businesses.</p>



<p><strong>SULLIVAN:</strong> Yeah, it&#8217;s a great point. Actually building on one of the comments you made on the role of, kind of, government, how do you see the role of private-public partnerships scaling and strengthening, you know, robust cybersecurity testing?</p>



<p><strong>MARTIN:</strong> I think they&#8217;re crucial, but they have to be practical. I&#8217;ve got a slight, sort of, high horse on this, if you don&#8217;t mind, Kathleen. It&#8217;s sort of … [LAUGHS]</p>



<p><strong>SULLIVAN:</strong> Of course.</p>



<p><strong>MARTIN:</strong> I think that there are two types of public-private partnership. One involves committees saying that we should strengthen partnerships and we should all work together and collaborate and share stuff. And we tried that for a very long time, and it didn&#8217;t get us very far. There are other types.</p>



<p>We had some at the National Cyber Security Centre where we paid companies to do spectacularly good technical work that the market wouldn&#8217;t provide. So I think it&#8217;s sort of partnership with a purpose. I think sometimes, and I understand the human instinct to do this, particularly in governments and big business, they think you need to get around a table and work out some grand strategy to fix everything, and the scale of the … not just the problem but the scale of the whole technology is just too big to do that.</p>



<p>So pick a bit of the problem. Find some ways of doing it. Don&#8217;t over-lawyer it. [LAUGHTER] I think sometimes people get very nervous. <em>Oh, well, is this our role? You know, should we be doing this, that, and the other?</em> Well, you know, sometimes certainly in this country, you think, well, who&#8217;s actually going to sue you over this, you know? So I wouldn&#8217;t over-programmatize it. Just get stuck practically into solving some problems.</p>



<p><strong>SULLIVAN:</strong> I love that. Actually, [it] made me think, are there any surprising allies that you&#8217;ve gained—you know, maybe someone who you never expected to be a cybersecurity champion—through your work?</p>



<p><strong>MARTIN:</strong> Ooh! That&#8217;s a … that&#8217;s a… what a question! To give you a slightly disappointing answer, but it relates to your previous question. In the early part of my career, I was working in institutions like the UK Treasury long before I was in cybersecurity, and the treasury and the British civil service in general, but the treasury in particular sort of trained you to believe that the private sector was amoral, not <em>immoral</em>, <em>amoral</em>. It just didn&#8217;t have values. It just had bottom line, and, you know, its job essentially was to provide employment and revenue then for the government to spend on good things that people cared about. And when I got into cybersecurity and people said, look, you need to develop relations with this cybersecurity company, often in the US, actually. I thought, well, what&#8217;s in it for them?</p>



<p>And, sure, sometimes you were paying them for specific services, but other times, there was a real public spiritedness about this. There was a realization that if you tried to delineate public-private boundaries, that it wouldn&#8217;t really work. It was a shared risk. And you could analyze where the boundaries fell or you could actually go on and do something about it together. So I was genuinely surprised at the allyship from the cybersecurity sector. Absolutely, I really, really was. And I think it&#8217;s a really positive part of certainly the UK cybersecurity ecosystem.</p>



<p><strong>SULLIVAN:</strong> Wonderful. Well, we&#8217;re coming to the end of our time here, but is there any maybe last thoughts or perhaps requests you have for our listeners today?</p>



<p><strong>MARTIN:</strong> I think that standards, assurance, and testing <em>really</em> matter, but it&#8217;s a bit like the discussion we&#8217;re having over AI. Get all these things to take you 80, 90% of the way and then really apply your judgment. There&#8217;s been some bad regulation under the auspices of standards and assurance. First of all, it’s, have you done this assessment? Have you done that? Have you looked at this? Well, fine. And you can tick that box, but what does it actually mean when you do it? What bits that you know in your heart of hearts are really important to the defense of your organization that may not be covered by this and just go and do those anyway. Because sure it helps, but it&#8217;s not everything.</p>



<p><strong>SULLIVAN:</strong> No. Great, great closing sentiment. Well, Ciaran, thank you for joining us today. This has been just a super fun conversation and really insightful. Just really enjoyed the conversation. Thank you.</p>



<p><strong>MARTIN:</strong> My pleasure, Kathleen, thank you.</p>



<p>[TRANSITION MUSIC]</p>



<p><strong>SULLIVAN: </strong>Now, I&#8217;m happy to introduce Tori Westerhoff. As a principal director on the Microsoft AI Red Team, Tori leads all AI security and safety red team operations, as well as dangerous capability testing, to directly inform C-suite decision-makers.</p>



<p>So, Tori, welcome!</p>



<p><strong>TORI WESTERHOFF: </strong>Thanks. I am so excited to be here.</p>



<p><strong>SULLIVAN:</strong> I&#8217;d love to just start a little bit more learning about your background. You&#8217;ve worn some very intriguing hats. I mean, cognitive neuroscience grad from Yale, national security consultant, strategist in augmented and virtual reality … how do those experiences help shape the way you lead the Microsoft AI Red Team?</p>



<p><strong>WESTERHOFF:</strong> I always joke this is the only role I think will always combine the entire patchwork LinkedIn résumé. [LAUGHS]</p>



<p>I think I use those experiences to help me understand the really broad approach that AI Red Team—artist also known as <em>AIRT</em>; I&#8217;m sure I&#8217;ll slip into our acronym—how we frame up the broad security implications of AI. So I think the cognitive neuroscience element really helped me initially approach AI hacking, right. There&#8217;s a lot of social engineering and manipulation within chat interfaces that are enabled by AI. And also, kind of, this, like, metaphor for understanding how to find soft spots in the way that you see human heuristics show up, too. And so I think that was actually my personal “in” to getting hooked into AI red teaming generally.</p>



<p>But my experience in national security and I&#8217;d also say working through the AR/VR/metaverse space at the time where I was in it helped me balance both how our impact is framed, how we&#8217;re thinking about critical industries, how we&#8217;re really trying to push our understanding of where security of AI can help people the most. And also do it in a really breakneck speed in an industry that&#8217;s evolving all of the time, that&#8217;s really pushing you to always be at the bleeding edge of your understanding. So I draw a lot of the energy and the mission criticality and the speed from those experiences as we&#8217;re shaping up how we approach it.</p>



<p><strong>SULLIVAN:</strong> Can you just give us a quick rundown? What does the Red Team do? What actually, kind of, is involved on a day-to-day basis? And then as we think about, you know, our engagements with large enterprises and companies, how do we work alongside some of those companies in terms of testing?</p>



<p><strong>WESTERHOFF:</strong> The way I see our team is almost like an indicator light that works really part and parcel with product development. So the way we&#8217;ve organized our expert red teaming efforts is that we work with product development before anything ships out to anyone who can use it. And our job is to act as expert AI manipulators, AI hackers. And we are supposed to take the theories and methods and new research and harness it to find examples of vulnerabilities or soft spots in products to enable product teams to harden those soft spots before anything actually reaches someone who wants to use it.</p>



<p>So if we&#8217;re the indicator light, we are also not the full workup, right. I see that as measurement and evals. And we also are not the mechanic, which is that product development team that&#8217;s creating mitigations. It&#8217;s platform-security folks who are creating mitigations at scale. And there&#8217;s a really great throughput of insights from those groups back into our area where we love to inform about them, but we also love to add on to, how do we break the next thing, right? So it&#8217;s a continuous cycle.</p>



<p>And part of that is just being really creative and thinking outside of a traditional cybersecurity box. And part of that is also really thinking about how we pull in research—we have a research function within our AI Red Team—and how we automate and scale. This year, we&#8217;ve pulled a lot of those assets and insights into the <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" target="_blank" href="https://devblogs.microsoft.com/foundry/ai-red-teaming-agent-preview/">Azure [AI] Foundry AI Red Teaming Agent<span class="sr-only"> (opens in new tab)</span></a>. And so folks can now access a lot of our mechanisms through that. So you can get a little taste of what we do day to day in the AI Red Teaming Agent.</p>



<p><strong>SULLIVAN:</strong> You recently—actually, with your team—published <a href="https://www.microsoft.com/en-us/research/publication/lessons-from-red-teaming-100-generative-ai-products/">a report that outlined lessons from testing over a hundred generative AI products</a>. But could you share a bit about what you learned? What were some of the important lessons? Where do you see opportunities to improve the state of red teaming as a method for probing AI safety?</p>



<p><strong>WESTERHOFF:</strong> I think the most important takeaway from those lessons is that AI security is truly a team sport. You&#8217;ll hear cybersecurity folks say that a lot. And part of the rationale there is that the defense in depth and integrating and a view towards AI security through the entire development of AI systems is really the way that we&#8217;re going to approach this with intentionality and responsibility.</p>



<p>So in our space, we really focus on novel harm categories. We are pushing bleeding edge, and we also are pushing iterative and, like, contextually based red teaming in product dev. So outside of those hundred that we&#8217;ve done, there&#8217;s a community [LAUGHS] through the entire, again, multistage life cycle of a product that is really trying to push the cost of attacking those AI systems higher and higher with all of the expertise they bring. So we may be, like, the experts in AI hacking in that line, but there are also so many partners in the Microsoft ecosystem who are thinking about their market context or they really, really know the people who love their products. How are <em>they</em> using it?</p>



<p>And then when you bubble out, you also have industry and government who are working together to push towards the most secure AI implementation <em>for</em> <em>people</em>, right? And I think our team in particular, we feel really grateful to be part of the big AI safety and security ecosystem at Microsoft and also to be able to contribute to the industry writ large. <s></s></p>



<p><strong>SULLIVAN:</strong> As you know, we had a chance to speak with Professor Ciaran Martin from the University of Oxford about the cybersecurity industry and governance there. What are some of the ideas and tools from that space that are surfacing in how we think about approaching red teaming and AI governance broadly?</p>



<p><strong>WESTERHOFF:</strong> Yeah, I think it&#8217;s such a broad set of perspectives to bring in, in the AI instance. Something that I&#8217;ve noticed interjecting into security at the AI junction, right, is that cybersecurity has so many decades of experience of working through how to build trustworthy computing, for example, or bring an entire industry to bear in that way. And I think that AI security and safety can learn a lot of lessons of how to bring clarity and transparency across the industry to push universal understanding of where the threats really are.</p>



<p>So frameworks coming out of NIST, coming out of MITRE that help us have a universal language that inform governance, I think, are really important because it brings clarity irrespective of where you are looking into AI security, irrespective of your company size, what you&#8217;re working on. It means you all understand, “Hey, we are really worried about this fundamental impact.” And I think cybersecurity has done a really good job of driving towards impact as their organizational vector. And I am starting to see that in the AI space, too, where we&#8217;re trying to really clarify terms and threats.&nbsp;And you see it in updates of those frameworks, as well, that I really love.</p>



<p>So I think that the innovation is in transparency to folks who are really innovating and doing the work so we all have a shared language, and from that, it really creates communal goals across security instead of a lot of people being worried about the same thing and talking about it in a different way.</p>



<p><strong>SULLIVAN: </strong>Mm-hmm.<strong> </strong>In the cybersecurity context, Ciaran really stressed matching risk frameworks to an organization&#8217;s role <em>and</em> scale. Microsoft plays many roles, including building models and shipping applications. How does your red teaming approach shift across those layers?&nbsp;</p>



<p><strong>WESTERHOFF:</strong> I love this question also because I love it as part of our work. So one of the most fascinating things about working on this team has been the diversity of the technology that we end up red teaming and testing. And it feels like we&#8217;re in the crucible in that way. Because we see AI applied to so many different architectures, tech stacks, individual features, models, you name it.</p>



<p>Part of my answer is that we still care about the highest-impact things. And so irrespective of the iteration, which <em>is</em> really fascinating and I love, I still think that our team drives to say, “OK, what is that critical vulnerability that is going to affect people in the largest ways, and can we battle test to see if that can occur?”</p>



<p>So in some ways, the task is always the same. I think in the ways that we change our testing, we customize a lot to the access to systems and data and also people&#8217;s trust almost as different variables that could affect the impact, right.</p>



<p>So a good example is if we&#8217;re thinking through agentic frameworks that have access to functions and tools and preferential ability to act on data, it&#8217;s really different to spaces where that action may not be feasible, right. And so I think the tailoring of the way to get to that impact is hyper-custom every time we start an engagement. And part of it is very thesis driven and almost mechanizing <em>empathy</em>.</p>



<p>You almost need to really focus on how people could use, or misuse, in such a way that you can emulate it before to a really great signal to product development, to say this is truly what people could do and we want to deliver the highest-impact scenarios so you can solve for those and also solve the underlying patterns, actually, that could contribute to maybe that one piece of evidence but also all the related pieces of evidence. So singular drive but like hyper-, hyper-customization to what that piece of tech could do and has access to.</p>



<p><strong>SULLIVAN:</strong> What are some of the unexplored testing approaches or considerations from cybersecurity that you think we should encourage AI technologists, policymakers, and other stakeholders to focus on? <strong></strong></p>



<p><strong>WESTERHOFF:</strong> I do love that AI humbles us each and every day with new capabilities and the potential for new capabilities. It&#8217;s not just saying, “Hey, there&#8217;s one test that we want to try,” but more, “Hey, can we create a methodology that we feel really, really solid about so that when we are asked a question we haven&#8217;t even thought of, we feel confident that we have the resources and the system?”</p>



<p>So part of me is really intrigued by the process that we&#8217;re asked to make without knowing what those capabilities are really going to bring. And then I think tactically, AIRT is really pushing on how we create new research methodologies. How are we investing in, kind of, these longer-term iterations of red teaming? So we&#8217;re really excited about pushing out those insights in an experimental and longer-term way.</p>



<p>I think another element is a little bit of that evolution of how industry standards and frameworks are updating to the AI moment and really articulating where AI is either furthering adversarial ability to create those harms or threats or identifying where AI has a net new harm. And I think that demystifies a little bit about what we talked about in terms of the lessons learned, that fundamentally, a lot of the things that we talk about <em>are</em> traditional security vulnerabilities, and we are standing on kind of that cybersecurity shoulder. And I&#8217;m starting to see those updates translate in spaces that are already considered trustworthy and kind of the basis on which not only cybersecurity folks build their work but also business decision-makers make decisions on those frameworks.</p>



<p>So to me, integration of AI into those frameworks by those same standards means that we&#8217;re evolving security to include AI. We aren&#8217;t creating an entirely new industry of AI security and that, I think, really helps anchor people in the really solid foundation that we have in cybersecurity anyways.</p>



<p>I think there&#8217;s also some work around how the cyber, like, defenses will actually benefit from AI. So we think a lot about threats because that&#8217;s our job. But the other side of cybersecurity is offense. And I&#8217;m seeing a ton of people come out with frameworks and methodologies, especially in the research space, on how defensive networks are going to be benefited from things like agentic systems.</p>



<p>Generally speaking, I think the best practice is to realize that we&#8217;re fundamentally still talking about the same impacts, and we can use the same avenues, conversations, and frameworks. We just really want them to be crisply updated with that understanding of AI applications.</p>



<p><strong>SULLIVAN:</strong> How do you think about bringing others into the fold there? I think those standards and frameworks are often informed by technologists. But I&#8217;d love for you to expand [that to] policymakers or other kind of stakeholders in our ecosystem, even, you know, end consumers of these products. Like, how do we communicate some of this to them in a way that resonates and it has an impactful meaning?</p>



<p><strong>WESTERHOFF:</strong> I&#8217;ve found the AI security-safety space to be one of the more collaborative. I actually think the fact that I&#8217;m talking to you today is probably evidence that a ton of people are bringing in perspectives that don&#8217;t only come from a long-term cybersecurity view. And I see that as a trend in how AI is being approached opposed to how those areas were moving earlier. So I think that speed and the idea of conversations and not always having the perfect answer but really trying to be transparent with what everyone does know is kind of a communal energy in the communities, at least, where we&#8217;re playing. [LAUGHS] So I am pretty biased but at least the spaces where we are.</p>



<p><strong>SULLIVAN:</strong> No, I think we&#8217;re seeing that across the board. I mean, I&#8217;d echo [that] sitting in research, as well, like, that ability to have impact now and at speed to getting the amazing technology and models that we&#8217;re creating into the hands of our customers and partners and ecosystem is just underscored.</p>



<p>So on the note of speed, let&#8217;s shift gears a little bit to just a quick lightning round. I&#8217;d love to get maybe some quick thoughts from you, just 30-second answers here. I&#8217;ll start with one.</p>



<p>Which headline-grabbing AI threat do you think is mostly hot air?</p>



<p><strong>WESTERHOFF:</strong> I think we should pay attention to it all. I&#8217;m a red team lead. I love a good question to see if we can find an answer in real life. So no hot air, just questions.</p>



<p><strong>SULLIVAN:</strong> Is there some sort of maybe new tool that you can&#8217;t wait to sneak into the red team arsenal?</p>



<p><strong>WESTERHOFF:</strong> I think there are really interesting methodologies that break our understanding of cybersecurity by looking at the intersection between different layers of AI and how you can manipulate AI-to-AI interaction, especially now when we&#8217;re looking at agentic systems. So I would say a method, not a tool.</p>



<p><strong>SULLIVAN:</strong> So maybe ending on a little bit of a lighter note, do you have a go-to snack during an all-night red teaming session?</p>



<p><strong>WESTERHOFF:</strong> Always coffee. I would love it to be a protein smoothie, but honestly, it is probably Trader Joe&#8217;s elote chips. Like the whole bag. [LAUGHTER] It’s going to get me through. I&#8217;m going to not love that I did it.</p>



<p>[MUSIC]</p>



<p><strong>SULLIVAN:</strong> Amazing. Well, Tori, thanks so much for joining us today, and just a huge thanks also to Ciaran for his insights, as well.</p>



<p><strong>WESTERHOFF:</strong> Thank you so much for having me. This was a joy.</p>



<p><strong>SULLIVAN: </strong>And to our listeners, thanks for tuning in. You can find resources related to this podcast in the show notes. And if you want to learn more about how Microsoft approaches AI governance, you can visit <a href="https://www.microsoft.com/en-us/ai/responsible-ai">microsoft.com/RAI</a>.</p>



<p>See you next time! </p>



<p>[MUSIC FADES]</p>

				</span>
			</div>
			<button
				class="action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle"
				aria-expanded="false"
				data-show-less-text="Show less"
				type="button"
				aria-controls="show-more-show-less-toggle-7"
				aria-label="Show more content"
				data-alternate-aria-label="Show less content">
				Show more			</button>
		</div>
	</div>
</div>



<div class="wp-block-buttons is-layout-flex wp-block-buttons-is-layout-flex">
<div class="wp-block-button is-style-outline is-style-outline--8"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/story/ai-testing-and-evaluation-learnings-from-science-and-industry/">AI Testing and Evaluation podcast series</a></div>
</div>
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-cybersecurity/">AI Testing and Evaluation: Learnings from cybersecurity</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
					
		
		
			</item>
	</channel>
</rss>
