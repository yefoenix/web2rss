<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>Microsoft Research</title>
	<atom:link href="https://www.microsoft.com/en-us/research/feed/" rel="self" type="application/rss+xml" />
	<link>https://www.microsoft.com/en-us/research/</link>
	<description></description>
	<lastBuildDate>Fri, 18 Jul 2025 20:18:15 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.7.2</generator>
	<item>
		<title>CollabLLM: Teaching LLMs to collaborate with users</title>
		<link>https://www.microsoft.com/en-us/research/blog/collabllm-teaching-llms-to-collaborate-with-users/</link>
		
		<dc:creator><![CDATA[Shirley Wu, Michel Galley, Baolin Peng, Swadheen Shukla, Jianfeng Gao]]></dc:creator>
		<pubDate>Tue, 15 Jul 2025 18:00:00 +0000</pubDate>
				<category><![CDATA[Research Blog]]></category>
		<guid isPermaLink="false">https://www.microsoft.com/en-us/research/?p=1144588</guid>

					<description><![CDATA[<p>Recipient of an ICML 2025 Outstanding Paper Award, CollabLLM improves how LLMs collaborate with users, including knowing when to ask questions and how to adapt tone and communication style to different situations. This approach helps move AI toward more user-centric and trustworthy systems.</p>
<p>The post <a href="https://www.microsoft.com/en-us/research/blog/collabllm-teaching-llms-to-collaborate-with-users/">CollabLLM: Teaching LLMs to collaborate with users</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img fetchpriority="high" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM-BlogHeroFeature-1400x788_Update.jpg" alt="CollabLLM blog hero | flowchart diagram starting in the upper left corner with an icon of two overlapping chat bubbles; arrow pointing right to an LLM network node icon; branching down to show three simulated users; right arrow to a "Reward" box" class="wp-image-1144599" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM-BlogHeroFeature-1400x788_Update.jpg 1400w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM-BlogHeroFeature-1400x788_Update-300x169.jpg 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM-BlogHeroFeature-1400x788_Update-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM-BlogHeroFeature-1400x788_Update-768x432.jpg 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM-BlogHeroFeature-1400x788_Update-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM-BlogHeroFeature-1400x788_Update-655x368.jpg 655w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM-BlogHeroFeature-1400x788_Update-240x135.jpg 240w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM-BlogHeroFeature-1400x788_Update-640x360.jpg 640w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM-BlogHeroFeature-1400x788_Update-960x540.jpg 960w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM-BlogHeroFeature-1400x788_Update-1280x720.jpg 1280w" sizes="(max-width: 1400px) 100vw, 1400px" /></figure>



<p>Large language models (LLMs) can solve complex puzzles in seconds, yet they sometimes struggle over simple conversations. When these AI tools make assumptions, overlook key details, or neglect to ask clarifying questions, the result can erode trust and derail real-world interactions, where nuance is everything.</p>



<p>A key reason these models behave this way lies in how they’re trained and evaluated. Most benchmarks use isolated, single-turn prompts with clear instructions. Training methods tend to optimize for the model&#8217;s next response, not its contribution to a successful, multi-turn exchange. But real-world interaction is dynamic and collaborative. It relies on context, clarification, and shared understanding.</p>



<h2 class="wp-block-heading" id="user-centric-approach-to-training">User-centric approach to training&nbsp;</h2>



<p>To address this, we’re exploring ways to train LLMs with users in mind. Our approach places models in simulated environments that reflect the back-and-forth nature of real conversations. Through reinforcement learning, these models improve through trial and error, for example, learning when to ask questions and how to adapt tone and communication style to different situations. This user-centric approach helps bridge the gap between how LLMs are typically trained and how people actually use them.  </p>



<p>This is the concept behind <a href="https://www.microsoft.com/en-us/research/publication/collabllm-from-passive-responders-to-active-collaborators/">CollabLLM<span class="sr-only"> (opens in new tab)</span></a>, recipient of an <a href="https://www.microsoft.com/en-us/research/event/icml-2025/">ICML<span class="sr-only"> (opens in new tab)</span></a> <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://icml.cc/virtual/2025/awards_detail" target="_blank" rel="noreferrer noopener">Outstanding Paper Award<span class="sr-only"> (opens in new tab)</span></a>. This training framework helps LLMs improve through simulated multi-turn interactions, as illustrated in Figure 1. The core insight behind CollabLLM is simple: in a constructive collaboration, the value of a response isn’t just in its immediate usefulness, but in how it contributes to the overall success of the conversation. A clarifying question might seem like a delay but often leads to better outcomes. A quick answer might appear useful but can create confusion or derail the interaction.</p>



<figure class="wp-block-image aligncenter size-full"><img decoding="async" width="1365" height="486" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM_fig1.png" alt="Figure 1 compares two training strategies for Large Language Models: a standard non-collaborative method and our proposed collaborative method (CollabLLM). On the left, the standard method uses a preference/reward dataset with single-turn evaluations, resulting in a model that causes ineffective interactions. The user gives feedback, but the model generates multiple verbose and unsatisfactory responses, requiring many back-and-forth turns. On the right, CollabLLM incorporates collaborative simulation during training, using multi-turn interactions and reinforcement learning. After training, the model asks clarifying questions (e.g., tone preferences), receives focused user input, and quickly generates tailored, high-impact responses." class="wp-image-1144594" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM_fig1.png 1365w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM_fig1-300x107.png 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM_fig1-1024x365.png 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM_fig1-768x273.png 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM_fig1-240x85.png 240w" sizes="(max-width: 1365px) 100vw, 1365px" /><figcaption class="wp-element-caption">Figure 1. Diagram comparing two training approaches for LLMs. (a) The standard method lacks user-agent collaboration and uses single-turn rewards, leading to an inefficient conversation. (b) In contrast, CollabLLM simulates multi-turn user-agent interactions during training, enabling it to learn effective collaboration strategies and produce more efficient dialogues.</figcaption></figure>



<p>CollabLLM puts this collaborative approach into practice with a simulation-based training loop, illustrated in Figure 2. At any point in a conversation, the model generates multiple possible next turns by engaging in a dialogue with a simulated user.</p>



<figure class="wp-block-image aligncenter size-full"><img decoding="async" width="970" height="438" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM_fig2.png" alt="Figure 2 illustrates the overall training procedure of CollabLLM. For a given conversational input, the LLM and a user simulator are used to sample conversation continuations. The sampled conversations are then scored using a reward model that utilizes various multiturn-aware rewards, which are then in turn used to update parameters of the LLM." class="wp-image-1144593" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM_fig2.png 970w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM_fig2-300x135.png 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM_fig2-768x347.png 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM_fig2-240x108.png 240w" sizes="(max-width: 970px) 100vw, 970px" /><figcaption class="wp-element-caption">Figure 2: Simulation-based training process used in CollabLLM</figcaption></figure>



<p>The system uses a sampling method to extend conversations turn by turn, choosing likely responses for each participant (the AI agent or the simulated user), while adding some randomness to vary the conversational paths. The goal is to expose the model to a wide variety of conversational scenarios, helping it learn more effective collaboration strategies.</p>



	<div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide" data-bi-aN="promo" data-bi-id="1141385">
		

	
	<div class="row pt-3 pb-4 align-items-center">
						<div class="msr-promo__media col-12 col-md-5">
				<a class="bg-gray-300 display-block" href="https://ai.azure.com/labs" aria-label="Azure AI Foundry Labs" data-bi-cN="Azure AI Foundry Labs" target="_blank">
					<img decoding="async" class="w-100 display-block" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/Azure-AI-Foundry_1600x900.jpg" />
				</a>
			</div>
			
			<div class="msr-promo__content p-3 px-5 col-12 col-md">

									<h2 class="h4">Azure AI Foundry Labs</h2>
				
								<p id="azure-ai-foundry-labs" class="large">Get a glimpse of potential future directions for AI, with these experimental technologies from Microsoft Research.</p>
				
								<div class="wp-block-buttons justify-content-center justify-content-md-start">
					<div class="wp-block-button">
						<a href="https://ai.azure.com/labs" aria-describedby="azure-ai-foundry-labs" class="btn btn-brand glyph-append glyph-append-chevron-right" data-bi-cN="Azure AI Foundry Labs" target="_blank">
							Azure AI Foundry						</a>
					</div>
				</div>
							</div><!--/.msr-promo__content-->
	</div><!--/.msr-promo__inner-wrap-->
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span>	</div><!--/.msr-promo-->
	


<p>To each simulated conversation, we applied multiturn-aware reward (MR) functions, which assess how the model’s response at the given turn influences the entire trajectory of the conversation. We sampled multiple conversational follow-ups from the model, such as statements, suggestions, questions, and used MR to assign a reward to each based on how well the conversation performed in later turns. We based these scores on automated metrics that reflect key factors like goal completion, conversational efficiency, and user engagement.</p>



<p>To score the sampled conversations, we used task-specific metrics and metrics from an LLM-as-a-judge framework, which supports efficient and scalable evaluation. For metrics like engagement, a judge model rates each sampled conversation on a scale from 0 to 1.</p>



<p>The MR of each model response was computed by averaging the scores from the sampled conversations, originating from the model response. Based on the score, the model updates its parameters using established reinforcement learning algorithms like Proximal Policy Optimization (PPO) or Direct Preference Optimization (DPO).</p>



<p>We tested CollabLLM through a combination of automated and human evaluations, detailed in the <a href="https://www.microsoft.com/en-us/research/publication/collabllm-from-passive-responders-to-active-collaborators/">paper</a>. One highlight is a user study involving 201 participants in a document co-creation task, shown in Figure 3. We compared CollabLLM to a baseline trained with single-turn rewards and to a second, more proactive baseline prompted to ask clarifying questions and take other proactive steps. CollabLLM outperformed both, producing higher-quality documents, better interaction ratings, and faster task completion times.</p>



<figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1860" height="492" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM_fig3.png" alt="Figure 3 shows the main results of our user study on a document co-creation task, by comparing a baseline, a proactive baseline, and CollabLLM. CollabLLM outperformed the two baselines. Relative to the best baseline, CollabLLM yields improved document quality rating (+0.12), interaction rating (+0.14), and a reduction of average time spent by the user (-129 seconds)." class="wp-image-1144597" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM_fig3.png 1860w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM_fig3-300x79.png 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM_fig3-1024x271.png 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM_fig3-768x203.png 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM_fig3-1536x406.png 1536w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM_fig3-240x63.png 240w" sizes="auto, (max-width: 1860px) 100vw, 1860px" /><figcaption class="wp-element-caption">Figure 3: Results of the user study in a document co-creation task comparing CollabLLM to a baseline trained with single-turn rewards.</figcaption></figure>



<h2 class="wp-block-heading" id="designing-for-real-world-collaboration">Designing for real-world collaboration</h2>



<p>Much of today’s AI research focuses on fully automated tasks, models working without input from or interaction with users. But many real-world applications depend on people in the loop: as users, collaborators, or decision-makers. Designing AI systems that treat user input not as a constraint, but as essential, leads to systems that are more accurate, more helpful, and ultimately more trustworthy.</p>



<p>This work is driven by a core belief: the future of AI depends not just on intelligence, but on the ability to collaborate effectively. And that means confronting the communication breakdowns in today’s systems.</p>



<p>We see CollabLLM as a step in that direction, training models to engage in meaningful multi-turn interactions, ask clarifying questions, and adapt to context. In doing so, we can build systems designed to work <em>with</em> people—not around them.</p>
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/blog/collabllm-teaching-llms-to-collaborate-with-users/">CollabLLM: Teaching LLMs to collaborate with users</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>AI Testing and Evaluation: Learnings from cybersecurity</title>
		<link>https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-cybersecurity/</link>
		
		<dc:creator><![CDATA[Kathleen Sullivan, Ciaran Martin, Tori Westerhoff]]></dc:creator>
		<pubDate>Mon, 14 Jul 2025 16:00:00 +0000</pubDate>
				<category><![CDATA[Microsoft Research Podcast]]></category>
		<guid isPermaLink="false">https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-cybersecurity/</guid>

					<description><![CDATA[<p>Drawing on his previous work as the UK’s cybersecurity chief, Professor Ciaran Martin explores differentiated standards and public-private partnerships in cybersecurity, and Microsoft’s Tori Westerhoff examines the insights through an AI red-teaming lens.</p>
<p>The post <a href="https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-cybersecurity/">AI Testing and Evaluation: Learnings from cybersecurity</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/EP3-AI-TE_Hero_Feature_1400x788-1.jpg" alt="Illustrated images of Kathleen Sullivan, Ciaran Martin, and Tori Westerhoff for the Microsoft Research podcast" class="wp-image-1144391" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/EP3-AI-TE_Hero_Feature_1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/EP3-AI-TE_Hero_Feature_1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/EP3-AI-TE_Hero_Feature_1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/EP3-AI-TE_Hero_Feature_1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/EP3-AI-TE_Hero_Feature_1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/EP3-AI-TE_Hero_Feature_1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/EP3-AI-TE_Hero_Feature_1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/EP3-AI-TE_Hero_Feature_1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/EP3-AI-TE_Hero_Feature_1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/EP3-AI-TE_Hero_Feature_1400x788-1-1280x720.jpg 1280w" sizes="auto, (max-width: 1400px) 100vw, 1400px" /></figure>


<div class="wp-block-msr-podcast-container my-4">
	<iframe loading="lazy" src="https://player.blubrry.com/?podcast_id=146975694&modern=1" class="podcast-player" frameborder="0" height="164px" width="100%" scrolling="no" title="Podcast Player"></iframe>
</div>



<p>Generative AI presents a unique challenge and opportunity to reexamine governance practices for the responsible development, deployment, and use of AI. To advance thinking in this space, Microsoft has tapped into the experience and knowledge of experts across domains—from genome editing to cybersecurity—to investigate the role of testing and evaluation as a governance tool.&nbsp;<a href="https://www.microsoft.com/en-us/research/story/ai-testing-and-evaluation-learnings-from-science-and-industry/"><em>AI Testing and Evaluation: Learnings from Science and Industry</em></a>,&nbsp;hosted by Microsoft Research’s&nbsp;<a href="https://www.microsoft.com/en-us/research/people/kasull/">Kathleen Sullivan</a>, explores what the technology industry and policymakers can learn from these fields and how that might help shape the course of AI development.</p>



<p>In this episode, Sullivan speaks with Professor <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.bsg.ox.ac.uk/people/ciaran-martin" target="_blank" rel="noreferrer noopener">Ciaran Martin<span class="sr-only"> (opens in new tab)</span></a> of the University of Oxford about risk assessment and testing in the field of cybersecurity. They explore the importance of differentiated standards for organizations of varying sizes, the role of public-private partnerships, and the opportunity to embed security into emerging technologies from the outset. Later, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.victoriawesterhoff.com/" target="_blank" rel="noreferrer noopener">Tori Westerhoff<span class="sr-only"> (opens in new tab)</span></a>, a principal director on the Microsoft AI Red Team, joins Sullivan to talk about identifying vulnerabilities in AI products and services. Westerhoff describes AI security in terms she’s heard cybersecurity professionals use for their work—a team sport—and points to cybersecurity’s establishment of a shared language and understanding of risk as a model for AI security.</p>



<div class="wp-block-group msr-pattern-link-list is-layout-flow wp-block-group-is-layout-flow">
<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading h5" id="learn-more-1">Learn more:</h2>



<ul class="wp-block-list list-unstyled">
<li><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" target="_blank" href="https://devblogs.microsoft.com/foundry/ai-red-teaming-agent-preview/">Introducing AI Red Teaming Agent: Accelerate your AI safety and security journey with Azure AI Foundry<span class="sr-only"> (opens in new tab)</span></a><br>Azure AI Foundry Blog | April 2025</li>



<li><a href="https://www.microsoft.com/en-us/research/publication/lessons-from-red-teaming-100-generative-ai-products/">Lessons From Red Teaming 100 Generative AI Products</a><br>Publication | January 2025</li>



<li><a href="https://www.microsoft.com/en-us/research/blog/learning-from-other-domains-to-advance-ai-evaluation-and-testing/">Learning from other domains to advance AI evaluation and testing</a><br>Microsoft Research Blog | June 2025</li>



<li><a href="https://www.microsoft.com/en-us/ai/responsible-ai?ef_id=_k_cb05d5950e4f117c457ebda628845b7f_k_&OCID=AIDcmm1o1fzy5i_SEM__k_cb05d5950e4f117c457ebda628845b7f_k_&msclkid=cb05d5950e4f117c457ebda628845b7f" target="_blank" rel="noreferrer noopener">Responsible AI: Ethical policies and practices | Microsoft AI</a></li>



<li><a href="https://www.microsoft.com/en-us/research/focus-area/ai-and-microsoft-research/" target="_blank" rel="noreferrer noopener">AI and Microsoft Research</a></li>
</ul>
</div>



<div style="height:25px" aria-hidden="true" class="wp-block-spacer"></div>



<section class="wp-block-msr-subscribe-to-podcast subscribe-to-podcast">
	<div class="subscribe-to-podcast__inner border-top border-bottom border-width-2">
		<h2 class="h5 subscribe-to-podcast__heading">
			Subscribe to the <a href="https://www.microsoft.com/en-us/research/podcast">Microsoft Research Podcast</a>:		</h2>
		<ul class="subscribe-to-podcast__list list-unstyled">
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://itunes.apple.com/us/podcast/microsoft-research-a-podcast/id1318021537?mt=2" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="black" viewBox="0 0 32 32">  <path d="M7.12 0c-3.937-0.011-7.131 3.183-7.12 7.12v17.76c-0.011 3.937 3.183 7.131 7.12 7.12h17.76c3.937 0.011 7.131-3.183 7.12-7.12v-17.76c0.011-3.937-3.183-7.131-7.12-7.12zM15.817 3.421c3.115 0 5.932 1.204 8.079 3.453 1.631 1.693 2.547 3.489 3.016 5.855 0.161 0.787 0.161 2.932 0.009 3.817-0.5 2.817-2.041 5.339-4.317 7.063-0.812 0.615-2.797 1.683-3.115 1.683-0.12 0-0.129-0.12-0.077-0.615 0.099-0.792 0.192-0.953 0.64-1.141 0.713-0.296 1.932-1.167 2.677-1.911 1.301-1.303 2.229-2.932 2.677-4.719 0.281-1.1 0.244-3.543-0.063-4.672-0.969-3.595-3.907-6.385-7.5-7.136-1.041-0.213-2.943-0.213-4 0-3.636 0.751-6.647 3.683-7.563 7.371-0.245 1.004-0.245 3.448 0 4.448 0.609 2.443 2.188 4.681 4.255 6.015 0.407 0.271 0.896 0.547 1.1 0.631 0.447 0.192 0.547 0.355 0.629 1.14 0.052 0.485 0.041 0.62-0.072 0.62-0.073 0-0.62-0.235-1.199-0.511l-0.052-0.041c-3.297-1.62-5.407-4.364-6.177-8.016-0.187-0.943-0.224-3.187-0.036-4.052 0.479-2.323 1.396-4.135 2.921-5.739 2.199-2.319 5.027-3.543 8.172-3.543zM16 7.172c0.541 0.005 1.068 0.052 1.473 0.14 3.715 0.828 6.344 4.543 5.833 8.229-0.203 1.489-0.713 2.709-1.619 3.844-0.448 0.573-1.537 1.532-1.729 1.532-0.032 0-0.063-0.365-0.063-0.803v-0.808l0.552-0.661c2.093-2.505 1.943-6.005-0.339-8.296-0.885-0.896-1.912-1.423-3.235-1.661-0.853-0.161-1.031-0.161-1.927-0.011-1.364 0.219-2.417 0.744-3.355 1.672-2.291 2.271-2.443 5.791-0.348 8.296l0.552 0.661v0.813c0 0.448-0.037 0.807-0.084 0.807-0.036 0-0.349-0.213-0.683-0.479l-0.047-0.016c-1.109-0.885-2.088-2.453-2.495-3.995-0.244-0.932-0.244-2.697 0.011-3.625 0.672-2.505 2.521-4.448 5.079-5.359 0.547-0.193 1.509-0.297 2.416-0.281zM15.823 11.156c0.417 0 0.828 0.084 1.131 0.24 0.645 0.339 1.183 0.989 1.385 1.677 0.62 2.104-1.609 3.948-3.631 3.005h-0.015c-0.953-0.443-1.464-1.276-1.475-2.36 0-0.979 0.541-1.828 1.484-2.328 0.297-0.156 0.709-0.235 1.125-0.235zM15.812 17.464c1.319-0.005 2.271 0.463 2.625 1.291 0.265 0.62 0.167 2.573-0.292 5.735-0.307 2.208-0.479 2.765-0.905 3.141-0.589 0.52-1.417 0.667-2.209 0.385h-0.004c-0.953-0.344-1.157-0.808-1.553-3.527-0.452-3.161-0.552-5.115-0.285-5.735 0.348-0.823 1.296-1.285 2.624-1.291z"/></svg>
						<span class="subscribe-to-podcast__link-text">Apple Podcasts</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://subscribebyemail.com/www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M6.4 6a2.392 2.392 0 00-2.372 2.119L16 15.6l11.972-7.481A2.392 2.392 0 0025.6 6H6.4zM4 10.502V22.8a2.4 2.4 0 002.4 2.4h19.2a2.4 2.4 0 002.4-2.4V10.502l-11.365 7.102a1.2 1.2 0 01-1.27 0L4 10.502z"/></svg>
						<span class="subscribe-to-podcast__link-text">Email</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://subscribeonandroid.com/www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M12.414 4.02c-.062.012-.126.023-.18.06a.489.489 0 00-.12.675L13.149 6.3c-1.6.847-2.792 2.255-3.18 3.944h13.257c-.388-1.69-1.58-3.097-3.179-3.944l1.035-1.545a.489.489 0 00-.12-.675.492.492 0 00-.675.135l-1.14 1.68a7.423 7.423 0 00-2.55-.45c-.899 0-1.758.161-2.549.45l-1.14-1.68a.482.482 0 00-.494-.195zm1.545 3.824a.72.72 0 110 1.44.72.72 0 010-1.44zm5.278 0a.719.719 0 110 1.44.719.719 0 110-1.44zM8.44 11.204A1.44 1.44 0 007 12.644v6.718c0 .795.645 1.44 1.44 1.44.168 0 .33-.036.48-.09v-9.418a1.406 1.406 0 00-.48-.09zm1.44 0V21.76c0 .793.646 1.44 1.44 1.44h10.557c.793 0 1.44-.647 1.44-1.44V11.204H9.878zm14.876 0c-.169 0-.33.035-.48.09v9.418c.15.052.311.09.48.09a1.44 1.44 0 001.44-1.44v-6.719a1.44 1.44 0 00-1.44-1.44zM11.8 24.16v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84zm5.759 0v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84z"/></svg>
						<span class="subscribe-to-podcast__link-text">Android</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://open.spotify.com/show/4ndjUXyL0hH1FXHgwIiTWU" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M16 4C9.383 4 4 9.383 4 16s5.383 12 12 12 12-5.383 12-12S22.617 4 16 4zm5.08 17.394a.781.781 0 01-1.086.217c-1.29-.86-3.477-1.434-5.303-1.434-1.937.002-3.389.477-3.403.482a.782.782 0 11-.494-1.484c.068-.023 1.71-.56 3.897-.562 1.826 0 4.365.492 6.171 1.696.36.24.457.725.217 1.085zm1.56-3.202a.895.895 0 01-1.234.286c-2.338-1.457-4.742-1.766-6.812-1.747-2.338.02-4.207.466-4.239.476a.895.895 0 11-.488-1.723c.145-.041 2.01-.5 4.564-.521 2.329-.02 5.23.318 7.923 1.995.419.26.547.814.286 1.234zm1.556-3.745a1.043 1.043 0 01-1.428.371c-2.725-1.6-6.039-1.94-8.339-1.942h-.033c-2.781 0-4.923.489-4.944.494a1.044 1.044 0 01-.474-2.031c.096-.023 2.385-.55 5.418-.55h.036c2.558.004 6.264.393 9.393 2.23.497.292.663.931.371 1.428z"/></svg>
						<span class="subscribe-to-podcast__link-text">Spotify</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M6.667 4a2.676 2.676 0 00-2.612 2.13v.003c-.036.172-.055.35-.055.534v18.666c0 .183.019.362.055.534v.003a2.676 2.676 0 002.076 2.075h.002c.172.036.35.055.534.055h18.666A2.676 2.676 0 0028 25.333V6.667a2.676 2.676 0 00-2.13-2.612h-.003A2.623 2.623 0 0025.333 4H6.667zM8 8h1.333C17.42 8 24 14.58 24 22.667V24h-2.667v-1.333c0-6.618-5.382-12-12-12H8V8zm0 5.333h1.333c5.146 0 9.334 4.188 9.334 9.334V24H16v-1.333A6.674 6.674 0 009.333 16H8v-2.667zM10 20a2 2 0 11-.001 4.001A2 2 0 0110 20z"/></svg>
						<span class="subscribe-to-podcast__link-text">RSS Feed</span>
					</a>
				</li>
					</ul>
	</div>
</section>


<div class="wp-block-msr-show-more">
	<div class="bg-neutral-100 p-5">
		<div class="show-more-show-less" data-mount="show-more-show-less">
			<div>
				<span>
					

<h2 class="wp-block-heading" id="transcript">Transcript</h2>



<p>[MUSIC]</p>



<p><strong>KATHLEEN SULLIVAN: </strong>Welcome to <em>AI Testing and Evaluation: Learnings from Science and Industry</em>. I&#8217;m your host, Kathleen Sullivan.</p>



<p>As generative AI continues to advance, Microsoft has gathered a range of experts—from genome editing to cybersecurity—to share how their fields approach evaluation and risk assessment. Our goal is to learn from their successes and their stumbles to move the science and practice of AI testing forward. In this series, we&#8217;ll explore how these insights might help guide the future of AI development, deployment, and responsible use.</p>



<p>[MUSIC ENDS]</p>



<p>Today, I&#8217;m excited to welcome Ciaran Martin to the podcast to explore testing and risk assessment in cybersecurity. Ciaran is a professor of practice in the management of public organizations at the University of Oxford. He had previously founded and served as chief executive of the National Cyber Security Centre within the UK&#8217;s intelligence, security, and cyber agency.</p>



<p>And after our conversation, we&#8217;ll talk to Microsoft&#8217;s Tori Westerhoff, a principal director on Microsoft’s AI Red Team, about how we should think about these insights in the context of AI.</p>



<p>Hi, Ciaran. Thank you so much for being here today.</p>



				</span>
				<span id="show-more-show-less-toggle-1" class="show-more-show-less-toggleable-content">
					



<p><strong>CIARAN MARTIN:</strong> Well, thanks so much for inviting me. It’s great to be here.</p>



<p><strong>SULLIVAN:</strong> Ciaran, before we get into some regulatory specifics, it&#8217;d be great to hear a little bit more about your origin story, and just take us to that day—who tapped you on the shoulder and said, “Ciaran, we need you to run a national cyber center! Do you fancy building one?”</p>



<p><strong>MARTIN:</strong> You could argue that I owe my job to Edward Snowden. Not an obvious thing to say. So the National Cyber Security Centre, which didn&#8217;t exist at the time—I was invited to join the British government&#8217;s cybersecurity effort in a leadership role—is now a subset of GCHQ. That&#8217;s the digital intelligence agency. The equivalent in the US obviously is the NSA [National Security Agency]. It had been convulsed by the Snowden disclosures. It was an unprecedented challenge.</p>



<p>I was a 17-year career government fixer with some national security experience. So I was asked to go out and help with the policy response, the media response, the legal response. But I said, look, any crisis, even one as big as this, is over one way or the other in six months. What should I do long term? And they said, well, we were thinking of asking you to try to help transform our cybersecurity mission. So the National Cyber Security Centre was born, and I was very proud to lead it, and all in all, I did it for seven years from startup to handing it on to somebody else.</p>



<p><strong>SULLIVAN:</strong> I mean, it&#8217;s incredible. And just building on that, people spend a significant portion of their lives online now with a variety of devices, and maybe for listeners who are newer to cybersecurity, could you give us the 90-second lightning talk? Kind of, what does risk assessment and testing look like in this space?</p>



<p><strong>MARTIN:</strong> Well, risk assessment and testing, I think, are two different things. You can&#8217;t defend everything. If you defend everything, you&#8217;re defending nothing. So broadly speaking, organizations face three threats. One is complete disruption of their systems. So just imagine not being able to access your system. The second is data protection, and that could be sensitive customer information. It could be intellectual property. And the third is, of course, you could be at risk of just straightforward being stolen from. I mean, you don&#8217;t want any of them to happen, but you have to have a hierarchy of harm.</p>



<p><strong>SULLIVAN: </strong>Yes.</p>



<p><strong>MARTIN: </strong>So that&#8217;s your risk assessment.</p>



<p>The testing side, I think, is slightly different. One of the paradoxes, I think, of cybersecurity is for such a scientific, data-rich subject, the sort of metrics about what works are very, very hard to come by. So you&#8217;ve got boards and corporate leadership and senior governmental structures, and they say, “Look, how do I run this organization safely and securely?” And a cybersecurity chief within the organization will say, “Well, we could get this capability in.” Well, the classic question for a leadership team to ask is, well, what risk and harm will this reduce, by how much, and what&#8217;s the cost-benefit analysis? And we find that <em>really</em> hard.</p>



<p>So that&#8217;s really where testing and assurance comes in. And also as technology changes so fast, we have to figure out, well, if we&#8217;re worried about post-quantum cryptography, for example, what standards does it have to meet? How do you assess whether it&#8217;s meeting those standards? So it&#8217;s a huge issue in cybersecurity and one that we&#8217;re always very conscious of. It’s really hard.</p>



<p><strong>SULLIVAN:</strong> Given the scope of cybersecurity, are there any differences in testing, let&#8217;s say, for maybe a small business versus a critical infrastructure operator? Are there any, sort of, metrics we can look at in terms of distinguishing risk or assessment?</p>



<p><strong>MARTIN:</strong> There have to be. One of the reasons I think why we have to be is that no small business can be expected to take on a hostile nation-state that&#8217;s well equipped. You have to be realistic.</p>



<p>If you look at government guidance, certainly in the UK 15 years ago on cybersecurity, you were telling small businesses that are living hand to mouth, week by week, trying to make payments at the end of each month, we were telling them they needed sort of nation-state-level cyber defenses. That was never going to happen, even if they could afford it, which they couldn&#8217;t. So you have to have some differentiation. So again, you&#8217;ve got assessment frameworks and so forth where you have to meet higher standards. So there absolutely has to be that distinction. Otherwise, you end up in a crazy world of crippling small businesses with just unmanageable requirements which they&#8217;re never going to meet.</p>



<p><strong>SULLIVAN:</strong> It&#8217;s such a great point. You touched on this a little bit earlier, as well, but just cybersecurity governance operates in a fast-moving technology and threat environment. How have testing standards evolved, and where do new technical standards usually originate?</p>



<p><strong>MARTIN:</strong> I keep saying this is very difficult, and it is. [LAUGHTER] So I think there are two challenges. One is actually about the balance, and this applies to the technology of today as well as the technology of tomorrow. This is about, how do you make sure things are good enough without crowding out new entrants? You want people to be innovative and dynamic. You want disruptors in this business.</p>



<p>But if you say to them, “Look, well, you have to meet these 14 impossibly high technical standards before you can even sell to anybody or sell to the government,” whatever, then you&#8217;ve got a problem. And I think we&#8217;ve wrestled with that, and there&#8217;s no perfect answer. You just have to try and go to … find the sweet spot between two ends of a spectrum. And that&#8217;s going to evolve.</p>



<p>The second point, which in some respects if you&#8217;ve got the right capabilities is slightly <em>easier</em> but still a big call, is around, you know, those newer and evolving technologies. And here, having, you know, been a bit sort of gloomy and pessimistic, here I think is actually an opportunity. So one of the things we always say in cybersecurity is that the internet was built and developed without security in mind. And that was kind of true in the ’90s and the noughties, as we call them over here.</p>



<p>But I think as you move into things like post-quantum computing, applied use of AI, and so on, you can actually set the standards at the beginning. And that&#8217;s really good because it&#8217;s saying to people that these are the things that are going to matter in the post-quantum age. Here&#8217;s the outline of the standards you&#8217;re going to have to meet; start looking at them. So there&#8217;s an opportunity actually to make technology safer by design, by getting ahead of it. And I think that&#8217;s the era we&#8217;re in now.</p>



<p><strong>SULLIVAN:</strong> That makes a lot of sense. Just building on that, do businesses and the public trust these standards? And I guess, which standard do you wish the world would just adopt already, and what&#8217;s the real reason they haven&#8217;t?</p>



<p><strong>MARTIN:</strong> Well, again, where do you start? I mean, most members of the public quite rightly haven&#8217;t heard of any of these standards. I think public trust and public capital in any society matters. But I think it is important that these things are credible.</p>



<p>And there&#8217;s quite a lot of convergence between, you know, the top-level frameworks. And obviously in the US, you know, the NIST [National Institute of Standards and Technology] framework is the one that&#8217;s most popular for cybersecurity, but it bears quite a strong resemblance to the international one, ISO[/IEC] 27001, and there are others, as well. But fundamentally, they boil down to kind of five things. Do a risk assessment; work out what your crown jewels are. Protect your perimeter as best you can. Those are the first two.</p>



<p>The third one then is when your perimeter&#8217;s breached, be able to detect it more times than not. And when you can&#8217;t do that, you go to the fourth one, which is, can you mitigate it? And when all else fails, how quickly can you recover and manage it? I mean, all the standards are expressed in way more technical language than that, but fundamentally, if everybody adopted those five things and operated them in a simple way, you wouldn&#8217;t eliminate the harm, but you would reduce it quite substantially.</p>



<p><strong>SULLIVAN:</strong> Which policy initiatives are most promising for incentivizing companies to undertake, you know, these cybersecurity testing parameters that you’ve just outlined? Governments, including the UK, have used carrots and sticks, but what do you think will actually move the needle?</p>



<p><strong>MARTIN:</strong> I think there are two answers to that, and it comes back to your split between smaller businesses and critically important businesses. In the critically important services, I think it&#8217;s easier because most industries are looking for a level playing field. In other words, they realize there have to be rules and they want to apply them to everyone.</p>



<p>We had a fascinating experience when I was in government back in around 2018 where the telecom sector, they came to us and they said, we&#8217;ve got a very good cooperative relationship with the British government, but it needs to be put on a proper legal footing because you&#8217;re just asking us nicely to do expensive things. And in a regulated sector, if you actually put in some rules—and please develop them jointly with us; that&#8217;s the crucial part—then that will help because it means that we&#8217;re not going to our boards and saying, or our shareholders, and saying that we should do this, and they&#8217;re saying, “Well, do you have to do it? Are our competitors doing it?” And if the answer to that is, yes, we have to, and, yes, our competitors are doing it, then it tends to be OK.</p>



<p>The harder nut to crack is the smaller business. And I think there&#8217;s a real mystery here: why has nobody cracked a really good and easy solution for small business? We need to be careful about this because, you know, you can&#8217;t throttle small businesses with onerous regulation. At the same time, we&#8217;re not brilliant, I think, in any part of the world at using the normal corporate governance rules to try and get people to figure out how to do cybersecurity.</p>



<p>There are initiatives there that are not the sort of pretty heavy stick that you might have to take to a critical function, but they could help. But that is a hard nut to crack. And I look around the world, and, you know, I think if this was easy, somebody would have figured it out by now. I think most of the developed economies around the world really struggle with cybersecurity for smaller businesses.</p>



<p><strong>SULLIVAN:</strong> Yeah, it&#8217;s a great point. Actually building on one of the comments you made on the role of, kind of, government, how do you see the role of private-public partnerships scaling and strengthening, you know, robust cybersecurity testing?</p>



<p><strong>MARTIN:</strong> I think they&#8217;re crucial, but they have to be practical. I&#8217;ve got a slight, sort of, high horse on this, if you don&#8217;t mind, Kathleen. It&#8217;s sort of … [LAUGHS]</p>



<p><strong>SULLIVAN:</strong> Of course.</p>



<p><strong>MARTIN:</strong> I think that there are two types of public-private partnership. One involves committees saying that we should strengthen partnerships and we should all work together and collaborate and share stuff. And we tried that for a very long time, and it didn&#8217;t get us very far. There are other types.</p>



<p>We had some at the National Cyber Security Centre where we paid companies to do spectacularly good technical work that the market wouldn&#8217;t provide. So I think it&#8217;s sort of partnership with a purpose. I think sometimes, and I understand the human instinct to do this, particularly in governments and big business, they think you need to get around a table and work out some grand strategy to fix everything, and the scale of the … not just the problem but the scale of the whole technology is just too big to do that.</p>



<p>So pick a bit of the problem. Find some ways of doing it. Don&#8217;t over-lawyer it. [LAUGHTER] I think sometimes people get very nervous. <em>Oh, well, is this our role? You know, should we be doing this, that, and the other?</em> Well, you know, sometimes certainly in this country, you think, well, who&#8217;s actually going to sue you over this, you know? So I wouldn&#8217;t over-programmatize it. Just get stuck practically into solving some problems.</p>



<p><strong>SULLIVAN:</strong> I love that. Actually, [it] made me think, are there any surprising allies that you&#8217;ve gained—you know, maybe someone who you never expected to be a cybersecurity champion—through your work?</p>



<p><strong>MARTIN:</strong> Ooh! That&#8217;s a … that&#8217;s a… what a question! To give you a slightly disappointing answer, but it relates to your previous question. In the early part of my career, I was working in institutions like the UK Treasury long before I was in cybersecurity, and the treasury and the British civil service in general, but the treasury in particular sort of trained you to believe that the private sector was amoral, not <em>immoral</em>, <em>amoral</em>. It just didn&#8217;t have values. It just had bottom line, and, you know, its job essentially was to provide employment and revenue then for the government to spend on good things that people cared about. And when I got into cybersecurity and people said, look, you need to develop relations with this cybersecurity company, often in the US, actually. I thought, well, what&#8217;s in it for them?</p>



<p>And, sure, sometimes you were paying them for specific services, but other times, there was a real public spiritedness about this. There was a realization that if you tried to delineate public-private boundaries, that it wouldn&#8217;t really work. It was a shared risk. And you could analyze where the boundaries fell or you could actually go on and do something about it together. So I was genuinely surprised at the allyship from the cybersecurity sector. Absolutely, I really, really was. And I think it&#8217;s a really positive part of certainly the UK cybersecurity ecosystem.</p>



<p><strong>SULLIVAN:</strong> Wonderful. Well, we&#8217;re coming to the end of our time here, but is there any maybe last thoughts or perhaps requests you have for our listeners today?</p>



<p><strong>MARTIN:</strong> I think that standards, assurance, and testing <em>really</em> matter, but it&#8217;s a bit like the discussion we&#8217;re having over AI. Get all these things to take you 80, 90% of the way and then really apply your judgment. There&#8217;s been some bad regulation under the auspices of standards and assurance. First of all, it’s, have you done this assessment? Have you done that? Have you looked at this? Well, fine. And you can tick that box, but what does it actually mean when you do it? What bits that you know in your heart of hearts are really important to the defense of your organization that may not be covered by this and just go and do those anyway. Because sure it helps, but it&#8217;s not everything.</p>



<p><strong>SULLIVAN:</strong> No. Great, great closing sentiment. Well, Ciaran, thank you for joining us today. This has been just a super fun conversation and really insightful. Just really enjoyed the conversation. Thank you.</p>



<p><strong>MARTIN:</strong> My pleasure, Kathleen, thank you.</p>



<p>[TRANSITION MUSIC]</p>



<p><strong>SULLIVAN: </strong>Now, I&#8217;m happy to introduce Tori Westerhoff. As a principal director on the Microsoft AI Red Team, Tori leads all AI security and safety red team operations, as well as dangerous capability testing, to directly inform C-suite decision-makers.</p>



<p>So, Tori, welcome!</p>



<p><strong>TORI WESTERHOFF: </strong>Thanks. I am so excited to be here.</p>



<p><strong>SULLIVAN:</strong> I&#8217;d love to just start a little bit more learning about your background. You&#8217;ve worn some very intriguing hats. I mean, cognitive neuroscience grad from Yale, national security consultant, strategist in augmented and virtual reality … how do those experiences help shape the way you lead the Microsoft AI Red Team?</p>



<p><strong>WESTERHOFF:</strong> I always joke this is the only role I think will always combine the entire patchwork LinkedIn résumé. [LAUGHS]</p>



<p>I think I use those experiences to help me understand the really broad approach that AI Red Team—artist also known as <em>AIRT</em>; I&#8217;m sure I&#8217;ll slip into our acronym—how we frame up the broad security implications of AI. So I think the cognitive neuroscience element really helped me initially approach AI hacking, right. There&#8217;s a lot of social engineering and manipulation within chat interfaces that are enabled by AI. And also, kind of, this, like, metaphor for understanding how to find soft spots in the way that you see human heuristics show up, too. And so I think that was actually my personal “in” to getting hooked into AI red teaming generally.</p>



<p>But my experience in national security and I&#8217;d also say working through the AR/VR/metaverse space at the time where I was in it helped me balance both how our impact is framed, how we&#8217;re thinking about critical industries, how we&#8217;re really trying to push our understanding of where security of AI can help people the most. And also do it in a really breakneck speed in an industry that&#8217;s evolving all of the time, that&#8217;s really pushing you to always be at the bleeding edge of your understanding. So I draw a lot of the energy and the mission criticality and the speed from those experiences as we&#8217;re shaping up how we approach it.</p>



<p><strong>SULLIVAN:</strong> Can you just give us a quick rundown? What does the Red Team do? What actually, kind of, is involved on a day-to-day basis? And then as we think about, you know, our engagements with large enterprises and companies, how do we work alongside some of those companies in terms of testing?</p>



<p><strong>WESTERHOFF:</strong> The way I see our team is almost like an indicator light that works really part and parcel with product development. So the way we&#8217;ve organized our expert red teaming efforts is that we work with product development before anything ships out to anyone who can use it. And our job is to act as expert AI manipulators, AI hackers. And we are supposed to take the theories and methods and new research and harness it to find examples of vulnerabilities or soft spots in products to enable product teams to harden those soft spots before anything actually reaches someone who wants to use it.</p>



<p>So if we&#8217;re the indicator light, we are also not the full workup, right. I see that as measurement and evals. And we also are not the mechanic, which is that product development team that&#8217;s creating mitigations. It&#8217;s platform-security folks who are creating mitigations at scale. And there&#8217;s a really great throughput of insights from those groups back into our area where we love to inform about them, but we also love to add on to, how do we break the next thing, right? So it&#8217;s a continuous cycle.</p>



<p>And part of that is just being really creative and thinking outside of a traditional cybersecurity box. And part of that is also really thinking about how we pull in research—we have a research function within our AI Red Team—and how we automate and scale. This year, we&#8217;ve pulled a lot of those assets and insights into the <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" target="_blank" href="https://devblogs.microsoft.com/foundry/ai-red-teaming-agent-preview/">Azure [AI] Foundry AI Red Teaming Agent<span class="sr-only"> (opens in new tab)</span></a>. And so folks can now access a lot of our mechanisms through that. So you can get a little taste of what we do day to day in the AI Red Teaming Agent.</p>



<p><strong>SULLIVAN:</strong> You recently—actually, with your team—published <a href="https://www.microsoft.com/en-us/research/publication/lessons-from-red-teaming-100-generative-ai-products/">a report that outlined lessons from testing over a hundred generative AI products</a>. But could you share a bit about what you learned? What were some of the important lessons? Where do you see opportunities to improve the state of red teaming as a method for probing AI safety?</p>



<p><strong>WESTERHOFF:</strong> I think the most important takeaway from those lessons is that AI security is truly a team sport. You&#8217;ll hear cybersecurity folks say that a lot. And part of the rationale there is that the defense in depth and integrating and a view towards AI security through the entire development of AI systems is really the way that we&#8217;re going to approach this with intentionality and responsibility.</p>



<p>So in our space, we really focus on novel harm categories. We are pushing bleeding edge, and we also are pushing iterative and, like, contextually based red teaming in product dev. So outside of those hundred that we&#8217;ve done, there&#8217;s a community [LAUGHS] through the entire, again, multistage life cycle of a product that is really trying to push the cost of attacking those AI systems higher and higher with all of the expertise they bring. So we may be, like, the experts in AI hacking in that line, but there are also so many partners in the Microsoft ecosystem who are thinking about their market context or they really, really know the people who love their products. How are <em>they</em> using it?</p>



<p>And then when you bubble out, you also have industry and government who are working together to push towards the most secure AI implementation <em>for</em> <em>people</em>, right? And I think our team in particular, we feel really grateful to be part of the big AI safety and security ecosystem at Microsoft and also to be able to contribute to the industry writ large. <s></s></p>



<p><strong>SULLIVAN:</strong> As you know, we had a chance to speak with Professor Ciaran Martin from the University of Oxford about the cybersecurity industry and governance there. What are some of the ideas and tools from that space that are surfacing in how we think about approaching red teaming and AI governance broadly?</p>



<p><strong>WESTERHOFF:</strong> Yeah, I think it&#8217;s such a broad set of perspectives to bring in, in the AI instance. Something that I&#8217;ve noticed interjecting into security at the AI junction, right, is that cybersecurity has so many decades of experience of working through how to build trustworthy computing, for example, or bring an entire industry to bear in that way. And I think that AI security and safety can learn a lot of lessons of how to bring clarity and transparency across the industry to push universal understanding of where the threats really are.</p>



<p>So frameworks coming out of NIST, coming out of MITRE that help us have a universal language that inform governance, I think, are really important because it brings clarity irrespective of where you are looking into AI security, irrespective of your company size, what you&#8217;re working on. It means you all understand, “Hey, we are really worried about this fundamental impact.” And I think cybersecurity has done a really good job of driving towards impact as their organizational vector. And I am starting to see that in the AI space, too, where we&#8217;re trying to really clarify terms and threats.&nbsp;And you see it in updates of those frameworks, as well, that I really love.</p>



<p>So I think that the innovation is in transparency to folks who are really innovating and doing the work so we all have a shared language, and from that, it really creates communal goals across security instead of a lot of people being worried about the same thing and talking about it in a different way.</p>



<p><strong>SULLIVAN: </strong>Mm-hmm.<strong> </strong>In the cybersecurity context, Ciaran really stressed matching risk frameworks to an organization&#8217;s role <em>and</em> scale. Microsoft plays many roles, including building models and shipping applications. How does your red teaming approach shift across those layers?&nbsp;</p>



<p><strong>WESTERHOFF:</strong> I love this question also because I love it as part of our work. So one of the most fascinating things about working on this team has been the diversity of the technology that we end up red teaming and testing. And it feels like we&#8217;re in the crucible in that way. Because we see AI applied to so many different architectures, tech stacks, individual features, models, you name it.</p>



<p>Part of my answer is that we still care about the highest-impact things. And so irrespective of the iteration, which <em>is</em> really fascinating and I love, I still think that our team drives to say, “OK, what is that critical vulnerability that is going to affect people in the largest ways, and can we battle test to see if that can occur?”</p>



<p>So in some ways, the task is always the same. I think in the ways that we change our testing, we customize a lot to the access to systems and data and also people&#8217;s trust almost as different variables that could affect the impact, right.</p>



<p>So a good example is if we&#8217;re thinking through agentic frameworks that have access to functions and tools and preferential ability to act on data, it&#8217;s really different to spaces where that action may not be feasible, right. And so I think the tailoring of the way to get to that impact is hyper-custom every time we start an engagement. And part of it is very thesis driven and almost mechanizing <em>empathy</em>.</p>



<p>You almost need to really focus on how people could use, or misuse, in such a way that you can emulate it before to a really great signal to product development, to say this is truly what people could do and we want to deliver the highest-impact scenarios so you can solve for those and also solve the underlying patterns, actually, that could contribute to maybe that one piece of evidence but also all the related pieces of evidence. So singular drive but like hyper-, hyper-customization to what that piece of tech could do and has access to.</p>



<p><strong>SULLIVAN:</strong> What are some of the unexplored testing approaches or considerations from cybersecurity that you think we should encourage AI technologists, policymakers, and other stakeholders to focus on? <strong></strong></p>



<p><strong>WESTERHOFF:</strong> I do love that AI humbles us each and every day with new capabilities and the potential for new capabilities. It&#8217;s not just saying, “Hey, there&#8217;s one test that we want to try,” but more, “Hey, can we create a methodology that we feel really, really solid about so that when we are asked a question we haven&#8217;t even thought of, we feel confident that we have the resources and the system?”</p>



<p>So part of me is really intrigued by the process that we&#8217;re asked to make without knowing what those capabilities are really going to bring. And then I think tactically, AIRT is really pushing on how we create new research methodologies. How are we investing in, kind of, these longer-term iterations of red teaming? So we&#8217;re really excited about pushing out those insights in an experimental and longer-term way.</p>



<p>I think another element is a little bit of that evolution of how industry standards and frameworks are updating to the AI moment and really articulating where AI is either furthering adversarial ability to create those harms or threats or identifying where AI has a net new harm. And I think that demystifies a little bit about what we talked about in terms of the lessons learned, that fundamentally, a lot of the things that we talk about <em>are</em> traditional security vulnerabilities, and we are standing on kind of that cybersecurity shoulder. And I&#8217;m starting to see those updates translate in spaces that are already considered trustworthy and kind of the basis on which not only cybersecurity folks build their work but also business decision-makers make decisions on those frameworks.</p>



<p>So to me, integration of AI into those frameworks by those same standards means that we&#8217;re evolving security to include AI. We aren&#8217;t creating an entirely new industry of AI security and that, I think, really helps anchor people in the really solid foundation that we have in cybersecurity anyways.</p>



<p>I think there&#8217;s also some work around how the cyber, like, defenses will actually benefit from AI. So we think a lot about threats because that&#8217;s our job. But the other side of cybersecurity is offense. And I&#8217;m seeing a ton of people come out with frameworks and methodologies, especially in the research space, on how defensive networks are going to be benefited from things like agentic systems.</p>



<p>Generally speaking, I think the best practice is to realize that we&#8217;re fundamentally still talking about the same impacts, and we can use the same avenues, conversations, and frameworks. We just really want them to be crisply updated with that understanding of AI applications.</p>



<p><strong>SULLIVAN:</strong> How do you think about bringing others into the fold there? I think those standards and frameworks are often informed by technologists. But I&#8217;d love for you to expand [that to] policymakers or other kind of stakeholders in our ecosystem, even, you know, end consumers of these products. Like, how do we communicate some of this to them in a way that resonates and it has an impactful meaning?</p>



<p><strong>WESTERHOFF:</strong> I&#8217;ve found the AI security-safety space to be one of the more collaborative. I actually think the fact that I&#8217;m talking to you today is probably evidence that a ton of people are bringing in perspectives that don&#8217;t only come from a long-term cybersecurity view. And I see that as a trend in how AI is being approached opposed to how those areas were moving earlier. So I think that speed and the idea of conversations and not always having the perfect answer but really trying to be transparent with what everyone does know is kind of a communal energy in the communities, at least, where we&#8217;re playing. [LAUGHS] So I am pretty biased but at least the spaces where we are.</p>



<p><strong>SULLIVAN:</strong> No, I think we&#8217;re seeing that across the board. I mean, I&#8217;d echo [that] sitting in research, as well, like, that ability to have impact now and at speed to getting the amazing technology and models that we&#8217;re creating into the hands of our customers and partners and ecosystem is just underscored.</p>



<p>So on the note of speed, let&#8217;s shift gears a little bit to just a quick lightning round. I&#8217;d love to get maybe some quick thoughts from you, just 30-second answers here. I&#8217;ll start with one.</p>



<p>Which headline-grabbing AI threat do you think is mostly hot air?</p>



<p><strong>WESTERHOFF:</strong> I think we should pay attention to it all. I&#8217;m a red team lead. I love a good question to see if we can find an answer in real life. So no hot air, just questions.</p>



<p><strong>SULLIVAN:</strong> Is there some sort of maybe new tool that you can&#8217;t wait to sneak into the red team arsenal?</p>



<p><strong>WESTERHOFF:</strong> I think there are really interesting methodologies that break our understanding of cybersecurity by looking at the intersection between different layers of AI and how you can manipulate AI-to-AI interaction, especially now when we&#8217;re looking at agentic systems. So I would say a method, not a tool.</p>



<p><strong>SULLIVAN:</strong> So maybe ending on a little bit of a lighter note, do you have a go-to snack during an all-night red teaming session?</p>



<p><strong>WESTERHOFF:</strong> Always coffee. I would love it to be a protein smoothie, but honestly, it is probably Trader Joe&#8217;s elote chips. Like the whole bag. [LAUGHTER] It’s going to get me through. I&#8217;m going to not love that I did it.</p>



<p>[MUSIC]</p>



<p><strong>SULLIVAN:</strong> Amazing. Well, Tori, thanks so much for joining us today, and just a huge thanks also to Ciaran for his insights, as well.</p>



<p><strong>WESTERHOFF:</strong> Thank you so much for having me. This was a joy.</p>



<p><strong>SULLIVAN: </strong>And to our listeners, thanks for tuning in. You can find resources related to this podcast in the show notes. And if you want to learn more about how Microsoft approaches AI governance, you can visit <a href="https://www.microsoft.com/en-us/ai/responsible-ai">microsoft.com/RAI</a>.</p>



<p>See you next time! </p>



<p>[MUSIC FADES]</p>

				</span>
			</div>
			<button
				class="action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle"
				aria-expanded="false"
				data-show-less-text="Show less"
				type="button"
				aria-controls="show-more-show-less-toggle-1"
				aria-label="Show more content"
				data-alternate-aria-label="Show less content">
				Show more			</button>
		</div>
	</div>
</div>



<div class="wp-block-buttons is-layout-flex wp-block-buttons-is-layout-flex">
<div class="wp-block-button is-style-outline is-style-outline--2"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/story/ai-testing-and-evaluation-learnings-from-science-and-industry/">AI Testing and Evaluation podcast series</a></div>
</div>
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-cybersecurity/">AI Testing and Evaluation: Learnings from cybersecurity</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>How AI will accelerate biomedical research and discovery</title>
		<link>https://www.microsoft.com/en-us/research/podcast/how-ai-will-accelerate-biomedical-research-and-discovery/</link>
		
		<dc:creator><![CDATA[Peter Lee, Daphne Koller, Noubar Afeyan, Dr. Eric Topol]]></dc:creator>
		<pubDate>Thu, 10 Jul 2025 16:00:00 +0000</pubDate>
				<category><![CDATA[Microsoft Research Podcast]]></category>
		<guid isPermaLink="false">https://www.microsoft.com/en-us/research/?p=1144029</guid>

					<description><![CDATA[<p>Daphne Koller, Noubar Afeyan, and Dr. Eric Topol, leaders in AI-driven medicine, discuss how AI is changing biomedical research and discovery, from accelerating drug target identification and biotech R&#038;D to helping pursue the “holy grail” of a virtual cell.</p>
<p>The post <a href="https://www.microsoft.com/en-us/research/podcast/how-ai-will-accelerate-biomedical-research-and-discovery/">How AI will accelerate biomedical research and discovery</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Episode8-PeterEricNoubarDaphne-AIRevolution_Hero_Feature_No_Text_1400x788.jpg" alt="Illustrated images of Peter Lee, Daphne Koller, Noubar Afeyan, and Dr. Eric Topol for the Microsoft Research Podcast" class="wp-image-1144053" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Episode8-PeterEricNoubarDaphne-AIRevolution_Hero_Feature_No_Text_1400x788.jpg 1400w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Episode8-PeterEricNoubarDaphne-AIRevolution_Hero_Feature_No_Text_1400x788-300x169.jpg 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Episode8-PeterEricNoubarDaphne-AIRevolution_Hero_Feature_No_Text_1400x788-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Episode8-PeterEricNoubarDaphne-AIRevolution_Hero_Feature_No_Text_1400x788-768x432.jpg 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Episode8-PeterEricNoubarDaphne-AIRevolution_Hero_Feature_No_Text_1400x788-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Episode8-PeterEricNoubarDaphne-AIRevolution_Hero_Feature_No_Text_1400x788-655x368.jpg 655w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Episode8-PeterEricNoubarDaphne-AIRevolution_Hero_Feature_No_Text_1400x788-240x135.jpg 240w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Episode8-PeterEricNoubarDaphne-AIRevolution_Hero_Feature_No_Text_1400x788-640x360.jpg 640w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Episode8-PeterEricNoubarDaphne-AIRevolution_Hero_Feature_No_Text_1400x788-960x540.jpg 960w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Episode8-PeterEricNoubarDaphne-AIRevolution_Hero_Feature_No_Text_1400x788-1280x720.jpg 1280w" sizes="auto, (max-width: 1400px) 100vw, 1400px" /></figure>


<div class="wp-block-msr-podcast-container my-4">
	<iframe loading="lazy" src="https://player.blubrry.com/?podcast_id=146906724&modern=1" class="podcast-player" frameborder="0" height="164px" width="100%" scrolling="no" title="Podcast Player"></iframe>
</div>



<p>In November 2022, OpenAI’s ChatGPT kick-started a new era in AI. This was followed less than a half year later by the release of GPT-4. In the months leading up to GPT-4&#8217;s public release, Peter Lee, president of Microsoft Research, cowrote a book full of optimism for the potential of advanced AI models to transform the world of healthcare. What has happened since? In this special podcast series, <em>The AI Revolution in Medicine, Revisited</em>, Lee revisits the book, exploring how patients, providers, and other medical professionals are experiencing and using generative AI today while examining what he and his coauthors got right—and what they didn’t foresee.</p>



<p>In this episode, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.insitro.com/leadership/daphne-koller/" target="_blank" rel="noreferrer noopener">Daphne Koller<span class="sr-only"> (opens in new tab)</span></a>, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.flagshippioneering.com/people/noubar-afeyan" target="_blank" rel="noreferrer noopener">Noubar Afeyan<span class="sr-only"> (opens in new tab)</span></a>, and <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.scripps.edu/faculty/topol/" target="_blank" rel="noreferrer noopener">Dr. Eric Topol<span class="sr-only"> (opens in new tab)</span></a>, leaders in AI-driven medicine, join Lee to explore the rapidly evolving role of AI across the biomedical and healthcare landscape. Koller, founder and CEO of Insitro, shares how machine learning is transforming drug discovery, especially target identification for complex diseases like ALS, by uncovering biological patterns across massive datasets. Afeyan, founder and CEO of Flagship Pioneering and co-founder and chairman of Moderna, discusses how AI is being applied across biotech research and development, from protein design to autonomous science platforms. Topol, executive vice president of Scripps Research and founder and director of the Scripps Research Translational Institute, highlights how AI can <em>today</em> help mitigate and prevent the core diseases that erode our health and the possibility of realizing a virtual cell. Through his conversations with the three, Lee investigates how AI is reshaping the discovery, deployment, and delivery of medicine. </p>



<div class="wp-block-group msr-pattern-link-list is-layout-flow wp-block-group-is-layout-flow">
<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading h5" id="learn-more-1">Learn more:</h2>



<ul class="wp-block-list list-unstyled">
<li><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.youtube.com/watch?v=4uypxF54qaA" target="_blank" rel="noreferrer noopener">How Machine Learning Is Revolutionising Drug Discovery<span class="sr-only"> (opens in new tab)</span></a> (Koller)&nbsp;<br>WIRED Health talk | March 2025</li>



<li><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.insitro.com/news/insitro-and-lilly-enter-strategic-agreements-to-advance-novel-treatments-for-metabolic-diseases/" target="_blank" rel="noreferrer noopener">Insitro and Lilly Enter Strategic Agreements to Advance Novel Treatments for Metabolic Diseases<span class="sr-only"> (opens in new tab)</span></a>&nbsp;(Koller)&nbsp;<br>Insitro release | October 2024&nbsp;</li>



<li><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.flagshippioneering.com/polyintelligence/2025-annual-letter" target="_blank" rel="noreferrer noopener">2025 Annual Letter: Polyintelligence<span class="sr-only"> (opens in new tab)</span></a> (Afeyan)&nbsp;<br>Flagship Pioneering | 2025</li>



<li><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://archive.org/details/McGillLibrary-mcgill-daily-v72-n023-october-20-1982-12472/page/n5/mode/2up" target="_blank" rel="noreferrer noopener">The ultimate in mind extenders<span class="sr-only"> (opens in new tab)</span></a> (Afeyan)&nbsp;<br><em>McGill Daily</em> article (college newspaper) | October 1982&nbsp;</li>



<li><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://drerictopol.com/portfolio/super-agers/" target="_blank" rel="noreferrer noopener">Super Agers: An Evidence-Based Approach to Longevity<span class="sr-only"> (opens in new tab)</span></a> (Topol)&nbsp;<br>Book | May 2025&nbsp;</li>



<li><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://drerictopol.com/portfolio/deep-medicine/" target="_blank" rel="noreferrer noopener">Deep Medicine: How Artificial Intelligence Can Make Healthcare Human Again<span class="sr-only"> (opens in new tab)</span></a> (Topol)&nbsp;<br>Book | March 2019&nbsp;</li>



<li><a href="https://www.microsoft.com/en-us/research/publication/the-ai-revolution-in-medicine-gpt-4-and-beyond/">The AI Revolution in Medicine: GPT-4 and Beyond</a><br>Book | Peter Lee, Carey Goldberg, Isaac Kohane | April 2023</li>
</ul>
</div>



<div style="height:25px" aria-hidden="true" class="wp-block-spacer"></div>



<section class="wp-block-msr-subscribe-to-podcast subscribe-to-podcast">
	<div class="subscribe-to-podcast__inner border-top border-bottom border-width-2">
		<h2 class="h5 subscribe-to-podcast__heading">
			Subscribe to the <a href="https://www.microsoft.com/en-us/research/podcast">Microsoft Research Podcast</a>:		</h2>
		<ul class="subscribe-to-podcast__list list-unstyled">
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://itunes.apple.com/us/podcast/microsoft-research-a-podcast/id1318021537?mt=2" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="black" viewBox="0 0 32 32">  <path d="M7.12 0c-3.937-0.011-7.131 3.183-7.12 7.12v17.76c-0.011 3.937 3.183 7.131 7.12 7.12h17.76c3.937 0.011 7.131-3.183 7.12-7.12v-17.76c0.011-3.937-3.183-7.131-7.12-7.12zM15.817 3.421c3.115 0 5.932 1.204 8.079 3.453 1.631 1.693 2.547 3.489 3.016 5.855 0.161 0.787 0.161 2.932 0.009 3.817-0.5 2.817-2.041 5.339-4.317 7.063-0.812 0.615-2.797 1.683-3.115 1.683-0.12 0-0.129-0.12-0.077-0.615 0.099-0.792 0.192-0.953 0.64-1.141 0.713-0.296 1.932-1.167 2.677-1.911 1.301-1.303 2.229-2.932 2.677-4.719 0.281-1.1 0.244-3.543-0.063-4.672-0.969-3.595-3.907-6.385-7.5-7.136-1.041-0.213-2.943-0.213-4 0-3.636 0.751-6.647 3.683-7.563 7.371-0.245 1.004-0.245 3.448 0 4.448 0.609 2.443 2.188 4.681 4.255 6.015 0.407 0.271 0.896 0.547 1.1 0.631 0.447 0.192 0.547 0.355 0.629 1.14 0.052 0.485 0.041 0.62-0.072 0.62-0.073 0-0.62-0.235-1.199-0.511l-0.052-0.041c-3.297-1.62-5.407-4.364-6.177-8.016-0.187-0.943-0.224-3.187-0.036-4.052 0.479-2.323 1.396-4.135 2.921-5.739 2.199-2.319 5.027-3.543 8.172-3.543zM16 7.172c0.541 0.005 1.068 0.052 1.473 0.14 3.715 0.828 6.344 4.543 5.833 8.229-0.203 1.489-0.713 2.709-1.619 3.844-0.448 0.573-1.537 1.532-1.729 1.532-0.032 0-0.063-0.365-0.063-0.803v-0.808l0.552-0.661c2.093-2.505 1.943-6.005-0.339-8.296-0.885-0.896-1.912-1.423-3.235-1.661-0.853-0.161-1.031-0.161-1.927-0.011-1.364 0.219-2.417 0.744-3.355 1.672-2.291 2.271-2.443 5.791-0.348 8.296l0.552 0.661v0.813c0 0.448-0.037 0.807-0.084 0.807-0.036 0-0.349-0.213-0.683-0.479l-0.047-0.016c-1.109-0.885-2.088-2.453-2.495-3.995-0.244-0.932-0.244-2.697 0.011-3.625 0.672-2.505 2.521-4.448 5.079-5.359 0.547-0.193 1.509-0.297 2.416-0.281zM15.823 11.156c0.417 0 0.828 0.084 1.131 0.24 0.645 0.339 1.183 0.989 1.385 1.677 0.62 2.104-1.609 3.948-3.631 3.005h-0.015c-0.953-0.443-1.464-1.276-1.475-2.36 0-0.979 0.541-1.828 1.484-2.328 0.297-0.156 0.709-0.235 1.125-0.235zM15.812 17.464c1.319-0.005 2.271 0.463 2.625 1.291 0.265 0.62 0.167 2.573-0.292 5.735-0.307 2.208-0.479 2.765-0.905 3.141-0.589 0.52-1.417 0.667-2.209 0.385h-0.004c-0.953-0.344-1.157-0.808-1.553-3.527-0.452-3.161-0.552-5.115-0.285-5.735 0.348-0.823 1.296-1.285 2.624-1.291z"/></svg>
						<span class="subscribe-to-podcast__link-text">Apple Podcasts</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://subscribebyemail.com/www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M6.4 6a2.392 2.392 0 00-2.372 2.119L16 15.6l11.972-7.481A2.392 2.392 0 0025.6 6H6.4zM4 10.502V22.8a2.4 2.4 0 002.4 2.4h19.2a2.4 2.4 0 002.4-2.4V10.502l-11.365 7.102a1.2 1.2 0 01-1.27 0L4 10.502z"/></svg>
						<span class="subscribe-to-podcast__link-text">Email</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://subscribeonandroid.com/www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M12.414 4.02c-.062.012-.126.023-.18.06a.489.489 0 00-.12.675L13.149 6.3c-1.6.847-2.792 2.255-3.18 3.944h13.257c-.388-1.69-1.58-3.097-3.179-3.944l1.035-1.545a.489.489 0 00-.12-.675.492.492 0 00-.675.135l-1.14 1.68a7.423 7.423 0 00-2.55-.45c-.899 0-1.758.161-2.549.45l-1.14-1.68a.482.482 0 00-.494-.195zm1.545 3.824a.72.72 0 110 1.44.72.72 0 010-1.44zm5.278 0a.719.719 0 110 1.44.719.719 0 110-1.44zM8.44 11.204A1.44 1.44 0 007 12.644v6.718c0 .795.645 1.44 1.44 1.44.168 0 .33-.036.48-.09v-9.418a1.406 1.406 0 00-.48-.09zm1.44 0V21.76c0 .793.646 1.44 1.44 1.44h10.557c.793 0 1.44-.647 1.44-1.44V11.204H9.878zm14.876 0c-.169 0-.33.035-.48.09v9.418c.15.052.311.09.48.09a1.44 1.44 0 001.44-1.44v-6.719a1.44 1.44 0 00-1.44-1.44zM11.8 24.16v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84zm5.759 0v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84z"/></svg>
						<span class="subscribe-to-podcast__link-text">Android</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://open.spotify.com/show/4ndjUXyL0hH1FXHgwIiTWU" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M16 4C9.383 4 4 9.383 4 16s5.383 12 12 12 12-5.383 12-12S22.617 4 16 4zm5.08 17.394a.781.781 0 01-1.086.217c-1.29-.86-3.477-1.434-5.303-1.434-1.937.002-3.389.477-3.403.482a.782.782 0 11-.494-1.484c.068-.023 1.71-.56 3.897-.562 1.826 0 4.365.492 6.171 1.696.36.24.457.725.217 1.085zm1.56-3.202a.895.895 0 01-1.234.286c-2.338-1.457-4.742-1.766-6.812-1.747-2.338.02-4.207.466-4.239.476a.895.895 0 11-.488-1.723c.145-.041 2.01-.5 4.564-.521 2.329-.02 5.23.318 7.923 1.995.419.26.547.814.286 1.234zm1.556-3.745a1.043 1.043 0 01-1.428.371c-2.725-1.6-6.039-1.94-8.339-1.942h-.033c-2.781 0-4.923.489-4.944.494a1.044 1.044 0 01-.474-2.031c.096-.023 2.385-.55 5.418-.55h.036c2.558.004 6.264.393 9.393 2.23.497.292.663.931.371 1.428z"/></svg>
						<span class="subscribe-to-podcast__link-text">Spotify</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M6.667 4a2.676 2.676 0 00-2.612 2.13v.003c-.036.172-.055.35-.055.534v18.666c0 .183.019.362.055.534v.003a2.676 2.676 0 002.076 2.075h.002c.172.036.35.055.534.055h18.666A2.676 2.676 0 0028 25.333V6.667a2.676 2.676 0 00-2.13-2.612h-.003A2.623 2.623 0 0025.333 4H6.667zM8 8h1.333C17.42 8 24 14.58 24 22.667V24h-2.667v-1.333c0-6.618-5.382-12-12-12H8V8zm0 5.333h1.333c5.146 0 9.334 4.188 9.334 9.334V24H16v-1.333A6.674 6.674 0 009.333 16H8v-2.667zM10 20a2 2 0 11-.001 4.001A2 2 0 0110 20z"/></svg>
						<span class="subscribe-to-podcast__link-text">RSS Feed</span>
					</a>
				</li>
					</ul>
	</div>
</section>


<div class="wp-block-msr-show-more">
	<div class="bg-neutral-100 p-5">
		<div class="show-more-show-less" data-mount="show-more-show-less">
			<div>
				<span>
					

<h2 class="wp-block-heading" id="transcript">Transcript&nbsp;</h2>



<p>[MUSIC]</p>



<p>[BOOK PASSAGE]&nbsp;</p>



<p><strong>PETER LEE: </strong>“Can GPT-4 indeed accelerate the progression of medicine<strong> </strong>… ? It seems like a tall order, but if I had been told six months ago that it could rapidly summarize any published paper, that alone would have satisfied me as a strong contribution to research productivity. … But now that I&#8217;ve seen what GPT-4 can do with the healthcare process, I expect a lot more in the realm of research.”&nbsp;</p>



<p>[END OF BOOK PASSAGE]</p>



<p>[THEME MUSIC]</p>



<p>This is <em>The AI Revolution in Medicine, Revisited</em>. I’m your host, Peter Lee.</p>



<p>Shortly after OpenAI&#8217;s GPT-4 was publicly released, Carey Goldberg, Dr. Zak Kohane, and I published <em>The AI Revolution in Medicine </em>to help educate the world of healthcare and medical research about the transformative impact this new generative AI technology could have. But because we wrote the book when GPT-4 was still a secret, we had to speculate. Now, two years later, what did we get right, and what did we get wrong?</p>



<p>In this series, we’ll talk to clinicians, patients, hospital administrators, and others to understand the reality of AI in the field and where we go from here.</p>



<p>[THEME MUSIC FADES]</p>



<p>The book passage I read at the top was from “Chapter 8: Smarter Science,” which was written by Zak.</p>



<p>In writing the book, we were optimistic about AI’s potential to accelerate biomedical research and help get new and much-needed treatments and drugs to patients sooner. One area we explored was generative AI as a designer of clinical trials. We looked at generative AI’s adeptness at summarizing helping speed up pre-trial triage and research. We even went so far as to predict the arrival of a large language model that can serve as a central intellectual tool.&nbsp;</p>



<p>For a look at how AI is impacting biomedical research today, I’m excited to welcome Daphne Koller, Noubar Afeyan, and Eric Topol.&nbsp;</p>



				</span>
				<span id="show-more-show-less-toggle-3" class="show-more-show-less-toggleable-content">
					



<p>Daphne Koller is the CEO and founder of Insitro, a machine learning-driven drug discovery and development company that recently made news for its identification of a novel drug target for ALS and its collaboration with Eli Lilly to license Lilly&#8217;s biochemical delivery systems. Prior to founding Insitro, Daphne was the co-founder, co-CEO, and president of the online education platform Coursera.</p>



<p>Noubar Afeyan is the founder and CEO of Flagship Pioneering, which creates biotechnology companies focused on transforming human health and environmental sustainability. He is also co-founder and chairman of the messenger RNA company Moderna. An entrepreneur and biochemical engineer, Noubar has numerous patents to his name and has co-founded many startups in science and technology.</p>



<p>Dr. Eric Topol is the executive vice president of the biomedical research non-profit Scripps Research, where he founded and now directs the Scripps Research Translational Institute. One of the most cited researchers in medicine, Eric has focused on promoting human health and individualized medicine through the use of genomic and digital data and AI.&nbsp;</p>



<p>These three are likely to have an outsized influence on how drugs and new medical technologies soon will be developed.</p>



<p>[TRANSITION MUSIC]&nbsp;</p>



<p>Here’s my interview with Daphne Koller:</p>



<p><strong>LEE:</strong> Daphne, I&#8217;m just thrilled to have you join us.&nbsp;</p>



<p><strong>DAPHNE KOLLER: </strong>Thank you for having me, Peter. It&#8217;s a pleasure to be here.&nbsp;</p>



<p><strong>LEE: </strong>Well, you know, you&#8217;re quite well-known across several fields. But maybe for some audience members of this podcast, they might not have encountered you before. So where I&#8217;d like to start is a question I&#8217;ve been asking all of our guests.</p>



<p>How would you describe what you do? And the way I kind of put it is, you know, how do you explain to someone like your parents what you do for a living?&nbsp;</p>



<p><strong>KOLLER: </strong>So that answer obviously has shifted over the years.</p>



<p>What I would say now is that we are working to leverage the incredible convergence of very powerful technologies, of which AI is one but not the only one, to change the way in which we discover and develop new treatments for diseases for which patients are currently suffering and even dying.&nbsp;</p>



<p><strong>LEE: </strong>You know, I think I&#8217;ve known you for a long time.&nbsp;</p>



<p><strong>KOLLER:</strong> Longer than I think either of us care to admit.&nbsp;</p>



<p><strong>LEE: </strong>[LAUGHS] In fact, I think I remember you even when you were still a graduate student. But of course, I knew you best when you took up your professorship at Stanford. And I always, in my mind, think of you as a computer scientist and a machine learning person. And in fact, you really made a big name for yourself in computer science research in machine learning.</p>



<p>But now you&#8217;re, you know, leading one of the most important biotech companies on the planet. How did that happen?</p>



<p><strong>KOLLER:</strong> So people often think that this is a recent transition. That is, after I left Coursera, I looked around and said, “Hmm. What should I do next? Oh, biotech seems like a good thing,” but that&#8217;s actually not the way it transpired.</p>



<p>This goes all the way back to my early days at Stanford, where, in fact, I was, you know, as a young faculty member in machine learning, because I was the first machine learning hire into Stanford&#8217;s computer science department, I was looking for really exciting places in which this technology could be deployed, and applications back then, because of scarcity of data, were just not that inspiring.</p>



<p>And so I looked around, and this was around the late ’90s, and realized that there was interesting data emerging in biology and medicine. My first application actually was in, interestingly, in epidemiology—patient tracking and tuberculosis. You know, you can think of it as a tiny microcosm of the very sophisticated models that COVID then enabled in a much later stage.</p>



<p><strong>LEE: </strong>Right.&nbsp;</p>



<p><strong>KOLLER:</strong> And so initially, this was based almost entirely on just technical interest. It&#8217;s kind of like, oh, this is more interesting as a question to tackle than spam filtering. But then I became interested in biology in its own right, biology and medicine, and ended up having a bifurcated existence as a Stanford professor where half my lab continued to do core computer science research published in, you know, NeurIPS and ICML. And the other half actually did biomedical research that was published in, you know, <em>Nature Cell [and] Science</em>. So that was back in, you know, the early, early 2000s, and for most of my Stanford career, I continued to have both interests.</p>



<p>And then the Coursera experience kind of took me out of Stanford and put me in an industry setting for the first time in my life actually.<strong> </strong>But then when my time at Coursera came to an end, you know, I&#8217;d been there for five years. And if you look at the timeline, I left Stanford in early 2012, right as the machine learning revolution was starting. So I missed the beginning.</p>



<p>And it was only in like 2016 or so that, as I picked my head up over the trenches, like, “Oh my goodness, this technology is going to change the world.” And I wanted to deploy that big thing towards places where it would have beneficial impact on the world, like to make the world a better place.</p>



<p><strong>LEE: </strong>Yeah. </p>



<p><strong>KOLLER:</strong> And so I decided that one of the areas where I could make a unique, differentiated impact was in really bringing AI and machine learning to the life sciences, having spent, you know, the majority of my career at the boundary of those two disciplines. And notice I say “boundary” with deliberation because there wasn&#8217;t very much of an intersection.</p>



<p><strong>LEE: </strong>Right.&nbsp;</p>



<p><strong>KOLLER:</strong> I felt like I could do something that was unique.&nbsp;</p>



<p><strong>LEE: </strong>So just to stick on you for a little bit longer, you know, we have been sort of getting into your origin story about what we call AI today—but machine learning, so deep learning.&nbsp;</p>



<p>And, you know, there has always been a kind of an emotional response for people like you and me and now the general public about their first encounters with what we now call generative AI. I’d love to hear what your first encounter was with generative AI and how you reacted to this.&nbsp;</p>



<p><strong>KOLLER:</strong> I think my first encounter was actually an indirect one. Because, you know, the earlier generations of generative AI didn’t directly touch our work at <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.insitro.com/" target="_blank" rel="noreferrer noopener">Insitro<span class="sr-only"> (opens in new tab)</span></a>.&nbsp;</p>



<p>And yet at the same time, I had always had an interest in computer vision. That was a large part of my non-bio work when I was at Stanford.&nbsp;</p>



<p>And so some of my earlier even presentations, when I was trying to convey to people back in 2016 how this technology was going to transform the world, I was talking about the incredible progress in image recognition that had happened up until that point.&nbsp;</p>



<p>So my first interaction was actually in the generative AI for images, where you are able to go the other way …&nbsp;</p>



<p><strong>LEE:</strong> Yes.&nbsp;</p>



<p><strong>KOLLER: </strong>… where you can take a verbal description of an image and create—and this was back in the days when the images weren&#8217;t particularly photorealistic, but still a natural language description to an image was magic given that only two or three years before that, we were barely able to look at an image and write a short phrase saying, “This is a dog on the beach.” And so that arc, that hockey curve, was just mind blowing to me.&nbsp;</p>



<p><strong>LEE:</strong> Did you have moments of skepticism?&nbsp;</p>



<p><strong>KOLLER: </strong>Yeah, I mean the early, you know, early versions of ChatGPT, where it was more like parlor tricks and poking it a little bit revealed all of the easy ways that one could break it and make it do really stupid things. I was like, yeah, OK, this is kind of cute, but is it going to actually make a difference? Is it going to solve a problem that matters?&nbsp;</p>



<p>And I mean, obviously, I think now everyone agrees that the answer is yes, although there are still people who are like, yeah, but maybe it&#8217;s around the edges. I&#8217;m not among them, by the way, but &#8230; yeah, so initially there were like, “Yeah, this is cute and very impressive, but is it going to make a difference to a problem that matters?”&nbsp;</p>



<p><strong>LEE:</strong> Yeah.<strong> </strong>So now, maybe this is a good time to get into what you&#8217;ve been doing with ALS [amyotrophic lateral sclerosis]. You know, there&#8217;s a knee-jerk reaction from the technology side to focus on designing small molecules, on predicting, you know, their properties, you know, maybe binding affinity or aspects of ADME [absorption, distribution, metabolism, and excretion], you know, like absorption or dispersion or whatever.&nbsp;</p>



<p>And all of that is very useful, but if I understand the work on ALS, you went to a much harder place, which is to actually identify and select targets.&nbsp;</p>



<p><strong>KOLLER:</strong> That’s right.&nbsp;</p>



<p><strong>LEE:</strong> So first off, just for the benefit of the standard listeners of this podcast, explain what that problem is in general.&nbsp;</p>



<p><strong>KOLLER:</strong> No, for sure. And I think maybe I&#8217;ll start by just very quickly talking about the drug discovery and development arc, &#8230;</p>



<p><strong>LEE:</strong> Yeah.</p>



<p><strong>KOLLER:</strong> &#8230; which, by and large, consists of three main phases. That&#8217;s the standard taxonomy.&nbsp;The first is what&#8217;s called sometimes target discovery or identifying a therapeutic hypothesis, which looks like: if I modulate this target in this disease, something beneficial will happen.&nbsp;</p>



<p>Then, you have to take that target and turn it into a molecule that you can actually put into a person. It could be a small molecule. It could be a large molecule like an antibody, whatever. And then you have that construct, that molecule. And the last piece is you put it into a person in the context of a clinical trial, and you measure what has happened. And there&#8217;s been AI deployed towards each of those three stages in different ways.&nbsp;</p>



<p>The last one is mostly like an efficiency gain. You know, the trial is kind of already defined, and you want to deploy technology to make it more efficient and effective, which is great because those are expensive operations.&nbsp;</p>



<p><strong>LEE: </strong>Yep.&nbsp;</p>



<p><strong>KOLLER:</strong> The middle one is where I would say the vast majority of efforts so far has been deployed in AI because it is a nice, well-defined problem. It doesn&#8217;t mean it&#8217;s easy, but it&#8217;s one where you can define the problem. It is, <em>I need to inhibit this protein by this amount, and the molecule needs to be soluble and whatever and go past the blood-brain barrier</em>. And you know probably within a year and a half or so, or two, if you succeeded or not.&nbsp;</p>



<p>The first stage is the one where I would say the least amount of energy has gone because when you&#8217;re uncovering a novel target in the context of an indication, you don&#8217;t know that you&#8217;ve been successful until you go <em>all the way</em> to the end, which is the clinical trial, which is what makes this a long and risky journey. And not a lot of people have the appetite or the capital to actually do that.&nbsp;</p>



<p>However, in my opinion, and that of, I think, quite a number of others, it is where the biggest impact can be made. And the reason is that while pharma has its deficiencies, making good molecules is actually something they&#8217;re pretty good at.&nbsp;</p>



<p>It might take them longer than it should, maybe it&#8217;s not as efficient as it could be, but at the end of the day, if you tell them to drug A target, pharma is actually pretty good at generating those molecules. However, when you put those molecules into the clinic, 90% of them fail. And the reason they fail is not by and large because the molecule wasn&#8217;t good. In the majority of cases, it&#8217;s because the target you went after didn&#8217;t do anything useful in the context of the patient population in which you put it.&nbsp;</p>



<p>And so in order to fix the inefficiency of this industry, which is <em>incredible</em> inefficiency, you need to address the problem at the root, and the root is picking the right targets to go after. And so that is what we elected to do.&nbsp;</p>



<p>It doesn&#8217;t mean we don&#8217;t make molecules. I mean, of course, you can&#8217;t just end up with a target because a target is not actionable. You need to turn it into a molecule. And we absolutely do that. And by the way, the <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.insitro.com/news/insitro-and-lilly-enter-strategic-agreements-to-advance-novel-treatments-for-metabolic-diseases/" target="_blank" rel="noreferrer noopener">partnership with Lilly<span class="sr-only"> (opens in new tab)</span></a> is actually one where they help us make a molecule.&nbsp;</p>



<p><strong>LEE: </strong>Yes.&nbsp;</p>



<p><strong>KOLLER: </strong>I mean, it&#8217;s our target. It&#8217;s our program. But Lilly is deploying its very state-of-the-art molecule-making capabilities to help us turn that target into a drug.&nbsp;</p>



<p><strong>LEE: </strong>So let&#8217;s get now into the machine learning of this. Again, this just strikes me as such a difficult problem to solve.&nbsp;</p>



<p><strong>KOLLER:</strong> Yeah.&nbsp;</p>



<p><strong>LEE:</strong> So how does machine learning &#8230; how does AI help you?&nbsp;</p>



<p><strong>KOLLER:</strong> So I think when you look at how people currently select targets, it&#8217;s a combination of oftentimes at this point, with an increasing respect for the power of human genetics, some search for a genetic association, oftentimes with a human-defined, highly subjective, highly noisy clinical outcome, like some ICD [International Classification of Diseases] code.&nbsp;</p>



<p>And those are often underpowered and very difficult to deconvolute the underlying biology. You combine that with some mechanistic interrogation in a highly reductionist model system looking at a small number of readouts, biochemical readouts, that a biologist thinks are relevant to the disease. Like does this make this, whatever, cholesterol go up or amyloid beta go down? Or whatever. And then you take that as the second stage, and you pick, based on typically human intuition about, <em>Oh, this one looks good to me</em>, and then you take that forward.&nbsp;</p>



<p>What we&#8217;re doing is an attempt to be as unbiased and holistic as possible. So, first of all, rather than rely on human-defined clinical endpoints, like this person has been diagnosed with diabetes or fatty liver, we try and measure as much as we can a holistic physiological state and then use machine learning to find structure, patterns <em>in</em> that human physiological readouts, imaging readouts, and omics readouts from blood, from tissue, different kinds of imaging, and say, these are different vectors that this disease takes, this group of individuals, and here&#8217;s a different group of individuals that maybe from a diagnostical perspective are all called the same thing, but they are actually exhibiting a very different biology underlying it.&nbsp;</p>



<p>And so that is something that doesn&#8217;t emerge when a human being takes a reductionist view to looking at this high-content data, and oftentimes, they don&#8217;t even look at it and produce an ICD code.&nbsp;</p>



<p><strong>LEE: </strong>Right. Yep.&nbsp;</p>



<p><strong>KOLLER:</strong> The same approach, actually even the same code base, is taken in the cellular data. So we don&#8217;t just say, “Well, the thing that matters is, you know, the total amount of lipid in the cell or whatever.” Rather, we say, “Let&#8217;s look at multiple readouts, multiple ways of looking at the cells, combine them using the power of machine learning.” And again, looking at imaging readouts where a human&#8217;s eyes just glaze over looking at even a few dozen cells, far less a few hundreds of millions of cells, and understand what are the different biological processes that are going on. What are the vectors that the disease might take you in this direction, in this group of cells, or in that direction?&nbsp;</p>



<p>And then importantly, we take all of that information from the human side, from the cellular side, across these different readouts, and we combine them using an integrative approach that looks at the combined weight of evidence and says, these are the targets that I have the greatest amount of conviction about by looking across all of that information. Whereas we know, and we know this, I&#8217;m sure you&#8217;ve seen this analysis done for clinicians, a human being typically is able to keep three or four things in their head at the same time.&nbsp;</p>



<p><strong>LEE: </strong>Right.&nbsp;</p>



<p><strong>KOLLER:</strong> A really <em>good</em> human being who&#8217;s really expert at what they do can maybe get to six to eight.&nbsp;</p>



<p><strong>LEE: </strong>Yeah.&nbsp;</p>



<p><strong>KOLLER:</strong> The machine learning has no problem doing a few hundred.&nbsp;</p>



<p><strong>LEE: </strong>Right.&nbsp;</p>



<p><strong>KOLLER:</strong> And so you put that together, and that allows you, to your earlier question, really select the targets around which you have the highest conviction. And then those are the ones that we then prioritize for interrogation in more expensive systems like mice and monkeys and then at the end of the day pick the small handful that one can afford to actually take into clinical trials.&nbsp;</p>



<p><strong>LEE: </strong>So now, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.insitro.com/news/insitro-receives-25-million-in-milestone-payments-from-bristol-myers-squibb-for-the-achievement-of-discovery-milestones-and-the-selection-of-first-novel-genetic-target-for-als/" target="_blank" rel="noreferrer noopener">Insitro recently received $25 million in milestone payments from Bristol Myers Squibb<span class="sr-only"> (opens in new tab)</span></a> after discovering and selecting a novel drug target for ALS. Can you tell us a little bit more about that? </p>



<p><strong>KOLLER:</strong> We are incredibly excited about the first novel target, and there is a couple of others just behind it in line that seem, you know, quite efficacious, as well, that truly seem to reverse, albeit in a cellular system, what we now understand to be ALS pathology across multiple different dimensions. There&#8217;s been obviously many attempts made to try and address ALS, which by the way, horrible, horrible disease, worse than most cancers. It kills you almost inevitably in three to five years in a particularly horrific way.&nbsp;</p>



<p>And what we have in our hands is a target that seems to revert a lot of the pathologies that are associated with the disease, which we now understand has to do with the mis-splicing of multiple proteins within the cell and creating defective versions of those proteins that are just not operational. And we are seeing reversion of many of those.&nbsp;</p>



<p>So can I tell you for sure it&#8217;ll work in a human? No, there&#8217;s many steps between now and then. But we couldn&#8217;t be more excited about the opportunity to provide what we hope will be a disease-modifying intervention for these patients who really desperately need something.&nbsp;</p>



<p><strong>LEE: </strong>Well, it&#8217;s certainly been making waves in the biotech and biomedical world.&nbsp;</p>



<p><strong>KOLLER:</strong> Thank you.&nbsp;</p>



<p><strong>LEE: </strong>So we&#8217;ll be really watching very closely.&nbsp;</p>



<p>So, you know, I think just reflecting on, you know, what we missed and what we got right in our book, I think in our book, we did have the insight that there would be an ability to connect, say, genotypic and phenotypic data and, you know, just broadly the kinds of clinical measurements that get made on real patients and that these things could be brought together. And I think the work that you&#8217;re doing really illustrates that in a very, very sophisticated, very ambitious way.&nbsp;</p>



<p>But the fact that this could be connected all the way down to the biology, to the biochemistry, I think we didn&#8217;t have any clue what would happen, at least not this quickly.&nbsp;</p>



<p><strong>KOLLER:</strong> Well, I think the &#8230;&nbsp;</p>



<p><strong>LEE: </strong>And I realize, you&#8217;ve been at this for quite a few years, but still, it&#8217;s quite amazing.&nbsp;</p>



<p><strong>KOLLER:</strong> The thread that connects them is human genetics. And I think that has, to us, been, sort of, the, kind of, the connective tissue that allows you to translate across different systems and say, “What does this gene do? What does this gene do in this organ and in that organ? What does it do in this type of cell and in that type of cell?”&nbsp;</p>



<p>And then use that as sort of the thread, if you will, that follows the impact of modulating this gene all the way from the simple systems where you can do the experiment to the complex systems where you can&#8217;t do the experiment until the very end, but you have the human genetics as a way of looking at the statistics and understanding what the impact might be.&nbsp;</p>



<p><strong>LEE: </strong>So I&#8217;d like to now switch gears and take … I want to take two steps in the remainder of this conversation towards the future. So one step into that future, of course, we&#8217;re living through now, which is just all of the crazy pace of work and advancement in generative AI generally, you know, just the scale of transformers, of post-training, and now inference scale and reasoning models and so on. And where do you see all of that going with respect to the goals that you have and that Insitro has?&nbsp;</p>



<p><strong>KOLLER:</strong> So I think first and foremost is the parallel, if you will, to the predictions that you focused on in your book, which is this will transform a lot of the core data processing tasks, the information tasks. And sure, the doctors and nurses is one thing. But if you just think of clinical trial operations or the submission of regulatory documents, these are all kind of simple data … they&#8217;re not simple, obviously, but they&#8217;re data processing tasks. They involve natural language. That&#8217;s not going to be our focus, but I hope that others will use that to make clinical trials faster, more efficient, less expensive.&nbsp;</p>



<p>There&#8217;s already a lot of progress that&#8217;s happening on the molecular design side of things and taking hypotheses and turning them quickly and effectively into molecules. As I said, this is part of our work that we absolutely do and we don&#8217;t talk about it very much, simply because it&#8217;s a very crowded landscape and a lot of companies are engaged on that. But I think it&#8217;s really important to be able to take biological insights and turn them into new molecules.&nbsp;</p>



<p>And then, of course, the transformer models and their likes play a very significant role in that sort of turning insights into molecules because you can have foundation models for proteins. There are increasing efforts to create foundation models for other categories of molecules. And so that will undoubtedly accelerate the process by which you can quickly generate different molecular hypotheses and test them and learn from what you did so that you can do fewer iterations …&nbsp;</p>



<p><strong>LEE: </strong>Right.&nbsp;</p>



<p><strong>KOLLER:</strong> … before you converge on a successful molecule.&nbsp;</p>



<p>I do think that arguably the biggest impact as yet to be had is in that understanding of core human biology and what are the right ways to intervene in it. And that plays a role in a couple different ways. First of all, it certainly plays a role in which … if we are able to understand the human physiological state and, you know, the state of different systems all the way down to the cell level, that will inform our ability to pick hypotheses that are more likely to actually impact the right biologies underneath.&nbsp;</p>



<p><strong>LEE: </strong>Yep. Yeah.&nbsp;</p>



<p><strong>KOLLER:</strong> And the more data we&#8217;re able to collect about humans and about cells, the more successful our models will be at representing that human physiological state or the cell biological state and making predictions reliably on the impact of these interventions.&nbsp;</p>



<p>The other side of it, though, and this comes back, I think, to themes that were very much in your book, is this will impact not only the early stages of which hypotheses we interrogate, which molecules we move forward, but also hopefully at the end of the day, which molecule we prescribe to which patient.&nbsp;</p>



<p><strong>LEE: </strong>Right.&nbsp;</p>



<p><strong>KOLLER:</strong> And I think there&#8217;s been obviously so much narrative over the years about precision medicine, personalized medicine, and very little of that has come to fruition, with the exception of, you know, certain islands in oncology, primarily on genetically driven cancers.&nbsp;</p>



<p>But I think the opportunity is still there. We just haven&#8217;t been able to bring it to life because of the lack of the right kind of data. And I think with the increasing amount of human, kind of, foundational data that we&#8217;re able to acquire, things that are not sort of distilled through the eye of a clinician, for example, …&nbsp;</p>



<p><strong>LEE: </strong>Yes.&nbsp;</p>



<p><strong>KOLLER:</strong> … but really measurements of human pathology, we can start to get to some of that precision, carving out of the human population and then get to a world where we can prescribe the right medicine to the right patient and not only in cancer but also in other diseases that are also not a single disease.&nbsp;</p>



<p><strong>LEE: </strong>All right, so now to wrap up this time together, I always try to ask one more provocative last question. One of the dreams that comes naturally to someone like me or any of my colleagues, probably even to you, is this idea of, you know, wouldn&#8217;t it be possible someday to have a foundation model for biology or for human biology or foundation model for the human cell or something along these lines?&nbsp;</p>



<p>And in fact, there are, of course, you and I are both aware of people who are taking that idea seriously and chasing after it. I have people in our labs that think hard about this kind of thing. Is it a reasonable thought at all?&nbsp;</p>



<p><strong>KOLLER:</strong> I have learned over the years to avoid saying the word <em>never</em> because technology proceeds in ways that you often don&#8217;t expect. And so will we at some point be able to measure the cell in enough different ways across enough different channels at the same time that you can piece together what a cell does? I think that is eminently feasible, not today, but over time.&nbsp;</p>



<p>I don&#8217;t think it&#8217;s feasible using today&#8217;s technology, although the efforts to get there may expose where the biggest opportunities lie to, you know, build that next layer. So I think it&#8217;s good that people are working on really hard problems. I would also point out that even if one were to solve that really challenging problem of creating a model of <em>a cell</em>, there is thousands of different types of cells within the human body.&nbsp;</p>



<p>They&#8217;re very different. They also talk to each other …&nbsp;</p>



<p><strong>LEE: </strong>Yep.&nbsp;</p>



<p><strong>KOLLER:</strong> … both within the cell type and across different cell types. So the combinatorial complexity of that system is, I think, unfathomable to many people. I mean, I would say to all of us.&nbsp;</p>



<p><strong>LEE: </strong>Yeah.&nbsp;</p>



<p><strong>KOLLER: </strong>And so even from that very lofty goal, there is multiple big steps that would need to be taken to a <em>mechanistic</em> model of the full organism. So will we ever get there? Again, you know, I don&#8217;t see a reason why this is impossible to do. So I think over time, technology will get better and will allow us to build more and more elaborate models of more and more complex systems.&nbsp;</p>



<p>Patients can&#8217;t wait &#8230;</p>



<p><strong>LEE: </strong>Right. Yeah.&nbsp;</p>



<p><strong>KOLLER:</strong> … for that to happen in order for us to get them better medicines. So I think there is a great basic science initiative on that side of things. And, in parallel, we need to make do with the data that we have or can collect or can print. We print a lot of data in our internal wet labs and get to drugs that are effective even though they don&#8217;t benefit from having a full-blown mechanistic model.&nbsp;</p>



<p><strong>LEE: </strong>Last question: where do you think we&#8217;ll be in five years?&nbsp;</p>



<p><strong>KOLLER:</strong> Phew. If I had answered that question five years ago, I would have been very badly embarrassed at the inaccuracy of my answer. [LAUGHTER] So I will not answer it today either.&nbsp;</p>



<p>I will say that the thing about exponential curves is that they are very, very tricky, and they move in unexpected ways. I would hope that in five years, we will have made a sufficient investment in the generation of scientific data that we will be able to move beyond data that was generated entirely by humans and therefore insights that are derivative of what people already know to things that are truly novel discoveries.&nbsp;</p>



<p>And I think in order to do that in, you know, math, maybe because math is entirely conceptual, maybe you can do that today. Math is effectively a construct of the human mind. I don&#8217;t think biology is a construct of the human mind, and therefore one needs to collect enough data to really build those models that will give rise to those novel insights.&nbsp;</p>



<p>And that&#8217;s where I hope we will have made considerable progress in five years.&nbsp;</p>



<p><strong>LEE: </strong>Well, I&#8217;m with you. I hope so, too. Well, you know, thank you, Daphne, so much for this conversation. I learn a lot talking to you, and it was great to, you know, connect again on this. And congratulations on all of this success. It&#8217;s really groundbreaking.&nbsp;</p>



<p><strong>KOLLER:</strong> Thank you very much, Peter. It was a pleasure chatting with you, as well.&nbsp;</p>



<p>[TRANSITION MUSIC]&nbsp;</p>



<p><strong>LEE:</strong> I still think of Daphne first and foremost as an AI researcher. And for sure, her research work in machine learning continues to be incredibly influential to this day. But it&#8217;s her work on AI-enhanced drug development that now is on the verge of making a really big difference on some of the most difficult diseases afflicting people today.&nbsp;</p>



<p>In our book, Carey, Zak, and I predicted that AI might be a meaningful accelerant in biomedical research, but I don&#8217;t know that we foresaw the incredible potential specifically in drug development.&nbsp;</p>



<p>Today, we&#8217;re seeing a flurry of activity at companies, universities, and startups on generative AI systems that aid and maybe even completely automate the design of new molecules as drug candidates. But now, in our conversation with Daphne, seeing AI go even further than that to do what one might reasonably have assumed to be impossible, to identify and select novel drug targets, especially for a neurodegenerative disease like ALS, it&#8217;s just, well, mind blowing. </p>



<p>Let&#8217;s continue our deep dive on AI and biomedical research with this conversation with Noubar Afeyan:&nbsp;</p>



<p><strong>LEE: </strong>Noubar, thanks so much for joining. I&#8217;m really looking forward to this conversation.&nbsp;</p>



<p><strong>NOUBAR AFEYAN: </strong>Peter, thanks. Thrilled to be here.&nbsp;</p>



<p><strong>LEE:</strong> While I think most of the listeners to this podcast have heard of <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.flagshippioneering.com/" target="_blank" rel="noreferrer noopener">Flagship Pioneering<span class="sr-only"> (opens in new tab)</span></a>, it&#8217;s still worth hearing from you, you know, what is Flagship? And maybe a little bit about your background. And finally, you found a way to balance science and business creation. And so, you know, your approach and philosophy to all of that.&nbsp;</p>



<p><strong>AFEYAN: </strong>Well, great. So maybe I&#8217;ll just start out by way of quick background. You know, my &#8230; and since we&#8217;re going talk about AI, I&#8217;ll also highlight my first contact with the topic of AI. So as an undergraduate in 1980 up at McGill University, I was an engineering student, but I was really captivated by, at that time, the talk on the campus around the expert system, heuristic-based, rule-based kind of programs.&nbsp;</p>



<p><strong>LEE:</strong> Right.&nbsp;</p>



<p><strong>AFEYAN:</strong> And so actually I had the dubious distinction of writing my one and only college newspaper article. [LAUGHTER] That was a short career. And it was all about how artificial intelligence would be impacting medicine, would be impacting, you know, speech capture, translation, and some of the ideas that were there that it&#8217;s interesting to see now 45 years later re-emerge with some of the new learning-based models.&nbsp;</p>



<p>My journey after college ended up taking me into biotechnology. In the early ’80s, I came to MIT to do a PhD. At the time, the field was brand new. I ended up being the first PhD graduate from MIT in this combination biology and engineering degree. And since then, I&#8217;ve basically been—so since 1987—a founder, a technologist in the space of biotechnology for human health and as well for planetary health.&nbsp;</p>



<p>And then in 1999/2000 formed what is now Flagship Pioneering, which essentially was an attempt to bring together the three elements of what we know are important in startups. That is scientific capital, human capital, and financial capital. Right now, startups get that from different places. The science in our fields mostly come from academia, research hospitals. The human capital comes from other startups …&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>AFEYAN:</strong> … or large companies or some academics leave. And then the financial capital is usually venture capital, but there&#8217;s also now more and more other deeper pockets of money.&nbsp;</p>



<p>What we thought was, what if all that existed in one entity and instead of having to convince each other how much they should believe the other if we just said, “Let&#8217;s use that power to go work on much further out things”? But in a way where nobody would believe it in the beginning, but we could give ourselves a little bit of time to do impactful big things.&nbsp;</p>



<p>Twenty-five years later, that&#8217;s the road we&#8217;ve stayed on.&nbsp;</p>



<p><strong>LEE:</strong> OK. So let&#8217;s get into AI. Now, you know, what I&#8217;ve been asking guests is kind of an origin story. And there&#8217;s the origin story of contact with AI, you know, before the emergence of generative AI and afterwards. I don&#8217;t think there&#8217;s much of a point to asking you the pre-ChatGPT. But … so let&#8217;s focus on your first encounter with ChatGPT or generative AI. When did that happen, and what went through your head?&nbsp;</p>



<p><strong>AFEYAN:</strong> Yeah. So, if you permit me, Peter, just for very briefly, let me actually say I had the interesting opportunity over the last 25 years to actually stay pretty close to the machine learning world …&nbsp;</p>



<p><strong>LEE: </strong>Yeah. Yeah.&nbsp;</p>



<p><strong>AFEYAN:</strong> … because one, as you well know, among the most prolific users of machine learning has been the bioinformatics computational biology world because it&#8217;s been so data rich that anything that can be done, people have thrown at these problems because unlike most other things, we&#8217;re not working on man-made data. We&#8217;re looking at data that comes from nature, the complexity of which far exceeds our ability to comprehend.&nbsp;</p>



<p>So you could imagine that any approach to statistically reduce complexity, get signal out of scant data—that&#8217;s a problem that&#8217;s been around.&nbsp;</p>



<p>The other place where I&#8217;ve been exposed to this, which I&#8217;m going to come back to because that&#8217;s where it first felt totally different to me, is that some 25 years ago, actually the very first company we started was a company that attempted to use evolutionary algorithms to essentially iteratively evolve consumer-packaged goods online. Literally, we tried to, you know, consider features of products as genes and create little genomes of them. And by recombination and mutation, we could create variety. And then we could get people through panels online—this was 2002/2003 timeframe—we could essentially get people through iterative cycles of voting to create a survival of the fittest. And that&#8217;s a company that was called Affinnova.&nbsp;</p>



<p>The reason I say that is that I knew that there’s a much better way to do this if only: one, you can generate variety …&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>AFEYAN:</strong> … without having to prespecify genes. We couldn’t do that before. And, two, which we’ve come back to nowadays, you can actually mimic how humans think about voting on things and just get rid of that element of it.&nbsp;</p>



<p>So then to your question of when does this kind of begin to feel different? So you could imagine that in biotechnology, you know, as an engineer by background, I always wanted to do CAD, and I picked the one field in which CAD doesn&#8217;t exist, which is biology. Computer-aided design is kind of a notional thing in that space. But boy, have we tried. For a long time, &#8230;</p>



<p><strong>LEE:</strong> Yep.&nbsp;</p>



<p><strong>AFEYAN:</strong> &#8230; people would try to do, you know, hidden Markov models of genomes to try to figure out what <em>should</em> be the next, you know, base that you may want to or where genes might be, etc. But the notion of generating in biology has been something we&#8217;ve tried for a while. And in the late teens, so kind of 2018, ’17, ’18, because we saw deep learning come along, and you could basically generate novelty with some of the deep learning models … and so we started asking, “Could you generate a protein basically by training a correspondence table, if you will, between protein structures and their underlying DNA sequence?” Not their protein sequence, but their DNA sequence.&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>AFEYAN:</strong> So that&#8217;s a big leap. So ’17/’18, we started this thing. It was called 56. It was FL56, Flagship Labs 56, our 56th project.&nbsp;</p>



<p>By the way, we started this parallel one called “57” that did it in a very different way. So one of them did pure black box model-building. The other one said, you know what, we don&#8217;t want to do the kind of &#8230; at that time, AlphaFold was in its very early embodiments. And we said, “Is there a way we could actually take little, you know, multi amino acid kind of almost grammars, if you will, a little piece, and then see if we could compose a protein that way?” So we were experimenting.&nbsp;</p>



<p>And what we found was that actually, if you show enough instances and you could train a transformer model—back in the day, that&#8217;s what we were using—you could actually, say, predict another sequence that should have the same activity as the first one.&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>AFEYAN: </strong>So we trained on green fluorescent proteins. Now, we&#8217;re talking about seven years ago. We trained on enzymes, and then we got to antibodies.&nbsp;</p>



<p>With antibodies, we started seeing that, boy, this could be a pretty big deal because it has big market impact. And we started bringing in some of the diffusion models that were beginning to come along at that time. And so we started getting much more excited. This was all done in a company that subsequently got renamed from FL56 to <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://generatebiomedicines.com/" target="_blank" rel="noreferrer noopener">Generate:Biomedicines<span class="sr-only"> (opens in new tab)</span></a>, …&nbsp;</p>



<p><strong>LEE:</strong> Yep, yep.&nbsp;</p>



<p><strong>AFEYAN: </strong>… which is one of the leaders in protein design using the generative techniques. It was interesting because Generate:Biomedicines is a company that was called that before generative AI was a thing, [LAUGHTER] which was kind of very ironic.&nbsp;</p>



<p>And, of course, that team, which operates today very, very kind of at the cutting edge, has published their models. They came up with this first <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://generatebiomedicines.com/media-center/generate-biomedicines-uses-ai-to-create-proteins-that-have-never-existed?utm_source=chatgpt.com" target="_blank" rel="noreferrer noopener">Chroma<span class="sr-only"> (opens in new tab)</span></a> model, which is a diffusion-based model, and then started incorporating a lot of the LLM capabilities and fusing them.&nbsp;</p>



<p>Now we&#8217;re doing atomistic models and many other things. The point being, that gave us a glimpse of how quickly the capability was gaining, …&nbsp;</p>



<p><strong>LEE: </strong>Yeah. Yeah.&nbsp;</p>



<p><strong>AFEYAN:</strong> … just like evolution shows you. Sometimes evolution is super silent, and then all of a sudden, all hell breaks loose. And that&#8217;s what we saw.&nbsp;</p>



<p><strong>LEE: </strong>Right. One of the things that I reflect on just in my own journey through this is there are other emotions that come up. One that was prominent for me early on was skepticism. Were there points when even in your own work, transformer-based work on this early on, that you had doubts or skepticism that these transformer architectures would be or diffusion-based approaches would be worth anything?&nbsp;</p>



<p><strong>AFEYAN:</strong> You know, it&#8217;s interesting, I think that, I&#8217;m going to say this to you in a kind of a friendly way, but you&#8217;ll understand what I mean. In the world I live in, it&#8217;s kind of like the slums of innovation, [LAUGHTER] kind of like just doing things that are not supposed to work. The notion of skepticism is a luxury, right. I assume everything we do won&#8217;t work. And then once in a while I&#8217;m wrong.&nbsp;</p>



<p>And so I don&#8217;t actually try to evaluate whether before I bring something in, like just think about it. We, some hundred or so times a year, ask “what if” questions that lead us to totally weird places of thought. We then try to iterate, iterate, iterate to come up with something that&#8217;s testable. Then we go into a lab, and we test it.&nbsp;</p>



<p>So in that world, right, sitting there going, like, “How do I know this transformer is going to work?” The answer is, “For what?” Like, it&#8217;s going to work. To make something up &#8230; well, guess what? We knew early on with LLMs that hallucination was a feature, not a bug for what we wanted to do.&nbsp;</p>



<p>So it&#8217;s just such a different use that, of course, I have trained scientific skepticism, but it&#8217;s a little bit like looking at a competitive situation in an ecology and saying, “I bet that thing&#8217;s going to die.” Well, you&#8217;d be right—most of the time, you&#8217;d be right. [LAUGHTER]&nbsp;</p>



<p>So I just don&#8217;t … like, it … and that&#8217;s why—I guess, call me an early adopter—for us, things that could move the needle even a little, but then upon repetition a lot, let alone this, …&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>AFEYAN:</strong> … you have to embrace. You can&#8217;t wait there and say, I&#8217;ll embrace it once it&#8217;s ready. And so that&#8217;s what we did.&nbsp;</p>



<p><strong>LEE: </strong>Hmm. All right. So let&#8217;s get into some specifics and what you are seeing either in your portfolio companies or in the research projects or out in the industry. What is going on today with respect to AI really being used for something meaningful in the design and development of drugs?&nbsp;</p>



<p><strong>AFEYAN:</strong> In companies that are doing as diverse things as—let me give you a few examples—a project that&#8217;s now become a named company called <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.profoundtx.com/" target="_blank" rel="noreferrer noopener">ProFound Therapeutics<span class="sr-only"> (opens in new tab)</span></a> that literally discovered three, four years ago, and would not have been able to without some of the big data-model-building capabilities, that our cells make literally thousands, if not tens of thousands, of more proteins than we were aware of, full stop.&nbsp;</p>



<p>We had done the human genome sequence, there was 20,000 genes, we thought that there was …&nbsp;</p>



<p><strong>LEE: </strong>Wow.&nbsp;</p>



<p><strong>AFEYAN:</strong> … maybe 70-80,000, 100,000 proteins, and that&#8217;s that. And it turns out that our cells have a penchant to express themselves in the form of proteins, and they have many other ways than we knew to do that.&nbsp;</p>



<p>Now, so what does that mean? That means that we have generated a massive amount of data, the interpretation of which, the use of which to guide what you do and what these things might be involved with is purely being done using the most cutting-edge data-trained models that allow you to navigate such complexity.&nbsp;</p>



<p><strong>LEE:</strong> Wow. Hmm.&nbsp;</p>



<p><strong>AFEYAN:</strong> That&#8217;s just one example. Another example: a company called <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://quotient-tx.com/" target="_blank" rel="noreferrer noopener">Quotient Therapeutics<span class="sr-only"> (opens in new tab)</span></a>, again three, four years old. I can talk about the ones that are three, four years old because we&#8217;ve kind of gotten to a place where we&#8217;ve decided that it&#8217;s not going to fail <em>yet</em>, [LAUGHTER] so we can talk about it.&nbsp;</p>



<p>You know, we discovered—our team discovered—that in our cells, right, so we know that when we get cancer, our cells have genetic mutations in them or DNA mutations that are correlated and often causal to the hyperproliferative stages of cancer. But what we assume is that all the other cells in our body, pretty much, have one copy of their genes from our mom, one copy from our dad, and that&#8217;s that.&nbsp;</p>



<p>And when very precise deep sequencing came along, we always asked the question, “How much variation is there cell to cell?”&nbsp;</p>



<p><strong>LEE:</strong> Right.&nbsp;</p>



<p><strong>AFEYAN:</strong> And the answer was it&#8217;s kind of noise, random variation. Well, our team said, “Well, what if it&#8217;s not really that random?” because upon cell division cycles, there&#8217;s selection happening on these cells. And so not just in cancer but in liver cells, in muscle cells, in skin cells …&nbsp;</p>



<p><strong>LEE: </strong>Oh, interesting.&nbsp;</p>



<p><strong>AFEYAN:</strong> … can you imagine that there&#8217;s an evolutionary experiment that is favoring either compensatory mutations that are helping you avoid disease or disease-caused mutations that are gaining advantage as a way to understand the mechanism? Sure enough—I wouldn&#8217;t be telling you otherwise—with <em>massive</em> amount of single cell sequencing from individual patient samples, we&#8217;ve now discovered that the human genome is mutated on average in our bodies 10,000 times, like over every base, like, it&#8217;s huge numbers.&nbsp;</p>



<p>And we&#8217;re finding very interesting big signals come out of this massive amount of data. By the way, data of the sort that the human mind, if it tries to assign causal explanations to what&#8217;s happening …&nbsp;</p>



<p><strong>LEE: </strong>Right.&nbsp;</p>



<p><strong>AFEYAN:</strong> … is completely inadequate.&nbsp;</p>



<p><strong>LEE:</strong> When you think about a language model, we&#8217;re learning from human language, and the totality of human language—at least relative to what we&#8217;re able to compute today in terms of constructing a model—the totality of human language is actually pretty limited. And in fact, you know, as is always written about in click-baity titles, you know, the big model builders are actually starting to run short.&nbsp;</p>



<p><strong>AFEYAN:</strong> Running out, running out, yes. [LAUGHTER]&nbsp;</p>



<p><strong>LEE:</strong> But one of the things that perplexes me and maybe even worries me—like these two examples—are generally in the realm of cellular biology and the complexity. Let&#8217;s just take the example of your company, ProFound. You know, the complexity of what&#8217;s going on and the potential genetic diversity is such that, can we ever have enough data? You know, because there just aren&#8217;t that many human beings. There just aren&#8217;t that many samples.&nbsp;</p>



<p><strong>AFEYAN: </strong>Well, it depends on what you want to train, right. So if you want to train a <em>de novo</em> evolutionary model that could take you from bacteria to human mammalian cells and the like, there may not be—and I&#8217;m not an expert in that—but that&#8217;s a question that we often kind of think about.&nbsp;</p>



<p>But if you&#8217;re trying to train a &#8230; like you know what the proteins we know about, how they interact with pathways and disease mechanisms and the like. Now all of a sudden you find out that there&#8217;s a whole continent of them missing in your explanations. But there are things you can reason, in quotations, through analogy, functional analogy, sequence analogy, homology. So there&#8217;s a lot of things that we could do to essentially make use of this, even though you may not have the totality of data needed to, kind of, predict, based on a de novo sequence, exactly what it&#8217;s going to do.&nbsp;</p>



<p>So I agree with the comparison. But &#8230; but you&#8217;re right. The complexity is … just keep in mind, on average, a protein may be interacting with 50 to 100 other proteins.&nbsp;</p>



<p><strong>LEE: </strong>Right.&nbsp;</p>



<p><strong>AFEYAN:</strong> So if you find thousands of proteins, you&#8217;ve found a massive interaction space through which information is being processed in a living cell.&nbsp;</p>



<p><strong>LEE: </strong>But do you find in your AI companies that access to data ends up being a key challenge? Or, you know, how central is that?&nbsp;</p>



<p><strong>AFEYAN:</strong> Access to data is a key challenge for the companies we have that are trying to build just models. But that&#8217;s the minority of things we do. The majority of things we do is to actually co-develop the data and the models. And as you know well, because you guys, you know, have given us some ideas around this space, that, you know, you could generate data and <em>then</em> think about what you&#8217;re to do with it, which is the way biotech is operated with bioinformatics.&nbsp;</p>



<p><strong>LEE:</strong> Right, right.&nbsp;</p>



<p><strong>AFEYAN:</strong> Or you could generate bespoke data that is used to train the model that&#8217;s quite separate from what you would have done in the natural course of biology. So we&#8217;re doing much more of the latter of late, and I think that&#8217;ll continue. So, but these things are proliferating.&nbsp;</p>



<p>I mean,<strong> </strong>it&#8217;s hard to find a place where we&#8217;re not using this.<strong> </strong>And the “this” is any and all data-driven model building, generative, LLM-based, but also every other technique to make progress.&nbsp;</p>



<p><strong>LEE: </strong>Sure.<strong> </strong>So now moving away from the straight biochemistry applications, what about AI in the process of building a business, of making investment decisions, of actually running an operation? What are you seeing there?&nbsp;</p>



<p><strong>AFEYAN:</strong> So, well, you know, Moderna, which is a company that I&#8217;m quite proud of being a founder and chairman of, has adopted a significant, significant amount of AI embedded into their operations in all aspects: from the manufacturing, quality control, the clinical monitoring, the design—every aspect. And in fact, they&#8217;ve had a partnership that they&#8217;ve had for a little while here with OpenAI, and they&#8217;ve tried many different ways to stay at the cutting edge of that.&nbsp;</p>



<p>So we see that play out at some scale. That’s a 5,000-, 6,000-person organization, and what they&#8217;re doing is a good example of what early adopters would do, at least in our kind of biotechnology company.&nbsp;</p>



<p>But then, you know, in our space, I would say the efficiency impact is kind of no different, than, you know, anywhere else in academia you might adopt it or in other kinds of companies. But where I find it an interesting kind of maybe segue is the degree to which<strong> </strong>it may fundamentally change the way we think about how to do science, which is a whole other use, right?&nbsp;</p>



<p><strong>LEE: </strong>Right.&nbsp;</p>



<p><strong>AFEYAN:</strong> So it&#8217;s not an efficiency gain <em>per se</em>, although it&#8217;s maybe an effectiveness gain when it comes to science, but can you just fundamentally train models to generate hypotheses?&nbsp;</p>



<p><strong>LEE: </strong>Yep.&nbsp;</p>



<p><strong>AFEYAN: </strong>And we have done that, and we&#8217;ve been doing this for the last three years. And now it&#8217;s getting better and better, the better these reasoning engines are getting and kind of being able to extrapolate and train for novelty. Can you convert that to the world&#8217;s best experimental protocol to very precisely falsify your hypothesis, on and on?&nbsp;</p>



<p>That closing of that loop, kind of what we call <em>autonomous science</em>, which we&#8217;ve been trying to do for the last two, three years and are making some progress in, that to me is another kind of bespoke use of these things, not to generate molecules in its chemistry, but to change the behavior of how science is done.&nbsp;</p>



<p><strong>LEE: </strong>Yeah.<strong> </strong>So I always end with a couple of provocative questions, but I need—before we do that, while we&#8217;re on this subject—to get your take on <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.flagshippioneering.com/news/press-release/flagship-pioneering-unveils-lila-sciences-to-build-superintelligence-in-science" target="_blank" rel="noreferrer noopener">Lila Sciences<span class="sr-only"> (opens in new tab)</span></a>.&nbsp;</p>



<p>And there is a vision there that I think is very interesting. It&#8217;d be great to hear it described by you.&nbsp;</p>



<p><strong>AFEYAN:</strong> Sure. So Lila, after operating for two to three years in kind of a preparatory kind of stealth mode, we&#8217;ve now had a little bit more visibility around, and essentially what we&#8217;re trying to do there is to create what we call automated science factories, and such a factory would essentially be able to take problems, either computationally specified or human-specified, and essentially do the experimental work in order to either make an optimization happen or enable something that just didn’t exist. And it’s really, at this point, we’ve shown proof of concept in narrow areas.&nbsp;</p>



<p><strong>LEE:</strong> Yep.&nbsp;</p>



<p><strong>AFEYAN:</strong> But it’s hard to say that if you can do this, you can’t do some other things, so we’re just expanding it that way. We don’t think we need a complete proof or complete demonstration of it for every aspect.&nbsp;</p>



<p><strong>LEE: </strong>Right.&nbsp;</p>



<p><strong>AFEYAN:</strong> So we&#8217;re just kind of being opportunistic. The idea for Lila is to partner with a number of companies. The good news is, within Flagship, there&#8217;s 48 of them. And so there&#8217;s a whole lot of them they can partner with to get their learning cycles. But eventually they want to be a real alternative to every time somebody has an idea, having to kind of go into a lab and manually do this.&nbsp;</p>



<p>I do want to say one thing we touched on, Peter, though, just on that front, which is &#8230;&nbsp;</p>



<p><strong>LEE:</strong> Yep.&nbsp;</p>



<p><strong>AFEYAN:</strong> &#8230; if you say, like, “What problem is this going to solve?” It&#8217;s several but an important one is just the flat-out human capacity to reason on this much data and this much complexity that is real. Because nature doesn&#8217;t try to abstract itself in a human understandable form.&nbsp;</p>



<p><strong>LEE:</strong> Right. Yeah.&nbsp;</p>



<p><strong>AFEYAN:</strong> In biology, since it&#8217;s kind of like progress happens through evolutionary kind of selections, the evidence of which [has] long been lost, and so therefore, you just see what you have, and then it has a behavior. I really do think that there&#8217;s something to be said, and I want to—just for your audience—lay out a provocative, at least, thought on all this, which Lila is a beginning embodiment of, which is that I really think that what&#8217;s going to happen over the next five, 10 years, even while we&#8217;re all fascinated with the impending arrival of AGI [artificial general intelligence] is really what I call <em>poly-intelligence</em>, which is the combination of human intelligence, machine intelligence, AI, and nature&#8217;s intelligence.&nbsp;</p>



<p>We&#8217;re all fascinated at the human-machine interface. We know the human-nature interface, but imagine the machine-nature interface—that is, actually letting loose a digital kind of information processing life form through the algorithms that are being developed and the commensurately complex, maybe much more complex. We&#8217;ll see. And so now the question becomes, what does the human do?&nbsp;</p>



<p>And we&#8217;re living in a world which is human dominated, which means the humans say, “If I don&#8217;t understand it, it&#8217;s not real, basically. And if I don&#8217;t understand it, I can&#8217;t regulate it.” And we&#8217;re going to have to make peace with the fact that we&#8217;re not going to be able to predictably affect things without necessarily understanding them the way we could if we just forced ourselves to only work on problems we can understand. And that world we&#8217;re not ready for at all.&nbsp;</p>



<p><strong>LEE:</strong> Yeah. All right. So this one I predict is going to be a little harder for you because I think while you think about the future, you live very much in the present. But I&#8217;d like you to make some predictions about what the biotech and biopharmaceutical industries are going to be able to do two years from now, five years from now, 10 years from now.&nbsp;</p>



<p><strong>AFEYAN:</strong> Yeah, well, it&#8217;s hard for me because you know my nature, which is that I think this is all emergent.&nbsp;</p>



<p><strong>LEE:</strong> Right.&nbsp;</p>



<p><strong>AFEYAN:</strong> And so I would be the conceit of predicting. So I would say with likelihood positive predictive value of less than 10%, I&#8217;m happy to answer your question. So I&#8217;m not trying to score high [LAUGHTER] because I really think that my job is to envision it, not to predict it. And that&#8217;s a little bit different, right?&nbsp;</p>



<p><strong>LEE:</strong> Yeah, I actually was trying to pick what would be the hardest possible question I could ask you, [LAUGHTER] and this is what I came up with.&nbsp;</p>



<p><strong>AFEYAN:</strong> Yeah, no, no, I&#8217;m kidding here. So now look, I think that we will cross this threshold of understandability. And of course you&#8217;re seeing that in a lot of LLM things today. And of course, people are trying to train for things that are explainers and all that whole, there&#8217;s a whole world of that. But I think at some point we&#8217;re going to have to kind of let go and get comfortable working on things that, you know …&nbsp;</p>



<p>I sometimes tell people, you know, and I&#8217;m not the first, but scientists and engineers are different, it&#8217;s said, in that engineers work on things that they don&#8217;t wait until they get a full understanding of before they work with them. Well, now scientists are going to have to get used to that, too, right?&nbsp;</p>



<p><strong>LEE:</strong> Yeah. Yeah.&nbsp;</p>



<p><strong>AFEYAN:</strong> Because insisting that it&#8217;s only valid if it&#8217;s understandable. So, I would say, look, I hope that the time … for example, I think major improvements will be made in patient selection. If we can test drugs on patients that are more synchronized as to the stage of their disease …&nbsp;</p>



<p><strong>LEE:</strong> Yep.&nbsp;</p>



<p><strong>AFEYAN:</strong> &#8230; I think the answer will be much better. We&#8217;re working on that. It&#8217;s a company called <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.flagshippioneering.com/companies/etiome" target="_blank" rel="noreferrer noopener">Etiome<span class="sr-only"> (opens in new tab)</span></a>, very, very early stage. It&#8217;s really beautiful data, very early data that shows that when we talk about MASH [metabolic dysfunction-associated steatohepatitis], liver disease, when we talk about Parkinson&#8217;s, there&#8217;s such a heterogeneity, not only of the subset type of the disease, but the stage of the disease, that this notion that you have stage one cancer, stage two cancer, again, nobody told nature there&#8217;s stages of that kind. It&#8217;s a continuum.&nbsp;</p>



<p>But if you can synchronize based on training, kind of, the ability to detect who are the patients that are in enough of a close proximity that should be treated so that the trial—much smaller a trial size—could give you a drug, then afterwards, you can prescribe it using these approaches.&nbsp;</p>



<p>Kind of we&#8217;re going to find that what we thought is one disease is more like 15 diseases. That&#8217;s bad news because we&#8217;re not going to be able to claim that we can treat everything which we can. It&#8217;s good news in that there&#8217;s going to be people who are going to start making much more specific solutions to things.&nbsp;</p>



<p><strong>LEE: </strong>Right.&nbsp;</p>



<p><strong>AFEYAN:</strong> So I can imagine that. I can imagine a generation of, kind of, students who are going to be able to play in this space without having 25 years of graduate education on the subject. So what is deemed knowledge sufficient to do creative things will change. I can go on and on, but I think all this is very close by and it&#8217;s very exciting.&nbsp;</p>



<p><strong>LEE: </strong>Noubar, I just always have so much fun, and I learn really a lot. It&#8217;s high-density learning when I talk to you. And so I hope our listeners feel the same way. It&#8217;s something I really appreciate.&nbsp;</p>



<p><strong>AFEYAN:</strong> Well, Peter, thanks for this. And I think your listeners know that if I was asking you questions, you would be answering them with equal if not more fascinating stuff. So, thanks for giving me the chance to do that today.&nbsp;</p>



<p>[TRANSITION MUSIC]&nbsp;</p>



<p><strong>LEE: </strong>I’m always fascinated by Noubar’s perspectives on fundamental research and how it connects to human health and the building of successful companies. I see him as a classic “systems thinker,” and by that, I mean he builds impressive things like Flagship Pioneering itself, which he created as a kind of biomedical innovation system.&nbsp;</p>



<p>In our conversation, I was really struck by the fact that he’s been thinking about the potential impact of transformers—transformers being the fundamental building block of large language models—as far back as 2017, when the first paper on the attention mechanism in transformers was published by Google.&nbsp;</p>



<p>But, you know, it isn’t only about using AI to do things like understand and design molecules and antibodies faster. It&#8217;s interesting that he is also pushing really hard towards a future where AI might “close the loop” from hypothesis generation, to experiment design, to analysis, and so on.&nbsp;</p>



<p>Now, here’s my conversation with Dr. Eric Topol:&nbsp;</p>



<p><strong>LEE:</strong> Eric, it&#8217;s really great to have you here.&nbsp;</p>



<p><strong>ERIC TOPOL: </strong>Oh, Peter, I&#8217;m thrilled to be here with you here at Microsoft.&nbsp;</p>



<p><strong>LEE:</strong> You&#8217;re a super famous person. Extremely well known to researchers even in computer science, as we have here at Microsoft Research.&nbsp;</p>



<p>But the question I&#8217;d like to ask is, how would you explain to your parents what you do every day?&nbsp;</p>



<p><strong>TOPOL:</strong> [LAUGHS] That&#8217;s a good question. If I was just telling them I&#8217;m trying to come up with better ways to keep people healthy, that probably would be the easiest way to do it because if I ever got in deeper, I would lose them real quickly. They&#8217;re not around, but just thinking about what they could understand.&nbsp;</p>



<p><strong>LEE:</strong> Right.&nbsp;</p>



<p><strong>TOPOL:</strong> I think as long as they knew it was work centered on innovative paths to promoting and preserving human health, that would get to them, I think.&nbsp;</p>



<p><strong>LEE:</strong> OK, so now, kind of the second topic, and then we let the conversation flow, is about origin stories with respect to AI. And with most of our guests, you know, I factor that into two pieces: the encounters with AI before ChatGPT and what we call generative AI and then the first contacts after.&nbsp;</p>



<p>And, of course, you have extensive contact with both now. But let&#8217;s start with how you got interested in machine learning and AI prior to ChatGPT. How did that happen?&nbsp;</p>



<p><strong>TOPOL: </strong>Yeah, it was out of necessity. So back, you know, when I started at Scripps at the end of ’06, we started accumulating, you know, massive datasets. First, it was whole genomes. We did one of the early big cohorts of 1,400 people of healthy aging. We called the <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.scripps.edu/science-and-medicine/translational-institute/translational-research/genomic-medicine/wellderly/" target="_blank" rel="noreferrer noopener">Wellderly whole genome sequence<span class="sr-only"> (opens in new tab)</span></a>.&nbsp;</p>



<p>And then we started big in the sensor world, and then we started saying, what are we going to do with all this data, with electronic health records and all those sensors? And now we got whole genomes.&nbsp;</p>



<p>And basically, what we were doing, we were in hoarding mode. We didn&#8217;t have a way to meaningfully analyze it.&nbsp;</p>



<p><strong>LEE:</strong> Right.&nbsp;</p>



<p><strong>TOPOL: </strong>You would read about how, you know, data is the new oil and, you know, gold and whatnot. But we just didn&#8217;t have a way to extract the juice. And even when we wanted to analyze genomes, it was incredibly laborious.&nbsp;</p>



<p><strong>LEE: </strong>Yeah.&nbsp;</p>



<p><strong>TOPOL:</strong> And we weren&#8217;t extracting a lot of the important information. So that&#8217;s why &#8230; not having any training in computer science, when I was doing the &#8230; about three years of work to do the book <em>Deep Medicine</em>, I started really, first auto-didactic about, you know, machine learning. And then I started contacting a lot of the real top people in the field and hanging out with them, and learning from them, getting their views as to, you know, where we are today, what models are coming in the future.&nbsp;</p>



<p>And then I said, “You know what? We are going to be able to fix this mess.” [LAUGHS] We&#8217;re going to get out of the hoarding phase, and we&#8217;re going to get into, you know, really making a difference.&nbsp;</p>



<p>So that&#8217;s when I embraced the future of AI. And I knew, you know, back—that was six years ago when it was published and probably eight or nine years ago when I was doing the research, and I knew that we weren&#8217;t there yet.&nbsp;</p>



<p>You know, at the time, we were seeing the image interpretation. That was kind of the early promise. But really, the models that were transformative, the transformer models, they were incubating back in 2017. So people knew something was brewing.&nbsp;</p>



<p><strong>LEE: </strong>Right. Yes.&nbsp;</p>



<p><strong>TOPOL:</strong> And everyone said we&#8217;re going to get there.&nbsp;</p>



<p><strong>LEE: </strong>So then, ChatGPT comes out November of 2022; there’s GPT-4 in 2023, and now a lot has happened. Do you remember what your first encounter with that technology was?&nbsp;</p>



<p><strong>TOPOL: </strong>Oh, sure. First, ChatGPT. You know, in the last days of November ’22, I was just blown away. I mean, I&#8217;m having a conversation. I&#8217;m having fun. And this is humanoid responding to me. I said, “<em>What?</em>” You know? So that was to me, a moment I&#8217;ll never forget. And so I knew that the world was, you know, at a very kind of momentous changing point.&nbsp;</p>



<p>Of course, knowing, too, that this is going to be built on, and built on quickly. Of course, I didn&#8217;t know how soon GPT-4 and all the others were going to come forward, but that was a wake-up call that the capabilities of AI had just made a humongous jump, which seemingly was all of a sudden, although I did know this had been percolating …&nbsp;</p>



<p><strong>LEE:</strong> Right.&nbsp;</p>



<p><strong>TOPOL:</strong> … you know, for what, at least five years, that, you know, it really was getting into its position to do this.&nbsp;</p>



<p><strong>LEE:</strong> I know one of the things that was challenging psychologically and emotionally for me is, it made me rethink a lot of things that were going on in Microsoft Research in areas like causal reasoning, natural language processing, speech processing, and so on.&nbsp;</p>



<p>I&#8217;m imagining you must have had some emotional struggles too because you have this amazing book, <em>Deep Medicine</em>. Did you have to … did it go through your mind to rethink what you wrote in <em>Deep Medicine </em>in light of this or, or, you know, how did that feel?&nbsp;</p>



<p><strong>TOPOL: </strong>It&#8217;s funny you ask that because in this one chapter I have on the virtual health coach, I wrote a whole bunch of scenarios &#8230;&nbsp;</p>



<p><strong>LEE: </strong>Yeah.&nbsp;</p>



<p><strong>TOPOL:</strong> … that were very kind of futuristic. You know, about how the AI interacts with the person&#8217;s health and schedules their appointment for this and their scan and tells them what lab tests they should tell their doctor to have, and, you know, all these things. And I sent a whole bunch of these, thinking that they were a little too far-fetched.&nbsp;</p>



<p><strong>LEE:</strong> Yes.&nbsp;</p>



<p><strong>TOPOL: </strong>And I sent them to my editor when I wrote the book, and he says, “Oh, these are great. You should put them all in.” [LAUGHTER] What I didn&#8217;t realize is they weren&#8217;t that, you know, they were all going to happen.&nbsp;</p>



<p>&nbsp;<strong>LEE:</strong> Yeah. They weren&#8217;t that far-fetched at all.&nbsp;</p>



<p><strong>TOPOL: </strong>Not at all. If there&#8217;s one thing I&#8217;ve learned from all this, is our imagination isn&#8217;t big enough.&nbsp;</p>



<p>&nbsp;<strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>TOPOL:</strong> We think too small.&nbsp;</p>



<p><strong>LEE:</strong> Now in our book that Carey, Zak, and I wrote, you know, we made, you know, we sort of guessed that GPT-4 might help biomedical researchers, but I don&#8217;t think that any of us had the thought in mind that the architecture around generative AI would be so directly applicable to, you know, say, protein structures or, you know, to clinical health records and so on.&nbsp;</p>



<p>And so a lot of that seems much more obvious today. But two years ago, it wasn&#8217;t. But we did guess that biomedical researchers would find this interesting and be helped along.&nbsp;</p>



<p>So as you reflect over the past two years, you know, do you have things that you think are very important, kind of, meaningful applications of generative AI in the kinds of research that Scripps does?&nbsp;</p>



<p><strong>TOPOL</strong>: Yeah. I mean, I think for one, you pointed out how the term <em>generative AI</em> is a misnomer.&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>TOPOL:</strong> And so it really was prescient about how, you know, it had a pluripotent capability in every respect, you know, of editing and creating. So that was something that I think was telling us, an indicator that this is, you know, a lot bigger than how it&#8217;s being labeled. And our expectations can actually be more than what we had seen previously with the earlier version.&nbsp;</p>



<p>So I think what&#8217;s happened is that now, we keep jumping. It&#8217;s so quick that we can&#8217;t … you know, first we think, oh, well, we’ve gone into the agentic era, and then we could pass that with reasoning. [LAUGHTER] And, you know, we just can&#8217;t …&nbsp;</p>



<p><strong>LEE: </strong>Right.&nbsp;</p>



<p><strong>TOPOL:</strong> It&#8217;s just wild.&nbsp;</p>



<p><strong>LEE: </strong>Yeah.&nbsp;</p>



<p><strong>TOPOL:</strong> So I think so many of us now will put in prompts that will necessitate or ideally result in a not-immediate gratification, but rather one that requires, you know, quite a bit of combing through the corpus of knowledge &#8230;&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>TOPOL:</strong> … and getting, with all the citations, a report or a response. And I think now this has been a reset because to do that on our own, it takes, you know, many, many hours. And it&#8217;s usually incomplete.&nbsp;</p>



<p>But one of the things that was so different in the beginning was you would get the references from up to a year and a half previously.&nbsp;</p>



<p><strong>LEE:</strong> Yep.&nbsp;</p>



<p><strong>TOPOL: </strong>And that&#8217;s not good enough. [LAUGHS]&nbsp;</p>



<p><strong>LEE:</strong> Right.&nbsp;</p>



<p><strong>TOPOL: </strong>And now you get references, like, from the day before.&nbsp;</p>



<p><strong>LEE:</strong> Yes. Yeah.&nbsp;</p>



<p><strong>TOPOL: </strong>And so, you say, “Why would you do a regular search for anything when you could do something like this?”&nbsp;</p>



<p><strong>LEE: </strong>Yeah.&nbsp;</p>



<p><strong>TOPOL:</strong> And then, you know, the reasoning power. And a lot of people who are not using this enough still are talking about, “Well, there&#8217;s no reasoning.”&nbsp;</p>



<p><strong>LEE:</strong> Yeah.</p>



<p><strong>TOPOL:</strong> Which you dealt with really well in the book. But what, of course, you couldn&#8217;t have predicted is the new dimensions.&nbsp;</p>



<p><strong>LEE:</strong> Right.&nbsp;</p>



<p><strong>TOPOL:</strong> I think you nailed it with GPT-4. But it&#8217;s all these just, kind of, stepwise progressions that have been occurring because of the velocity that&#8217;s unprecedented. I just can&#8217;t believe it.&nbsp;</p>



<p><strong>LEE: </strong>We were aware of the idea of multi-modality, but we didn&#8217;t appreciate, you know, what that would mean. Like <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://alphafold.com/" target="_blank" rel="noreferrer noopener">AlphaFold<span class="sr-only"> (opens in new tab)</span></a> [protein structure database], you know, the ability for AI to understand—or crystal structures—to really start understanding something more fundamental about biochemistry or medicinal chemistry.&nbsp;</p>



<p>I have to admit, when we wrote the book, we really had no idea.&nbsp;</p>



<p><strong>TOPOL: </strong>Well, I feel the same way. I still today can&#8217;t get over it because the reason AlphaFold and Demis [Hassabis] and John Jumper [AlphaFold’s co-creators] were so successful is there was this protein databank.&nbsp;</p>



<p><strong>LEE:</strong> Yes.&nbsp;</p>



<p><strong>TOPOL: </strong>And it had been kept for decades. And so, they had the substrate to work with.&nbsp;</p>



<p><strong>LEE:</strong> Right.&nbsp;</p>



<p><strong>TOPOL:</strong> So, you say, “OK, we can do proteins.” But then how do you do everything else?&nbsp;</p>



<p><strong>LEE:</strong> Right.&nbsp;</p>



<p><strong>TOPOL:</strong> And so this whole, what I call, “large language of <em>life</em> model” work, which has gone into high gear like I&#8217;ve never seen.&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>TOPOL:</strong> You know, now to this holy grail of a virtual cell, and &#8230;&nbsp;</p>



<p><strong>LEE: </strong>Yeah.&nbsp;</p>



<p><strong>TOPOL:</strong> You know, it&#8217;s basically &#8230; it&#8217;s &#8230; it was inspired by proteins. But now it&#8217;s hitting on, you know, ligands and small molecules, cells. I mean, nothing is being held back here.&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>TOPOL:</strong> So how could anybody have predicted that?&nbsp;</p>



<p><strong>LEE:</strong> Right.&nbsp;</p>



<p><strong>TOPOL:</strong> I sure wouldn&#8217;t have thought it would be possible at this point.&nbsp;</p>



<p><strong>LEE: </strong>Yeah. So just to challenge you, where do you think that is going to be two years from now? Five years from now? Ten years from now? Like, so you talk about a virtual cell. Is that achievable within 10 years, or is that still too far out?&nbsp;</p>



<p><strong>TOPOL:</strong> No, I think within 10 years for sure. You know the group that got assembled that <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://quakelab.stanford.edu/" target="_blank" rel="noreferrer noopener">Steve Quake<span class="sr-only"> (opens in new tab)</span></a> pulled together?&nbsp;</p>



<p><strong>LEE:</strong> Right.&nbsp;</p>



<p><strong>TOPOL:</strong> I think has 42 authors in a <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.cell.com/cell/fulltext/S0092-8674(24)01332-1" target="_blank" rel="noreferrer noopener">paper<span class="sr-only"> (opens in new tab)</span></a> in <em>Cell</em>. The fact that he could get these 42 experts in life science and some in computer science to come together and all agree …&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>TOPOL:</strong> … that not only is this a worthy goal, but it&#8217;s actually going to be realized, that was impressive.&nbsp;</p>



<p>I challenged him about that. How did you get these people all to agree? So many of them were naysayers. And by the time the workshop finished, they were fully convinced. I think that what we&#8217;re seeing is so much progress happening so quickly. And then all the different models, you know, across DNA, RNA, and everything are just zooming forward.&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>TOPOL:</strong> And it&#8217;s just a matter of pulling this together. Now when we have that, and I think it could easily be well before a decade and possibly, you know, between the five- and 10-year mark—that&#8217;s just a guess—but then we&#8217;re moving into another era of life science because right now, you know, this whole buzz about drug discovery.&nbsp;</p>



<p><strong>LEE: </strong>Yep.&nbsp;</p>



<p><strong>TOPOL: </strong>It&#8217;s not&#8230; with the ability to do all these perturbations at a cellular level.&nbsp;</p>



<p><strong>LEE:</strong> Right.&nbsp;</p>



<p><strong>TOPOL: </strong>Or the cell of interest.&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>TOPOL:</strong> Or the cell-to-cell interactions or the intra-cell interaction. So once you nail that, yeah, it takes it to a kind of another predictive level that we haven&#8217;t really fathomed. So, yes, there&#8217;s going to be drug discovery that&#8217;s accelerated. But this would make that and also the underpinnings of diseases.&nbsp;</p>



<p><strong>LEE: </strong>Yeah.&nbsp;</p>



<p><strong>TOPOL:</strong> So the idea that there&#8217;s so many diseases we don&#8217;t understand now. And if you had virtual cell, …&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>TOPOL:</strong> … you would probably get to that answer …&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>TOPOL:</strong> … much more quickly. So whether it&#8217;s underpinnings of diseases or what it&#8217;s going to take to really come up with far better treatments—preventions—I think that&#8217;s where virtual cell will get us.&nbsp;</p>



<p><strong>LEE:</strong> There&#8217;s a technical question &#8230; I wonder if you have an opinion. You may or may not. There is sort of what I would refer to as <em>ab initio</em> approaches to this. You know, you start from the fundamental physics and chemistry, and we know the laws, we have the math and, you know, we can try to derive from there … in fact, we can even run simulations of that math to generate training data to build generative models and work up to a cell, <em>or</em> forget all of that and just take as many observations and measurements of, say, living cells as possible, and just have faith that hidden amongst all of the observational data, there is structure and language that can be derived.&nbsp;</p>



<p>So that&#8217;s sort of bottom-up versus top-down approaches. Do you have an opinion about which way?&nbsp;</p>



<p><strong>TOPOL:</strong> Oh, I think you go after both. And clearly whenever you&#8217;re positing that you&#8217;ve got a virtual cell model that&#8217;s working, you&#8217;ve got to do the traditional methods as well to validate it, and … so all that. You know, I think if you&#8217;re going to go out after this seriously, you have to pull out all the stops. Both approaches, I think, are going to be essential.&nbsp;</p>



<p><strong>LEE:</strong> You know, if what you&#8217;re saying is true, and it is amazing to hear the confidence, the one thing I tried to explain to someone nontechnical is that for a lot of problems in medicine, we just don&#8217;t have enough data in a really profound way. And the most profound way to say that is, since Adam and Eve, there have only been an estimated 106 billion people who have ever lived.&nbsp;</p>



<p>So even if we had the DNA of every human being, every individual of <em>Homo sapiens</em>, there are certain problems for which we would not have enough data.&nbsp;</p>



<p><strong>TOPOL: </strong>Sure.&nbsp;</p>



<p><strong>LEE: </strong>And so I think another thing that seems profound to me, if we can actually have a virtual cell, is we can actually make trillions of virtual …&nbsp;</p>



<p><strong>TOPOL:</strong> Yeah&nbsp;</p>



<p><strong>LEE:</strong> … human beings. The true genetic diversity could be realized for our species.&nbsp;</p>



<p><strong>TOPOL: </strong>I think you nailed it. The ability to have that type of data, no less synthetic data, I mean, it’s just extraordinary.&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>TOPOL: </strong>We will get there someday. I&#8217;m confident of that. We may be wrong in projections. And I do think [science writer] Philip Ball won&#8217;t be right that it will never happen, though. [LAUGHTER] No, I think that if there&#8217;s a holy grail of biology, this is it.&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>TOPOL: </strong>And I think you&#8217;re absolutely right about where that will get us.&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>TOPOL: </strong>Transcending the beginning of the species.&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>TOPOL:</strong> Of<em> our</em> species.&nbsp;</p>



<p><strong>LEE: </strong>Yeah. All right. So now, we&#8217;re starting to run short on time here. And so I wanted to ask you about, I&#8217;m in my 60s, so I actually think about this a lot more. [LAUGHTER] And I know you&#8217;ve been thinking a lot about longevity. And, of course, your new book, <em>Super Agers</em>.&nbsp;</p>



<p>And one of the reasons I&#8217;m so eager to read is it&#8217;s a topic very top of mind for me and actually for a lot of people. Where is this going? Because this is another area where you hear so much hype. At the same time, you see Nobel laureate scientists &#8230;&nbsp;</p>



<p><strong>TOPOL: </strong>Yeah.&nbsp;</p>



<p><strong>LEE:</strong> &#8230; working on this.&nbsp;</p>



<p><strong>TOPOL:</strong> Yeah.&nbsp;</p>



<p><strong>LEE:</strong> So, so what&#8217;s, what&#8217;s real there?&nbsp;</p>



<p><strong>TOPOL: </strong>Yeah. Well, it&#8217;s really … the real deal is the science of aging is zooming forward.&nbsp;</p>



<p>And that&#8217;s exciting. But I see it bifurcating. On the one hand, all these new ideas, strategies to reverse aging are very ambitious. Like cell reprogramming and senolytics and, you know, the rejuvenation of our thymus gland, and it&#8217;s a long list.&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>TOPOL:</strong> And they’re really cool science, and it used to be the mouse lived longer. Now it&#8217;s the old mouse looks really young.&nbsp;</p>



<p><strong>LEE: </strong>Yeah. Yeah.&nbsp;</p>



<p><strong>TOPOL:</strong> All the different features. A blind mouse with cataracts is all of a sudden there&#8217;s no cataracts. I mean, so these things are exciting, but none of them are proven in people, and they all have significant risk, no less, you know, the expense that might be attached.&nbsp;</p>



<p><strong>LEE:</strong> Right.&nbsp;</p>



<p><strong>TOPOL:</strong> And some people are jumping the gun. They&#8217;re taking rapamycin, which can really knock out their immune system. So they all carry a lot of risk. And people are just getting a little carried away. We&#8217;re not there yet.&nbsp;</p>



<p>But the other side, which is what I emphasize in the book, which is exciting, is that we have all these new metrics that came out of the science of aging.&nbsp;</p>



<p><strong>LEE: </strong>Yes.&nbsp;</p>



<p><strong>TOPOL:</strong> So we have clocks of the body. Our biological clock versus our chronological clock, and we have organ clocks. So I can say, you know, Peter, we&#8217;ve assessed all your organs and your immune system. And guess what? Every one of them is either at or less than your actual age.&nbsp;</p>



<p><strong>LEE:</strong> Right.&nbsp;</p>



<p><strong>TOPOL: </strong>And that&#8217;s very reassuring. And by the way, your methylation clock is also … I don&#8217;t need to worry about you so much. And then I have these other tests that I can do now, like, for example, the brain. We have an amazing protein p-Tau217 that we can say over 20 years in advance of you developing Alzheimer&#8217;s, …&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>TOPOL:</strong> … we can look at that, and it&#8217;s modifiable by lifestyle, bringing it down. It should be you can change the natural history. So what we&#8217;ve seen is an explosion of knowledge of metrics, proteins, no less, you know, our understanding at the gene level, the gut microbiome, the immune system. So that&#8217;s what&#8217;s so exciting. How our immune system ages. <em>Immunosenescence</em>. How we have more inflammation—<em>inflammaging</em>—with aging. So basically, we have three diseases that kill us, that take away our health: heart, cancer, and neurodegenerative.&nbsp;</p>



<p><strong>LEE:</strong> Yep.&nbsp;</p>



<p><strong>TOPOL:</strong> And they all take more than 20 years. They all have a defective immune system inflammation problem, and they&#8217;re all going to be preventable.&nbsp;</p>



<p><strong>LEE: </strong>Yeah.&nbsp;</p>



<p><strong>TOPOL: </strong>That&#8217;s what&#8217;s so exciting.&nbsp;So we don&#8217;t have to have reverse aging. We can actually work on …&nbsp;</p>



<p><strong>LEE:</strong> Just prevent aging in the first place.&nbsp;</p>



<p><strong>TOPOL: </strong>…<strong> </strong>the age-related diseases. So basically, what it means is: I got to find out if you have a risk, if you&#8217;re in this high-risk group for this particular condition, because if you are—and we have many levels, layers, orthogonal ways to check—we don&#8217;t just bank it all on one polygenic test. We&#8217;re going to have several ways, say this is the one we are going &#8230;&nbsp;</p>



<p>And then we go into high surveillance, where, let&#8217;s say if it&#8217;s your brain, we do more p-Tau, if we need to do brain imaging—whatever it takes. And also, we do preventive treatments on top of the lifestyle [changes], that one of the problems we have today is a lot of people know generally, what are good lifestyle factors. Although, I go through a lot more than people generally acknowledge.&nbsp;</p>



<p>But they don&#8217;t incorporate them because they don&#8217;t know that they&#8217;re at risk and they could change their &#8230; extend their health span and prevent that disease. So what I at least put out there, a blueprint, is how we can use AI, because it&#8217;s multimodal AI, with all these layers of data, and then temporally, it&#8217;s like today you could say if you have two protein tests, not only are you going to have Alzheimer&#8217;s, but within a two-year time frame <em>when</em> &#8230;&nbsp;</p>



<p><strong>LEE:</strong> Yep.&nbsp;</p>



<p><strong>TOPOL: </strong>&#8230; and if you don&#8217;t change things, if we don&#8217;t gear up … you know, we can &#8230; we can completely prevent this, so … or at least defer it for a decade or more. So that&#8217;s why I&#8217;m excited, is that we made these strides in the science of aging. But we haven&#8217;t acknowledged the part that doesn&#8217;t require reversing aging. There&#8217;s this much less flashy, attainable, less risky approach &#8230;&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>TOPOL: </strong>&#8230;<strong> </strong>than the one that … when you reverse aging, you&#8217;re playing with the hallmarks of cancer. They are like, if you look at the hallmarks of cancer …&nbsp;</p>



<p><strong>LEE:</strong> That has been one of the primary challenges.&nbsp;</p>



<p><strong>TOPOL: </strong>They&#8217;re lined up.&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>TOPOL:</strong> They’re all the same, you know, whether it&#8217;s telomeres, or whether it&#8217;s &#8230; you know &#8230; so this is the problem. I actually say in the book, I do think one of these—we have so many shots on goal—one of these reverse aging things will likely happen someday. But we&#8217;re nowhere close.&nbsp;</p>



<p>On the other hand, let&#8217;s gear up. Let&#8217;s do what we can do. Because we have these new metrics that&#8217;s &#8230; people don&#8217;t … like, when I read the <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.nature.com/articles/s41586-023-06802-1" target="_blank" rel="noreferrer noopener">organ clock paper<span class="sr-only"> (opens in new tab)</span></a> from Tony Wyss-Coray from Stanford. It was published end of ’23; it was the cover of <em>Nature</em>. It blew me away.&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>TOPOL: </strong>And I wrote a <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://erictopol.substack.com/p/the-emergence-of-protein-organ-clocks" target="_blank" rel="noreferrer noopener">Substack<span class="sr-only"> (opens in new tab)</span></a> [article] on it. And Tony said, “Well, that&#8217;s so nice of you.” I said, “So nice? This is revolutionary, you know.” [LAUGHTER] So …&nbsp;</p>



<p><strong>LEE: </strong>By the way, what&#8217;s so interesting is, how these things, this kind of understanding and AI, are coming together.</p>



<p><strong>TOPOL: </strong>Yes.&nbsp;</p>



<p><strong>LEE: </strong>It&#8217;s almost eerie the timing of these things.&nbsp;</p>



<p><strong>TOPOL: </strong>Absolutely. Because you couldn&#8217;t take all these layers of data, just like we were talking about data hoarding.</p>



<p><strong>LEE: </strong>Yep.</p>



<p><strong>TOPOL:</strong> Now we have data hoarding on individual with no way to be able to make these assessments of what level of risk, when, what are we going to do in <em>this</em> individual to prevent that? We can do that now.&nbsp;</p>



<p>We can do it today. And we could keep building on that. So I&#8217;m really excited about it. I think that, you know, when I wrote the last book on deep medicine, it was our overarching goal should be to bring back the patient-doctor relationship. I&#8217;m an old dog, and I know what it used to be when I got out of medical school.&nbsp;</p>



<p>It&#8217;s totally &#8230; you couldn&#8217;t imagine how much erosion from the ’70s, ’80s to now. But now I have a new overarching goal. I&#8217;m thinking that that still is really important—humanity in medicine—but let&#8217;s prevent these three &#8230; big three diseases because it&#8217;s an opportunity that we&#8217;re not … you know, in medicine, all my life we&#8217;ve been hearing and talking about we need to prevent diseases.&nbsp;</p>



<p>Curing is much harder than prevention. And the economics. Oh my gosh. But we haven&#8217;t done it.&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>TOPOL: </strong>Now we can do it. Primary prevention. We’d do really well. Somebody’s had heart attack.&nbsp;</p>



<p><strong>LEE:</strong> Yeah.&nbsp;</p>



<p><strong>TOPOL: </strong>Oh, we&#8217;re going to get all over it. Why did they have a heart attack in the first place?&nbsp;</p>



<p><strong>LEE:</strong> Well, the thing that makes so much sense in what you&#8217;re saying is that we understand we have an understanding both economically and medically that prevention is a good thing. And extending the concept of prevention to these age-related conditions, I think, makes all the sense in the world.&nbsp;</p>



<p>You know, Eric, maybe on that optimistic note, it’s time to wrap up this conversation. Really appreciate you coming. Let me just brag in closing that I&#8217;m now the proud owner of an autographed copy of your latest book, and, really, thank you for that.&nbsp;</p>



<p><strong>TOPOL: </strong>Oh, thank you. I could spend the rest of the day talking to you. I&#8217;ve really enjoyed it. Thanks.&nbsp;</p>



<p>[TRANSITION MUSIC]&nbsp;</p>



<p><strong>LEE:</strong> For me, the biggest takeaway from our conversation was Eric’s supremely optimistic predictions about what AI will allow us to do in much less than 10 years.&nbsp;</p>



<p>You know, for me personally, I started off several years ago with the typical techie naivete that if we could solve protein folding using machine learning, we would solve human biology. But as I’ve gotten smarter, I’ve realized that things are way, way more complicated than that, and so hearing Eric’s techno-optimism on this is really both heartening and so interesting.&nbsp;</p>



<p>Another thing that really caught my attention are Eric’s views on AI in medical diagnosis. That really stood out to me because within our labs here at Microsoft Research, we have been doing a lot of work on this, for example in creating foundation models for whole-slide digital pathology.&nbsp;</p>



<p>The bottom line, though, is that biomedical research and development is really changing and changing quickly. It&#8217;s something that we thought about and wrote briefly about in our book, but just hearing it from these three people gives me reason to believe that this is going to create tremendous benefits in the diagnosis and treatment of disease.&nbsp;</p>



<p>And in fact, I wonder now how regulators, such as the Food and Drug Administration here in the United States, will be able to keep up with what might become a really big increase in the number of animal and human studies that need to be approved. On this point, it&#8217;s clear that the FDA and other regulators will need to use AI to help process the likely rise in the pace of discovery and experimentation. And so stay tuned for more information about that.&nbsp;</p>



<p>[THEME MUSIC] </p>



<p>I&#8217;d like to thank Daphne, Noubar, and Eric again for their time and insights. And to our listeners, thank you for joining us. There are several episodes left in the series, including discussions on medical students’ experiences with AI and AI’s influence on the operation of health systems and public health departments. We hope you&#8217;ll continue to tune in.&nbsp;</p>



<p>Until next time.&nbsp;</p>



<p>[MUSIC FADES] </p>

				</span>
			</div>
			<button
				class="action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle"
				aria-expanded="false"
				data-show-less-text="Show less"
				type="button"
				aria-controls="show-more-show-less-toggle-3"
				aria-label="Show more content"
				data-alternate-aria-label="Show less content">
				Show more			</button>
		</div>
	</div>
</div>



<div class="wp-block-buttons is-layout-flex wp-block-buttons-is-layout-flex">
<div class="wp-block-button is-style-outline is-style-outline--4"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/story/the-ai-revolution-in-medicine-revisited/">AI Revolution in Medicine podcast series</a></div>
</div>
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/podcast/how-ai-will-accelerate-biomedical-research-and-discovery/">How AI will accelerate biomedical research and discovery</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>AI Testing and Evaluation: Learnings from pharmaceuticals and medical devices</title>
		<link>https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-pharmaceuticals-and-medical-devices/</link>
		
		<dc:creator><![CDATA[Kathleen Sullivan, Daniel Carpenter, Timo Minssen, Chad Atalla]]></dc:creator>
		<pubDate>Mon, 07 Jul 2025 16:00:00 +0000</pubDate>
				<category><![CDATA[Microsoft Research Podcast]]></category>
		<guid isPermaLink="false">https://www.microsoft.com/en-us/research/?p=1143099</guid>

					<description><![CDATA[<p>Professors Daniel Carpenter and Timo Minssen explore evolving pharma and medical device regulation, including the role of clinical trials, while Microsoft applied scientist Chad Atalla shares where AI governance stakeholders might find inspiration in the fields.</p>
<p>The post <a href="https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-pharmaceuticals-and-medical-devices/">AI Testing and Evaluation: Learnings from pharmaceuticals and medical devices</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP2-AI-TE_Hero_Feature_1400x788.jpg" alt="Illustrated headshots of Daniel Carpented, Timo Minssen, Chad Atalla, and Kathleen Sullivan." class="wp-image-1143327" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP2-AI-TE_Hero_Feature_1400x788.jpg 1400w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP2-AI-TE_Hero_Feature_1400x788-300x169.jpg 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP2-AI-TE_Hero_Feature_1400x788-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP2-AI-TE_Hero_Feature_1400x788-768x432.jpg 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP2-AI-TE_Hero_Feature_1400x788-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP2-AI-TE_Hero_Feature_1400x788-655x368.jpg 655w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP2-AI-TE_Hero_Feature_1400x788-240x135.jpg 240w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP2-AI-TE_Hero_Feature_1400x788-640x360.jpg 640w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP2-AI-TE_Hero_Feature_1400x788-960x540.jpg 960w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP2-AI-TE_Hero_Feature_1400x788-1280x720.jpg 1280w" sizes="auto, (max-width: 1400px) 100vw, 1400px" /></figure>


<div class="wp-block-msr-podcast-container my-4">
	<iframe loading="lazy" src="https://player.blubrry.com/?podcast_id=146743491&modern=1" class="podcast-player" frameborder="0" height="164px" width="100%" scrolling="no" title="Podcast Player"></iframe>
</div>



<p>Generative AI presents a unique challenge and opportunity to reexamine governance practices for the responsible development, deployment, and use of AI. To advance thinking in this space, Microsoft has tapped into the experience and knowledge of experts across domains—from genome editing to cybersecurity—to investigate the role of testing and evaluation as a governance tool. <em><a href="https://www.microsoft.com/en-us/research/story/ai-testing-and-evaluation-learnings-from-science-and-industry/">AI Testing and Evaluation: Learnings from Science and Industry</a></em>, hosted by Microsoft Research’s <a href="https://www.microsoft.com/en-us/research/people/kasull/">Kathleen Sullivan</a>, explores what the technology industry and policymakers can learn from these fields and how that might help shape the course of AI development.</p>



<p>In this episode, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://dcarpenter.scholar.harvard.edu/" target="_blank" rel="noreferrer noopener">Daniel Carpenter</a>, the Allie S. Freed Professor of Government and chair of the department of government at Harvard University, explains how the US Food and Drug Administration’s rigorous, multi-phase drug approval process serves as a gatekeeper that builds public trust and scientific credibility, while <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://researchprofiles.ku.dk/en/persons/timo-minssen" target="_blank" rel="noreferrer noopener">Timo Minssen</a>, professor of law and founding director of the Center for Advanced Studies in Bioscience Innovation Law at the University of Copenhagen, explores the evolving regulatory landscape of medical devices with a focus on the challenges of balancing innovation with public safety. Later, Microsoft’s <a href="https://www.microsoft.com/en-us/research/people/chatalla/">Chad Atalla</a>, an applied scientist in responsible AI, discusses the sociotechnical nature of AI models and systems, their team’s work building an evaluation framework inspired by social science, and where AI researchers, developers, and policymakers might find inspiration from the approach to governance and testing in pharmaceuticals and medical devices.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading h4" id="learn-more">Learn more:</h2>



<p><a href="https://www.microsoft.com/en-us/research/publication/learning-from-other-domains-to-advance-ai-evaluation-and-testing-the-history-and-evolution-of-testing-in-pharmaceutical-regulation/" target="_blank" rel="noreferrer noopener">Learning from other Domains to Advance AI Evaluation and Testing: The History and Evolution of Testing in Pharmaceutical Regulation</a><br>Case study | January 2025&nbsp;</p>



<p><a href="https://www.microsoft.com/en-us/research/publication/learning-from-other-domains-to-advance-ai-evaluation-and-testing-medical-device-testing-regulatory-requirements-evolution-and-lessons-for-ai-governance/" target="_blank" rel="noreferrer noopener">Learning from other Domains to Advance AI Evaluation and Testing: Medical Device Testing: Regulatory Requirements, Evolution and Lessons for AI Governance</a><br>Case study | January 2025&nbsp;</p>



<p><a href="https://www.microsoft.com/en-us/research/blog/learning-from-other-domains-to-advance-ai-evaluation-and-testing/">Learning from other domains to advance AI evaluation and testing</a>&nbsp;<br>Microsoft Research Blog | June 2025  &nbsp;</p>



<p><a href="https://www.microsoft.com/en-us/research/publication/evaluating-generative-ai-systems-is-a-social-science-measurement-challenge/" target="_blank" rel="noreferrer noopener">Evaluating Generative AI Systems is a Social Science Measurement Challenge</a>&nbsp;<br>Publication&nbsp;|&nbsp;November 2024 &nbsp;</p>



<p><a href="https://www.microsoft.com/en-us/research/group/stac-sociotechnical-alignment-center/?msockid=35739e94ab6c69d41b738b93aa076831" target="_blank" rel="noreferrer noopener">STAC: Sociotechnical Alignment Center</a> </p>



<p><a href="https://www.microsoft.com/en-us/ai/responsible-ai?msockid=35739e94ab6c69d41b738b93aa076831" target="_blank" rel="noreferrer noopener">Responsible AI: Ethical policies and practices | Microsoft AI</a></p>



<p><a href="https://www.microsoft.com/en-us/research/focus-area/ai-and-microsoft-research/">AI and Microsoft Research </a></p>



<div style="height:25px" aria-hidden="true" class="wp-block-spacer"></div>



<section class="wp-block-msr-subscribe-to-podcast subscribe-to-podcast">
	<div class="subscribe-to-podcast__inner border-top border-bottom border-width-2">
		<h2 class="h5 subscribe-to-podcast__heading">
			Subscribe to the <a href="https://www.microsoft.com/en-us/research/podcast">Microsoft Research Podcast</a>:		</h2>
		<ul class="subscribe-to-podcast__list list-unstyled">
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://itunes.apple.com/us/podcast/microsoft-research-a-podcast/id1318021537?mt=2" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="black" viewBox="0 0 32 32">  <path d="M7.12 0c-3.937-0.011-7.131 3.183-7.12 7.12v17.76c-0.011 3.937 3.183 7.131 7.12 7.12h17.76c3.937 0.011 7.131-3.183 7.12-7.12v-17.76c0.011-3.937-3.183-7.131-7.12-7.12zM15.817 3.421c3.115 0 5.932 1.204 8.079 3.453 1.631 1.693 2.547 3.489 3.016 5.855 0.161 0.787 0.161 2.932 0.009 3.817-0.5 2.817-2.041 5.339-4.317 7.063-0.812 0.615-2.797 1.683-3.115 1.683-0.12 0-0.129-0.12-0.077-0.615 0.099-0.792 0.192-0.953 0.64-1.141 0.713-0.296 1.932-1.167 2.677-1.911 1.301-1.303 2.229-2.932 2.677-4.719 0.281-1.1 0.244-3.543-0.063-4.672-0.969-3.595-3.907-6.385-7.5-7.136-1.041-0.213-2.943-0.213-4 0-3.636 0.751-6.647 3.683-7.563 7.371-0.245 1.004-0.245 3.448 0 4.448 0.609 2.443 2.188 4.681 4.255 6.015 0.407 0.271 0.896 0.547 1.1 0.631 0.447 0.192 0.547 0.355 0.629 1.14 0.052 0.485 0.041 0.62-0.072 0.62-0.073 0-0.62-0.235-1.199-0.511l-0.052-0.041c-3.297-1.62-5.407-4.364-6.177-8.016-0.187-0.943-0.224-3.187-0.036-4.052 0.479-2.323 1.396-4.135 2.921-5.739 2.199-2.319 5.027-3.543 8.172-3.543zM16 7.172c0.541 0.005 1.068 0.052 1.473 0.14 3.715 0.828 6.344 4.543 5.833 8.229-0.203 1.489-0.713 2.709-1.619 3.844-0.448 0.573-1.537 1.532-1.729 1.532-0.032 0-0.063-0.365-0.063-0.803v-0.808l0.552-0.661c2.093-2.505 1.943-6.005-0.339-8.296-0.885-0.896-1.912-1.423-3.235-1.661-0.853-0.161-1.031-0.161-1.927-0.011-1.364 0.219-2.417 0.744-3.355 1.672-2.291 2.271-2.443 5.791-0.348 8.296l0.552 0.661v0.813c0 0.448-0.037 0.807-0.084 0.807-0.036 0-0.349-0.213-0.683-0.479l-0.047-0.016c-1.109-0.885-2.088-2.453-2.495-3.995-0.244-0.932-0.244-2.697 0.011-3.625 0.672-2.505 2.521-4.448 5.079-5.359 0.547-0.193 1.509-0.297 2.416-0.281zM15.823 11.156c0.417 0 0.828 0.084 1.131 0.24 0.645 0.339 1.183 0.989 1.385 1.677 0.62 2.104-1.609 3.948-3.631 3.005h-0.015c-0.953-0.443-1.464-1.276-1.475-2.36 0-0.979 0.541-1.828 1.484-2.328 0.297-0.156 0.709-0.235 1.125-0.235zM15.812 17.464c1.319-0.005 2.271 0.463 2.625 1.291 0.265 0.62 0.167 2.573-0.292 5.735-0.307 2.208-0.479 2.765-0.905 3.141-0.589 0.52-1.417 0.667-2.209 0.385h-0.004c-0.953-0.344-1.157-0.808-1.553-3.527-0.452-3.161-0.552-5.115-0.285-5.735 0.348-0.823 1.296-1.285 2.624-1.291z"/></svg>
						<span class="subscribe-to-podcast__link-text">Apple Podcasts</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://subscribebyemail.com/www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M6.4 6a2.392 2.392 0 00-2.372 2.119L16 15.6l11.972-7.481A2.392 2.392 0 0025.6 6H6.4zM4 10.502V22.8a2.4 2.4 0 002.4 2.4h19.2a2.4 2.4 0 002.4-2.4V10.502l-11.365 7.102a1.2 1.2 0 01-1.27 0L4 10.502z"/></svg>
						<span class="subscribe-to-podcast__link-text">Email</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://subscribeonandroid.com/www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M12.414 4.02c-.062.012-.126.023-.18.06a.489.489 0 00-.12.675L13.149 6.3c-1.6.847-2.792 2.255-3.18 3.944h13.257c-.388-1.69-1.58-3.097-3.179-3.944l1.035-1.545a.489.489 0 00-.12-.675.492.492 0 00-.675.135l-1.14 1.68a7.423 7.423 0 00-2.55-.45c-.899 0-1.758.161-2.549.45l-1.14-1.68a.482.482 0 00-.494-.195zm1.545 3.824a.72.72 0 110 1.44.72.72 0 010-1.44zm5.278 0a.719.719 0 110 1.44.719.719 0 110-1.44zM8.44 11.204A1.44 1.44 0 007 12.644v6.718c0 .795.645 1.44 1.44 1.44.168 0 .33-.036.48-.09v-9.418a1.406 1.406 0 00-.48-.09zm1.44 0V21.76c0 .793.646 1.44 1.44 1.44h10.557c.793 0 1.44-.647 1.44-1.44V11.204H9.878zm14.876 0c-.169 0-.33.035-.48.09v9.418c.15.052.311.09.48.09a1.44 1.44 0 001.44-1.44v-6.719a1.44 1.44 0 00-1.44-1.44zM11.8 24.16v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84zm5.759 0v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84z"/></svg>
						<span class="subscribe-to-podcast__link-text">Android</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://open.spotify.com/show/4ndjUXyL0hH1FXHgwIiTWU" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M16 4C9.383 4 4 9.383 4 16s5.383 12 12 12 12-5.383 12-12S22.617 4 16 4zm5.08 17.394a.781.781 0 01-1.086.217c-1.29-.86-3.477-1.434-5.303-1.434-1.937.002-3.389.477-3.403.482a.782.782 0 11-.494-1.484c.068-.023 1.71-.56 3.897-.562 1.826 0 4.365.492 6.171 1.696.36.24.457.725.217 1.085zm1.56-3.202a.895.895 0 01-1.234.286c-2.338-1.457-4.742-1.766-6.812-1.747-2.338.02-4.207.466-4.239.476a.895.895 0 11-.488-1.723c.145-.041 2.01-.5 4.564-.521 2.329-.02 5.23.318 7.923 1.995.419.26.547.814.286 1.234zm1.556-3.745a1.043 1.043 0 01-1.428.371c-2.725-1.6-6.039-1.94-8.339-1.942h-.033c-2.781 0-4.923.489-4.944.494a1.044 1.044 0 01-.474-2.031c.096-.023 2.385-.55 5.418-.55h.036c2.558.004 6.264.393 9.393 2.23.497.292.663.931.371 1.428z"/></svg>
						<span class="subscribe-to-podcast__link-text">Spotify</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M6.667 4a2.676 2.676 0 00-2.612 2.13v.003c-.036.172-.055.35-.055.534v18.666c0 .183.019.362.055.534v.003a2.676 2.676 0 002.076 2.075h.002c.172.036.35.055.534.055h18.666A2.676 2.676 0 0028 25.333V6.667a2.676 2.676 0 00-2.13-2.612h-.003A2.623 2.623 0 0025.333 4H6.667zM8 8h1.333C17.42 8 24 14.58 24 22.667V24h-2.667v-1.333c0-6.618-5.382-12-12-12H8V8zm0 5.333h1.333c5.146 0 9.334 4.188 9.334 9.334V24H16v-1.333A6.674 6.674 0 009.333 16H8v-2.667zM10 20a2 2 0 11-.001 4.001A2 2 0 0110 20z"/></svg>
						<span class="subscribe-to-podcast__link-text">RSS Feed</span>
					</a>
				</li>
					</ul>
	</div>
</section>


<div class="wp-block-msr-show-more">
	<div class="bg-neutral-100 p-5">
		<div class="show-more-show-less" data-mount="show-more-show-less">
			<div>
				<span>
					

<h2 class="wp-block-heading" id="transcript">Transcript</h2>



<p>[MUSIC]</p>



<p><strong>KATHLEEN SULLIVAN</strong>: Welcome to <em>AI Testing and Evaluation: Learnings from Science and Industry</em>. I&#8217;m your host, Kathleen Sullivan.</p>



<p>As generative AI continues to advance, Microsoft has gathered a range of experts—from genome editing to cybersecurity—to share how their fields approach evaluation and risk assessment. Our goal is to learn from their successes and their stumbles to move the science and practice of AI testing forward. In this series, we&#8217;ll explore how these insights might help guide the future of AI development, deployment, and responsible use.</p>



<p>[MUSIC ENDS]</p>



<p><strong>SULLIVAN</strong>: Today, I&#8217;m excited to welcome Dan Carpenter and Timo Minssen to the podcast to explore testing and risk assessment in the areas of pharmaceuticals and medical devices, respectively.</p>



<p>Dan Carpenter is chair of the Department of Government at Harvard University. His research spans the sphere of social and political science, from petitioning in democratic society to regulation and government organizations. His recent work includes the FDA Project, which examines pharmaceutical regulation in the United States.</p>



<p>Timo is a professor of law at the University of Copenhagen, where he is also director of the Center for Advanced Studies in Bioscience Innovation Law. He specializes in legal aspects of biomedical innovation, including intellectual property law and regulatory law. He&#8217;s exercised his expertise as an advisor to such organizations as the World Health Organization and the European Commission.</p>



<p>And after our conversations, we&#8217;ll talk to Microsoft&#8217;s Chad Atalla, an applied scientist in responsible AI, about how we should think about these insights in the context of AI.</p>



<p>Daniel, it&#8217;s a pleasure to welcome you to the podcast. I&#8217;m just so appreciative of you being here. Thanks for joining us today.</p>



				</span>
				<span id="show-more-show-less-toggle-5" class="show-more-show-less-toggleable-content">
					



<p><strong>DANIEL CARPENTER:</strong>&nbsp;Thanks for having me.&nbsp;</p>



<p><strong>SULLIVAN:</strong>&nbsp;Dan, before we dissect policy,&nbsp;let&#8217;s&nbsp;rewind the tape to your&nbsp;origin&nbsp;story. Can you take us to the moment that you first became fascinated with regulators rather than, say, politicians? Was there a spark that pulled you toward the FDA story?&nbsp;</p>



<p><strong>CARPENTER:</strong>&nbsp;At one point during graduate school, I was studying a combination of American politics and political theory, and I did a summer interning at the Department of Housing and Urban Development. And I began to think, why don&#8217;t people study these administrators more and the rules they make, the, you know,&nbsp;inefficiencies, the efficiencies?&nbsp;Really more&nbsp;from,&nbsp;kind of,&nbsp;a descriptive standpoint, less from a normative standpoint.&nbsp;And I was reading a lot that summer about the Food and Drug Administration and some of the decisions it was making on AIDS drugs. That was&nbsp;a,&nbsp;sort of,&nbsp;a major, &#8230;</p>



<p><strong>SULLIVAN: </strong>Right.&nbsp;</p>



<p><strong>CARPENTER:</strong> &#8230; sort of, you know,&nbsp;moment in the news, in the global news as well as the national news during, I would say, what?&nbsp;The late&nbsp;’80s, early&nbsp;’90s? And&nbsp;so&nbsp;I began to&nbsp;look&nbsp;into&nbsp;that.</p>



<p><strong>SULLIVAN:</strong>&nbsp;So now that we know what pulled you in,&nbsp;let’s&nbsp;zoom out for our listeners. Give us&nbsp;the&nbsp;whirlwind tour. I think most of us know pharma involves years of trials, but&nbsp;what’s&nbsp;the part we&nbsp;don’t&nbsp;know?</p>



<p><strong>CARPENTER:</strong>&nbsp;So&nbsp;I think when most businesses develop a product, they all go through some phases of research and development and testing. And I think&nbsp;what&#8217;s&nbsp;different about the FDA is,&nbsp;sort of,&nbsp;two-&nbsp;or three-fold.</p>



<p>First, a lot of those tests are much more stringently specified and regulated by the government, and second, one of the reasons for that is that the FDA imposes not simply safety requirements upon drugs&nbsp;in particular but&nbsp;also efficacy requirements. The FDA wants you to prove not simply that&nbsp;it&#8217;s&nbsp;safe and non-toxic&nbsp;but also that&nbsp;it&#8217;s&nbsp;effective.&nbsp;And the final thing,&nbsp;I think, that&nbsp;makes the FDA different is that it stands as what I would call the&nbsp;“veto player”&nbsp;over R&D [research and development] to the marketplace.&nbsp;The FDA&nbsp;basically has,&nbsp;sort of,&nbsp;this control over entry&nbsp;to&nbsp;the marketplace.</p>



<p>And&nbsp;so&nbsp;what that involves is usually first, a set of human trials where people who have no disease take it. And&nbsp;you&#8217;re&nbsp;only looking&nbsp;for&nbsp;toxicity generally. Then&nbsp;there&#8217;s&nbsp;a set of Phase 2 trials, where they look more at safety and a little bit at efficacy, and&nbsp;you&#8217;re&nbsp;now examining people who have the disease that the drug claims to treat. And&nbsp;you&#8217;re&nbsp;also basically comparing people who get the drug,&nbsp;often&nbsp;with those who do not.</p>



<p>And then finally, Phase 3 involves a much more direct and large-scale attack, if you will, or assessment of efficacy, and&nbsp;that&#8217;s&nbsp;where you get the sort of large randomized clinical trials that are&nbsp;very expensive&nbsp;for pharmaceutical companies, biomedical companies to launch, to execute, to analyze. And those are often the sort of core evidence base for the decisions that the FDA makes about&nbsp;whether or not&nbsp;to approve a new drug for marketing in the United States.</p>



<p><strong>SULLIVAN:</strong>&nbsp;Are there&nbsp;differences in how that process has, you know, changed through other countries and&nbsp;maybe just&nbsp;how&nbsp;that&#8217;s&nbsp;evolved as&nbsp;you&#8217;ve&nbsp;seen it play out?&nbsp;</p>



<p><strong>CARPENTER:</strong>&nbsp;Yeah, for a long time, I would say that the United States had&nbsp;probably the&nbsp;most&nbsp;stringent regime&nbsp;of regulation for biopharmaceutical products until,&nbsp;I would say,&nbsp;about the 1990s and early 2000s. It used to be the case that a number of other countries, especially in Europe but around the world, basically waited for the FDA to mandate tests on a drug and only after the drug was approved in the United States would they deem it approvable and marketable in their own countries. And then after the formation of the European Union and the creation of the European Medicines Agency, gradually the European Medicines Agency began to get a bit more stringent.&nbsp;&nbsp;</p>



<p>But, you know,&nbsp;over the long run,&nbsp;there&#8217;s&nbsp;been a&nbsp;lot of,&nbsp;sort&nbsp;of,&nbsp;heterogeneity, a lot of variation over time and space, in the way that the FDA has approached these problems. And&nbsp;I&#8217;d&nbsp;say in the last 20 years, it&#8217;s begun to partially deregulate, namely,&nbsp;you know,&nbsp;trying to find all sorts of mechanisms or pathways for really innovative&nbsp;drugs for deadly diseases without a lot of treatments to&nbsp;basically get&nbsp;through the process at lower cost.&nbsp;For many people,&nbsp;that has not been sufficient.&nbsp;They&#8217;re&nbsp;concerned about the cost of the system.&nbsp;Of course, then the agency also gets criticized by those&nbsp;who believe&nbsp;it&#8217;s&nbsp;too lax. It is&nbsp;potentially letting&nbsp;ineffective and unsafe therapies on the market.</p>



<p><strong>SULLIVAN:</strong>&nbsp;In your view, when does the structured model genuinely safeguard patients and where do you think it&nbsp;maybe slows&nbsp;or&nbsp;limits&nbsp;innovation?</p>



<p><strong>CARPENTER:</strong>&nbsp;So&nbsp;I think&nbsp;the worry&nbsp;is that if you approach pharmaceutical approval as a world where only things can go wrong,&nbsp;then&nbsp;you&#8217;re&nbsp;really at a risk of limiting innovation. And even if you end up letting a lot of things through, if by your regulations you end up basically slowing down the development process or making it very, very costly, then there&#8217;s just a whole bunch of drugs that either come to market too slowly or they come to market not at all because&nbsp;they just aren&#8217;t worth the kind of cost-benefit or, sort of, profit analysis of the firm.&nbsp;You know, so&nbsp;that&#8217;s&nbsp;been a concern.&nbsp;And I think&nbsp;it&#8217;s&nbsp;been one of the reasons that the Food and Drug Administration as well as other world regulators have begun to&nbsp;basically try&nbsp;to smooth the process and accelerate the process at the margins.</p>



<p>The other thing is that&nbsp;they&#8217;ve&nbsp;started to&nbsp;basically make&nbsp;approvals&nbsp;on the basis of&nbsp;what are called&nbsp;<em>surrogate endpoints</em>. So the idea is that a cancer drug, we really want to know whether that drug saves lives, but if we wait to see whose lives are saved or prolonged by that drug, we might miss the opportunity to make judgments on the basis of, well, are we detecting tumors in the bloodstream? Or can we measure the size of those tumors&nbsp;in, say, a&nbsp;solid cancer? And then the further question is, is the size of the tumor&nbsp;basically a&nbsp;really good&nbsp;correlate&nbsp;or predictor of whether people will die or&nbsp;not, right?&nbsp;Generally, the&nbsp;FDA tends to be less stringent when&nbsp;you&#8217;ve&nbsp;got, you know, a remarkably innovative new&nbsp;therapy&nbsp;and the disease being treated is one that just&nbsp;doesn&#8217;t&nbsp;have a lot of available treatments,&nbsp;right.</p>



<p>The one thing that people often think about when&nbsp;they&#8217;re&nbsp;thinking about pharmaceutical regulation is they often contrast,&nbsp;kind of,&nbsp;speed versus safety &#8230;</p>



<p><strong>SULLIVAN:&nbsp;</strong>Right.&nbsp;&nbsp;</p>



<p><strong>CARPENTER:&nbsp;</strong>&#8230; right. And&nbsp;that&#8217;s&nbsp;useful as a tradeoff,&nbsp;but I often try to remind people that&nbsp;it&#8217;s&nbsp;not simply&nbsp;about whether the drug gets out&nbsp;there&nbsp;and&nbsp;it&#8217;s&nbsp;unsafe. You know, you and I as patients and even doctors have&nbsp;a hard time&nbsp;knowing whether something works and whether it should be prescribed. And the evidence for knowing whether something works&nbsp;isn&#8217;t&nbsp;just, well,&nbsp;you&nbsp;know, Sally took&nbsp;it&nbsp;or Dan took it or Kathleen took it, and they&nbsp;seem to get&nbsp;better or they&nbsp;didn&#8217;t&nbsp;seem to get better.&nbsp;&nbsp;</p>



<p>The really rigorous evidence comes from randomized clinical trials.&nbsp;And I think&nbsp;it&#8217;s&nbsp;fair to say that if you didn&#8217;t&nbsp;have the FDA there as a veto player, you&nbsp;wouldn&#8217;t&nbsp;get as many randomized clinical&nbsp;trials&nbsp;and the evidence&nbsp;probably&nbsp;wouldn&#8217;t&nbsp;be as rigorous for whether these things work. And as I like to put it,&nbsp;basically there&#8217;s&nbsp;a whole ecology of expectations and beliefs around the biopharmaceutical industry in the United States and globally,&nbsp;and to some extent,&nbsp;it&#8217;s&nbsp;undergirded by&nbsp;all of&nbsp;these tests that happen.&nbsp;&nbsp;</p>



<p><strong>SULLIVAN:&nbsp;</strong>Right.&nbsp;&nbsp;</p>



<p><strong>CARPENTER:&nbsp;</strong>And in part, that means&nbsp;it&#8217;s&nbsp;undergirded by regulation. Would there still be a market without regulation? Yes. But it would be a market in which people had far less information in and confidence about the drugs that are being taken. And&nbsp;so&nbsp;I think&nbsp;it&#8217;s&nbsp;important to recognize that kind of confidence-boosting potential of, kind of, a scientific regulation base.&nbsp;</p>



<p><strong>SULLIVAN:</strong>&nbsp;Actually, if we could&nbsp;double-click&nbsp;on that for a minute, I&#8217;d love to hear your perspective on, <em>testing&nbsp;has been completed;&nbsp;there&#8217;s results</em>.&nbsp;Can you walk us through how those results actually shape the next steps and decisions of a particular drug and just,&nbsp;like,&nbsp;how regulators actually think about using that data to influence really what happens next with it?</p>



<p><strong>CARPENTER:</strong>&nbsp;Right.&nbsp;So&nbsp;it&#8217;s&nbsp;important to understand that every drug is approved for&nbsp;what&#8217;s called&nbsp;an <em>indication</em>. It can have a first primary&nbsp;indication, which is the main disease that it treats, and then others can be added as more evidence is shown. But a drug is not something that just kind of exists out there in the ether.&nbsp;It has to have the right form of administration.&nbsp;Maybe it&nbsp;should be injected.&nbsp;Maybe it&nbsp;should be <em>ingested</em>.&nbsp;Maybe it&nbsp;should&nbsp;be administered only at a clinic&nbsp;because it needs to be&nbsp;kind of administered&nbsp;in just the right way. As doctors will tell you, dosage is everything, right.&nbsp;&nbsp;</p>



<p>And&nbsp;so&nbsp;one of the reasons that you want those trials is not simply a, you know, yes or no answer about whether the drug works,&nbsp;right.&nbsp;It&#8217;s&nbsp;not simply if-then.&nbsp;It&#8217;s&nbsp;literally what&nbsp;goes into what you might call the dose response curve.&nbsp;You know, how much of this drug do we need to&nbsp;basically, you know,&nbsp;get the benefit? At what point does that fall off significantly that we can&nbsp;basically say, we can stop there? All that evidence comes from&nbsp;trials. And&nbsp;that&#8217;s&nbsp;the kind of evidence that is&nbsp;required&nbsp;on the basis of&nbsp;regulation.&nbsp;&nbsp;</p>



<p>Because&nbsp;it&#8217;s&nbsp;not simply a drug&nbsp;that&#8217;s&nbsp;approved.&nbsp;It&#8217;s&nbsp;a drug and a&nbsp;<em>frequency</em>&nbsp;of administration. It&#8217;s&nbsp;a&nbsp;<em>method</em> of administration.&nbsp;And&nbsp;so&nbsp;the drug&nbsp;isn&#8217;t&nbsp;just,&nbsp;there&#8217;s&nbsp;something to be taken off the shelf and popped into your mouth. I mean, sometimes&nbsp;that&#8217;s&nbsp;what happens, but even then,&nbsp;we want to know what the dosage is,&nbsp;right.&nbsp;We want to know what to look for in terms of side effects, things like that.</p>



<p><strong>SULLIVAN:</strong>&nbsp;Going back to that point, I&nbsp;mean,&nbsp;it sounds like&nbsp;we&#8217;re&nbsp;making a lot of progress from a regulation perspective&nbsp;in, you know, sort of speed and getting things approved but doing it in a&nbsp;really balanced&nbsp;way. I mean, any other kind of closing thoughts on the tradeoffs there or where&nbsp;you&#8217;re&nbsp;seeing that going?</p>



<p><strong>CARPENTER:</strong>&nbsp;I think&nbsp;you&#8217;re&nbsp;going to see some move in the coming years—there&#8217;s&nbsp;already been some of it—to say, do we always need a&nbsp;really large&nbsp;Phase 3 clinical trial? And to what degree do we need the, like, you&nbsp;know,&nbsp;all the i&#8217;s dotted and the t&#8217;s crossed or a really,&nbsp;really large&nbsp;sample size?&nbsp;And&nbsp;I&#8217;m&nbsp;open to innovation there.&nbsp;I&#8217;m&nbsp;also open to the idea that we consider, again, things like accelerated approvals or pathways for looking at&nbsp;different kinds&nbsp;of surrogate endpoints.&nbsp;I do think, once we do that, then we also have to have some degree of follow-up.</p>



<p><strong>SULLIVAN:</strong>&nbsp;So&nbsp;I know&nbsp;we&#8217;re&nbsp;getting&nbsp;close to&nbsp;out of time, but&nbsp;maybe just&nbsp;a quick rapid fire if&nbsp;you’re&nbsp;open to it. Biggest myth about clinical trials?</p>



<p><strong>CARPENTER:</strong>&nbsp;Well, some people tend to think that the FDA performs them.&nbsp;You know,&nbsp;it&#8217;s&nbsp;companies that do it. And the only other thing I would say is the company that does a lot of the testing and even the innovating is not always the company that takes the drug to market, and it tells you something about how powerful regulation is in our system, in our world,&nbsp;that you often need a company that has dealt with the FDA quite a bit and knows all the regulations and knows how to dot the i&#8217;s and cross the t&#8217;s in order to get a drug across the finish line.</p>



<p><strong>SULLIVAN:</strong>&nbsp;If you had a magic wand,&nbsp;what&#8217;s&nbsp;the one thing&nbsp;you&#8217;d&nbsp;change in regulation today?</p>



<p><strong>CARPENTER:</strong>&nbsp;I would like people to think a little bit less about just speed versus safety and,&nbsp;again, more about this basic issue of confidence. I think&nbsp;it&#8217;s&nbsp;fundamental to everything that happens in markets but especially in biopharmaceuticals.</p>



<p><strong>SULLIVAN:</strong>&nbsp;Such a great point.&nbsp;This has been really fun.&nbsp;Just thanks so much for being here today. We&#8217;re really excited to share your thoughts&nbsp;out to&nbsp;our listeners. Thanks.</p>



<p>[TRANSITION MUSIC]&nbsp;</p>



<p><strong>CARPENTER:</strong>&nbsp;Likewise.&nbsp;</p>



<p><strong>SULLIVAN:</strong>&nbsp;Now&nbsp;to&nbsp;the world of medical devices,&nbsp;I&#8217;m&nbsp;joined by Professor Timo&nbsp;Minssen. Professor Minssen, it&#8217;s&nbsp;great to have you here. Thank you for joining us today.&nbsp;</p>



<p><strong>TIMO&nbsp;MINSSEN:</strong>&nbsp;Yeah, thank you very much,&nbsp;it&#8217;s&nbsp;a pleasure.</p>



<p><strong>SULLIVAN:</strong>&nbsp;Before getting into the regulatory world of medical devices, tell our audience a bit about your personal journey or your origin story, as&nbsp;we&#8217;re&nbsp;asking our guests. How did you land in regulation, and what&#8217;s kept you hooked in this space?</p>



<p><strong>MINSSEN:</strong>&nbsp;So&nbsp;I started out as a patent expert in the biomedical area, starting with my PhD thesis on patenting biologics in Europe and in the US.&nbsp;So&nbsp;during that time, I was mostly interested in patent and trade secret questions.&nbsp;But at the same time, I also developed and taught courses in regulatory law and held talks on regulating advanced medical therapy medicinal products.&nbsp;I&nbsp;then&nbsp;started to lead large research projects on legal challenges in a wide variety of health and life science innovation frontiers. I also started to focus increasingly on AI-enabled medical devices and software as a medical device, resulting in several academic articles in this area&nbsp;and also&nbsp;in the regulatory area and a book on the future of medical device regulation.&nbsp;&nbsp;</p>



<p><strong>SULLIVAN:</strong>&nbsp;Yeah,&nbsp;what&#8217;s&nbsp;kept you hooked in&nbsp;the space?</p>



<p><strong>MINSSEN:</strong>&nbsp;It&#8217;s&nbsp;just incredibly exciting,&nbsp;in particular right&nbsp;now with everything that is going on, you know, in the software arena, in the marriage between AI and medical devices. And this is really challenging not only societies but also regulators and authorities in Europe and in the US.</p>



<p><strong>SULLIVAN:</strong>&nbsp;Yeah,&nbsp;it&#8217;s&nbsp;a super exciting time to be in this space. You know, we talked to Daniel a little earlier and, you know, I think&nbsp;similar to&nbsp;pharmaceuticals, people have a general sense of what we mean when we say medical devices, but most listeners may&nbsp;picture&nbsp;like a stethoscope or a hip implant. The word &#8220;medical device&#8221;&nbsp;reaches&nbsp;much wider. Can you give us a quick, kind of, range from perhaps&nbsp;very simple&nbsp;to even, I don&#8217;t know, sci-fi and then your 90-second tour of how risk assessment works and why a framework is essential?</p>



<p><strong>MINSSEN:</strong>&nbsp;Let me start out by saying that&nbsp;the WHO [World Health Organization] estimates that today there are approximately 2 million different kinds of medical devices on the world market, and as of the FDA&#8217;s latest update that I&#8217;m aware of, the FDA has authorized more than 1,000 AI-, machine learning-enabled medical devices, and that number is rising rapidly.</p>



<p>So in that context, I think it is important to understand that medical devices can be any instrument, apparatus, implement, machine, appliance, implant, reagent for in vitro use, software, material, or other similar or related articles that are&nbsp;<em>intended</em>&nbsp;by the manufacturer to be used alone or in combination for a medical purpose. And the spectrum of what constitutes a medical device can&nbsp;thus&nbsp;range from very simple devices such as tongue depressors, contact lenses, and thermometers to more complex devices such as blood pressure monitors, insulin pumps, MRI machines, implantable pacemakers, and even software as a medical device or AI-enabled monitors or drug device combinations, as well.</p>



<p>So&nbsp;talking about regulation,&nbsp;I think&nbsp;it&nbsp;is also&nbsp;very important&nbsp;to stress that medical devices are used in many diverse situations by&nbsp;very different&nbsp;stakeholders. And testing&nbsp;has to&nbsp;take this variety into consideration, and it is intrinsically tied to regulatory requirements across various&nbsp;jurisdictions.</p>



<p>During the pre-market phase, medical testing&nbsp;establishes&nbsp;baseline safety and effectiveness metrics through bench testing, performance standards, and clinical studies. And post-market testing ensures that real-world data informs ongoing compliance and safety improvements. So testing is indispensable in translating technological innovation into safe and effective medical devices. And while&nbsp;particular details&nbsp;of pre-market and post-market review procedures may slightly differ among countries, most developed&nbsp;jurisdictions regulate medical devices similarly to the US or European models. </p>



<p>So&nbsp;most&nbsp;jurisdictions&nbsp;with medical device regulation classify devices based on their risk profile, intended use, indications for use, technological characteristics,&nbsp;and the regulatory controls necessary to provide a reasonable assurance of safety and effectiveness.</p>



<p><strong>SULLIVAN:</strong>&nbsp;So medical devices face a pretty prescriptive multi-level testing path before they hit the market. From your vantage point, what are some of the downsides of that system and when does it make the most sense?</p>



<p><strong>MINSSEN:</strong>&nbsp;One primary drawback is, of course, the lengthy and expensive approval process. High-risk devices, for example, often undergo years of clinical trials,&nbsp;which can cost millions of dollars, and this can create a significant barrier for startups and small companies with limited resources.&nbsp;And even for moderate-risk devices, the regulatory burden can slow product development and time to the market.</p>



<p>And the approach can also limit flexibility. Prescriptive requirements may not accommodate emerging innovations like digital therapeutics or AI-based diagnostics in&nbsp;a feasible&nbsp;way. And in such cases, the framework can unintentionally [stiffen]&nbsp;innovation by discouraging creative solutions or iterative improvements, which as matter of fact can also&nbsp;<em>put</em>&nbsp;patients&nbsp;at risk when you&nbsp;don&#8217;t&nbsp;use&nbsp;new technologies and AI.&nbsp;And&nbsp;additionally, the same level of scrutiny may be applied to low-risk devices, where&nbsp;the extensive testing and documentation may also be disproportionate to the actual patient risk.</p>



<p>However, the prescriptive model is highly&nbsp;appropriate where&nbsp;we have high testing standards for high-risk medical devices, in my view, particularly those that are life-sustaining, implanted, or involve new materials or mechanisms.</p>



<p>I also wanted to say that I think that these higher compliance thresholds can be OK and necessary if you have a system where authorities and stakeholders also have the capacity and funding to enforce, monitor, and achieve compliance with such rules in a feasible, time-effective, and straightforward manner. And this, of course, requires resources, novel solutions,&nbsp;and investments.</p>



<p><strong>SULLIVAN:</strong>&nbsp;A range of tests are undertaken across the life cycle of medical devices.&nbsp;How do these testing requirements vary across&nbsp;different stages&nbsp;of development and across various applications?</p>



<p><strong>MINSSEN:</strong>&nbsp;Yes,&nbsp;that&#8217;s&nbsp;a good question.&nbsp;So&nbsp;I think first it&nbsp;is important to realize that testing is conducted by various entities, including manufacturers, independent third-party laboratories, and regulatory agencies. And it occurs throughout the device&nbsp;life&nbsp;cycle, beginning with iterative testing during the research and development stage, advancing to pre-market evaluations, and continuing into post-market monitoring. And the outcomes of&nbsp;these tests directly&nbsp;impact&nbsp;regulatory approvals, market access, and device design refinements, as well.&nbsp;So&nbsp;the testing results are typically shared with regulatory authorities and in some cases with healthcare providers and the broader public to enhance transparency and trust.</p>



<p>So&nbsp;if you talk about the&nbsp;different phases&nbsp;that play a role here … so&nbsp;let&#8217;s&nbsp;turn to the pre-market phase, where manufacturers must&nbsp;demonstrate&nbsp;that the device is conformed to safety and performance benchmarks defined by regulatory authorities. Pre-market evaluations include functional bench testing, biocompatibility, for example, assessments and software validation, all of which are integral components of a manufacturer&#8217;s submission.&nbsp;</p>



<p>But, yes, but, testing also, and we touched already up on that, extends into the post-market phase, where it continues to ensure device safety and efficacy, and post-market surveillance relies on testing to&nbsp;monitor real-world performance and&nbsp;identify&nbsp;emerging risks on the post-market phase. By integrating real-world evidence into ongoing assessments, manufacturers can address unforeseen issues, update devices as needed, and&nbsp;maintain compliance with evolving regulatory expectations. And&nbsp;I think this&nbsp;is particularly important in this new generation of medical devices that are AI-enabled or machine-learning enabled.</p>



<p>I think we have to understand that in this AI-enabled medical devices field, you know, the devices and the algorithms that are working with&nbsp;them, they&nbsp;can improve in the lifetime of a product.&nbsp;So actually, not&nbsp;only you could assess them and make sure that they&nbsp;maintain&nbsp;safe,&nbsp;you&nbsp;could also sometimes lower the risk category by finding evidence that these devices are&nbsp;actually becoming&nbsp;more precise and safer.&nbsp;So&nbsp;it can both, you know, heighten the risk&nbsp;category&nbsp;or lower the risk category, and&nbsp;that&#8217;s&nbsp;why&nbsp;this continuous testing is so important.</p>



<p><strong>SULLIVAN:&nbsp;</strong>Given what you just said, how should regulators handle a device whose algorithm keeps updating itself after approval?</p>



<p><strong>MINSSEN:</strong>&nbsp;Well, it&nbsp;has to&nbsp;be an iterative process that is&nbsp;feasible&nbsp;and straightforward and that is based on a very efficient, both time efficient and performance efficient, communication between the regulatory authorities and the medical device developers, right. We need to have&nbsp;the sensors&nbsp;in place that spot potential changes, and we need to have&nbsp;the mechanisms&nbsp;in place that allow us to quickly react to these changes both regulatory wise&nbsp;and also&nbsp;in&nbsp;the&nbsp;technological way. </p>



<p>So&nbsp;I think communication&nbsp;is important,&nbsp;and we need to have&nbsp;the pathways&nbsp;and&nbsp;the feedback&nbsp;loops in the regulation that quickly allow us to&nbsp;monitor&nbsp;these self-learning algorithms and devices.</p>



<p><strong>SULLIVAN:</strong>&nbsp;It sounds like&nbsp;it&#8217;s&nbsp;just …&nbsp;there&#8217;s&nbsp;such a delicate balance between advancing technology and really ensuring public safety. You know, if we clamp down too hard, we stifle that innovation. You already touched upon this a bit. But if&nbsp;we&#8217;re&nbsp;too lax, we risk unintended consequences. And&nbsp;I&#8217;d&nbsp;just love to hear how you think the field is balancing that and any learnings you can share.</p>



<p><strong>MINSSEN:</strong>&nbsp;So&nbsp;this is&nbsp;very true, and&nbsp;you just touched upon a very central question also in our research and our writing. And this is also the&nbsp;reason why&nbsp;medical device regulation is so fascinating and continues to evolve in response to rapid advancements in technologies, particularly dual technologies&nbsp;regarding&nbsp;digital health, artificial intelligence, for example, and personalized medicine.</p>



<p>And finding the balance is tricky because also [a] related major future challenge relates to the increasing regulatory jungle and the complex interplay between evolving regulatory landscapes that regulate AI more generally.</p>



<p>We really need to make sure that the regulatory authorities that deal with this, that need to find the right balance to promote innovation and mitigate and prevent risks, need to have the&nbsp;capacity&nbsp;to do this.&nbsp;So&nbsp;this requires investments, and it also requires new ways to regulate this technology more flexibly, for example through regulatory sandboxes and so on.</p>



<p><strong>SULLIVAN:</strong>&nbsp;Could you just expand upon that a bit and double-click on what it is&nbsp;you&#8217;re&nbsp;seeing there? What excites you about&nbsp;what&#8217;s&nbsp;happening in that space?</p>



<p><strong>MINSSEN:</strong>&nbsp;Yes, well, the research of my group at the Center for Advanced Studies in Bioscience Innovation Law is&nbsp;very broad. I mean, we are looking into gene editing technologies. We are looking into new biologics. We are looking into medical&nbsp;devices,&nbsp;as well, obviously, but also other technologies&nbsp;in advanced medical computing.</p>



<p>And what we see across the line here is that there is an increasing demand for having more adaptive and flexible regulatory frameworks in these&nbsp;new technologies,&nbsp;in particular when&nbsp;they have new uses, regulations that are focusing more on the product rather than the process. And I have recently&nbsp;written&nbsp;a report, for example,&nbsp;for&nbsp;emerging biotechnologies and&nbsp;bio-solutions&nbsp;for the EU commission. And even in that area, regulatory sandboxes are increasingly important, increasingly considered.</p>



<p>So&nbsp;this idea of regulatory sandboxes has been developing originally in the financial sector, and it is now penetrating into&nbsp;other sectors, including synthetic biology, emerging biotechnologies, gene editing, AI, quantum technology, as&nbsp;well. This is&nbsp;basically creating&nbsp;an environment where actors can test&nbsp;new ideas&nbsp;in close collaboration and under the oversight of regulatory authorities.</p>



<p>But&nbsp;to implement&nbsp;this in the AI sector now also leads us to&nbsp;a&nbsp;lot of questions and challenges. For example, you need to have the&nbsp;capacities&nbsp;of authorities that are governing and&nbsp;monitoring&nbsp;and deciding&nbsp;on these regulatory sandboxes. There are issues relating to competition law, for example, which&nbsp;you&nbsp;call antitrust law in the US, because the question is, who can enter the sandbox and how may they compete after they exit the sandbox? And there are many questions relating to, how&nbsp;should we&nbsp;work with these sandboxes and how&nbsp;should we&nbsp;implement these sandboxes?</p>



<p>[TRANSITION MUSIC]&nbsp;</p>



<p><strong>SULLIVAN:</strong>&nbsp;Well, Timo, it has just been such a pleasure to speak with you today.</p>



<p><strong>MINSSEN:</strong>&nbsp;Yes, thank you very much.&nbsp;</p>



<p>And now&nbsp;I&#8217;m&nbsp;happy to introduce Chad Atalla.</p>



<p>Chad&nbsp;is&nbsp;senior applied scientist&nbsp;in&nbsp;Microsoft Research&nbsp;New York City&#8217;s&nbsp;Sociotechnical Alignment Center, where they contribute to foundational responsible AI research and practical responsible AI solutions for teams across Microsoft.</p>



<p>Chad, welcome!</p>



<p><strong>CHAD ATALLA:</strong>&nbsp;Thank you.</p>



<p><strong>SULLIVAN:</strong>&nbsp;So&nbsp;we&#8217;ll&nbsp;kick off with a couple questions just to dive right in.&nbsp;So&nbsp;tell me a little bit more about the&nbsp;Sociotechnical Alignment Center,&nbsp;or&nbsp;<em>STAC</em>? I know it was founded in&nbsp;2022.&nbsp;I&#8217;d&nbsp;love to just learn a little bit more about what the group does, how&nbsp;you&#8217;re&nbsp;thinking about evaluating AI, and&nbsp;maybe just&nbsp;give us a sense of some of the projects&nbsp;you&#8217;re&nbsp;working on.</p>



<p><strong>ATALLA:</strong>&nbsp;Yeah, absolutely. The name is quite a mouthful.</p>



<p><strong>SULLIVAN:</strong>&nbsp;It is!&nbsp;[LAUGHS]&nbsp;</p>



<p><strong>ATALLA:</strong>&nbsp;So&nbsp;let&#8217;s&nbsp;start by breaking that down and seeing what that means.</p>



<p><strong>SULLIVAN:</strong>&nbsp;Great.</p>



<p><strong>ATALLA:</strong> So modern AI systems are sociotechnical systems, meaning that the social and technical aspects are deeply intertwined. And&nbsp;we&#8217;re interested in aligning the behaviors of these sociotechnical&nbsp;systems with some values.&nbsp;Those could be societal values;&nbsp;they could be regulatory values, organizational values, etc. And to make this alignment happen, we need the ability to evaluate the systems.</p>



<p>So&nbsp;my team is broadly working on an evaluation framework that acknowledges the sociotechnical nature of the technology and the often-abstract nature of the concepts&nbsp;we&#8217;re&nbsp;actually interested&nbsp;in evaluating. As you noted,&nbsp;it&#8217;s&nbsp;an applied science team, so we split our time between some fundamental research and time to bridge the work into real products across the company. And I also want to note that to power this sort of work, we have an interdisciplinary team drawing upon the social sciences, linguistics, statistics, and,&nbsp;of course, computer science.</p>



<p><strong>SULLIVAN:</strong>&nbsp;Well,&nbsp;I&#8217;m&nbsp;eager to get into our takeaways from the conversation with&nbsp;both Daniel&nbsp;and Timo. But&nbsp;maybe just&nbsp;to double-click on this for a minute, can you talk a bit about some of the overarching goals of the AI evaluations that you noted?&nbsp;</p>



<p><strong>ATALLA:</strong>&nbsp;So&nbsp;evaluation is really the act of making valuative judgments based on some evidence, and in the case of AI evaluation, that evidence might be from tests or measurements, right.&nbsp;And the goal of why&nbsp;we&#8217;re doing this in the first place is to make decisions and claims most often.</p>



<p>So&nbsp;perhaps I&nbsp;am going to make a claim about a model that&nbsp;I&#8217;m&nbsp;producing, and I want to say that&nbsp;it&#8217;s&nbsp;better than this other model. Or we are asking whether a certain product is safe to ship.&nbsp;All of these decisions need to be informed by good evaluation and therefore good measurement or testing.&nbsp;And&nbsp;I&#8217;ll&nbsp;also note that in&nbsp;the regulatory conversation, <em>risk</em>&nbsp;is often what we want to evaluate. So that is a goal in and of itself. And&nbsp;I&#8217;ll&nbsp;touch more on that later.</p>



<p><strong>SULLIVAN:</strong>&nbsp;I read a recent&nbsp;<a href="https://www.microsoft.com/en-us/research/publication/evaluating-generative-ai-systems-is-a-social-science-measurement-challenge/" target="_blank" rel="noreferrer noopener">paper that you had put out with some of our colleagues from Microsoft Research, from the University of Michigan, and Stanford</a>, and you were arguing that evaluating generative AI is&nbsp;<em>the</em>&nbsp;social-science measurement challenge.&nbsp;Maybe for&nbsp;those who&nbsp;haven&#8217;t&nbsp;read the paper, what does this mean? And can you tell us a little bit more about what motivated you and your coauthors?&nbsp;</p>



<p><strong>ATALLA:</strong>&nbsp;So the measurement tasks involved in evaluating generative AI systems are often abstract and contested. So that means they cannot be directly measured and must instead [be] indirectly measured via other observable phenomena. So this is very different than the older machine learning paradigm, where, let&#8217;s say, for example, I had a system that took a picture of a traffic light and told you whether it was green, yellow, or red at a given time.&nbsp;</p>



<p>If we wanted to evaluate that system, the task is much simpler. But with the modern generative AI systems that are also general purpose, they have open-ended output, and language in a whole chat or multiple paragraphs being outputted can have a lot of different properties. And as I noted, these are general-purpose systems, so we don&#8217;t know exactly what task they&#8217;re supposed to be carrying out.</p>



<p>So&nbsp;then the question becomes, if I want to make some decision or claim—maybe I&nbsp;want to make a claim that this system has human-level reasoning capabilities—well, what does that mean? Do I have the same impression of what that means as you do? And how do we know whether the downstream, you know, measurements and tests that&nbsp;I&#8217;m&nbsp;conducting&nbsp;actually will&nbsp;support my notion of what it means to have human-level reasoning,&nbsp;right?&nbsp;Difficult questions. But luckily, social scientists have been dealing with these exact sorts of challenges for multiple decades in fields like education, political science, and psychometrics. So&nbsp;we&#8217;re&nbsp;really&nbsp;attempting&nbsp;to avoid reinventing the wheel here and trying to learn from their past methodologies.</p>



<p>And so the rest of the paper goes on to delve into&nbsp;a four-level framework, a measurement framework, that&#8217;s grounded in the measurement theory from the quantitative social sciences that takes us all the way from these abstract and contested concepts through processes to get much clearer and eventually reach reliable and valid measurements that can power our evaluations.</p>



<p><strong>SULLIVAN:</strong>&nbsp;I love that. I mean,&nbsp;that&#8217;s&nbsp;the whole point of this podcast,&nbsp;too,&nbsp;right.&nbsp;Is&nbsp;to really&nbsp;build&nbsp;on those other learnings and frameworks that&nbsp;we&#8217;re&nbsp;taking from industries that have been thinking about this for much longer.&nbsp;Maybe from&nbsp;your vantage point, what are some of the biggest day-to-day hurdles in building solid AI evaluations&nbsp;and,&nbsp;I&nbsp;don&#8217;t&nbsp;know, do we need more shared standards? Are there&nbsp;bespoke methods? Are those&nbsp;the way to go? I would love&nbsp;to just&nbsp;hear your thoughts on that.</p>



<p><strong>ATALLA:</strong>&nbsp;So&nbsp;let&#8217;s&nbsp;talk about some of those practical challenges. And I want to briefly go back to what I mentioned about risk before, all right.&nbsp;Oftentimes,&nbsp;some of the regulatory environment&nbsp;is requiring practitioners to measure the&nbsp;<em>risk</em>&nbsp;involved in deploying one of their models or AI systems. Now, risk is importantly a&nbsp;concept that includes both event and impact,&nbsp;right.&nbsp;So&nbsp;there&#8217;s&nbsp;the probability of some event occurring. For the case of AI evaluation,&nbsp;perhaps this&nbsp;is us seeing a certain AI behavior&nbsp;exhibited. Then there&#8217;s also the severity of the&nbsp;<em>impacts</em>,&nbsp;and this is a complex chain of effects in the real world that&nbsp;happen&nbsp;to people, organizations, systems, etc., and&nbsp;it&#8217;s&nbsp;a lot more challenging to&nbsp;observe&nbsp;the impacts,&nbsp;right.</p>



<p>So&nbsp;if we&#8217;re saying that we need to measure risk, we have to measure both the event and the&nbsp;impacts. But realistically, right now, the field is not doing&nbsp;a very good&nbsp;job of&nbsp;actually measuring&nbsp;the impacts. This requires vastly different techniques and methodologies where if I just wanted to measure something about the event itself, I can, you know, do that in a technical sandbox&nbsp;environment&nbsp;and&nbsp;perhaps have&nbsp;some automated methods to detect whether a certain AI behavior is being&nbsp;exhibited. But if I want to measure the impacts? Now,&nbsp;we&#8217;re&nbsp;in the realm of needing to have real people involved, and&nbsp;perhaps a&nbsp;longitudinal study where you have interviews, questionnaires, and more qualitative evidence-gathering techniques to&nbsp;truly understand&nbsp;the long-term impacts. So&nbsp;that&#8217;s&nbsp;a significant challenge.</p>



<p>Another is that, you know,&nbsp;let&#8217;s&nbsp;say we forget about the impacts for&nbsp;now&nbsp;and we focus on the event side of things. Still, we need datasets, we need&nbsp;annotations,&nbsp;and we need&nbsp;metrics to make this whole thing work. When I say we need datasets, if I want to test whether my system has good mathematical reasoning, what questions should I ask? What are my set of inputs that are relevant? And then when I get&nbsp;the&nbsp;response from the system, how do I annotate them? How do I know if it was a good response that&nbsp;<em>did</em> demonstrate mathematical reasoning or if it was a mediocre response? And then once I have an annotation of&nbsp;all of these outputs from the AI system, how do I aggregate those all up into a single informative number?</p>



<p><strong>SULLIVAN:</strong>&nbsp;Earlier in this episode, we heard Daniel and&nbsp;Timo walk&nbsp;through the regulatory frameworks in pharma and medical devices.&nbsp;I&#8217;d&nbsp;be curious what pieces of those mature systems are already showing up or at least may&nbsp;be bubbling up in AI governance.</p>



<p><strong>ATALLA:</strong>&nbsp;Great question. You know, Timo was talking about the pre-market and post-market testing difference. Of course, this is similarly important in the AI evaluation space. But again, these have different methodologies and serve different purposes.</p>



<p>So&nbsp;within the pre-deployment phase, we&nbsp;don&#8217;t&nbsp;have evidence of how people are going to use the system. And when we have these general-purpose AI systems,&nbsp;to understand what the risks are, we really need to have a sense of what might happen and how they might be used.&nbsp;So&nbsp;there are&nbsp;significant challenges there where I think we can learn from other fields and how they do pre-market testing. And the difference in that pre- versus post-market testing also ties to testing at&nbsp;different stages&nbsp;in the life cycle.</p>



<p>For AI systems, we already see some regulations saying you need to start with the base model and do some evaluation of the base model, some basic attributes, some core attributes,&nbsp;of that base model before you start putting it into any real products. But once we have a product in mind, we have a user base in mind, we have a specific task—like maybe we&#8217;re going to integrate this model into Outlook and it&#8217;s going to help you write&nbsp;emails—now we suddenly have a much crisper picture of how the system will interact with the world around it. And again, at that stage, we need to think about another round of evaluation.</p>



<p>Another part that jumped out to me in what they were saying about pharmaceuticals is that sometimes approvals can be based on surrogate endpoints.&nbsp;So&nbsp;this is like&nbsp;we&#8217;re&nbsp;choosing some&nbsp;heuristic.&nbsp;Instead of measuring the long-term impact, which is what we&nbsp;actually care&nbsp;about,&nbsp;perhaps we&nbsp;have a proxy that we&nbsp;feel like&nbsp;is a good enough indicator of what that long-term impact might look like.&nbsp;&nbsp;</p>



<p>This is occurring in the AI evaluation space right now and is often perhaps even the default here since&nbsp;we&#8217;re not seeing that many studies of the long-term impact itself. We are seeing, instead, folks constructing these heuristics or proxies and saying if I see this behavior happen,&nbsp;I&#8217;m&nbsp;going to&nbsp;<em>assume</em>&nbsp;that it&nbsp;indicates&nbsp;this sort of impact will happen downstream. And&nbsp;that&#8217;s&nbsp;great.&nbsp;It&#8217;s&nbsp;one of the techniques that was used to speed up and reduce the barrier to innovation in&nbsp;the other&nbsp;fields. And I think&nbsp;it&#8217;s&nbsp;great that we are applying that in the AI evaluation space. But&nbsp;special care&nbsp;is,&nbsp;of course, needed to ensure that those heuristics and proxies you&#8217;re&nbsp;using are reasonable indicators of the greater outcome&nbsp;you&#8217;re&nbsp;looking for.</p>



<p><strong>SULLIVAN:</strong>&nbsp;What are some of the promising ideas from&nbsp;maybe pharma&nbsp;or med device regulation that maybe haven&#8217;t&nbsp;made it to AI testing yet and&nbsp;maybe should? And where would you urge technologists, policymakers,&nbsp;and researchers to focus their energy next?</p>



<p><strong>ATALLA:</strong>&nbsp;Well, one of the key things that jumped out to me in the discussion about pharmaceuticals was driving home the emphasis that there&nbsp;is&nbsp;a&nbsp;<em>holistic</em>&nbsp;focus on safety&nbsp;<em>and</em>&nbsp;efficacy. These go hand in hand&nbsp;and decisions must be made while considering both pieces of the picture. I would like to see that further emphasized in the AI evaluation space.</p>



<p>Often,&nbsp;we&nbsp;are seeing&nbsp;evaluations of risk being separated from evaluations of&nbsp;performance or quality&nbsp;or efficacy, but these two pieces of the puzzle really are not enough for us to make informed decisions independently.&nbsp;And that ties back into my desire to really also see us measuring the impacts.</p>



<p>So&nbsp;we see Phase 3 trials as something that occurs in the medical devices and pharmaceuticals field. That&#8217;s not something that we are doing an equivalent of in the AI evaluation space at this time.&nbsp;These are really&nbsp;cost intensive. They can last years and really involve careful monitoring of that holistic picture of safety and efficacy. And realistically, we are not going to be able to put that on the critical path to getting specific individual AI models or AI systems vetted before they&nbsp;go out&nbsp;into the world. However, I would love to see a world in which this sort of work is prioritized&nbsp;and funded or&nbsp;required. Think of how, with&nbsp;social media, it took quite a long time for us to understand that there are some long-term negative impacts on mental health, and we have the opportunity now, while the AI wave is still building,&nbsp;to start prioritizing and funding this sort of work. Let it run in the background and as soon as possible develop a good understanding of the subtle, long-term effects.</p>



<p>More broadly, I would love to see us focus on reliability and validity of the evaluations&nbsp;we&#8217;re&nbsp;conducting because trust in these decisions and claims is important. If we&nbsp;don&#8217;t&nbsp;focus on building reliable, valid, and trustworthy evaluations,&nbsp;we&#8217;re&nbsp;just going to continue to be flooded by a bunch of competing, conflicting, and&nbsp;largely meaningless&nbsp;AI evaluations.</p>



<p><strong>SULLIVAN:</strong>&nbsp;In a number of the discussions we&#8217;ve had on this podcast, we talked about how it&#8217;s not just one entity that really needs to ensure safety across the board,&nbsp;and I’d&nbsp;just love to hear from you how you think about some of those ecosystem collaborations, and you know, from across &#8230; where we think about ourselves as more of a platform company or places that these AI models are being deployed more at the application level. Tell me a little bit about how you think about,&nbsp;sort&nbsp;of, stakeholders in that mix and where responsibility lies across the board.</p>



<p><strong>ATALLA:</strong>&nbsp;It&#8217;s&nbsp;interesting. In this age of general-purpose AI technologies,&nbsp;we&#8217;re&nbsp;often&nbsp;seeing&nbsp;one company or organization&nbsp;being responsible for&nbsp;building the foundational model. And then many, many other people will take that model and build it into specific products that are designed for specific tasks and contexts.</p>



<p>Of course,&nbsp;in that, we already see that there is&nbsp;a responsibility&nbsp;of the owners of that foundational model to do some testing of the central model before they distribute it broadly. And then again, there is responsibility of all of the downstream individuals digesting that and turning it into products to consider the specific contexts that they are deploying into and how that may affect the risks we&#8217;re concerned with or the types of quality and safety and performance we need to evaluate.</p>



<p>Again, because that field of risks we may be concerned with is so broad, some of them also require an immense amount of&nbsp;expertise.&nbsp;Let&#8217;s&nbsp;think about whether AI systems can enable people to create dangerous chemicals or dangerous weapons at home. It&#8217;s not that every AI practitioner is going to have the knowledge to evaluate this, so in some of those cases, we really need third-party experts, people who are experts in chemistry, biology, etc., to come in and evaluate certain systems and models for those specific risks,&nbsp;as well.</p>



<p>So&nbsp;I think there&nbsp;are many reasons why multiple stakeholders need to be involved, partly from who owns what and&nbsp;is responsible for&nbsp;what and partly from the perspective of who has the&nbsp;expertise&nbsp;to meaningfully construct the evaluations that we need.</p>



<p><strong>SULLIVAN:</strong>&nbsp;Well, Chad, this has just been great to connect, and in a few of our discussions,&nbsp;we&#8217;ve&nbsp;done a bit of a lightning round, so&nbsp;I&#8217;d&nbsp;love to just hear your&nbsp;30-second responses to a few of these questions. Perhaps&nbsp;favorite&nbsp;evaluation&nbsp;you&#8217;ve&nbsp;run so far this year?&nbsp;</p>



<p><strong>ATALLA:</strong>&nbsp;So&nbsp;I&#8217;ve&nbsp;been involved in trying to evaluate some language models for whether they&nbsp;<em>infer</em>&nbsp;sensitive attributes about people. So&nbsp;perhaps&nbsp;you&#8217;re&nbsp;chatting with a&nbsp;chatbot,&nbsp;and it infers your religion or sexuality based on things&nbsp;you&#8217;re&nbsp;saying or how you sound,&nbsp;right.&nbsp;And in working to evaluate this, we&nbsp;encounter&nbsp;a lot of interesting questions. Or,&nbsp;like,&nbsp;what is a sensitive attribute? What makes these attributes sensitive, and what are the differences that make it inappropriate for an AI system to infer these things about a person? Whereas realistically, whenever I meet a person on the street, my&nbsp;brain is&nbsp;immediately&nbsp;forming&nbsp;first impressions and some assumptions about these people.&nbsp;So&nbsp;it&#8217;s&nbsp;a very interesting&nbsp;and thought-provoking evaluation to conduct and think about the norms that we place upon&nbsp;<em>people</em>&nbsp;interacting with other people and the norms we place upon&nbsp;<em>AI systems</em>&nbsp;interacting with other people.</p>



<p><strong>SULLIVAN:</strong>&nbsp;That’s&nbsp;fascinating!&nbsp;I&#8217;d&nbsp;love to hear the AI&nbsp;buzzword&nbsp;you&#8217;d&nbsp;retire tomorrow.&nbsp;[LAUGHTER]</p>



<p><strong>ATALLA:</strong>&nbsp;I would love to see the term “bias” being&nbsp;used less when referring to fairness-related issues and systems. Bias happens to be a highly overloaded term in statistics and machine learning and has a lot of technical meanings and just&nbsp;fails to&nbsp;perfectly capture what we mean in the AI risk sense.</p>



<p><strong>SULLIVAN:</strong>&nbsp;And last one. One metric&nbsp;we&#8217;re&nbsp;not tracking enough.</p>



<p><strong>ATALLA:</strong>&nbsp;I would say <em>over-blocking</em>, and this comes into that connection between the holistic picture of safety and efficacy. It&#8217;s too easy to produce systems that throw safety to the wind and focus purely on utility or achieving some goal, but simultaneously, the other side of the picture is possible, where we can clamp down too hard and reduce the utility of our systems and block even benign and useful outputs just because they border on something sensitive.&nbsp;So&nbsp;it&#8217;s&nbsp;important for us to track that over-blocking and actively track that tradeoff between safety and efficacy.</p>



<p><strong>SULLIVAN:</strong>&nbsp;Yeah, we talk a lot about this on the podcast,&nbsp;too,&nbsp;of how do you both make things safe but also ensure innovation can&nbsp;thrive,&nbsp;and&nbsp;I think you&nbsp;hit the nail on the head with that last piece.</p>



<p>[MUSIC]&nbsp;</p>



<p>Well, Chad, this was&nbsp;really terrific. Thanks for joining us and thanks for your work and your&nbsp;perspectives. And another big thanks to Daniel and Timo for setting the stage earlier in the podcast.</p>



<p>And to our listeners, thanks for tuning in. You can find resources related to this podcast in the show notes. And if you want to learn more about how Microsoft approaches AI governance, you can visit <a href="https://www.microsoft.com/RAI" target="_blank" rel="noreferrer noopener">microsoft.com/RAI</a>. </p>



<p>See you next time! </p>



<p>[MUSIC FADES]</p>

				</span>
			</div>
			<button
				class="action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle"
				aria-expanded="false"
				data-show-less-text="Show less"
				type="button"
				aria-controls="show-more-show-less-toggle-5"
				aria-label="Show more content"
				data-alternate-aria-label="Show less content">
				Show more			</button>
		</div>
	</div>
</div>



<div class="wp-block-buttons is-layout-flex wp-block-buttons-is-layout-flex">
<div class="wp-block-button is-style-outline is-style-outline--6"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/story/ai-testing-and-evaluation-learnings-from-science-and-industry/">AI Testing and Evaluation podcast series</a></div>
</div>
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-pharmaceuticals-and-medical-devices/">AI Testing and Evaluation: Learnings from pharmaceuticals and medical devices</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>AI Testing and Evaluation: Learnings from genome editing</title>
		<link>https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-genome-editing/</link>
		
		<dc:creator><![CDATA[Kathleen Sullivan, Alta Charo, Daniel Kluttz]]></dc:creator>
		<pubDate>Mon, 30 Jun 2025 16:00:17 +0000</pubDate>
				<category><![CDATA[Microsoft Research Podcast]]></category>
		<guid isPermaLink="false">https://www.microsoft.com/en-us/research/?p=1142130</guid>

					<description><![CDATA[<p>Bioethics and law expert R. Alta Charo explores the value of regulating technologies at the application level and the role of coordinated oversight in genome editing, while Microsoft GM Daniel Kluttz reflects on Charo’s points, drawing parallels to AI governance.</p>
<p>The post <a href="https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-genome-editing/">AI Testing and Evaluation: Learnings from genome editing</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP1-AI-TE_Hero_Feature_1400x788.jpg" alt="illustration of R. Alta Charo, Kathleen Sullivan, and Daniel Kluttz for the Microsoft Research Podcast" class="wp-image-1142157" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP1-AI-TE_Hero_Feature_1400x788.jpg 1400w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP1-AI-TE_Hero_Feature_1400x788-300x169.jpg 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP1-AI-TE_Hero_Feature_1400x788-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP1-AI-TE_Hero_Feature_1400x788-768x432.jpg 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP1-AI-TE_Hero_Feature_1400x788-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP1-AI-TE_Hero_Feature_1400x788-655x368.jpg 655w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP1-AI-TE_Hero_Feature_1400x788-240x135.jpg 240w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP1-AI-TE_Hero_Feature_1400x788-640x360.jpg 640w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP1-AI-TE_Hero_Feature_1400x788-960x540.jpg 960w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP1-AI-TE_Hero_Feature_1400x788-1280x720.jpg 1280w" sizes="auto, (max-width: 1400px) 100vw, 1400px" /></figure>


<div class="wp-block-msr-podcast-container my-4">
	<iframe loading="lazy" src="https://player.blubrry.com/?podcast_id=146599312&modern=1" class="podcast-player" frameborder="0" height="164px" width="100%" scrolling="no" title="Podcast Player"></iframe>
</div>



<p>Generative AI presents a unique challenge and opportunity to reexamine governance practices for the responsible development, deployment, and use of AI. To advance thinking in this space, Microsoft has tapped into the experience and knowledge of experts across domains—from genome editing to cybersecurity—to investigate the role of testing and evaluation as a governance tool. <em><a href="https://www.microsoft.com/en-us/research/story/ai-testing-and-evaluation-learnings-from-science-and-industry/">AI Testing and Evaluation: Learnings from Science and Industry</a>, </em>hosted by Microsoft Research’s <a href="https://www.microsoft.com/en-us/research/people/kasull/">Kathleen Sullivan</a>, explores what the technology industry and policymakers can learn from these fields and how that might help shape the course of AI development.</p>



<p>In this episode, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" target="_blank" href="https://law.wisc.edu/profiles/racharo@wisc.edu">Alta Charo<span class="sr-only"> (opens in new tab)</span></a>, emerita professor of law and bioethics at the University of Wisconsin–Madison, joins Sullivan for a conversation on the evolving landscape of genome editing and its regulatory implications. Drawing on decades of experience in biotechnology policy, Charo emphasizes the importance of distinguishing between hazards and risks and describes the field&#8217;s approach to regulating <em>applications </em>of technology rather than the technology itself. The discussion also explores opportunities and challenges in biotech’s multi-agency oversight model and the role of international coordination. Later, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" target="_blank" href="https://www.linkedin.com/in/daniel-kluttz/">Daniel Kluttz<span class="sr-only"> (opens in new tab)</span></a>, a partner general manager in Microsoft&#8217;s Office of Responsible AI, joins Sullivan to discuss how insights from genome editing could inform more nuanced and robust governance frameworks for emerging technologies like AI.</p>



<div class="wp-block-group msr-pattern-link-list is-layout-flow wp-block-group-is-layout-flow">
<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading h5" id="learn-more">Learn more:</h2>



<p><a href="https://www.microsoft.com/en-us/research/publication/learning-from-other-domains-to-advance-ai-evaluation-and-testing-governance-of-genome-edition-in-human-therapeutics-and-agricultural-applications/" target="_blank" rel="noreferrer noopener">Learning from other Domains to Advance AI Evaluation and Testing: Governance of Genome Edition in Human Therapeutics and Agricultural Applications</a><br>Case study | January 2025&nbsp;</p>



<p><a href="https://www.microsoft.com/en-us/research/blog/learning-from-other-domains-to-advance-ai-evaluation-and-testing/" target="_blank" rel="noreferrer noopener">Learning from other domains to advance AI evaluation and testing</a>&nbsp;<br>Microsoft Research Blog | June 2025&nbsp;</p>



<p><a href="https://www.microsoft.com/en-us/ai/responsible-ai?ef_id=_k_cb05d5950e4f117c457ebda628845b7f_k_&OCID=AIDcmm1o1fzy5i_SEM__k_cb05d5950e4f117c457ebda628845b7f_k_&msclkid=cb05d5950e4f117c457ebda628845b7f" target="_blank" rel="noreferrer noopener">Responsible AI: Ethical policies and practices | Microsoft AI</a>&nbsp;</p>



<p><a href="https://www.microsoft.com/en-us/research/focus-area/ai-and-microsoft-research/" target="_blank" rel="noreferrer noopener">AI and Microsoft Research</a>&nbsp;</p>
</div>



<div style="height:25px" aria-hidden="true" class="wp-block-spacer"></div>



<section class="wp-block-msr-subscribe-to-podcast subscribe-to-podcast">
	<div class="subscribe-to-podcast__inner border-top border-bottom border-width-2">
		<h2 class="h5 subscribe-to-podcast__heading">
			Subscribe to the <a href="https://www.microsoft.com/en-us/research/podcast">Microsoft Research Podcast</a>:		</h2>
		<ul class="subscribe-to-podcast__list list-unstyled">
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://itunes.apple.com/us/podcast/microsoft-research-a-podcast/id1318021537?mt=2" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="black" viewBox="0 0 32 32">  <path d="M7.12 0c-3.937-0.011-7.131 3.183-7.12 7.12v17.76c-0.011 3.937 3.183 7.131 7.12 7.12h17.76c3.937 0.011 7.131-3.183 7.12-7.12v-17.76c0.011-3.937-3.183-7.131-7.12-7.12zM15.817 3.421c3.115 0 5.932 1.204 8.079 3.453 1.631 1.693 2.547 3.489 3.016 5.855 0.161 0.787 0.161 2.932 0.009 3.817-0.5 2.817-2.041 5.339-4.317 7.063-0.812 0.615-2.797 1.683-3.115 1.683-0.12 0-0.129-0.12-0.077-0.615 0.099-0.792 0.192-0.953 0.64-1.141 0.713-0.296 1.932-1.167 2.677-1.911 1.301-1.303 2.229-2.932 2.677-4.719 0.281-1.1 0.244-3.543-0.063-4.672-0.969-3.595-3.907-6.385-7.5-7.136-1.041-0.213-2.943-0.213-4 0-3.636 0.751-6.647 3.683-7.563 7.371-0.245 1.004-0.245 3.448 0 4.448 0.609 2.443 2.188 4.681 4.255 6.015 0.407 0.271 0.896 0.547 1.1 0.631 0.447 0.192 0.547 0.355 0.629 1.14 0.052 0.485 0.041 0.62-0.072 0.62-0.073 0-0.62-0.235-1.199-0.511l-0.052-0.041c-3.297-1.62-5.407-4.364-6.177-8.016-0.187-0.943-0.224-3.187-0.036-4.052 0.479-2.323 1.396-4.135 2.921-5.739 2.199-2.319 5.027-3.543 8.172-3.543zM16 7.172c0.541 0.005 1.068 0.052 1.473 0.14 3.715 0.828 6.344 4.543 5.833 8.229-0.203 1.489-0.713 2.709-1.619 3.844-0.448 0.573-1.537 1.532-1.729 1.532-0.032 0-0.063-0.365-0.063-0.803v-0.808l0.552-0.661c2.093-2.505 1.943-6.005-0.339-8.296-0.885-0.896-1.912-1.423-3.235-1.661-0.853-0.161-1.031-0.161-1.927-0.011-1.364 0.219-2.417 0.744-3.355 1.672-2.291 2.271-2.443 5.791-0.348 8.296l0.552 0.661v0.813c0 0.448-0.037 0.807-0.084 0.807-0.036 0-0.349-0.213-0.683-0.479l-0.047-0.016c-1.109-0.885-2.088-2.453-2.495-3.995-0.244-0.932-0.244-2.697 0.011-3.625 0.672-2.505 2.521-4.448 5.079-5.359 0.547-0.193 1.509-0.297 2.416-0.281zM15.823 11.156c0.417 0 0.828 0.084 1.131 0.24 0.645 0.339 1.183 0.989 1.385 1.677 0.62 2.104-1.609 3.948-3.631 3.005h-0.015c-0.953-0.443-1.464-1.276-1.475-2.36 0-0.979 0.541-1.828 1.484-2.328 0.297-0.156 0.709-0.235 1.125-0.235zM15.812 17.464c1.319-0.005 2.271 0.463 2.625 1.291 0.265 0.62 0.167 2.573-0.292 5.735-0.307 2.208-0.479 2.765-0.905 3.141-0.589 0.52-1.417 0.667-2.209 0.385h-0.004c-0.953-0.344-1.157-0.808-1.553-3.527-0.452-3.161-0.552-5.115-0.285-5.735 0.348-0.823 1.296-1.285 2.624-1.291z"/></svg>
						<span class="subscribe-to-podcast__link-text">Apple Podcasts</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://subscribebyemail.com/www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M6.4 6a2.392 2.392 0 00-2.372 2.119L16 15.6l11.972-7.481A2.392 2.392 0 0025.6 6H6.4zM4 10.502V22.8a2.4 2.4 0 002.4 2.4h19.2a2.4 2.4 0 002.4-2.4V10.502l-11.365 7.102a1.2 1.2 0 01-1.27 0L4 10.502z"/></svg>
						<span class="subscribe-to-podcast__link-text">Email</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://subscribeonandroid.com/www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M12.414 4.02c-.062.012-.126.023-.18.06a.489.489 0 00-.12.675L13.149 6.3c-1.6.847-2.792 2.255-3.18 3.944h13.257c-.388-1.69-1.58-3.097-3.179-3.944l1.035-1.545a.489.489 0 00-.12-.675.492.492 0 00-.675.135l-1.14 1.68a7.423 7.423 0 00-2.55-.45c-.899 0-1.758.161-2.549.45l-1.14-1.68a.482.482 0 00-.494-.195zm1.545 3.824a.72.72 0 110 1.44.72.72 0 010-1.44zm5.278 0a.719.719 0 110 1.44.719.719 0 110-1.44zM8.44 11.204A1.44 1.44 0 007 12.644v6.718c0 .795.645 1.44 1.44 1.44.168 0 .33-.036.48-.09v-9.418a1.406 1.406 0 00-.48-.09zm1.44 0V21.76c0 .793.646 1.44 1.44 1.44h10.557c.793 0 1.44-.647 1.44-1.44V11.204H9.878zm14.876 0c-.169 0-.33.035-.48.09v9.418c.15.052.311.09.48.09a1.44 1.44 0 001.44-1.44v-6.719a1.44 1.44 0 00-1.44-1.44zM11.8 24.16v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84zm5.759 0v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84z"/></svg>
						<span class="subscribe-to-podcast__link-text">Android</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://open.spotify.com/show/4ndjUXyL0hH1FXHgwIiTWU" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M16 4C9.383 4 4 9.383 4 16s5.383 12 12 12 12-5.383 12-12S22.617 4 16 4zm5.08 17.394a.781.781 0 01-1.086.217c-1.29-.86-3.477-1.434-5.303-1.434-1.937.002-3.389.477-3.403.482a.782.782 0 11-.494-1.484c.068-.023 1.71-.56 3.897-.562 1.826 0 4.365.492 6.171 1.696.36.24.457.725.217 1.085zm1.56-3.202a.895.895 0 01-1.234.286c-2.338-1.457-4.742-1.766-6.812-1.747-2.338.02-4.207.466-4.239.476a.895.895 0 11-.488-1.723c.145-.041 2.01-.5 4.564-.521 2.329-.02 5.23.318 7.923 1.995.419.26.547.814.286 1.234zm1.556-3.745a1.043 1.043 0 01-1.428.371c-2.725-1.6-6.039-1.94-8.339-1.942h-.033c-2.781 0-4.923.489-4.944.494a1.044 1.044 0 01-.474-2.031c.096-.023 2.385-.55 5.418-.55h.036c2.558.004 6.264.393 9.393 2.23.497.292.663.931.371 1.428z"/></svg>
						<span class="subscribe-to-podcast__link-text">Spotify</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M6.667 4a2.676 2.676 0 00-2.612 2.13v.003c-.036.172-.055.35-.055.534v18.666c0 .183.019.362.055.534v.003a2.676 2.676 0 002.076 2.075h.002c.172.036.35.055.534.055h18.666A2.676 2.676 0 0028 25.333V6.667a2.676 2.676 0 00-2.13-2.612h-.003A2.623 2.623 0 0025.333 4H6.667zM8 8h1.333C17.42 8 24 14.58 24 22.667V24h-2.667v-1.333c0-6.618-5.382-12-12-12H8V8zm0 5.333h1.333c5.146 0 9.334 4.188 9.334 9.334V24H16v-1.333A6.674 6.674 0 009.333 16H8v-2.667zM10 20a2 2 0 11-.001 4.001A2 2 0 0110 20z"/></svg>
						<span class="subscribe-to-podcast__link-text">RSS Feed</span>
					</a>
				</li>
					</ul>
	</div>
</section>


<div class="wp-block-msr-show-more">
	<div class="bg-neutral-100 p-5">
		<div class="show-more-show-less" data-mount="show-more-show-less">
			<div>
				<span>
					

<h2 class="wp-block-heading" id="transcript-1">Transcript</h2>



<p>[MUSIC]</p>



<p><strong>KATHLEEN SULLIVAN:</strong> Welcome to <em>AI Testing and Evaluation: Learnings from Science and Industry</em>. I&#8217;m your host, Kathleen Sullivan.</p>



<p>As generative AI continues to advance, Microsoft has gathered a range of experts—from genome editing to cybersecurity—to share how their fields approach evaluation and risk assessment. Our goal is to learn from their successes and their stumbles to move the science and practice of AI testing forward. In this series, we&#8217;ll explore how these insights might help guide the future of AI development, deployment, and responsible use.</p>



<p>[MUSIC ENDS]</p>



<p>Today I&#8217;m excited to welcome R. Alta Charo, the Warren P. Knowles Professor Emerita of Law and Bioethics at the University of Wisconsin–Madison, to explore testing and risk assessment in genome editing.</p>



<p>Professor Charo has been at the forefront of biotechnology policy and governance for decades, advising former President Obama&#8217;s transition team on issues of medical research and public health, as well as serving as a senior policy advisor at the Food and Drug Administration. She consults on gene therapy and genome editing for various companies and organizations and has held positions on a number of advisory committees, including for the National Academy of Sciences. Her committee work has spanned women&#8217;s health, stem cell research, genome editing, biosecurity, and more.</p>



<p>After our conversation with Professor Charo, we&#8217;ll hear from Daniel Kluttz, a partner general manager in Microsoft&#8217;s Office of Responsible AI, about what these insights from biotech regulation could mean for AI governance and risk assessment and his team&#8217;s work governing sensitive AI uses and emerging technologies.</p>



<p>Alta, thank you so much for being here today. I&#8217;m a follower of your work and have really been looking forward to our conversation.</p>



				</span>
				<span id="show-more-show-less-toggle-7" class="show-more-show-less-toggleable-content">
					



<p><strong>ALTA CHARO:</strong> It&#8217;s my pleasure. Thanks for having me.</p>



<p><strong>SULLIVAN:</strong> Alta, I&#8217;d love to begin by stepping back in time a bit before you became a leading figure in bioethics and legal policy. You&#8217;ve shared that your interest in science was really inspired by your brothers’ interest in the topic and that your upbringing really helped shape your perseverance and resilience. Can you talk to us about what put you on the path to law and policy?</p>



<p><strong>CHARO:</strong> Well, I think it&#8217;s true that many of us are strongly influenced by our families and certainly my family had, kind of, a science-y, techy orientation. My father was a refugee, you know, escaping the Nazis, and when he finally was able to start working in the United States, he took advantage of the G.I. Bill to learn how to repair televisions and radios, which were really just coming in in the 1950s. So he was, kind of, technically oriented.</p>



<p>My mother retrained from being a talented amateur artist to becoming a math teacher, and not surprisingly, both my brothers began to aim toward things like engineering and chemistry and physics. And our form of entertainment was to watch PBS or <em>Star Trek</em>. [LAUGHTER]</p>



<p>And so the interest comes from that background coupled with, in the 1960s, this enormous surge of interest in the so-called nature-versus-nurture debate about the degree to which we are destined by our biology or shaped by our environments. It was a heady debate, and one that perfectly combined the two interests in politics and science.</p>



<p><strong>SULLIVAN:</strong> For listeners who are brand new to your field in genomic editing, can you give us what I&#8217;ll call a “90-second survey” of the space in perhaps plain language and why it&#8217;s important to have a framework for ensuring its responsible use.</p>



<p><strong>CHARO:</strong> Well, you know, genome editing is both very old and very new. At base, what we&#8217;re talking about is a way to either delete sections of the <em>genome</em>, our collection of genes, or to add things or to alter what&#8217;s there. The goal is simply to be able to take what might not be healthy and make it healthy, whether it&#8217;s a plant, an animal, or a human.</p>



<p>Many people have compared it to a word processor, where you can edit text by swapping things in and out. You could change the letter <em>g</em> to the letter <em>h</em> in every word, and in our genomes, you can do similar kinds of things.</p>



<p>But because of this, we have a responsibility to make sure that whatever we change doesn&#8217;t become dangerous and that it doesn&#8217;t become socially disruptive. Now the earliest forms of genome editing were very inefficient, and so we didn&#8217;t worry that much. But with the advances that were spearheaded by people like Jennifer Doudna and Emmanuelle Charpentier, who won the Nobel Prize for their work in this area, genome editing has become much easier to do.</p>



<p>It&#8217;s become more efficient. It doesn&#8217;t require as much sophisticated laboratory equipment. It&#8217;s moved from being something that only a few people can do to something that we&#8217;re going to be seeing in our junior high school biology labs. And that means you have to pay attention to who&#8217;s doing it, why are they doing it, what are they releasing, if anything, into the environment, what are they trying to sell, and is it honest and is it safe?</p>



<p><strong>SULLIVAN:</strong> How would you describe the risks, and are there, you know, sort of, specifically inherent risks in the technology itself, or do those risks really emerge only when it&#8217;s applied in certain contexts, like CRISPR in agriculture or CRISPR for human therapies?</p>



<p><strong>CHARO:</strong> Well, to answer that, I&#8217;m going to do something that may seem a little picky, even pedantic. [LAUGHTER] But I&#8217;m going to distinguish between hazards and risks. So there are certain intrinsic hazards. That is, there are things that can go wrong.</p>



<p>You want to change one particular gene or one particular portion of a gene, and you might accidentally change something else, a so-called <em>off-target effect</em>. Or you might change something in a gene expecting a certain effect but not necessarily anticipating that there&#8217;s going to be an interaction between what you changed and what was there, a <em>gene-gene interaction</em>, that might have an unanticipated kind of result, a side effect essentially.</p>



<p>So there are some intrinsic hazards, but risk is a hazard coupled with the probability that it&#8217;s going to actually create something harmful. And that really depends upon the application.</p>



<p>If you are doing something that is making a change in a human being that is going to be a lifelong change, that enhances the significance of that hazard. It amplifies what I call the risk because if something goes wrong, then its consequences are greater.</p>



<p>It may also be that in other settings, what you&#8217;re doing is going to have a much lower risk because you&#8217;re working with a more familiar substance, your predictive power is much greater, and it&#8217;s not going into a human or an animal or into the environment. So I think that you have to say that the risk <em>and</em> the benefits, by the way, all are going to depend upon the particular application.</p>



<p><strong>SULLIVAN:</strong> Yeah, I think on this point of application, there&#8217;s many players involved in that, right. Like, we often hear about this puzzle of who&#8217;s actually responsible for ensuring safety and a reasonable balance between risks and benefits or hazards and benefits, to quote you. Is it the scientists, the biotech companies, government agencies? And then if you could touch upon, as well, maybe how does the nature of genome editing risks … how do those responsibilities get divvied up?</p>



<p><strong>CHARO:</strong> Well, in the 1980s, we had a very significant policy discussion about whether we should regulate the technology—no matter how it&#8217;s used or for whatever purpose—or if we should simply fold the technology in with all the other technologies that we currently have and regulate its applications the way we regulate applications generally. And we went for the second, the so-called <em>coordinated framework</em>.</p>



<p>So what we have in the United States is a system in which if you use genome editing in purely laboratory-based work, then you will be regulated the way we regulate laboratories.</p>



<p>There&#8217;s also, at most universities because of the way the government works with this, something called Institutional Biosafety Committees, <em>IBCs</em>. You want to do research that involves recombinant DNA and modern biotechnology, <em>including</em> genome editing but not limited to it, you have to go first to your IBC, and they look and see what you&#8217;re doing to decide if there&#8217;s a danger there that you have not anticipated that requires special attention.</p>



<p>If what you&#8217;re doing is going to get released into the environment or it&#8217;s going to be used to change an animal that&#8217;s going to be in the environment, then there are agencies that oversee the safety of our environment, predominantly the Environmental Protection Agency and the U.S. Department of Agriculture.</p>



<p>If you&#8217;re working with humans and you&#8217;re doing medical therapies, like you&#8217;re doing the gene therapies that just have been developed for things like sickle cell anemia, then you have to go through a very elaborate regulatory process that&#8217;s overseen by the Food and Drug Administration and also seen locally at the research stages overseen by institutional review boards that make sure the people who are being recruited into research understand what they&#8217;re getting into, that they&#8217;re the right people to be recruited, etc.</p>



<p>So we do have this kind of Jenga game …</p>



<p><strong>SULLIVAN:</strong> [LAUGHS] Yeah, sounds like it.</p>



<p><strong>CHARO:</strong> … of regulatory agencies. And on top of all that, most of this involves professionals who&#8217;ve had to be licensed in some way. There may be state laws specifically on licensing. If you are dealing with things that might cross national borders, there may be international treaties and agreements that cover this.</p>



<p>And, of course, the insurance industry plays a big part because they decide whether or not what you&#8217;re doing is safe enough to be insured. So all of these things come together in a way that is not at all easy to understand if you&#8217;re not, kind of, working in the field. But the bottom-line thing to remember, the way to really think about it is, we don&#8217;t regulate genome editing; we regulate the things that use genome editing.</p>



<p><strong>SULLIVAN:</strong> Yeah, that makes a lot of sense. Actually, maybe just following up a little bit on this notion of a variety of different, particularly like government agencies being involved. You know, in this multi-stakeholder model, where do you see gaps today that need to be filled, some of the pros and cons to keep in mind, and, you know, just as we think about distributing these systems at a global level, like, what are some of the considerations you are keeping in mind on that front?</p>



<p><strong>CHARO:</strong> Well, certainly there are times where the way the statutes were written that govern the regulation of drugs or the regulation of foods did not anticipate this tremendous capacity we now have in the area of biotechnology generally or genome editing in particular. And so you can find that there are times where it feels a little bit ambiguous, and the agencies have to figure out how to apply their existing rules.</p>



<p>So an example. If you&#8217;re going to make alterations in an animal, right, we have a system for regulating drugs, including veterinary drugs. But we didn&#8217;t have something that regulated genome editing of animals. But in a sense, genome editing of an animal is the same thing as using a veterinary drug. You&#8217;re trying to affect the animal&#8217;s physical constitution in some fashion.</p>



<p>And it took a long time within the FDA to, sort of, work out how the regulation of veterinary drugs would apply if you think about the genetic construct that&#8217;s being used to alter the animal as the same thing as injecting a chemically based drug. And on that basis, they now know here&#8217;s the regulatory path—here are the tests you have to do; here are the permissions you have to do; here&#8217;s the surveillance you have to do after it goes on the market.</p>



<p>Even there, sometimes, it was confusing. What happens when it&#8217;s not the kind of animal you&#8217;re thinking about when you think about animal drugs? Like, we think about pigs and dogs, but what about mosquitoes?</p>



<p>Because there, you&#8217;re really thinking more about pests, and if you&#8217;re editing the mosquito so that it can&#8217;t, for example, transmit dengue fever, right, it feels more like a public health thing than it is a drug for the mosquito itself, and it, kind of, fell in between the agencies that possibly had jurisdiction. And it took a while for the USDA, the Department of Agriculture, and the Food and Drug Administration to work out an agreement about how they would share this responsibility. So you do get those kinds of areas in which you have at least ambiguity.</p>



<p>We also have situations where frankly the fact that some things can move across national borders means you have to have a system for harmonizing or coordinating national rules. If you want to, for example, genetically engineer mosquitoes that can&#8217;t transmit dengue, mosquitoes have a tendency to fly. [LAUGHTER] And so &#8230; they can&#8217;t fly very far. That&#8217;s good. That actually makes it easier to control.</p>



<p>But if you&#8217;re doing work that&#8217;s right near a border, then you have to be sure that the country next to you has the same rules for whether it&#8217;s permitted to do this and how to surveil what you&#8217;ve done in order to be sure that you got the results you wanted to get and no other results. And that also is an area where we have a lot of work to be done in terms of coordinating across government borders and harmonizing our rules.</p>



<p><strong>SULLIVAN:</strong> Yeah, I mean, you&#8217;ve touched on this a little bit, but there is such this striking balance between advancing technology, ensuring public safety, and sometimes, I think it feels just like you&#8217;re walking a tightrope where, you know, if we clamp down too hard, we&#8217;ll stifle innovation, and if we&#8217;re too lax, we risk some of these unintended consequences. And on a global scale like you just mentioned, as well. How has the field of genome editing found its balance?</p>



<p><strong>CHARO:</strong> It&#8217;s still being worked out, frankly, but it&#8217;s finding its balance application by application. So in the United States, we have two very different approaches on regulation of things that are going to go into the market.</p>



<p>Some things can&#8217;t be marketed until they&#8217;ve gotten an approval from the government. So you come up with a new drug, you can&#8217;t sell that until it&#8217;s gone through FDA approval.</p>



<p>On the other hand, for most foods that are made up of familiar kinds of things, you can go on the market, and it&#8217;s only after they&#8217;re on the market that the FDA can act to withdraw it if a problem arises. So basically, we have either <em>pre</em>-market controls: you can&#8217;t go on without permission. Or <em>post</em>-market controls: we can take you off the market <em>if</em> a problem occurs.</p>



<p>How do we decide which one is appropriate for a particular application? It&#8217;s based on our experience. New drugs typically are both less familiar than existing things on the market and also have a higher potential for injury if they, in fact, are not effective or they are, in fact, dangerous and toxic.</p>



<p>If you have foods, even bioengineered foods, that are basically the same as foods that are already here, it can go on the market with notice but without a prior approval. But if you create something truly novel, then it has to go through a whole long process.</p>



<p>And so that is the way that we make this balance. We look at the application area. And we&#8217;re just now seeing in the Department of Agriculture a new approach on some of the animal editing, again, to try and distinguish between things that are simply a more efficient way to make a familiar kind of animal variant and those things that are genuinely novel and to have a regulatory process that is more rigid the more unfamiliar it is and the more that we see a risk associated with it.</p>



<p><strong>SULLIVAN:</strong> I know we&#8217;re at the end of our time here and maybe just a quick kind of lightning-round of a question. For students, young scientists, lawyers, or maybe even entrepreneurs listening who are inspired by your work, what&#8217;s the single piece of advice you give them if they&#8217;re interested in policy, regulation, the ethical side of things in genomics or other fields?</p>



<p><strong>CHARO:</strong> I&#8217;d say be a bio-optimist and read a lot of science fiction. Because it expands your imagination about what the world could be like. Is it going to be a world in which we&#8217;re now going to be growing our buildings instead of building them out of concrete?</p>



<p>Is it going to be a world in which our plants will glow in the evening so we don&#8217;t need to be using batteries or electrical power from other sources but instead our environment is adapting to our needs?</p>



<p>You know, expand your imagination with a sense of optimism about what could be and see ethics and regulation not as an obstacle but as a partner to bringing these things to fruition in a way that&#8217;s responsible and helpful to everyone.</p>



<p>[TRANSITION MUSIC]</p>



<p><strong>SULLIVAN:</strong> Wonderful. Well, Alta, this has been just an absolute pleasure. So thank you.</p>



<p><strong>CHARO:</strong> It was my pleasure. Thank you for having me.</p>



<p><strong>SULLIVAN:</strong> Now, I&#8217;m happy to bring in Daniel Kluttz. As a partner general manager in Microsoft&#8217;s Office of Responsible AI, Daniel leads the group’s Sensitive Uses and Emerging Technologies program.</p>



<p>Daniel, it&#8217;s great to have you here. Thanks for coming in.</p>



<p><strong>DANIEL KLUTTZ:</strong> It&#8217;s great to be here, Kathleen.</p>



<p><strong>SULLIVAN:</strong> Yeah. So maybe before we unpack Alta Charo’s insights, I&#8217;d love to just understand the elevator pitch here. What exactly is [the] Sensitive Uses and Emerging Tech program, and what was the impetus for establishing it?</p>



<p><strong>KLUTTZ:</strong> Yeah. So the Sensitive Uses and Emerging Technologies program sits within our Office of Responsible AI at Microsoft. And inherent in the name, there are two real core functions. There&#8217;s the sensitive uses and emerging technologies. What does that mean?</p>



<p>Sensitive uses, think of that as Microsoft&#8217;s internal consulting and oversight function for our higher-risk, most impactful AI system deployments. And so my team is a team of multidisciplinary experts who engages in sort of a white-glove-treatment sort of way with product teams at Microsoft that are designing, building, and deploying these higher-risk AI systems, and where that sort of consulting journey culminates is in a set of bespoke requirements tailored to the use case of that given system that really implement and apply our more standardized, generalized requirements that apply across the board.</p>



<p>Then the emerging technologies function of my team faces a little bit further out, trying to look around corners to see what new and novel and emerging risks are coming out of new AI technologies with the idea that we work with our researchers, our engineering partners, and, of course, product leaders across the company to understand where Microsoft is going with those emerging technologies, and we&#8217;re developing sort of rapid, quick-fire early-steer guidance that implements our policies ahead of that formal internal policymaking process, which can take a bit of time. So it&#8217;s designed to, sort of, both afford that innovation speed that we like to optimize for at Microsoft but also integrate our responsible AI commitments and our AI principles into emerging product development.</p>



<p><strong>SULLIVAN:</strong> That segues really nicely, actually, as we met with Professor Charo and she was, you know, talking about the field of genome editing and the governing at the application level. I&#8217;d love to just understand how similar or not is that to managing the risks of AI in our world?</p>



<p><strong>KLUTTZ:</strong> Yeah. I mean, Professor Charo’s comments were music to my ears because, you know, where we make our bread and butter, so to speak, in our team is in applying to use cases. AI systems, especially in this era of generative AI, are almost inherently multi-use, dual use. And so what really matters is how you&#8217;re going to apply that more general-purpose technology. Who&#8217;s going to use it? In what domain is it going to be deployed? And then tailor that oversight to those use cases. Try to be risk proportionate.</p>



<p>Professor Charo talked a little bit about this, but if it&#8217;s something that&#8217;s been done before and it&#8217;s just a new spin on an old thing, maybe we&#8217;re not so concerned about how closely we need to oversee and gate that application of that technology, whereas if it&#8217;s something new and novel or some new risk that might be posed by that technology, we take a little bit closer look and we are overseeing that in a more sort of high-touch way.</p>



<p><strong>SULLIVAN:</strong> Maybe following up on that, I mean, how do you define sensitive use or maybe like high-impact application, and once that&#8217;s labeled, what happens? Like, what kind of steps kick in from there?</p>



<p><strong>KLUTTZ:</strong> Yeah. So we have this Sensitive Uses program that&#8217;s been at Microsoft since 2019. I came to Microsoft in 2019 when we were starting this program in the Office of Responsible AI, and it had actually been incubated in Microsoft Research with our Aether community of colleagues who are experts in sociotechnical approaches to responsible AI, as well. Once we put it in the Office of Responsible AI, I came over. I came from academia. I was a researcher myself …</p>



<p><strong>SULLIVAN:</strong> At Berkeley, right?</p>



<p><strong>KLUTTZ:</strong> At Berkeley. That&#8217;s right. Yep. Sociologist by training and a lawyer in a past life. [LAUGHTER] But that has helped sort of bridge those fields for me.</p>



<p>But Sensitive Uses, we force all of our teams when they&#8217;re envisioning their system design to think about, could the reasonably foreseeable use or <em>misuse</em> of the system that they&#8217;re developing in practice result in three really major, sort of, risk types. One is, could that deployment result in a consequential impact on someone&#8217;s legal position or life opportunity? Another category we have is, could that foreseeable use or misuse result in significant psychological or physical injury or harm? And then the third really ties in with a longstanding commitment we&#8217;ve had to human rights at Microsoft. And so could that system in it&#8217;s reasonably foreseeable use or misuse result in human rights impacts and injurious consequences to folks along different dimensions of human rights? </p>



<p>Once you decide, we have a process to reporting that project into my office, and we will triage that project, working with the product team, for example, and our Responsible AI Champs community, which are folks who are dispersed throughout the ecosystem at Microsoft and educated in our responsible AI program, and then determine, OK, is it in scope for our program? If it is, say, OK, we&#8217;re going to go along for that ride with you, and then we get into that whole sort of consulting arrangement that then culminates in this set of bespoke use-case-based requirements applying our AI principles.</p>



<p><strong>SULLIVAN:</strong> That&#8217;s super fascinating. What are some of the approaches in the governance of genome editing are you maybe seeing happening in AI governance or maybe just, like, bubbling up in conversations around it?</p>



<p><strong>KLUTTZ:</strong> Yeah, I mean, I think we&#8217;ve learned a lot from fields like genome editing that Professor Charo talked about and others. And again, it gets back to this, sort of, risk-proportionate-based approach. It&#8217;s a balancing test. It&#8217;s a tradeoff of trying to, sort of, foster innovation and really look for the beneficial uses of these technologies. I appreciated her speaking about that. What are the intended uses of the system, right? And then getting to, OK, how do we balance trying to, again, foster that innovation in a very fast-moving space, a pretty complex space, and a very unsettled space contrasting to other, sort of, professional fields or technological fields that have a long history and are relatively settled from an oversight and regulatory standpoint? This one is <em>not</em>, and for good reason. It is still developing.</p>



<p>And I think, you know, there are certain oversight and policy regimes that exist today that can be applied. Professor Charo talked about this, as well, where, you know, maybe you have certain policy and oversight regimes that, depending on how the application of that technology is applied, applies there versus some horizontal, overarching regulatory sort of framework. And I think that applies from an internal governance standpoint, as well.</p>



<p><strong>SULLIVAN:</strong> Yeah. It&#8217;s a great point. So what isn&#8217;t being explored from genome editing that, you know, maybe we think could be useful to AI governance, or as we think about the evolving frameworks …</p>



<p><strong>KLUTTZ:</strong> Yeah.</p>



<p><strong>SULLIVAN:</strong> … what maybe we should be taking into account from what Professor Charo shared with us?</p>



<p><strong>KLUTTZ:</strong> So one of the things I&#8217;ve thought about and took from Professor Charo’s discussion was she had just this amazing way of framing up how genome editing regulation is done. And she said, you know, we don&#8217;t regulate genome editing; we regulate the things that <em>use</em> genome editing. And while it&#8217;s not a one-to-one analogy with the AI space because we do have this sort of very general model level distinction versus application layer and even platform layer distinctions, I think it&#8217;s fair to say, you know, we don&#8217;t regulate AI applications writ large. We regulate the things that use AI in a very similar way. And that&#8217;s how we think of our internal policy and oversight process at Microsoft, as well.</p>



<p>And maybe there are things that we regulated and oversaw internally at the first instance and the first time we saw it come through, and it graduates into more of a programmatic framework for how we manage that. So one good example of that is some of our higher-risk AI systems that we offer out of Azure at the platform level. When I say that, I mean APIs that you call that developers can then build their own applications on top of. We were really deep in evaluating and assessing mitigations on those platform systems in the first instance, but we also graduated them into what we call our Limited Access AI services program.</p>



<p>And some of the things that Professor Charo discussed really resonated with me. You know, she had this moment where she was mentioning how, you know, you want to know who&#8217;s using your tools and how they&#8217;re being used. And it&#8217;s the same concepts. We want to have trust in our customers, we want to understand their use cases, and we want to apply technical controls that, sort of, force those use cases or give us signal post-deployment that use cases are being done in a way that may give us some level of concern, to reach out and understand what those use cases are.</p>



<p><strong>SULLIVAN:</strong> Yeah, you&#8217;re hitting on a great point. And I love this kind of layered approach that we&#8217;re taking and that Alta highlighted, as well. Maybe to double-click a little bit just on that post-market control and what we&#8217;re tracking, kind of, once things are out and being used by our customers. How do we take some of that deployment data and bring it back in to maybe even better inform upfront governance or just how we think about some of the frameworks that we&#8217;re operating in?</p>



<p><strong>KLUTTZ:</strong> It&#8217;s a great question. The number one thing is for us at Microsoft, we want to know the voice of our customer. We want our customers to talk to us. We don&#8217;t want to just understand telemetry and data. But it&#8217;s really getting out there and understanding from our customers and not <em>just</em> our customers. I would say our <em>stakeholders</em> is maybe a better term because that includes civil society organizations. It includes governments. It includes all of these non, sort of, customer actors that we care about and that we&#8217;re trying to sort of optimize for, as well. It includes end users of our enterprise customers. If we can gather data about how our products are being used and trying to understand maybe areas that we didn&#8217;t foresee how customers or users might be using those things, and then we can tune those systems to better align with what both customers and users want but also our own AI principles and policies and programs.</p>



<p><strong>SULLIVAN:</strong> Daniel, before coming to Microsoft, you led social science research and sociotechnical applications of AI-driven tech at Berkeley. What do you think some of the biggest challenges are in defining and maybe even just, kind of, measuring at, like, a societal level some of the impacts of AI more broadly?</p>



<p><strong>KLUTTZ:</strong> Measuring social phenomenon is a difficult thing. And one of the things that, as social scientists, you&#8217;re very interested in is scientifically observing and measuring social phenomena. Well, that sounds great. It sounds also very high level and jargony. What do we mean by that? You know, it&#8217;s very easy to say that you&#8217;re collecting data and you&#8217;re measuring, I don&#8217;t know, trust in AI, right? That&#8217;s a very fuzzy concept.</p>



<p><strong>SULLIVAN:</strong> Right. Definitely.</p>



<p><strong>KLUTTZ:</strong> It is a concept that we want to get to, but we have to unpack that, and we have to develop what we call <em>measurable constructs</em>. What are the things that we might observe that could give us an indication toward what is a very fuzzy and general concept. And there&#8217;s challenges with that everywhere. And I&#8217;m extremely fortunate to work at Microsoft with some of the world&#8217;s leading sociotechnical researchers and some of these folks who are thinking about—you know, very steeped in measurement theory, literally PhDs in these fields—how to both measure <em>and</em> allow for a scalable way to do that at a place the size of Microsoft. And that is trying to develop frameworks that are scalable and repeatable and put into our platform that then serves our product teams. Are we providing, as a platform, a service to those product teams that they can plug in and do their automated evaluations at scale as much as possible and then go back in over the top and do some of your more qualitative targeted testing and evaluations.</p>



<p><strong>SULLIVAN:</strong> Yeah, makes a lot of sense. Before we close out, if you&#8217;re game for it, maybe we do a quick lightning round. Just 30-second answers here. Favorite real-world sensitive use case you&#8217;ve ever reviewed.</p>



<p><strong>KLUTTZ:</strong> Oh gosh. Wow, this is where I get to be the social scientist.</p>



<p><strong>SULLIVAN:</strong> [LAUGHS] Yes.</p>



<p><strong>KLUTTZ: </strong>It’s like, define <em>favorite</em>, Kathleen. [LAUGHS] Most <em>memorable</em>, most <em>painful</em>.</p>



<p><strong>SULLIVAN:</strong> Let&#8217;s do most memorable.</p>



<p><strong>KLUTTZ:</strong> We’ll do most memorable.</p>



<p><strong>SULLIVAN:</strong> Yeah.</p>



<p><strong>KLUTTZ:</strong> You know, I would say the most memorable project I worked on was when we rolled out the new Bing Chat, which is no longer called Bing Chat, because that was the first really big cross-company effort to deploy GPT-4, which was, you know, the next step up in AI innovation from our partners at OpenAI. And I really value working hand in hand with engineering teams and with researchers and that was us at our best and really sort of turbocharged the model that we have.<s></s></p>



<p><strong>SULLIVAN:</strong> Wonderful. What&#8217;s one of the most overused phrases that you have in your AI governance meetings?</p>



<p><strong>KLUTTZ:</strong> Gosh. [LAUGHS] If I hear “We need to get aligned; we need to align on this more” …</p>



<p><strong>SULLIVAN:</strong> [LAUGHS] Right.</p>



<p><strong>KLUTTZ:</strong> But, you know, it&#8217;s said for a reason. And I think it sort of speaks to that clever nature. That&#8217;s one that comes to mind.</p>



<p><strong>SULLIVAN:</strong> That&#8217;s great. And then maybe, maybe last one. What are you most excited about in the next, I don&#8217;t know, let&#8217;s say three months? This world is moving so fast!</p>



<p><strong>KLUTTZ:</strong> You know, the pace of innovation, as you just said, is just staggering. It is unbelievable. And sometimes it can feel overwhelming in my space. But what I am most excited about is how we are building up this Emerging … I mentioned this Emerging Technologies program in my team as a, sort of, formal program is relatively new. And I really enjoy being able to take a step back and think a little bit more about the future and a little bit more holistically. And I love working with engineering teams and sort of strategic visionaries who are thinking about what we&#8217;re doing a year from now or five years from now, or even 10 years from now, and I get to be a part of those conversations. And that really gives me energy and helps me … helps keep me grounded and not just dealing with the day to day, and, you know, various fire drills that you may run. It&#8217;s thinking strategically and having that foresight about what&#8217;s to come. And it&#8217;s exciting.</p>



<p><strong>SULLIVAN:</strong> Great. Well, Daniel, just thanks so much for being here. I had such a wonderful discussion with you, and I think the thoughtfulness in our discussion today I hope resonates with our listeners. And again, thanks to Alta for setting the stage and sharing her really amazing, insightful thoughts here, as well. So thank you.</p>



<p>[MUSIC]</p>



<p><strong>KLUTTZ:</strong> Thank you, Kathleen. I appreciate it. It&#8217;s been fun.</p>



<p><strong>SULLIVAN: </strong>And to our listeners, thanks for tuning in. You can find resources related to this podcast in the show notes. And if you want to learn more about how Microsoft approaches AI governance, you can visit microsoft.com/RAI.</p>



<p>See you next time!&nbsp;</p>



<p>[MUSIC FADES]</p>

				</span>
			</div>
			<button
				class="action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle"
				aria-expanded="false"
				data-show-less-text="Show less"
				type="button"
				aria-controls="show-more-show-less-toggle-7"
				aria-label="Show more content"
				data-alternate-aria-label="Show less content">
				Show more			</button>
		</div>
	</div>
</div>



<div class="wp-block-buttons is-layout-flex wp-block-buttons-is-layout-flex">
<div class="wp-block-button is-style-outline is-style-outline--8"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/story/ai-testing-and-evaluation-learnings-from-science-and-industry/">AI Testing and Evaluation podcast series</a></div>
</div>
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-genome-editing/">AI Testing and Evaluation: Learnings from genome editing</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>PadChest-GR: A bilingual grounded radiology reporting benchmark for chest X-rays</title>
		<link>https://www.microsoft.com/en-us/research/blog/padchest-gr-a-bilingual-grounded-radiology-reporting-benchmark-for-chest-x-rays/</link>
		
		<dc:creator><![CDATA[Daniel Coelho de Castro, Javier Alvarez-Valle]]></dc:creator>
		<pubDate>Thu, 26 Jun 2025 16:08:25 +0000</pubDate>
				<category><![CDATA[Research Blog]]></category>
		<guid isPermaLink="false">https://www.microsoft.com/en-us/research/?p=1142540</guid>

					<description><![CDATA[<p>The world’s first multimodal, bilingual radiology dataset could reshape the way radiologists and AI systems make sense of X-rays. PadChest-GR, developed by the University of Alicante with Microsoft Research, has the potential to advance research across the field for years to come.</p>
<p>The post <a href="https://www.microsoft.com/en-us/research/blog/padchest-gr-a-bilingual-grounded-radiology-reporting-benchmark-for-chest-x-rays/">PadChest-GR: A bilingual grounded radiology reporting benchmark for chest X-rays</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/PadChest-BlogHeroFeature-1400x788-1.jpg" alt="Alt text: The image features three white icons on a gradient background transitioning from blue on the left to green on the right. The first icon, located on the left, resembles an X-ray of a ribcage enclosed in a square with rounded corners. The middle icon depicts a hierarchical structure with one circle at the top connected by lines to two smaller circles below it. The third icon, positioned on the right, shows the letters "N" and "A" separated by a diagonal line, with a tilde (~) above the "N"." class="wp-image-1142658" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/PadChest-BlogHeroFeature-1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/PadChest-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/PadChest-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/PadChest-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/PadChest-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/PadChest-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/PadChest-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/PadChest-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/PadChest-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/PadChest-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w" sizes="auto, (max-width: 1400px) 100vw, 1400px" /></figure>



<p>In our ever-evolving journey to enhance healthcare through technology, we’re announcing a unique new benchmark for grounded radiology report generation—<strong><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://ai.nejm.org/doi/full/10.1056/AIdbp2401120" target="_blank" rel="noreferrer noopener">PadChest-GR<span class="sr-only"> (opens in new tab)</span></a></strong>. The world’s first multimodal, bilingual sentence-level radiology report dataset, developed&nbsp;by the University of Alicante with Microsoft Research, University Hospital Sant Joan d’Alacant and MedBravo, is set to redefine how AI and radiologists interpret radiological images. Our work demonstrates how collaboration between humans and AI can create powerful feedback loops—where new datasets drive better AI models, and those models, in turn, inspire richer datasets. We&#8217;re excited to share this progress in NEJM AI, highlighting both the clinical relevance and research excellence of this initiative.&nbsp;</p>



<h2 class="wp-block-heading" id="a-new-frontier-in-radiology-report-generation">A new frontier in radiology report generation&nbsp;</h2>



<p>It is estimated that over half of people visiting hospitals have radiology scans that must be interpreted by a clinical professional. Traditional radiology reports often condense multiple findings into unstructured narratives. In contrast, grounded radiology reporting demands that each finding be described and localized individually.</p>



<p>This can mitigate the risk of AI fabrications and enable new interactive capabilities that enhance clinical and patient interpretability. PadChest-GR is the first bilingual dataset to address this need with 4,555 chest X-ray studies complete with Spanish and English sentence-level descriptions and precise spatial (bounding box) annotations for both positive and negative findings. It is the first public benchmark that enables us to evaluate generation of fully grounded radiology reports in chest X-rays.&nbsp;</p>



<figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1516" height="781" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/grounded_report_example.png" alt="Figure 1: A chest X-ray overlaid with numbered bounding boxes, next to a matching list of structured radiological findings in Spanish and English. " class="wp-image-1142582" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/grounded_report_example.png 1516w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/grounded_report_example-300x155.png 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/grounded_report_example-1024x528.png 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/grounded_report_example-768x396.png 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/grounded_report_example-240x124.png 240w" sizes="auto, (max-width: 1516px) 100vw, 1516px" /><figcaption class="wp-element-caption">Figure 1. Example of a grounded report from PadChest-GR. The original free-text report in Spanish was <em>”Motivo de consulta: Preoperatorio. Rx PA tórax: Impresión diagnóstica: Ateromatosis aórtica calcificada. Engrosamiento pleural biapical. Atelectasia laminar basal izquierda. Elongación aórtica. Sin otros hallazgos radiológicos significativos.”</em></figcaption></figure>



<p>This benchmark isn’t standing alone—it plays a critical role in powering our state-of-the-art multimodal report generation model, <strong>MAIRA-2</strong>. Leveraging the detailed annotations of PadChest-GR, MAIRA-2 represents our commitment to building more interpretable and clinically useful AI systems. You can explore our work on MAIRA-2 on our <a href="https://www.microsoft.com/en-us/research/project/project-maira/">project web page</a>, including recent user research conducted with <a href="https://www.microsoft.com/en-us/research/publication/multimodal-healthcare-ai-identifying-and-designing-clinically-relevant-vision-language-applications-for-radiology/" target="_blank" rel="noreferrer noopener">clinicians in healthcare settings</a>.</p>



<p>PadChest-GR is a testament to the power of collaboration. Aurelia Bustos at MedBravo and Antonio Pertusa at the University of Alicante published the original&nbsp;<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://bimcv.cipf.es/bimcv-projects/padchest/" target="_blank" rel="noreferrer noopener">PadChest dataset<span class="sr-only"> (opens in new tab)</span></a> in 2020,&nbsp;with the help of Jose María Salinas from Hospital San Juan de Alicante and María de la Iglesia Vayá from the Center of Excellence in Biomedical Imaging at the Ministry of Health in Valencia, Spain. We started to look at PadChest and were deeply impressed by the scale, depth, and diversity of the data.</p>



<p>As we worked more closely with the dataset, we realized the opportunity to develop this for grounded radiology reporting research and worked with the team at the University of Alicante to determine how to approach this together. Our complementary expertise was a nice fit. At Microsoft Research, our mission is to push the boundaries of medical AI through innovative, data-driven solutions. The University of Alicante, with its deep clinical expertise, provided critical insights that greatly enriched the dataset’s relevance and utility. The result of this collaboration is the PadChest-GR dataset.</p>



<p>A significant enabler of our annotation process was <strong>Centaur Labs</strong>. The team of senior and junior radiologists from the University Hospital Sant Joan d’Alacant, coordinated by Joaquin Galant,&nbsp;used this HIPAA-compliant labeling platform to&nbsp;perform rigorous study-level quality control and bounding box annotations. The annotation protocol implemented ensured that each annotation was accurate and consistent, forming the backbone of a dataset designed for the next generation of grounded radiology report generation models.&nbsp;</p>



<h2 class="wp-block-heading" id="accelerating-padchest-gr-dataset-annotation-with-ai">Accelerating PadChest-GR dataset annotation with AI&nbsp;</h2>



<p>Our approach integrates advanced large language models with comprehensive manual annotation:&nbsp;</p>



<p><strong>Data Selection & Processing:</strong> Leveraging <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://azure.microsoft.com/en-us/products/ai-services/openai-service" target="_blank" rel="noreferrer noopener">Microsoft Azure OpenAI Service<span class="sr-only"> (opens in new tab)</span></a> with GPT-4, we extracted sentences describing individual positive and negative findings from raw radiology reports, translated them from Spanish to English, and linked each sentence to the existing expert labels from PadChest. This was done for a selected subset of the full PadChest dataset, carefully curated to reflect a realistic distribution of clinically relevant findings.&nbsp;</p>



<p><strong>Manual Quality Control & Annotation:</strong> The processed studies underwent meticulous quality checks on the Centaur Labs platform by radiologist from Hospital San Juan de Alicante. Each positive finding was then annotated with bounding boxes to capture critical spatial information.&nbsp;</p>



<p><strong>Standardization & Integration:</strong> All annotations were harmonized into coherent grounded reports, preserving the structure and context of the original findings while enhancing interpretability.&nbsp;</p>



<figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1752" height="790" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/dataflow.png" alt="Figure 2: A detailed block diagram illustrating the flow of data between various stages of AI processing and manual annotation. " class="wp-image-1142586" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/dataflow.png 1752w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/dataflow-300x135.png 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/dataflow-1024x462.png 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/dataflow-768x346.png 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/dataflow-1536x693.png 1536w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/dataflow-240x108.png 240w" sizes="auto, (max-width: 1752px) 100vw, 1752px" /><figcaption class="wp-element-caption">Figure 2. Overview of the data curation pipeline.</figcaption></figure>



<h2 class="wp-block-heading" id="impact-and-future-directions">Impact and future directions&nbsp;</h2>



<p>PadChest-GR not only sets a new benchmark for grounded radiology reporting, but also serves as the foundation for our MAIRA-2 model, which already showcases the potential of highly interpretable <a href="https://www.microsoft.com/en-us/industry/blog/healthcare/2025/05/19/developing-next-generation-cancer-care-management-with-multi-agent-orchestration/" target="_blank" rel="noreferrer noopener">AI in clinical settings</a>. While we developed PadChest-GR to help train and validate our own models, we believe the research community will greatly benefit from this dataset for many years to come. We look forward to seeing the broader research community build on this—improving grounded reporting AI models and using PadChest-GR as a standard for evaluation. We believe that by fostering open collaboration and sharing our resources, we can accelerate progress in medical imaging AI and ultimately improve patient care together with the community.</p>



<p>The collaboration between Microsoft Research and the University of Alicante highlights the transformative power of working together across disciplines. With our publication in NEJM-AI and the integral role of PadChest-GR in the development of <a href="https://www.microsoft.com/en-us/research/publication/maira-2-grounded-radiology-report-generation/" target="_blank" rel="noreferrer noopener">MAIRA-2<span class="sr-only"> (opens in new tab)</span></a> and <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://github.com/microsoft/radfact" target="_blank" rel="noreferrer noopener">RadFact<span class="sr-only"> (opens in new tab)</span></a>, we are excited about the future of AI-empowered radiology. We invite researchers and industry experts to explore PadChest-GR and MAIRA-2, contribute innovative ideas, and join us in advancing the field of grounded radiology reporting.&nbsp;</p>



<p>Papers already using PadChest-GR:</p>



<ul class="wp-block-list">
<li><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" target="_blank" href="https://nam06.safelinks.protection.outlook.com/?url=https%3A%2F%2Farxiv.org%2Fabs%2F2406.04449&data=05%7C02%7Cv-ammelfi%40microsoft.com%7C3a510e2a628c41f431e608ddb23acd37%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C638862687830178131%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&sdata=BI0coh1EYtLPEme8ygYDgaY8OLiLxA7kJj0dj3KXvNM%3D&reserved=0">[2406.04449] MAIRA-2: Grounded Radiology Report Generation<span class="sr-only"> (opens in new tab)</span></a></li>



<li><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" target="_blank" href="https://nam06.safelinks.protection.outlook.com/?url=https%3A%2F%2Farxiv.org%2Fabs%2F2502.03333&data=05%7C02%7Cv-ammelfi%40microsoft.com%7C3a510e2a628c41f431e608ddb23acd37%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C638862687830198918%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&sdata=udnptjC4kQA22qIDmTCwoSJI4ol%2Fp95%2FOsidJdZ4CWc%3D&reserved=0">RadVLM: A Multitask Conversational Vision-Language Model for Radiology<span class="sr-only"> (opens in new tab)</span></a></li>



<li><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" target="_blank" href="https://nam06.safelinks.protection.outlook.com/?url=https%3A%2F%2Farxiv.org%2Fabs%2F2503.03278&data=05%7C02%7Cv-ammelfi%40microsoft.com%7C3a510e2a628c41f431e608ddb23acd37%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C638862687830212221%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&sdata=taRcdqfs7Dis0FxmUDJDAr7DGmggLDyf9et2pYu0mm8%3D&reserved=0">Enhancing Abnormality Grounding for Vision Language Models with Knowledge Descriptions<span class="sr-only"> (opens in new tab)</span></a></li>



<li><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" target="_blank" href="https://nam06.safelinks.protection.outlook.com/?url=https%3A%2F%2Fopenreview.net%2Fforum%3Fid%3D0Jn1d4gYRS&data=05%7C02%7Cv-ammelfi%40microsoft.com%7C3a510e2a628c41f431e608ddb23acd37%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C638862687830225142%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&sdata=QcvL%2FgUDBqxkr5Zxtx9PwSLZsYwEKWdoGaC9LHKxr7Q%3D&reserved=0">Visual Prompt Engineering for Vision Language Models in Radiology<span class="sr-only"> (opens in new tab)</span></a></li>
</ul>



<p>For further details or to download PadChest-GR, please visit the <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://bimcv.cipf.es/bimcv-projects/padchest-gr/" target="_blank" rel="noreferrer noopener">BIMCV PadChest-GR Project<span class="sr-only"> (opens in new tab)</span></a>.&nbsp;</p>



<p>Models in the Azure Foundry that can do Grounded Reporting:&nbsp;</p>



<ul class="wp-block-list">
<li><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" target="_blank" href="https://nam06.safelinks.protection.outlook.com/?url=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fazure%2Fai-foundry%2Fhow-to%2Fhealthcare-ai%2Fdeploy-cxrreportgen&data=05%7C02%7Cv-ammelfi%40microsoft.com%7C3a510e2a628c41f431e608ddb23acd37%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C638862687830239988%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&sdata=dvRiCJL5l9vOk89pdPgmjPBVOtiHIzK5DZ7uhGbRk0Q%3D&reserved=0">How to deploy and use CXRReportGen healthcare AI model with Azure AI Foundry &#8211; Azure AI Foundry | Microsoft Learn<span class="sr-only"> (opens in new tab)</span></a></li>



<li><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" target="_blank" href="https://nam06.safelinks.protection.outlook.com/?url=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fazure%2Fhealth-bot%2Fcopilot%2Forchestrator&data=05%7C02%7Cv-ammelfi%40microsoft.com%7C3a510e2a628c41f431e608ddb23acd37%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C638862687830255286%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&sdata=t3r8%2BHHR1KvoLZi4YnI44DYT855MbYZisNc4f5f1OTg%3D&reserved=0">Healthcare Orchestrator &#8211; Healthcare agent service | Microsoft Learn<span class="sr-only"> (opens in new tab)</span></a></li>
</ul>



<h2 class="wp-block-heading" id="acknowledgement">Acknowledgement</h2>



<ul class="wp-block-list">
<li>Authors: <a href="https://www.microsoft.com/en-us/research/people/dacoelh/">Daniel C. Castro<span class="sr-only"> (opens in new tab)</span></a>, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://arxiv.org/search/cs?searchtype=author&query=Bustos,+A" target="_blank" rel="noreferrer noopener">Aurelia Bustos<span class="sr-only"> (opens in new tab)</span></a>, <a href="https://www.microsoft.com/en-us/research/people/shbannur/">Shruthi Bannur<span class="sr-only"> (opens in new tab)</span></a>, <a href="https://www.microsoft.com/en-us/research/people/sthyland/">Stephanie L. Hyland<span class="sr-only"> (opens in new tab)</span></a>, <a href="https://www.microsoft.com/en-us/research/people/kenzabouzid/">Kenza Bouzid<span class="sr-only"> (opens in new tab)</span></a>, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://arxiv.org/search/cs?searchtype=author&query=Wetscherek,+M+T" target="_blank" rel="noreferrer noopener">Maria Teodora Wetscherek<span class="sr-only"> (opens in new tab)</span></a>, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://arxiv.org/search/cs?searchtype=author&query=S%C3%A1nchez-Valverde,+M+D" target="_blank" rel="noreferrer noopener">Maria Dolores Sánchez-Valverde<span class="sr-only"> (opens in new tab)</span></a>, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://arxiv.org/search/cs?searchtype=author&query=Jaques-P%C3%A9rez,+L" target="_blank" rel="noreferrer noopener">Lara Jaques-Pérez<span class="sr-only"> (opens in new tab)</span></a>, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://arxiv.org/search/cs?searchtype=author&query=P%C3%A9rez-Rodr%C3%ADguez,+L" target="_blank" rel="noreferrer noopener">Lourdes Pérez-Rodríguez<span class="sr-only"> (opens in new tab)</span></a>, <a href="https://www.microsoft.com/en-us/research/people/kenjitak/" target="_blank" rel="noreferrer noopener">Kenji Takeda<span class="sr-only"> (opens in new tab)</span></a>, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://arxiv.org/search/cs?searchtype=author&query=Salinas,+J+M" target="_blank" rel="noreferrer noopener">José María Salinas<span class="sr-only"> (opens in new tab)</span></a>, <a href="https://www.microsoft.com/en-us/research/people/jaalvare/">Javier Alvarez-Valle<span class="sr-only"> (opens in new tab)</span></a>, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://arxiv.org/search/cs?searchtype=author&query=Herrero,+J+G" target="_blank" rel="noreferrer noopener">Joaquín Galant Herrero<span class="sr-only"> (opens in new tab)</span></a>, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://arxiv.org/search/cs?searchtype=author&query=Pertusa,+A" target="_blank" rel="noreferrer noopener">Antonio Pertusa<span class="sr-only"> (opens in new tab)</span></a>&nbsp;</li>
</ul>



<ul class="wp-block-list">
<li>MSR Health Futures UK: <a href="https://www.microsoft.com/en-us/research/people/hamurfet/">Hannah Richardson</a>, <a href="https://www.microsoft.com/en-us/research/people/vsalvatelli/">Valentina Salvatelli</a>, <a href="https://www.microsoft.com/en-us/research/people/harssharma/">Harshita Sharma</a>, <a href="https://www.microsoft.com/en-us/research/people/sbondtaylor/">Sam Bond-Taylor</a>, <a href="https://www.microsoft.com/en-us/research/people/maxilse/">Max Ilse</a>, <a href="https://www.microsoft.com/en-us/research/people/fperezgarcia/">Fernando Perez-Garcia</a>, <a href="https://www.microsoft.com/en-us/research/people/antonsc/">Anton Schwaighofer</a>, <a href="https://www.microsoft.com/en-us/research/people/carlson/">Jonathan Carlson</a> </li>
</ul>



<ul class="wp-block-list">
<li>MSR Flow: <a href="https://www.microsoft.com/en-us/research/people/kenjitak/">Kenji Takeda</a>, <a href="https://www.microsoft.com/en-us/research/people/evelynev/">Evelyn Viegas</a>, <a href="https://www.microsoft.com/en-us/research/people/allorens/">Ashley Llorens</a></li>
</ul>



<ul class="wp-block-list">
<li>HLS: <a href="https://www.microsoft.com/en-us/research/people/mlungren/">Matthew Lungren</a>, <a href="https://www.microsoft.com/en-us/research/people/naiteeks/">Naiteek Sangani</a>, <a href="https://www.microsoft.com/en-us/research/people/shreyjain/">Shrey Jain</a>, <a href="https://www.microsoft.com/en-us/research/people/itarapov/">Ivan Tarapov</a>, <a href="https://www.microsoft.com/en-us/research/people/wguyman/">Will Guyman</a>, Mert Oez, Chris Burt, David Ardman</li>
</ul>
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/blog/padchest-gr-a-bilingual-grounded-radiology-reporting-benchmark-for-chest-x-rays/">PadChest-GR: A bilingual grounded radiology reporting benchmark for chest X-rays</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>AI Testing and Evaluation: Learnings from Science and Industry</title>
		<link>https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-science-and-industry/</link>
		
		<dc:creator><![CDATA[Kathleen Sullivan, Amanda Craig Deckard]]></dc:creator>
		<pubDate>Mon, 23 Jun 2025 16:38:09 +0000</pubDate>
				<category><![CDATA[Microsoft Research Podcast]]></category>
		<guid isPermaLink="false"></guid>

					<description><![CDATA[<p>In the introductory episode of this new series, host Kathleen Sullivan and Senior Director Amanda Craig Deckard explore Microsoft’s efforts to draw on the experience of other domains to help advance the role of AI testing and evaluation as a governance tool.</p>
<p>The post <a href="https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-science-and-industry/">AI Testing and Evaluation: Learnings from Science and Industry</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP0-AI-TE_Hero_Feature_1400x788.jpg" alt="Illustrated headshots of Amanda Craig Deckard & Kathleen Sullivan." class="wp-image-1141309" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP0-AI-TE_Hero_Feature_1400x788.jpg 1400w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP0-AI-TE_Hero_Feature_1400x788-300x169.jpg 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP0-AI-TE_Hero_Feature_1400x788-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP0-AI-TE_Hero_Feature_1400x788-768x432.jpg 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP0-AI-TE_Hero_Feature_1400x788-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP0-AI-TE_Hero_Feature_1400x788-655x368.jpg 655w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP0-AI-TE_Hero_Feature_1400x788-240x135.jpg 240w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP0-AI-TE_Hero_Feature_1400x788-640x360.jpg 640w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP0-AI-TE_Hero_Feature_1400x788-960x540.jpg 960w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP0-AI-TE_Hero_Feature_1400x788-1280x720.jpg 1280w" sizes="auto, (max-width: 1400px) 100vw, 1400px" /></figure>


<div class="wp-block-msr-podcast-container my-4">
	<iframe loading="lazy" src="https://player.blubrry.com/?podcast_id=146460793&modern=1" class="podcast-player" frameborder="0" height="164px" width="100%" scrolling="no" title="Podcast Player"></iframe>
</div>



<p>Generative AI presents a unique challenge and opportunity to reexamine governance practices for the responsible development, deployment, and use of AI. To advance thinking in this space, Microsoft has tapped into the experience and knowledge of experts across domains—from genome editing to cybersecurity—to investigate the role of testing and evaluation as a governance tool. <em><a href="https://www.microsoft.com/en-us/research/story/ai-testing-and-evaluation-learnings-from-science-and-industry/">AI Testing and Evaluation: Learnings from Science and Industry</a>, </em>hosted by Microsoft Research’s <a href="https://www.microsoft.com/en-us/research/people/kasull/">Kathleen Sullivan</a>, explores what the technology industry and policymakers can learn from these fields and how that might help shape the course of AI development.</p>



<p>In this episode, <a href="https://www.microsoft.com/en-us/research/people/amcraig/">Amanda Craig Deckard</a>, senior director of public policy in Microsoft&#8217;s Office of Responsible AI, joins Sullivan to detail the company’s efforts to help inform AI governance discussions and decisions, including, more recently, around the role of AI testing and evaluation. Craig Deckard and Sullivan delve into the tension that exists between the risk and opportunity of technology, the similarities and differences between AI development and the fields Microsoft is studying, and the role of different stakeholders in advancing AI governance and public policy.</p>



<div class="wp-block-group msr-pattern-link-list is-layout-flow wp-block-group-is-layout-flow">
<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2 class="wp-block-heading h5" id="learn-more-1">Learn more:</h2>



<ul class="wp-block-list list-unstyled">
<li><a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" target="_blank" href="https://cdn-dynmedia-1.microsoft.com/is/content/microsoftcorp/microsoft/msc/documents/presentations/CSR/Global-Governance-Book-DIGITAL.pdf">Global Governance: Goals and Lessons for AI<span class="sr-only"> (opens in new tab)</span></a><br>E-book | May 2024</li>



<li><a href="https://www.microsoft.com/en-us/research/blog/learning-from-other-domains-to-advance-ai-evaluation-and-testing/">Learning from other domains to advance AI evaluation and testing</a><br>Microsoft Research Blog | June 2025</li>



<li><a href="https://www.microsoft.com/en-us/ai/responsible-ai?ef_id=_k_cb05d5950e4f117c457ebda628845b7f_k_&OCID=AIDcmm1o1fzy5i_SEM__k_cb05d5950e4f117c457ebda628845b7f_k_&msclkid=cb05d5950e4f117c457ebda628845b7f" target="_blank" rel="noreferrer noopener">Responsible AI: Ethical policies and practices | Microsoft AI</a></li>
</ul>
</div>



<p><a href="https://www.microsoft.com/en-us/research/focus-area/ai-and-microsoft-research/" target="_blank" rel="noreferrer noopener">AI and Microsoft Research</a></p>



<div style="height:25px" aria-hidden="true" class="wp-block-spacer"></div>



<section class="wp-block-msr-subscribe-to-podcast subscribe-to-podcast">
	<div class="subscribe-to-podcast__inner border-top border-bottom border-width-2">
		<h2 class="h5 subscribe-to-podcast__heading">
			Subscribe to the <a href="https://www.microsoft.com/en-us/research/podcast">Microsoft Research Podcast</a>:		</h2>
		<ul class="subscribe-to-podcast__list list-unstyled">
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://itunes.apple.com/us/podcast/microsoft-research-a-podcast/id1318021537?mt=2" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="black" viewBox="0 0 32 32">  <path d="M7.12 0c-3.937-0.011-7.131 3.183-7.12 7.12v17.76c-0.011 3.937 3.183 7.131 7.12 7.12h17.76c3.937 0.011 7.131-3.183 7.12-7.12v-17.76c0.011-3.937-3.183-7.131-7.12-7.12zM15.817 3.421c3.115 0 5.932 1.204 8.079 3.453 1.631 1.693 2.547 3.489 3.016 5.855 0.161 0.787 0.161 2.932 0.009 3.817-0.5 2.817-2.041 5.339-4.317 7.063-0.812 0.615-2.797 1.683-3.115 1.683-0.12 0-0.129-0.12-0.077-0.615 0.099-0.792 0.192-0.953 0.64-1.141 0.713-0.296 1.932-1.167 2.677-1.911 1.301-1.303 2.229-2.932 2.677-4.719 0.281-1.1 0.244-3.543-0.063-4.672-0.969-3.595-3.907-6.385-7.5-7.136-1.041-0.213-2.943-0.213-4 0-3.636 0.751-6.647 3.683-7.563 7.371-0.245 1.004-0.245 3.448 0 4.448 0.609 2.443 2.188 4.681 4.255 6.015 0.407 0.271 0.896 0.547 1.1 0.631 0.447 0.192 0.547 0.355 0.629 1.14 0.052 0.485 0.041 0.62-0.072 0.62-0.073 0-0.62-0.235-1.199-0.511l-0.052-0.041c-3.297-1.62-5.407-4.364-6.177-8.016-0.187-0.943-0.224-3.187-0.036-4.052 0.479-2.323 1.396-4.135 2.921-5.739 2.199-2.319 5.027-3.543 8.172-3.543zM16 7.172c0.541 0.005 1.068 0.052 1.473 0.14 3.715 0.828 6.344 4.543 5.833 8.229-0.203 1.489-0.713 2.709-1.619 3.844-0.448 0.573-1.537 1.532-1.729 1.532-0.032 0-0.063-0.365-0.063-0.803v-0.808l0.552-0.661c2.093-2.505 1.943-6.005-0.339-8.296-0.885-0.896-1.912-1.423-3.235-1.661-0.853-0.161-1.031-0.161-1.927-0.011-1.364 0.219-2.417 0.744-3.355 1.672-2.291 2.271-2.443 5.791-0.348 8.296l0.552 0.661v0.813c0 0.448-0.037 0.807-0.084 0.807-0.036 0-0.349-0.213-0.683-0.479l-0.047-0.016c-1.109-0.885-2.088-2.453-2.495-3.995-0.244-0.932-0.244-2.697 0.011-3.625 0.672-2.505 2.521-4.448 5.079-5.359 0.547-0.193 1.509-0.297 2.416-0.281zM15.823 11.156c0.417 0 0.828 0.084 1.131 0.24 0.645 0.339 1.183 0.989 1.385 1.677 0.62 2.104-1.609 3.948-3.631 3.005h-0.015c-0.953-0.443-1.464-1.276-1.475-2.36 0-0.979 0.541-1.828 1.484-2.328 0.297-0.156 0.709-0.235 1.125-0.235zM15.812 17.464c1.319-0.005 2.271 0.463 2.625 1.291 0.265 0.62 0.167 2.573-0.292 5.735-0.307 2.208-0.479 2.765-0.905 3.141-0.589 0.52-1.417 0.667-2.209 0.385h-0.004c-0.953-0.344-1.157-0.808-1.553-3.527-0.452-3.161-0.552-5.115-0.285-5.735 0.348-0.823 1.296-1.285 2.624-1.291z"/></svg>
						<span class="subscribe-to-podcast__link-text">Apple Podcasts</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://subscribebyemail.com/www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M6.4 6a2.392 2.392 0 00-2.372 2.119L16 15.6l11.972-7.481A2.392 2.392 0 0025.6 6H6.4zM4 10.502V22.8a2.4 2.4 0 002.4 2.4h19.2a2.4 2.4 0 002.4-2.4V10.502l-11.365 7.102a1.2 1.2 0 01-1.27 0L4 10.502z"/></svg>
						<span class="subscribe-to-podcast__link-text">Email</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://subscribeonandroid.com/www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M12.414 4.02c-.062.012-.126.023-.18.06a.489.489 0 00-.12.675L13.149 6.3c-1.6.847-2.792 2.255-3.18 3.944h13.257c-.388-1.69-1.58-3.097-3.179-3.944l1.035-1.545a.489.489 0 00-.12-.675.492.492 0 00-.675.135l-1.14 1.68a7.423 7.423 0 00-2.55-.45c-.899 0-1.758.161-2.549.45l-1.14-1.68a.482.482 0 00-.494-.195zm1.545 3.824a.72.72 0 110 1.44.72.72 0 010-1.44zm5.278 0a.719.719 0 110 1.44.719.719 0 110-1.44zM8.44 11.204A1.44 1.44 0 007 12.644v6.718c0 .795.645 1.44 1.44 1.44.168 0 .33-.036.48-.09v-9.418a1.406 1.406 0 00-.48-.09zm1.44 0V21.76c0 .793.646 1.44 1.44 1.44h10.557c.793 0 1.44-.647 1.44-1.44V11.204H9.878zm14.876 0c-.169 0-.33.035-.48.09v9.418c.15.052.311.09.48.09a1.44 1.44 0 001.44-1.44v-6.719a1.44 1.44 0 00-1.44-1.44zM11.8 24.16v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84zm5.759 0v1.92a1.92 1.92 0 003.84 0v-1.92h-3.84z"/></svg>
						<span class="subscribe-to-podcast__link-text">Android</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://open.spotify.com/show/4ndjUXyL0hH1FXHgwIiTWU" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M16 4C9.383 4 4 9.383 4 16s5.383 12 12 12 12-5.383 12-12S22.617 4 16 4zm5.08 17.394a.781.781 0 01-1.086.217c-1.29-.86-3.477-1.434-5.303-1.434-1.937.002-3.389.477-3.403.482a.782.782 0 11-.494-1.484c.068-.023 1.71-.56 3.897-.562 1.826 0 4.365.492 6.171 1.696.36.24.457.725.217 1.085zm1.56-3.202a.895.895 0 01-1.234.286c-2.338-1.457-4.742-1.766-6.812-1.747-2.338.02-4.207.466-4.239.476a.895.895 0 11-.488-1.723c.145-.041 2.01-.5 4.564-.521 2.329-.02 5.23.318 7.923 1.995.419.26.547.814.286 1.234zm1.556-3.745a1.043 1.043 0 01-1.428.371c-2.725-1.6-6.039-1.94-8.339-1.942h-.033c-2.781 0-4.923.489-4.944.494a1.044 1.044 0 01-.474-2.031c.096-.023 2.385-.55 5.418-.55h.036c2.558.004 6.264.393 9.393 2.23.497.292.663.931.371 1.428z"/></svg>
						<span class="subscribe-to-podcast__link-text">Spotify</span>
					</a>
				</li>
			
							<li class="subscribe-to-podcast__list-item">
					<a class="subscribe-to-podcast__link" href="https://www.blubrry.com/feeds/microsoftresearch.xml" target="_blank" rel="noreferrer noopener">
						<svg class="subscribe-to-podcast__svg" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 32 32"><path fill="currentColor" d="M6.667 4a2.676 2.676 0 00-2.612 2.13v.003c-.036.172-.055.35-.055.534v18.666c0 .183.019.362.055.534v.003a2.676 2.676 0 002.076 2.075h.002c.172.036.35.055.534.055h18.666A2.676 2.676 0 0028 25.333V6.667a2.676 2.676 0 00-2.13-2.612h-.003A2.623 2.623 0 0025.333 4H6.667zM8 8h1.333C17.42 8 24 14.58 24 22.667V24h-2.667v-1.333c0-6.618-5.382-12-12-12H8V8zm0 5.333h1.333c5.146 0 9.334 4.188 9.334 9.334V24H16v-1.333A6.674 6.674 0 009.333 16H8v-2.667zM10 20a2 2 0 11-.001 4.001A2 2 0 0110 20z"/></svg>
						<span class="subscribe-to-podcast__link-text">RSS Feed</span>
					</a>
				</li>
					</ul>
	</div>
</section>


<div class="wp-block-msr-show-more">
	<div class="bg-neutral-100 p-5">
		<div class="show-more-show-less" data-mount="show-more-show-less">
			<div>
				<span>
					

<h2 class="wp-block-heading" id="transcript">Transcript&nbsp;</h2>



<p>[MUSIC]&nbsp;</p>



<p><strong>KATHLEEN SULLIVAN:</strong> Welcome to <em>AI Testing and Evaluation: Learnings from Science and Industry</em>. I&#8217;m your host, Kathleen Sullivan.</p>



<p>As generative AI continues to advance, Microsoft has gathered a range of experts—from genome editing to cybersecurity—to share how their fields approach evaluation and risk assessment. Our goal is to learn from their successes and their stumbles to move the science and practice of AI testing forward. In this series, we&#8217;ll explore how these insights might help guide the future of AI development, deployment, and responsible use.</p>



<p>[MUSIC ENDS] </p>



<p>For our introductory episode, I&#8217;m pleased to welcome Amanda Craig Deckard from Microsoft to discuss the company&#8217;s efforts to learn about testing in other sectors. </p>



<p>Amanda is senior director of public policy in the Office of Responsible AI, where she leads a team that works closely with engineers, researchers, and policy experts to help ensure AI is being developed and used responsibly. Their insights shape Microsoft&#8217;s contribution to public policy discussions on laws, norms, and standards for AI. </p>



<p>Amanda, welcome to the podcast.</p>



				</span>
				<span id="show-more-show-less-toggle-9" class="show-more-show-less-toggleable-content">
					



<p><strong>AMANDA CRAIG DECKARD:</strong> Thank you. </p>



<p><strong>SULLIVAN:</strong> Amanda, let&#8217;s give the listeners a little bit of your background. What&#8217;s your origin story? Can you talk to us a little bit about maybe how you started in tech? And I would love to also learn a little bit more about what your team does in the Office of Responsible AI. </p>



<p><strong>CRAIG DECKARD:</strong> Sure. Thank you. I&#8217;d say my [LAUGHS] path to tech, to Microsoft, as well, was a bit, like, circuitous, maybe. You know, I thought for the longest time I was going to be a journalist. I studied forced migration. I worked in a sort of state level sort of trial court in Indiana, a legal service provider in India, just to give you a bit of a flavor.</p>



<p>I made my way to Microsoft in 2014 and have been here since, working in cybersecurity public policy first and now in responsible AI. And the way that our Office of Responsible AI has really, sort of, structured itself is bringing together the kind of expertise to really work on defining policy and how to operationalize it at the same time.</p>



<p>And, you know, that means that we have been working through this, you know, real challenge of defining internal policy and practice, making sure that&#8217;s deeply grounded in the work of our colleagues at Microsoft Research, and then really closely working with engineering to make sure that we have the processes, that we have the tools, to implement that policy at scale. </p>



<p>And I&#8217;m really drawn to these kind of hard problems where they have the character of two things being true or there&#8217;s like, you know, real tension on both sides and in particular, in the context of those kinds of problems, roles in which, like, the whole job is actually just sitting with that tension, not necessarily, like, resolving it and expecting that you&#8217;re done.</p>



<p>And I think, really, there are two reasons why tech is so, kind of, representative of that kind of challenge that I&#8217;ve always found fascinating. You know, one is that, of course, tech is, sort of, ubiquitous. It&#8217;s really impacting so many people&#8217;s lives. But also, you know, because, as I think has become part of our vernacular now, but, you know, is not necessarily immediately intuitive, is like the fact that technology is both a tool and a weapon. And so that&#8217;s just, like, another reason why, you know, we have to continuously work through that tension and, sort of, like, sit with it, right, and even as tech evolves over time.</p>



<p><strong>SULLIVAN:</strong> You bring up such great points, and this field is not black and white. I think that even underscores, you know, this notion that you highlighted that it&#8217;s impacting everyone. And, you know, to set the stage for our listeners, last year, we pulled in a bunch of experts from cybersecurity, biotech, finance, and we ran this large workshop to study how they&#8217;re thinking about governance in those playbooks. And so I&#8217;d love to understand a little bit more about what sparked that effort—and, you know, there&#8217;s a piece of this which is really centered around testing—and to hear from you why the focus on testing is so important.&nbsp;</p>



<p><strong>CRAIG DECKARD:</strong> If I could rewind a little bit and give you a bit of history of how we even arrived at bringing these experts together, you know, we actually started on this journey in 2023. At that time, there were, like, a lot of these big questions swirling around about, you know, what did we need in terms of governance for AI? Of course, this was in the immediate aftermath of the ChatGPT sort of wave and everyone recognizing that, like, the technology was going to have a different level of impact in the near term. And so, you know, what do we need from governance? What do we need at the global level, in particular, of governance? </p>



<p>And so at the time, in early 2023 especially, there were a lot of attempts to sort of draw analogies to other global governance institutions in other domains. So we actually in 2023 brought together a different workshop than the one that you&#8217;re referring to specifically focused on testing last year. And we, kind of, had two big takeaways from that conversation. </p>



<p>One was, what are the actual functions of these institutions and how do they apply to AI? And, actually, one of the takeaways was they all sort of apply. [LAUGHS] There&#8217;s, like, a role for, you know, any of the functions, whether it be sort of driving consensus on research or building industry standards or managing, kind of, frontier risks, for thinking about how those might be needed in the AI context. </p>



<p>And one of the other big takeaways was that, you know, there are also limitations in these analogies. You know, each of the institutions grew up in its own, sort of, unique historical moment, like the one that we sit in with AI right now. And in each of those circumstances, they don&#8217;t exactly translate to this moment. And so, yeah, there was like this kind of, OK, we want to draw what we can from this conversation and then we also want to understand, what is also very important that&#8217;s just different for AI right now? </p>



<p>We published a <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://cdn-dynmedia-1.microsoft.com/is/content/microsoftcorp/microsoft/msc/documents/presentations/CSR/Global-Governance-Book-DIGITAL.pdf" target="_blank" rel="noreferrer noopener">book with the lessons from that conversation in 2023<span class="sr-only"> (opens in new tab)</span></a>. And then we actually went on a bit of a tour [LAUGHS] with that content where we had a number of roundtables actually all over the world where we gathered feedback on how those analogies were landing, how our takeaways were landing. And one of the things that we took from them was a gap that some of the participants saw in the analogies that we chose to focus on. So across multiple conversations, other domains kept being raised, like, why did you not also study pharmaceuticals? Why did you also not study cybersecurity, for example? And so that, you know, naturally got us thinking about what further lessons we could draw from <em>those</em> domains.&nbsp;</p>



<p>At the same time, though, we also saw a need to, again, go deeper than what we went and really, like, focus on a narrower problem. So that&#8217;s really what led us to trying to think about a more specific problem where we could think across levels of governance and bring in some of these other domains. And, you know, testing was top of mind. Continues to be a really important topic in the AI policy conversation right now, I think, for really good reason. A lot of policymakers are focused on, you know, what we need to do to, kind of, have there be sufficient trust, and testing is going to be a part of that—really better understand risk, enable everyone to be able to make more, kind of, risk-informed decisions, right. Testing is an important component for governance and AI and, of course, in all of these other domains, as well. </p>



<p>So I&#8217;ll just add the other, kind of, input into the process for this second round was exploring other analogies beyond those that we, kind of, got feedback on. And one of the early, kind of, examples of another domain that would be really worthwhile to study that came to mind from, sort of, just studying the literature was genome editing. </p>



<p>You know, genome editing was really interesting through the process of thinking about other kind of general-purpose technologies. We also arrived at nanoscience and brought those into the conversation.&nbsp;</p>



<p><strong>SULLIVAN:</strong> That&#8217;s great. I mean, actually, if you could double-click,&nbsp;I mean, you just named a number of industries. I&#8217;d love to just understand which of those worlds maybe feels the closest to what we&#8217;re wrestling with, with AI and maybe which is kind of the farthest off, and what makes them stand out to you?</p>



<p><strong>CRAIG DECKARD:</strong> Oh, such a good question. For this second round, we actually brought together eight different domains, right. And I think we actually thought we would come out of this conversation with some bit of clarity around, <em>Oh, if we just, sort of, take this approach for this domain or that domain, we&#8217;ll sort of have—at least for now—really solved part of the puzzle.</em> [LAUGHS] And, you know, our public policy team the day after the workshop, we had a, sort of, follow-on discussion, and the very first thing that we started with in that conversation was like, <em>OK, so which of these domains?</em> And fascinatingly, like, everyone was sort of like, <em>Ahh! </em>[LAUGHS] <em>None of them are applying perfectly</em>. I mean, this is also speaking to the limitations of analogies that we already acknowledged. </p>



<p>And also, you know, all of the experts from across these domains gave us really interesting insights into, sort of, the tradeoffs and the limitations and how they were working. None are really applying perfectly for us. But all of them do offer a thread of insight that is really useful for thinking about testing in AI, and there are some different dimensions that I think are really useful as framing for that. </p>



<p>I mean, one is just this horizontal-versus-vertical,<strong>&nbsp;</strong>kind of, difference in domains and, you know, the horizontal technology like genome editing or nanoscience&nbsp;just being inherently different and seemingly very similar to AI in that you want to be able to understand risks in the technology itself <em>and</em> there is just so much contextual, sort of, factor that matters in the application of those technologies for how the risk manifests that you really need to, kind of, do those two things at once—of understanding the technology but then really thinking about risk and governance in the context of application versus, you know, a context like or a domain like civil aviation or nuclear technology, for example.</p>



<p>You know, even in the workshop itself that we hosted late last year, where we brought together this second round of experts, it was really interesting. We actually started the conversation by trying to understand how those different domains defined risks, where they were able to set risk thresholds. That&#8217;s been such a part of the AI policy conversation in the last year. And, you know, it was really instructive that the more vertical domains were able to, sort of, snap to clearer answers much more quickly. [LAUGHS] But, like, the horizontal nanoscience and genome editing were not because it just depends, right. So anyway, the horizontal-vertical dimension seems like a really important one to draw from and apply to AI. </p>



<p>The couple of others that I would offer is just, you know, thinking about the different kinds of technologies. You know, obviously, there&#8217;s some of the domains that we studied that they&#8217;re just inherently, sort of, like, physical technologies … a mix of physical and digital or virtual in a lot of cases because all of these are, of course, applying digital technology. But like, you know, there is just a difference between something like an <em>airplane</em> or a <em>medical device</em> or, you know, the more kind of virtual or intangible sort of technologies even, you know, of course, AI and some of the other like cyber and genome editing but also like, you know, financial services having some of that quality. And again, I think the thing that&#8217;s interesting to us about AI is to think about AI and risk evaluation of AI as being, you know, having a large component of that being about the kind of virtual or intangible technology. <em>And also</em>, you know, there is a future of robotics where we might need to think about the, kind of, physical risk evaluation kind of work, as well.</p>



<p>And then the final thing I&#8217;d maybe say in terms of thinking about which domains have the lessons for AI that are most applicable is just how they&#8217;ve grappled with these different kind of governance questions. Things like how to turn the dial in terms of being more or less prescriptive on risk evaluation approaches, how they think about the balance of, kind of, pre-market versus post-market risk evaluation in testing, and what the tradeoffs have been there across domains has been really interesting to kind of tease out. And then also thinking about, sort of, who does what?</p>



<p>So, you know, in each of these different domains, it was interesting to hear about, like, you know, the role of industry, the role of governments, the role of third-party experts in designing evaluations and developing standards and actually doing the work, and, kind of, having the pull through of what it means for risk and governance decisions. There were, again, there was a variety of, sort of, approaches across these domains that I think were interesting for AI.</p>



<p><strong>SULLIVAN:</strong> You mentioned that there&#8217;s a number of different stakeholders to be considering across the board as we&#8217;re thinking about policy, as we&#8217;re thinking about regulation. Where can we collaborate more across industry? Is it academia? Regulators? Just, how can we move the needle faster? </p>



<p><strong>CRAIG DECKARD:</strong> I think all of the above [LAUGHTER] is needed. But it&#8217;s also really important to have all of that, kind of, expertise brought together, you know, and I think, you know, one of the things that we certainly heard from multiple of the domains, if not all of them, was that same actual interest and need and the same sort of ongoing work to try to figure that out.</p>



<p>You know, even where there had been progress in some of the other domains with bringing together, you know, some industry stakeholders or, you know, industry and government, there was still a desire to actually do more there. Like, if there was some progress in industry and government, the need was, <em>And more kind of cross-jurisdiction government conversation</em>, for example. Or some progress on, you know, within the industry but needing to, like, strengthen the partnership with academia, for example. So, you know, I think it speaks to, like, the quality of your question, to be honest, that, you know, all of these domains are actually still grappling with this and still seeing the need to grow in that direction more. </p>



<p>What I&#8217;d say about AI today is that we have made good progress with, you know, starting to build some industry partnerships. You know, we were a founding member of the <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.frontiermodelforum.org/" target="_blank" rel="noreferrer noopener">Frontier Model Forum, or FMF<span class="sr-only"> (opens in new tab)</span></a>, which has been a very useful place for us to work with some peers on really trying to bring forward some best practices that apply across our organizations. You know, there are other forums as well, like <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://mlcommons.org/" target="_blank" rel="noreferrer noopener">MLCommons<span class="sr-only"> (opens in new tab)</span></a>, where we&#8217;re working with others in industry and broader, sort of, academic and civil society communities. <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://partnershiponai.org/" target="_blank" rel="noreferrer noopener">Partnership on AI<span class="sr-only"> (opens in new tab)</span></a> is another one I think about that, kind of, fits that mold, as well, in a really positive way. And, like, there are a lot of different, sort of, governance needs to think through and where, you know, we can really think about bringing that expertise together is going to be so important.</p>



<p>I think about almost, like, in the near to mid-term, like three issues that we need to address in the AI, kind of, policy and testing context. One is just building kind of, like, a flexible framework that allows us to really build trust while we continue to advance the science and the standards. You know, we are going to need to do both at once. And so we need a flexible framework that enables that kind of agility, and advancing the science and the standards, that <em>is </em>going to be something that really demands that kind of cross-discipline or cross kind of expertise group coming together to work on that—researchers, academics, civil society, governments and, of course, industry.</p>



<p>And so I think that is, actually, the second problem is, like, how do we actually build the kind of forums and ways of working together, the public-private partnership kind of efforts that allow all of that expertise to come together and fit together over time, right. Because when these are really big, broad challenges, you kind of have to break them down incrementally, make progress on them, and then bring them back together. </p>



<p>And so I think about, like, one example that I, you know, really have been reflecting on lately is, you know, in the context of building standards, like, how do you do that, right? Again, standards are going to benefit from that whole community of expertise. And, you know, there are lots of different kinds of quote-unquote standards, though, right. You kind of have the “small <em>s</em>” industry standards. You have the kind of “big <em>S</em>” international standards, for example. And how do you, kind of, leverage one to accelerate the other, I think, is part of, like, how we need to work together within this ecosystem. And, like, I think what we and others have done in an organization like <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://c2pa.org/" target="_blank" rel="noreferrer noopener">C2PA [Coalition for Content Provenance and Authenticity]<span class="sr-only"> (opens in new tab)</span></a>, for example, where we&#8217;ve really built an industry specification but then built on that towards an international standard effort is one example that is interesting, right, to point to.</p>



<p>And then, you know, I actually think that bridges to the third thing that we need to do together within this whole community, which is, you know, really think again about how we manage the breadth of this challenge and opportunity of AI by thinking about this horizontal-vertical problem. And, you know, I think that&#8217;s where it&#8217;s not just the sort of tech industry, for example. It&#8217;s broader industry that&#8217;s going to be really applying this technology that needs to get involved in the conversation about not just, sort of, testing AI models, for example, but also testing how AI systems or applications are working in context. And so, yes, so much fun opportunity!&nbsp;</p>



<p>[MUSIC]&nbsp;</p>



<p><strong>SULLIVAN:</strong> Amanda, this was just fantastic. You&#8217;ve really set the stage for this podcast. And thank you so much for sharing your time and wisdom with us. </p>



<p><strong>CRAIG DECKARD:</strong> Thank you.&nbsp;</p>



<p><strong>SULLIVAN:</strong> And to our listeners, we&#8217;re so glad you joined us for this conversation. An exciting lineup of episodes are on the way, and we can&#8217;t wait to have you back for the next one. </p>



<p>[MUSIC FADES]&nbsp;</p>

				</span>
			</div>
			<button
				class="action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle"
				aria-expanded="false"
				data-show-less-text="Show less"
				type="button"
				aria-controls="show-more-show-less-toggle-9"
				aria-label="Show more content"
				data-alternate-aria-label="Show less content">
				Show more			</button>
		</div>
	</div>
</div>



<div class="wp-block-buttons is-layout-flex wp-block-buttons-is-layout-flex">
<div class="wp-block-button is-style-outline is-style-outline--10"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/story/ai-testing-and-evaluation-learnings-from-science-and-industry/">AI Testing and Evaluation podcast series</a></div>
</div>
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-science-and-industry/">AI Testing and Evaluation: Learnings from Science and Industry</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Learning from other domains to advance AI evaluation and testing</title>
		<link>https://www.microsoft.com/en-us/research/blog/learning-from-other-domains-to-advance-ai-evaluation-and-testing/</link>
		
		<dc:creator><![CDATA[Amanda Craig Deckard, Chad Atalla]]></dc:creator>
		<pubDate>Mon, 23 Jun 2025 16:35:06 +0000</pubDate>
				<category><![CDATA[Research Blog]]></category>
		<guid isPermaLink="false">https://www.microsoft.com/en-us/research/?p=1142208</guid>

					<description><![CDATA[<p>As generative AI becomes more capable and widely deployed, familiar questions from the governance of other transformative technologies have resurfaced. Which opportunities, capabilities, risks, and impacts should be evaluated? Who should conduct evaluations, and at what stages of the technology lifecycle? What tests or measurements should be used? And how can we know if the [&#8230;]</p>
<p>The post <a href="https://www.microsoft.com/en-us/research/blog/learning-from-other-domains-to-advance-ai-evaluation-and-testing/">Learning from other domains to advance AI evaluation and testing</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/RAI-BlogHeroFeature-1400x788-2.jpg" alt="Illustrated headshots of the Guests from the limited podcast series, AI Testing and Evaluation: Learnings from Science and Industry" class="wp-image-1143007" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/RAI-BlogHeroFeature-1400x788-2.jpg 1400w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/RAI-BlogHeroFeature-1400x788-2-300x169.jpg 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/RAI-BlogHeroFeature-1400x788-2-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/RAI-BlogHeroFeature-1400x788-2-768x432.jpg 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/RAI-BlogHeroFeature-1400x788-2-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/RAI-BlogHeroFeature-1400x788-2-655x368.jpg 655w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/RAI-BlogHeroFeature-1400x788-2-240x135.jpg 240w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/RAI-BlogHeroFeature-1400x788-2-640x360.jpg 640w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/RAI-BlogHeroFeature-1400x788-2-960x540.jpg 960w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/RAI-BlogHeroFeature-1400x788-2-1280x720.jpg 1280w" sizes="auto, (max-width: 1400px) 100vw, 1400px" /></figure>



<p>As generative AI becomes more capable and widely deployed, familiar questions from the governance of other transformative technologies have resurfaced. Which opportunities, capabilities, risks, and impacts should be evaluated? Who should conduct evaluations, and at what stages of the technology lifecycle? What tests or measurements should be used? And how can we know if the results are reliable?&nbsp;&nbsp;</p>



<p>Recent research and reports from <a href="https://www.microsoft.com/en-us/research/publication/evaluating-generative-ai-systems-is-a-social-science-measurement-challenge/" target="_blank" rel="noreferrer noopener">Microsoft<span class="sr-only"> (opens in new tab)</span></a>, the <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.aisi.gov.uk/research-agenda" target="_blank" rel="noreferrer noopener">UK AI Security Institute<span class="sr-only"> (opens in new tab)</span></a>, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.nytimes.com/2024/04/15/technology/ai-models-measurement.html" target="_blank" rel="noreferrer noopener"><em>The New York Times</em><span class="sr-only"> (opens in new tab)</span></a>, and <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.technologyreview.com/2025/05/08/1116192/how-to-build-a-better-ai-benchmark/" target="_blank" rel="noreferrer noopener"><em>MIT Technology Review</em><span class="sr-only"> (opens in new tab)</span></a><em> </em>have highlighted gaps in how we evaluate AI models and systems. These gaps also form foundational context for recent international expert consensus reports: the inaugural&nbsp;<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.gov.uk/government/publications/international-ai-safety-report-2025/international-ai-safety-report-2025" target="_blank" rel="noreferrer noopener"><em>International AI Safety Report</em><span class="sr-only"> (opens in new tab)</span></a> (2025) and the <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.scai.gov.sg/2025/scai2025-report" target="_blank" rel="noreferrer noopener"><em>Singapore Consensus</em><span class="sr-only"> (opens in new tab)</span></a> (2025). Closing these gaps at a pace that matches AI innovation will lead to more reliable evaluations that can help guide deployment decisions, inform policy, and deepen trust.&nbsp;</p>



<p>Today, we’re launching a limited-series podcast, <em><a href="https://www.microsoft.com/en-us/research/story/ai-testing-and-evaluation-learnings-from-science-and-industry/">AI Testing and Evaluation: Learnings from Science and Industry</a></em>, to share insights from domains that have grappled with testing and measurement questions. Across four episodes, host <a href="https://www.microsoft.com/en-us/research/people/kasull/?msockid=2c47c4e187ba63ee2e2ed011867d620c" target="_blank" rel="noreferrer noopener">Kathleen Sullivan</a> speaks with academic experts in <a href="https://www.microsoft.com/en-us/research/publication/learning-from-other-domains-to-advance-ai-evaluation-and-testing-governance-of-genome-edition-in-human-therapeutics-and-agricultural-applications/">genome editing</a>, <a href="https://www.microsoft.com/en-us/research/publication/learning-from-other-domains-to-advance-ai-evaluation-and-testing-cybersecurity-standards-and-testing-lessons-for-ai-safety-and-security/">cybersecurity</a>, <a href="https://www.microsoft.com/en-us/research/publication/learning-from-other-domains-to-advance-ai-evaluation-and-testing-the-history-and-evolution-of-testing-in-pharmaceutical-regulation/">pharmaceuticals</a>, and <a href="https://www.microsoft.com/en-us/research/publication/learning-from-other-domains-to-advance-ai-evaluation-and-testing-medical-device-testing-regulatory-requirements-evolution-and-lessons-for-ai-governance/">medical devices</a> to find out which technical and regulatory steps have helped to close evaluation gaps and earn public trust.</p>



<p>We’re also sharing written case studies from experts, along with top-level lessons we’re applying to AI. At the close of the podcast series, we’ll offer Microsoft’s deeper reflections on next steps toward more reliable and trustworthy approaches to AI evaluation.&nbsp;</p>



<h2 class="wp-block-heading" id="lessons-from-eight-case-studies">Lessons from eight case studies&nbsp;</h2>



<p>Our research on risk evaluation, testing, and assurance models in other domains began in December 2024, when <a href="https://www.microsoft.com/en-us/ai/responsible-ai">Microsoft’s Office of Responsible AI<span class="sr-only"> (opens in new tab)</span></a> gathered independent experts from the fields of civil aviation, cybersecurity, financial services, genome editing, medical devices, nanoscience, nuclear energy, and pharmaceuticals. In bringing this group together, we drew on our own learnings and feedback received on our e-book, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://blogs.microsoft.com/on-the-issues/2024/09/23/global-governance-goals-and-lessons-for-ai/" target="_blank" rel="noreferrer noopener"><em>Global Governance: Goals and Lessons for AI</em><span class="sr-only"> (opens in new tab)</span></a><em>, </em>in which we studied the higher-level goals and institutional approaches that had been leveraged for cross-border governance in the past.&nbsp;</p>



<p>While approaches to risk evaluation and testing vary significantly across the case studies, there was one consistent, top-level takeaway: evaluation frameworks always reflect trade-offs among different policy objectives, such as safety, efficiency, and innovation.&nbsp;&nbsp;</p>



<p>Experts across all eight fields noted that policymakers have had to weigh trade-offs in designing evaluation frameworks. These frameworks must account for both the limits of current science and the need for agility in the face of uncertainty. They likewise agreed that early design choices, often reflecting the “DNA” of the historical moment in which they’re made, as cybersecurity expert Stewart Baker described it, are important as they are difficult to scale down or undo later.&nbsp;</p>



<p>Strict, pre-deployment testing regimes—such as those used in civil aviation, medical devices, nuclear energy, and pharmaceuticals—offer strong safety assurances but can be resource-intensive and slow to adapt. These regimes often emerged in response to well-documented failures and are backed by decades of regulatory infrastructure and detailed technical standards.&nbsp;&nbsp;</p>



<p>In contrast, fields marked by dynamic and complex interdependencies between the tested system and its external environment—such as cybersecurity and bank stress testing—rely on more adaptive governance frameworks, where testing may be used to generate actionable insights about risk rather than primarily serve as a trigger for regulatory enforcement.&nbsp;&nbsp;</p>



<p>Moreover, in pharmaceuticals, where interdependencies are at play and there is emphasis on pre-deployment testing, experts highlighted a potential trade-off with post-market monitoring of downstream risks and efficacy evaluation.&nbsp;</p>



<p>These variations in approaches across domains—stemming from differences in risk profiles, types of technologies, maturity of the evaluation science, placement of expertise in the assessor ecosystem, and context in which technologies are deployed, among other factors—also inform takeaways for AI.</p>



<h2 class="wp-block-heading" id="applying-risk-evaluation-and-governance-lessons-to-ai">Applying risk evaluation and governance lessons to AI&nbsp;</h2>



<p>While no analogy perfectly fits the AI context, the genome editing and nanoscience cases offer interesting insights for general-purpose technologies like AI, where risks vary widely depending on how the technology is applied.&nbsp;&nbsp;</p>



<p>Experts highlighted the benefits of governance frameworks that are more flexible and tailored to specific use cases and application contexts. In these fields, it is challenging to define risk thresholds and design evaluation frameworks in the abstract. Risks become more visible and assessable once the technology is applied to a particular use case and context-specific variables are known.&nbsp;&nbsp;</p>



<p>These and other insights also helped us distill qualities essential to ensuring that testing is a reliable governance tool across domains, including:&nbsp;</p>



<ol start="1" class="wp-block-list">
<li><strong>Rigor </strong>in defining what is being examined and why it matters. This requires detailed <a href="https://www.microsoft.com/en-us/research/publication/evaluating-generative-ai-systems-is-a-social-science-measurement-challenge/">specification of what is being measured</a> and understanding how the deployment context may affect outcomes.</li>



<li><strong>Standardization </strong>of how tests should be conducted to achieve valid, reliable results. This requires establishing technical standards that provide methodological guidance and ensure quality and consistency.&nbsp;</li>



<li><strong>Interpretability </strong>of test results and how they inform risk decisions. This requires establishing expectations for evidence and improving literacy in how to understand, contextualize, and use test results—while remaining aware of their limitations.&nbsp;</li>
</ol>



<h2 class="wp-block-heading" id="toward-stronger-foundations-for-ai-testing">Toward stronger foundations for AI testing&nbsp;</h2>



<p>Establishing robust foundations for AI evaluation and testing requires effort to improve rigor, standardization, and interpretability—and to ensure that methods keep pace with rapid technological progress and evolving scientific understanding.&nbsp;&nbsp;</p>



<p>Taking lessons from other general-purpose technologies, this foundational work must also be pursued for both AI models and systems. While testing models will continue to be important, reliable evaluation tools that provide assurance for system performance will enable broad adoption of AI, including in high-risk scenarios. A strong feedback loop on evaluations of AI models and systems could not only accelerate progress on methodological challenges but also bring focus to which opportunities, capabilities, risks, and impacts are most appropriate and efficient to evaluate at what points along the AI development and deployment lifecycle.</p>



<h2 class="wp-block-heading" id="acknowledgements">Acknowledgements&nbsp;</h2>



<p>We would like to thank the following external experts who have contributed to our research program on lessons for AI testing and evaluation: Mateo Aboy, Paul Alp, Gerónimo Poletto Antonacci, Stewart Baker, Daniel Benamouzig, Pablo Cantero, Daniel Carpenter, Alta Charo, Jennifer Dionne, Andy Greenfield, Kathryn Judge, Ciaran Martin, and Timo Minssen.&nbsp;&nbsp;</p>



<h2 class="wp-block-heading" id="case-studies">Case studies&nbsp;</h2>



<p><strong>Civil aviation:</strong> <em><a href="https://www.microsoft.com/en-us/research/publication/learning-from-other-domains-to-advance-ai-evaluation-and-testing-testing-in-aircraft-design-and-manufacturing/">Testing in Aircraft Design and Manufacturing</a></em>, by Paul Alp&nbsp;</p>



<p><strong>Cybersecurity:</strong> <em><a href="https://www.microsoft.com/en-us/research/publication/learning-from-other-domains-to-advance-ai-evaluation-and-testing-cybersecurity-standards-and-testing-lessons-for-ai-safety-and-security/">Cybersecurity Standards and Testing—Lessons for AI Safety and Security</a></em>, by Stewart Baker&nbsp;</p>



<p><strong>Financial services (bank stress testing):</strong> <em><a href="https://www.microsoft.com/en-us/research/publication/learning-from-other-domains-to-advance-ai-evaluation-and-testing-the-evolving-use-of-bank-stress-test/">The Evolving Use of Bank Stress Tests</a></em>, by Kathryn Judge&nbsp;</p>



<p><strong>Genome editing:</strong> <em><a href="https://www.microsoft.com/en-us/research/publication/learning-from-other-domains-to-advance-ai-evaluation-and-testing-governance-of-genome-edition-in-human-therapeutics-and-agricultural-applications/">Governance of Genome Editing in Human Therapeutics and Agricultural Applications</a></em>, by Alta Charo and Andy Greenfield&nbsp;</p>



<p><strong>Medical devices:</strong> <em><a href="https://www.microsoft.com/en-us/research/publication/learning-from-other-domains-to-advance-ai-evaluation-and-testing-medical-device-testing-regulatory-requirements-evolution-and-lessons-for-ai-governance/">Medical Device Testing: Regulatory Requirements, Evolution and Lessons for AI Governance</a></em>,<em> </em>by Mateo Aboy and Timo Minssen&nbsp;</p>



<p><strong>Nanoscience:</strong> <em><a href="https://www.microsoft.com/en-us/research/publication/learning-from-other-domains-to-advance-ai-evaluation-and-testing-the-regulatory-landscape-of-nanoscience-and-nanotechnology-and-applications-to-future-ai-regulation/">The regulatory landscape of nanoscience and nanotechnology, and applications to future AI regulation</a></em>, by Jennifer Dionne&nbsp;</p>



<p><strong>Nuclear energy:</strong> <em><a href="https://www.microsoft.com/en-us/research/publication/learning-from-other-domains-to-advance-ai-evaluation-and-testing-testing-in-the-nuclear-industry/">Testing in the Nuclear Industry</a></em>, by Pablo Cantero and Gerónimo Poletto Antonacci&nbsp;</p>



<p><strong>Pharmaceuticals:</strong> <em><a href="https://www.microsoft.com/en-us/research/publication/learning-from-other-domains-to-advance-ai-evaluation-and-testing-the-history-and-evolution-of-testing-in-pharmaceutical-regulation/">The History and Evolution of Testing in Pharmaceutical Regulation</a></em>, by Daniel Benamouzig and Daniel Carpenter</p>
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/blog/learning-from-other-domains-to-advance-ai-evaluation-and-testing/">Learning from other domains to advance AI evaluation and testing</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Breaking bonds, breaking ground: Advancing the accuracy of computational chemistry with deep learning</title>
		<link>https://www.microsoft.com/en-us/research/blog/breaking-bonds-breaking-ground-advancing-the-accuracy-of-computational-chemistry-with-deep-learning/</link>
		
		<dc:creator><![CDATA[Rianne van den Berg, Jan Hermann, Christopher Bishop, Paola Gori Giorgi]]></dc:creator>
		<pubDate>Wed, 18 Jun 2025 10:01:47 +0000</pubDate>
				<category><![CDATA[Research Blog]]></category>
		<guid isPermaLink="false">https://www.microsoft.com/en-us/research/?p=1141626</guid>

					<description><![CDATA[<p>Microsoft researchers achieved a breakthrough in the accuracy of DFT, a method for predicting the properties of molecules and materials, by using deep learning. This work can lead to better batteries, green fertilizers, precision drug discovery, and more.</p>
<p>The post <a href="https://www.microsoft.com/en-us/research/blog/breaking-bonds-breaking-ground-advancing-the-accuracy-of-computational-chemistry-with-deep-learning/">Breaking bonds, breaking ground: Advancing the accuracy of computational chemistry with deep learning</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/DFT-Blog-BlogHeroFeature-1400x788-1.jpg" alt="Alt text: A dark blue, wavy surface with multiple colorful spheres placed on it. The spheres are in various colors including red, green, blue, yellow, purple, and orange. Each sphere is surrounded by small white particles that appear to be floating around them. The background is a gradient of dark teal to black." class="wp-image-1142136" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/DFT-Blog-BlogHeroFeature-1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/DFT-Blog-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/DFT-Blog-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/DFT-Blog-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/DFT-Blog-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/DFT-Blog-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/DFT-Blog-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/DFT-Blog-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/DFT-Blog-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/DFT-Blog-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w" sizes="auto, (max-width: 1400px) 100vw, 1400px" /></figure>



<p>We are excited to share our first big milestone in solving a grand challenge that has hampered the predictive power of computational chemistry, biochemistry, and materials science for decades. By using a scalable deep-learning approach and generating an unprecedented quantity of diverse, highly accurate data, we have achieved a breakthrough in the accuracy of density functional theory (DFT), the workhorse method that thousands of scientists use every year to simulate matter at the atomistic level. Within the region of chemical space represented in our large training dataset, our model reaches the accuracy required to reliably predict experimental outcomes, as assessed on the well-known benchmark dataset <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://pubmed.ncbi.nlm.nih.gov/28675494/" target="_blank" rel="noreferrer noopener">W4-17<span class="sr-only"> (opens in new tab)</span></a>. This removes a fundamental barrier to shifting the balance of molecule and material design from being driven by laboratory experiments to being driven by computational simulations. The implications for accelerating scientific discovery are far reaching, spanning applications from drugs to batteries and green fertilizers.</p>



<h2 class="wp-block-heading" id="what-is-dft">What is DFT?</h2>



<p>Molecules and materials are made of atoms, which are held together by their electrons. These electrons act as a glue, determining the stability and properties of the chemical structure. Accurately computing the strength and properties of the electron glue is essential for predicting whether a chemical reaction will proceed, whether a candidate drug molecule will bind to its target protein, whether a material is suitable for carbon capture, or if a flow battery can be optimized for renewable energy storage. Unfortunately, a brute-force approach amounts to solving the many-electron Schrödinger equation, which requires computation that scales exponentially with the number of electrons. Considering that an atom has dozens of electrons, and that molecules and materials have large numbers of atoms, we could easily end up waiting the age of the universe to complete our computation unless we restrict our attention to small systems with only a few atoms.</p>



<figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<iframe loading="lazy" title="What is Density Functional Theory (DFT)" width="500" height="281" src="https://www.youtube-nocookie.com/embed/wtB50-si1hI?feature=oembed&rel=0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div></figure>



<p>DFT, introduced by Walter Kohn and collaborators in 1964-1965, was a true scientific breakthrough, earning Kohn the Nobel Prize in Chemistry in 1998. DFT provides an extraordinary reduction in the computational cost of calculating the electron glue in an exact manner, from exponential to cubic, making it possible to perform calculations of practical value within seconds to hours.</p>



<div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-6 wp-block-buttons-is-layout-flex">
<div class="wp-block-button is-style-outline is-style-outline--11"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://www.microsoft.com/en-us/research/articles/timeline-the-continuing-evolution-of-density-functional-theory/">DFT Timeline</a></div>
</div>



<h2 class="wp-block-heading" id="what-is-the-grand-challenge-in-dft">What is the grand challenge in DFT?&nbsp;</h2>



<p>But there is a catch: the exact reformulation has a small but crucial term—the exchange-correlation (XC) functional—which Kohn proved is universal (i.e., the same for all molecules and materials), but for which no explicit expression is known. For 60 years, people have designed practical approximations for the XC functional. The magazine <em>Science</em> dubbed the gold rush to design better XC models the “<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.science.org/doi/10.1126/science.1077710" target="_blank" rel="noreferrer noopener">pursuit of the Divine Functional<span class="sr-only"> (opens in new tab)</span></a>”. With time, these approximations have grown into a zoo of hundreds of different XC functionals from which users must choose, often using experimental data as a guide. Owing to the uniquely favorable computational cost of DFT, existing functionals have enabled scientists to gain extremely useful insight into a huge variety of chemical problems. However, the limited accuracy and scope of current XC functionals mean that DFT is still mostly used to interpret experimental results rather than predict them.</p>



<h2 class="wp-block-heading" id="why-is-it-important-to-increase-the-accuracy-of-dft">Why is it important to increase the accuracy of DFT?&nbsp;</h2>



<p>We can contrast the present state of computational chemistry with the state of aircraft engineering and design. Thanks to predictive simulations, aeronautical engineers no longer need to build and test thousands of prototypes to identify one viable design. However, this is exactly what we currently must do in molecular and materials sciences. We send thousands of potential candidates to the lab, because the accuracy of the computational methods is not sufficient to <em>predict</em> the experiments. To make a significant shift in the balance from laboratory to <em>in silico</em> experiments, we need to remove the fundamental bottleneck of the insufficient accuracy of present XC functionals. This amounts to bringing the error of DFT calculations with respect to experiments within <em>chemical accuracy</em>, which is around 1 kcal/mol for most chemical processes. Present approximations typically have errors that are 3 to 30 times larger.</p>



<figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<iframe loading="lazy" title="DFT for drug and material discovery" width="500" height="281" src="https://www.youtube-nocookie.com/embed/ckXVse-XZMQ?feature=oembed&rel=0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div></figure>



<h2 class="wp-block-heading" id="how-can-ai-make-a-difference">How can AI make a difference?&nbsp;</h2>



<p>AI can transform how we model molecules and materials with DFT by learning the XC functional directly from highly accurate data. The goal is to learn how the XC functional captures the complex relationship between its input, the electron density, and its output, the XC energy. You can think of the density like a glue, with regions of space where there is a lot of it and other regions with less of it. Traditionally, researchers have built XC functional approximations using the concept of the so-called <em>Jacob’s ladder</em>: a hierarchy of increasingly complex, hand-designed descriptors of the electron density. Including density descriptors from higher rungs of this ladder aims to improve accuracy, but it comes at the price of increased computational cost. Even the few attempts that use machine learning have stayed within this traditional paradigm, thereby taking an approach that is akin to what people were doing in computer vision and speech recognition before the deep-learning era. Progress toward better accuracy has stagnated for at least two decades with this approach.&nbsp;</p>



<p>Our project is driven by the intuition that a true deep learning approach—where relevant representations of the electron density are learned directly from data in a computationally scalable way—has the potential to revolutionize the accuracy of DFT, much like deep learning has transformed other fields.<strong> </strong>A significant challenge with going down this path, however, is that feature or representation learning is very data-hungry, and there is very little data around—too little to test this hypothesis reliably.</p>



<h2 class="wp-block-heading" id="what-have-we-done-in-this-milestone">What have we done in this milestone?</h2>



<p>The first step was generating data—a lot of it. This posed a major challenge, since the data must come from accurate solutions of the many-electron Schrödinger equation, which is precisely the prohibitively expensive problem that DFT is designed to replace. Fortunately, decades of progress in the scientific community have led to smarter, more efficient variants of brute-force methods, making it possible to compute reference data for <em>small</em> molecules at experimental accuracy. While these high-accuracy methods, also referred to as wavefunction methods, are far too costly for routine use in applications, we made a deliberate investment in them for this project. The reason? The upfront cost of generating high-quality training data is offset by the long-term benefit of enabling vast numbers of industrially relevant applications with cost effective DFT using the trained XC functional. Crucially, we rely on the ability of DFT—and our learned XC functional—to generalize from high-accuracy data for small systems to larger, more complex molecules.&nbsp;</p>



<p>There are many different high-accuracy wavefunction methods, each tailored to different regions of chemical space. However, their use at scale is not well established, as they require extensive expertise—small methodological choices can significantly affect accuracy at the level that we target. We therefore joined forces with <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.une.edu.au/staff-profiles/science-and-technology/amir-karton" target="_blank" rel="noreferrer noopener">Prof. Amir Karton<span class="sr-only"> (opens in new tab)</span></a> from the University of New England, Australia, a world-leading expert who developed widely recognized benchmark datasets for a fundamental thermochemical property: atomization energy—the energy required to break all bonds in a molecule and separate it into individual atoms. To create a training dataset of atomization energies at unprecedented scale, our team at Microsoft built a scalable pipeline to produce highly diverse molecular structures. Using these structures and substantial Azure compute resources via Microsoft’s <a href="https://www.microsoft.com/en-us/research/collaboration/accelerating-foundation-models-research/">Accelerating Foundation Models Research program<span class="sr-only"> (opens in new tab)</span></a>, Prof. Karton applied a high-accuracy wavefunction method to compute the corresponding energy labels. The result is a <a href="https://www.microsoft.com/en-us/research/publication/accurate-chemistry-collection-coupled-cluster-atomization-energies-for-broad-chemical-space/">dataset<span class="sr-only"> (opens in new tab)</span></a> two orders of magnitude larger than previous efforts. We are <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="http://aka.ms/MSR-ACC" target="_blank" rel="noreferrer noopener">releasing a large part of this dataset<span class="sr-only"> (opens in new tab)</span></a> to the scientific community.</p>



<p>Data generation was only half of the challenge. We also needed to design a dedicated deep-learning architecture for the XC functional—one that is both computationally scalable and capable of learning meaningful representations from electron densities to accurately predict the XC energy. Our team of machine learning specialists, assisted by DFT experts, introduced a series of innovations that solve these and other challenges inherent to this complex learning problem. The result is <a href="https://www.microsoft.com/en-us/research/publication/accurate-and-scalable-exchange-correlation-with-deep-learning/"><strong>Skala</strong>, an XC functional that generalizes to unseen molecules, reaching the accuracy needed to predict experiments</a>. This demonstrates for the first time that deep learning can truly disrupt DFT: reaching experimental accuracy does not require the computationally expensive hand-designed features of Jacob’s ladder. Instead, we can retain the original computational complexity of DFT while allowing the XC functional to learn how to extract meaningful features and predict accurate energies.</p>



<figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1400" height="391" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/DFT_combined-figure.png" alt="We compare the accuracy of Skala against the best existing functionals of varying computational cost. The prediction errors are evaluated on two well-known public benchmark datasets: the W4-17 dataset for atomization energies (y axis, mean absolute error) and the GMTKN55 dataset for general main-group chemistry (x axis, weighted total mean absolute deviation, or WTMAD-2 for short). Skala achieves near "chemical accuracy" (1 kcal/mol) on atomization energies. This is the accuracy required for predictive modeling of laboratory experiments, which, to date, no existing functional has reached. Skala works especially well on the “single reference” subset of this dataset, reaching a groundbreaking 0.85 kcal/mol. On the GMTKN55 dataset, Skala shows competitive accuracy to the best-performing hybrid functionals, at a lower cost." class="wp-image-1142366" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/DFT_combined-figure.png 1400w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/DFT_combined-figure-300x84.png 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/DFT_combined-figure-1024x286.png 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/DFT_combined-figure-768x214.png 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/DFT_combined-figure-240x67.png 240w" sizes="auto, (max-width: 1400px) 100vw, 1400px" /><figcaption class="wp-element-caption">We compare the accuracy of Skala against the best existing functionals of varying computational cost. The prediction errors are evaluated on two well-known public benchmark datasets: the W4-17 dataset for atomization energies (y axis, mean absolute error) and the GMTKN55 dataset for general main-group chemistry (x axis, weighted total mean absolute deviation, or WTMAD-2 for short). Skala achieves near &#8220;chemical accuracy&#8221; (1 kcal/mol) on atomization energies. This is the accuracy required for predictive modeling of laboratory experiments, which, to date, no existing functional has reached. Skala works especially well on the “single reference” subset of this dataset, reaching a groundbreaking 0.85 kcal/mol. On the GMTKN55 dataset, Skala shows competitive accuracy to the best-performing hybrid functionals, at a lower cost.</figcaption></figure>



<blockquote class="wp-block-quote is-style-spectrum is-layout-flow wp-block-quote-is-layout-flow">
<p>&#8220;<em>Skala is a new density functional for the exchange-correlation energy that employs meta-GGA ingredients plus D3 dispersion and machine-learned nonlocal features of the electron density. Some exact constraints were imposed, and some others “emerge” from the fitting to about 150,000 accurate energy differences for sp molecules and atoms. Skala achieves high, hybrid-like accuracy on a large and diverse data set of properties of main group molecules, which has no overlap with its training set. The computational cost of Skala is higher than that of the r2SCAN meta-GGA for small molecules, but about the same for systems with 1,000 or more occupied orbitals. Its cost seems to be only 10% of the cost of standard hybrids and 1% of the cost of local hybrids. Developed by a Microsoft team of density functional theorists and deep-learning experts, Skala could be the first machine-learned density functional to compete with existing functionals for wide use in computational chemistry, and a sign of things to come in that and related fields. Skala learned from big data and was taught by insightful human scientists.”</em></p>
<cite><em>— John P. Perdew, Professor of Physics, School of Science and Engineering, Tulane University</em></cite></blockquote>



<p>This first milestone was achieved for a challenging property in a specific region of chemical space—atomization energies of main group molecules—for which we generated our initial large batch of high-accuracy training data. Building on this foundation, we have started to expand our training dataset to cover a broader range of general chemistry, using our scalable in-house data generation pipeline. With the first small batch of training data beyond atomization energies, we have already extended the accuracy of our model, making it competitive with the best existing XC functionals across a wider spectrum of main group chemistry. This motivates us to continue growing our high-accuracy data generation campaign, engaging with external experts such as Prof. Amir Karton, who noted, “After years of benchmarking DFT methods against experimental accuracy, this is the first time I’ve witnessed such an unprecedented leap in the accuracy–cost trade-off. It is genuinely exciting to see how the creation of our new dataset has enabled these groundbreaking results — opening up a path for transformative advances across chemical, biochemical, and materials research.”</p>



<figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<iframe loading="lazy" title="Deep learning for DFT" width="500" height="281" src="https://www.youtube-nocookie.com/embed/Zzt3h10KLp4?feature=oembed&rel=0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div></figure>



<h2 class="wp-block-heading" id="advancing-computational-chemistry-together">Advancing computational chemistry together</h2>



<p>We are excited to work closely with the global computational chemistry community to accelerate progress for all and look forward to openly releasing our first XC functional in the near future.&nbsp;</p>



<blockquote class="wp-block-quote is-style-spectrum is-layout-flow wp-block-quote-is-layout-flow">
<p>&#8220;<em>Density Functional Theory&nbsp;(DFT) and related technologies are a core Digital Chemistry technology supporting advancements in&nbsp;Merck’s&nbsp;diverse Life Science, Healthcare and Electronics businesses.&nbsp;However, the limitations of traditional DFT methods, which have persisted for the last 50 years, have hindered its full potential. Microsoft Research&#8217;s innovative approach to integrating deep learning represents a&nbsp;substantial leap, enhancing its accuracy, robustness, and scalability. We are&nbsp;looking forward&nbsp;to exploring&nbsp;how this can advance&nbsp;Digital Chemistry workflows&nbsp;and unlock new possibilities for the future, aligning with our commitment to developing advanced algorithms and technologies that propel scientific innovation at Merck.&#8221;</em></p>
<cite><em>— Jan Gerit Brandenburg – Director for Digital Chemistry at Merck&nbsp;</em></cite></blockquote>



<blockquote class="wp-block-quote is-style-spectrum is-layout-flow wp-block-quote-is-layout-flow">
<p>&#8220;<em>We are entering a golden age for predictive and realistic simulations: very accurate electronic-structure calculations provide vast amounts of consistent data that can be used to train novel machine-learning architectures, delivering the holy grail of precision and computational efficiency.&#8221;</em></p>
<cite><em>— Professor Nicola Marzari, Chair of Theory and Simulation of Materials, EPFL and PSI</em></cite></blockquote>



<div style="height:10px" aria-hidden="true" class="wp-block-spacer"></div>



<p>We believe that our new functional can help unlock new opportunities for businesses and are eager to work together on real-world applications. <strong>Today, we are delighted to launch the DFT Research Early Access Program (DFT REAP) and welcome Flagship Pioneering as the first participant.</strong> This program is for companies and research labs to collaborate with us to accelerate innovation across many industries. To find out more about how to join this program please visit:&nbsp;<a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://aka.ms/DFT-REAP" target="_blank" rel="noreferrer noopener">https://aka.ms/DFT-REAP<span class="sr-only"> (opens in new tab)</span></a>&nbsp;</p>



<blockquote class="wp-block-quote is-style-spectrum is-layout-flow wp-block-quote-is-layout-flow">
<p><em>“Microsoft’s effort to enhance the predictive power of computational chemistry reflects a bold but thoughtful step toward a simulation-first future. At Flagship, we believe that openly shared, foundational advances in science &#8211; like this leap forward in DFT accuracy &#8211; can serve as powerful enablers of innovation. These next-generation tools promise to accelerate discovery across a wide range of sectors, from therapeutics to materials science, by helping researchers navigate chemical and biological space with far greater precision and speed.”</em></p>
<cite><em>— </em>Junaid Bajwa, M.D., Senior Partner at Flagship Pioneering and Science Partner at Pioneering Intelligence</cite></blockquote>



<p>By making our work available to the scientific community, we hope to enable widespread testing and gather valuable feedback that will guide future improvements. For the first time, deep learning offers a clear and computationally scalable path to building an accurate, efficient, and broadly applicable model of the universal XC functional—one that could transform the computational design of molecules and materials.</p>



<div class="wp-block-buttons is-content-justification-center is-content-justification-center is-layout-flex wp-container-core-buttons-is-layout-7 wp-block-buttons-is-layout-flex">
<div class="wp-block-button is-style-outline is-style-outline--12"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://aka.ms/SkalaDFT">Skala Paper</a></div>



<div class="wp-block-button is-style-outline is-style-outline--13"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="https://aka.ms/MSR-ACC-paper">Dataset Paper</a></div>



<div class="wp-block-button is-style-outline is-style-outline--14"><a data-bi-type="button" class="wp-block-button__link wp-element-button" href="http://aka.ms/MSR-ACC" target="_blank" rel="noreferrer noopener">Dataset</a></div>
</div>



<h2 class="wp-block-heading" id="acknowledgement">Acknowledgement</h2>



<p>This work is the product of a highly collaborative and interdisciplinary effort led by <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-ai-for-science/" target="_blank" rel="noreferrer noopener">Microsoft Research AI for Science</a>, in partnership with colleagues from Microsoft Research Accelerator, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://quantum.microsoft.com/" target="_blank" rel="noreferrer noopener">Microsoft Quantum</a> and the <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.une.edu.au/" target="_blank" rel="noreferrer noopener">University of New England</a>. The full author list includes <a href="https://www.microsoft.com/en-us/research/people/giulialuise/" target="_blank" rel="noreferrer noopener">Giulia Luise</a>, <a href="https://www.microsoft.com/en-us/research/people/chinweihuang/" target="_blank" rel="noreferrer noopener">Chin-Wei Huang</a>, <a href="https://www.microsoft.com/en-us/research/people/thijsvogels/" target="_blank" rel="noreferrer noopener">Thijs Vogels</a><a href="https://www.microsoft.com/en-us/research/people/derkkooi/" target="_blank" rel="noreferrer noopener">, Derk P. Kooi</a>, <a href="https://www.microsoft.com/en-us/research/people/sehlert/" target="_blank" rel="noreferrer noopener">Sebastian Ehlert</a>, <a href="https://www.microsoft.com/en-us/research/people/slanius/" target="_blank" rel="noreferrer noopener">Stephanie Lanius</a>, Klaas J. H. Giesbertz, <a class="msr-external-link glyph-append glyph-append-open-in-new-tab glyph-append-xsmall" href="https://www.une.edu.au/staff-profiles/science-and-technology/amir-karton" target="_blank" rel="noreferrer noopener">Amir Karton</a>, <a href="https://www.microsoft.com/en-us/research/people/dgunceler/" target="_blank" rel="noreferrer noopener">Deniz Gunceler</a>, <a href="https://www.microsoft.com/en-us/research/people/meganstanley/" target="_blank" rel="noreferrer noopener">Megan Stanley</a>, <a href="https://www.microsoft.com/en-us/research/people/wbruinsma/" target="_blank" rel="noreferrer noopener">Wessel P. Bruinsma</a>, <a href="https://www.microsoft.com/en-us/research/people/victorgar/" target="_blank" rel="noreferrer noopener">Victor Garcia Satorras</a>, <a href="https://www.microsoft.com/en-us/research/people/marwinsegler/" target="_blank" rel="noreferrer noopener">Marwin Segler</a>, <a href="https://www.microsoft.com/en-us/research/people/kenjitak/" target="_blank" rel="noreferrer noopener">Kenji Takeda</a>, <a href="https://www.microsoft.com/en-us/research/people/hul/" target="_blank" rel="noreferrer noopener">Lin Huang</a>, <a href="https://www.microsoft.com/en-us/research/people/weixinran/" target="_blank" rel="noreferrer noopener">Xinran Wei</a>, <a href="https://www.microsoft.com/en-us/research/people/josegarri/" target="_blank" rel="noreferrer noopener">José Garrido Torres</a>, Albert Katbashev, Rodrigo Chavez Zavaleta, Bálint Máté, Sékou-Oumar Kaba, Roberto Sordillo, Yingrong Chen, David B. Williams-Young, <a href="https://www.microsoft.com/en-us/research/people/cmbishop/" target="_blank" rel="noreferrer noopener">Christopher M. Bishop</a>, <a href="https://www.microsoft.com/en-us/research/people/janhermann/" target="_blank" rel="noreferrer noopener">Jan Hermann</a>, <a href="https://www.microsoft.com/en-us/research/people/rvandenberg/" target="_blank" rel="noreferrer noopener">Rianne van den Berg</a> and <a href="https://www.microsoft.com/en-us/research/people/pgorigiorgi/" target="_blank" rel="noreferrer noopener">Paola Gori Giorgi</a>. </p>
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/blog/breaking-bonds-breaking-ground-advancing-the-accuracy-of-computational-chemistry-with-deep-learning/">Breaking bonds, breaking ground: Advancing the accuracy of computational chemistry with deep learning</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>New methods boost reasoning in small and large language models</title>
		<link>https://www.microsoft.com/en-us/research/blog/new-methods-boost-reasoning-in-small-and-large-language-models/</link>
		
		<dc:creator><![CDATA[Li Lyna Zhang, Xian Zhang, Xueting Han, Dongdong Zhang]]></dc:creator>
		<pubDate>Tue, 17 Jun 2025 16:00:00 +0000</pubDate>
				<category><![CDATA[Research Blog]]></category>
		<guid isPermaLink="false">https://www.microsoft.com/en-us/research/?p=1141870</guid>

					<description><![CDATA[<p>New techniques are reimagining how LLMs reason. By combining symbolic logic, mathematical rigor, and adaptive planning, these methods enable models to tackle complex, real-world problems across a variety of fields.</p>
<p>The post <a href="https://www.microsoft.com/en-us/research/blog/new-methods-boost-reasoning-in-small-and-large-language-models/">New methods boost reasoning in small and large language models</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image size-full"><img loading="lazy" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/NewMethods-BlogHeroFeature-1400x788-1.jpg" alt="The image shows a diagram illustrating the relationship between mathematical statements in natural language and formal language. On the left, there is a blue box labeled "Mathematical statement in natural language." An arrow points from this box to a central section containing four smaller boxes arranged in two rows. The top row contains "Formalization" and "Informalization," while the bottom row contains "Symbolic Equivalence" and "Semantic Consistency." An arrow points from this central section to a purple box on the right labeled "Mathematical statement in formal language." The background of the image transitions from blue on the left to purple on the right." class="wp-image-1142121" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/NewMethods-BlogHeroFeature-1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/NewMethods-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/NewMethods-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/NewMethods-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/NewMethods-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/NewMethods-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/NewMethods-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/NewMethods-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/NewMethods-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/NewMethods-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w" sizes="auto, (max-width: 1400px) 100vw, 1400px" /></figure>



<p>Artificial intelligence is advancing across a wide range of fields, with one of the most important developments being its growing capacity for reasoning. This capability could help AI becomes a reliable partner in critical domains like scientific research and healthcare.</p>



<p>To support this progress, we’ve identified three primary strategies to strengthen reasoning capabilities in both small and large language models: improve architectural design to boost performance in smaller models; incorporate mathematical reasoning techniques to increase reliability; and build stronger generalization capabilities to enable reasoning across a variety of fields.</p>



<h2 class="wp-block-heading" id="smarter-reasoning-in-smaller-models">Smarter reasoning in smaller models</h2>



<p>While language models trained on broad world knowledge hold great potential, they lack the ability to learn continuously and refine their understanding. This limitation becomes especially pronounced in smaller models, where limited capacity makes strong reasoning even harder.</p>



<p>The problem stems from how current language models operate. They rely on fast, pattern recognition-based responses that break down in complex scenarios. In contrast, people use deliberate, step-by-step reasoning, test different approaches, and evaluate outcomes. To address this gap, we’re building methods to enable stronger reasoning in smaller systems.</p>



<p><a href="https://www.microsoft.com/en-us/research/articles/li-zhang-rstar-math/" target="_blank" rel="noreferrer noopener">rStar-Math</a> is a method that uses Monte Carlo Tree Search (MCTS) to simulate deeper, more methodical reasoning in smaller models. It uses a three-step, self-improving cycle:&nbsp;</p>



<ul class="wp-block-list">
<li><strong>Problem decomposition</strong> breaks down complex mathematical problems into manageable steps, creating a thorough and accurate course of reasoning.</li>



<li><strong>Process preference model (PPM)</strong> trains small models to predict reward labels for each step, improving process-level supervision.</li>



<li><strong>Iterative refinement</strong> applies a four-round, self-improvement cycle in which updated strategy models and PPMs guide MCTS to improve performance.&nbsp;</li>
</ul>



<p>When tested on four small language models ranging from 1.5 billion to 7 billion parameters, rStar-Math achieved an average accuracy of 53% on the American Invitational Mathematics Examination (AIME)—performance that places it among the top 20% of high school competitors in the US.</p>



<figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1049" height="322" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-1.png" alt="Figure 1: A three-part diagram illustrating the rStar-Math framework. (a) Shows an MCTS-driven reasoning tree with Q-values and answer verification using PPM or Python; correct and incorrect steps are marked. (b) Depicts how Q-value filtering constructs per-step preference pairs from partial to full solutions. (c) Outlines four rounds of self-evolution, alternating between SLM and PPM improvements using terminal-guided and PPM-augmented MCTS." class="wp-image-1141894" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-1.png 1049w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-1-300x92.png 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-1-1024x314.png 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-1-768x236.png 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-1-240x74.png 240w" sizes="auto, (max-width: 1049px) 100vw, 1049px" /><figcaption class="wp-element-caption">Figure 1. The rStar-Math framework </figcaption></figure>



<p>Logic-RL is a reinforcement learning framework that strengthens logical reasoning through a practical system prompt and a structured reward function. By training models on logic puzzles, Logic-RL grants rewards only when both the reasoning process and the final answer meet strict formatting requirements. This prevents shortcuts and promotes analytical rigor.</p>



<p>Language models trained with Logic-RL demonstrate strong performance beyond logic puzzles, generalizing effectively to mathematical competition problems. On the AIME and AMC (American Mathematics Competitions) datasets, 7-billion-parameter models improved accuracy by 125% and 38%, respectively, compared with baseline models.</p>



<h2 class="wp-block-heading" id="building-reliable-mathematical-reasoning">Building reliable mathematical reasoning&nbsp;</h2>



<p>Mathematics poses a unique challenge for language models, which often struggle to meet its precision and rigor using natural language. To address this, we’re creating formal and symbolic methods to enable language models to adopt structured mathematical tools. The goal is to convert language model outputs into code based on the fundamental rules of arithmetic, like 1 + 1 = 2, allowing us to systematically verify accuracy.&nbsp;</p>



<p><a href="https://www.microsoft.com/en-us/research/publication/proving-olympiad-inequalities-by-synergizing-llms-and-symbolic-reasoning/" target="_blank" rel="noreferrer noopener">LIPS</a> (LLM-based Inequality Prover with Symbolic Reasoning) is a system that combines LLMs’ pattern recognition capabilities with symbolic reasoning. LIPS draws on the strategies participants in math competitions use in order to distinguish between tasks best suited to symbolic solvers (e.g., scaling) and those better handled by language models (e.g., rewriting). On 161 Olympiad-level problems, LIPS achieved state-of-the-art results without additional training data.</p>



<figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1295" height="426" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-2.png" alt="Figure 2: A three-part diagram showing the LIPS framework for inequality proof generation. On the left, a current inequality problem is transformed into new inequality subproblems via tactic generation using symbolic-based and LLM-generated rewriting methods. In the center, these new goals are filtered and ranked using LLM and symbolic methods. On the right, a ranked sequence of inequalities forms a complete proof, applying named tactics like Cauchy-Schwarz, AM-GM, and LLM simplification, ending with the original inequality verified." class="wp-image-1141898" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-2.png 1295w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-2-300x99.png 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-2-1024x337.png 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-2-768x253.png 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-2-240x79.png 240w" sizes="auto, (max-width: 1295px) 100vw, 1295px" /><figcaption class="wp-element-caption">Figure 2. An overview of LIPS</figcaption></figure>



<p>However, translating natural-language math problems into precise, machine-readable formats is a challenge. Our goal is to bridge the gap between the one-pass success rate, where the top-ranked generated result is correct, and the k-pass success rate, where at least one of the top <em>k</em> generated results is correct.</p>



<p>We developed a <a href="https://www.microsoft.com/en-us/research/publication/autoformalizing-mathematical-statements-by-symbolic-equivalence-and-semantic-consistency/">new framework</a> using two evaluation methods. <strong>Symbolic equivalence</strong> checks whether outputs are logically identical, while <strong>semantic consistency</strong> uses embedding similarity to detect subtle differences missed by symbolic checks.</p>



<p>When we evaluated this approach on the MATH and miniF2F datasets, which include problems from various math competitions, it improved accuracy by up to 1.35 times over baseline methods.</p>



<figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1271" height="377" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-3.png" alt="Figure 3: A flowchart illustrating the autoformalization framework. On the left, a natural language math statement is converted into a formal language theorem via an "Autoformalize" step. In the center, formal statements undergo symbolic equivalence checks, while informalized versions are evaluated for semantic consistency. Arrows represent symbolic and semantic equivalence, informalization, and scoring. On the right, validated formal statements are output, demonstrating multiple logically equivalent formulations. A legend explains arrow types for formalization, equivalence, and output scoring." class="wp-image-1141897" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-3.png 1271w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-3-300x89.png 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-3-1024x304.png 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-3-768x228.png 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-3-240x71.png 240w" sizes="auto, (max-width: 1271px) 100vw, 1271px" /><figcaption class="wp-element-caption">Figure 3. An overview of the auto-formalization framework</figcaption></figure>



<p>To address the shortage of high-quality training data, we developed a <a href="https://www.microsoft.com/en-us/research/publication/neuro-symbolic-data-generation-for-math-reasoning/" target="_blank" rel="noreferrer noopener">neuro-symbolic framework</a> that automatically generates diverse, well-structured math problems. Symbolic solvers create the problems, while language models translate them into natural language. This approach not only broadens training resources but also supports more effective instruction and evaluation of mathematical reasoning in language models.</p>



<figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1255" height="404" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-4.png" alt="Figure 4: A flowchart illustrating the neuro-symbolic data generation framework. It begins with a natural language math problem about a sandbox's perimeter. This is formalized into symbolic assertions, then mutated while preserving structure. The formal problem is solved and informalized into a new natural language Q&A about a garden's dimensions. The process continues with further mutation to generate problems of varying difficulty—examples include an easy question about a rectangle’s width and a medium one involving expressions for area." class="wp-image-1142036" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-4.png 1255w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-4-300x97.png 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-4-1024x330.png 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-4-768x247.png 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-4-240x77.png 240w" sizes="auto, (max-width: 1255px) 100vw, 1255px" /><figcaption class="wp-element-caption">Figure 4. An overview of the neuro-symbolic data generation framework </figcaption></figure>



<h2 class="wp-block-heading" id="boosting-generalization-across-domains">Boosting generalization across domains&nbsp;</h2>



<p>A key indicator of advanced AI is its ability to generalize—the ability to transfer reasoning skills across different domains. We found that training language models on math data significantly improved performance in coding, science, and other areas, revealing unexpected cross-domain benefits.&nbsp;</p>



<p>This discovery motivated us to develop <a href="https://www.microsoft.com/en-us/research/publication/chain-of-reasoning-towards-unified-mathematical-reasoning-in-large-language-models-via-a-multi-paradigm-perspective/">Chain-of-Reasoning</a> (CoR), an approach that unifies reasoning across natural language, code, and symbolic forms. CoR lets models blend these formats using natural language to frame context, code for precise calculations, and symbolic representations for abstraction. By adjusting prompts, CoR adapts both reasoning depth and paradigm diversity to match specific problem requirements.&nbsp;</p>



<p>Tests of CoR across five math datasets showed its ability to tackle both computational and proof-based problems, demonstrating strong general mathematical problem-solving skills.</p>



<figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1183" height="493" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-5.png" alt="Figure 5: Diagram illustrating three reasoning paradigms: (a) Single-paradigm reasoning, where all reasoning steps use the same medium (e.g., natural language, algorithms, or symbols); (b) Tool-integrated single-paradigm reasoning, where natural language drives reasoning, but code is used to solve specific sub-problems, with results reintegrated into the language-based reasoning; (c) CoR (multi-paradigm) reasoning framework, which enables reasoning across different paradigms with varying depths to handle diverse problem types, supported by examples." class="wp-image-1141896" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-5.png 1183w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-5-300x125.png 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-5-1024x427.png 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-5-768x320.png 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-5-240x100.png 240w" sizes="auto, (max-width: 1183px) 100vw, 1183px" /><figcaption class="wp-element-caption">Figure 5. CoR’s reasoning process under different types of methods</figcaption></figure>



<p>Current language models often rely on domain-specific solutions, limiting their flexibility across different types of problems. To move beyond this constraint, we developed <a href="https://www.microsoft.com/en-us/research/articles/cpl/" target="_blank" rel="noreferrer noopener">Critical Plan Step Learning</a> (CPL), an approach focused on high-level abstract planning that teaches models to identify key knowledge, break down problems, and make strategic decisions.&nbsp;</p>



<p>The technique draws on how people solve problems, by breaking them down, identifying key information, and recalling relevant knowledge—strategies we want language models to learn.&nbsp;</p>



<p>CPL combines two key components: <strong>plan-based MCTS</strong>, which searches multi-step solution paths and constructs planning trees, and <strong>step-APO</strong>, which learns preferences for strong intermediate steps while filtering out weak ones. This combination enhances reasoning and improves generalization across tasks, moving AI systems closer to the flexible thinking that characterizes human intelligence.</p>



<figure class="wp-block-image aligncenter size-full"><img loading="lazy" decoding="async" width="1238" height="585" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-6.png" alt="Figure 6: Illustration of CPL. Left: Plans represent abstract thinking for problem-solving, which allows for better generalization, whereas task-specific solutions often limit it. Right: CPL searches within the action space on high-level abstract plans using MCTS and obtains advantage estimates for step-level preferences. CPL can then identify and learn critical steps that provide a distinct advantage over others." class="wp-image-1141895" srcset="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-6.png 1238w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-6-300x142.png 300w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-6-1024x484.png 1024w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-6-768x363.png 768w, https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/enhancing-llm-reasoning-abilities-6-240x113.png 240w" sizes="auto, (max-width: 1238px) 100vw, 1238px" /><figcaption class="wp-element-caption">Figure 6. Overview of the CPL framework</figcaption></figure>



<h2 class="wp-block-heading" id="looking-ahead-next-steps-in-ai-reasoning">Looking ahead: Next steps in AI reasoning</h2>



<p>From building reliable math solvers to unifying reasoning approaches, researchers are redefining how language models approach complex tasks. Their work sets the stage for more capable and versatile AI systems—applicable to education, science, healthcare, and beyond. Despite these advances, hallucinations and imprecise logic continue to pose risks in critical fields like medicine and scientific research, where accuracy is essential.</p>



<p>These challenges are driving the team’s exploration of additional tools and frameworks to improve language model reasoning. This includes <a href="https://www.microsoft.com/en-us/research/publication/autoverus-automated-proof-generation-for-rust-code/">AutoVerus</a> for automated proof generation in Rust code, <a href="https://www.microsoft.com/en-us/research/publication/automated-proof-generation-for-rust-code-via-self-evolution/">SAFE</a> for addressing data scarcity in Rust formal verification, and <a href="https://www.microsoft.com/en-us/research/publication/alchemy-amplifying-theorem-proving-capability-through-symbolic-mutation/">Alchemy</a>, which uses symbolic mutation to improve neural theorem proving.</p>



<p>Together, these technologies represent important progress toward building trustworthy, high-performing reasoning models and signal a broader shift toward addressing some of AI&#8217;s current limitations.</p>
<span id="label-external-link" class="sr-only" aria-hidden="true">Opens in a new tab</span><p>The post <a href="https://www.microsoft.com/en-us/research/blog/new-methods-boost-reasoning-in-small-and-large-language-models/">New methods boost reasoning in small and large language models</a> appeared first on <a href="https://www.microsoft.com/en-us/research">Microsoft Research</a>.</p>
]]></content:encoded>
					
		
		
			</item>
	</channel>
</rss>
